<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>GitHub R Daily Trending</title>
    <description>Daily Trending of R in GitHub</description>
    <pubDate>Sun, 16 Mar 2025 01:36:56 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>sqjin/CellChat</title>
      <link>https://github.com/sqjin/CellChat</link>
      <description>&lt;p&gt;R toolkit for inference, visualization and analysis of cell-cell communication from single-cell data&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; &lt;img width=&quot;200&quot; src=&quot;https://github.com/sqjin/CellChat/raw/master/CellChat_Logo.png&quot;&gt; &lt;/p&gt; 
&lt;h1&gt;CAUTION&lt;/h1&gt; 
&lt;p&gt;We have updated CellChat to v2 and migrated CellChat to a new repository. This repository will be NOT updated and maintained any more. Please check the new repository &lt;a href=&quot;https://github.com/jinworks/CellChat&quot;&gt;jinworks/CellChat&lt;/a&gt; for the new updates, and the &lt;a href=&quot;https://biorxiv.org/cgi/content/short/2023.11.05.565674v1&quot;&gt;CellChat v2 paper&lt;/a&gt; for a comprehensive protocol of CellChat.&lt;/p&gt; 
&lt;h1&gt;About CellChat and CellChatDB&lt;/h1&gt; 
&lt;p&gt;CellChat is an R package designed for inference, analysis, and visualization of cell-cell communication from single-cell data. CellChat aims to enable users to identify and interpret cell-cell communication within an easily interpretable framework, with the emphasis of clear, attractive, and interpretable visualizations.&lt;/p&gt; 
&lt;p&gt;CellChatDB is a manually curated database of literature-supported ligand-receptor interactions in mutiple species, leading to a comprehensive recapitulation of known molecular interaction mechanisms including multi-subunit structure of ligand-receptor complexes and co-factors.&lt;/p&gt; 
&lt;p&gt;If you use CellChat in your research, please considering citing our papers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://biorxiv.org/cgi/content/short/2023.11.05.565674v1&quot;&gt;Suoqin Jin et al., CellChat for systematic analysis of cell-cell communication from single-cell and spatially resolved transcriptomics, bioRxiv 2023&lt;/a&gt; [CellChat v2]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nature.com/articles/s41467-021-21246-9&quot;&gt;Suoqin Jin et al., Inference and analysis of cell-cell communication using CellChat, Nature Communications 2021&lt;/a&gt; [CellChat v1]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Capabilities&lt;/h1&gt; 
&lt;p&gt;In addition to infer the intercellular communication from any given single-cell data, CellChat provides functionality for further data exploration, analysis, and visualization.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;It can quantitatively characterize and compare the inferred cell-cell communication networks using a systems approach by combining social network analysis, pattern recognition, and manifold learning approaches.&lt;/li&gt; 
 &lt;li&gt;It provides an easy-to-use tool for extracting and visualizing high-order information of the inferred networks. For example, it allows ready prediction of major signaling inputs and outputs for all cell populations and how these populations and signals coordinate together for functions.&lt;/li&gt; 
 &lt;li&gt;It enables comparative analysis of cell-cell communication across different conditions and identification of altered signaling and cell populations.&lt;/li&gt; 
 &lt;li&gt;It provides several visualization outputs to facilitate intuitive user-guided data interpretation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img width=&quot;700&quot; src=&quot;https://github.com/sqjin/CellChat/raw/master/overview_CellChat.png&quot;&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://clustrmaps.com/site/1bpq2&quot;&gt; &lt;img width=&quot;200&quot; src=&quot;https://clustrmaps.com/map_v2.png?cl=ffffff&amp;amp;w=a&amp;amp;t=n&amp;amp;d=42WqeykSXznN_NSaBlpf6CtSXQxhqmIs6QusUsguFdY&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://raw.githubusercontent.com/sqjin/CellChat/master/#&quot;&gt; &lt;img src=&quot;https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fsqjin%2FCellChat&amp;amp;labelColor=%233499cc&amp;amp;countColor=%2370c168&quot;&gt; &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tidyverse/dplyr</title>
      <link>https://github.com/tidyverse/dplyr</link>
      <description>&lt;p&gt;dplyr: A grammar of data manipulation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;dplyr &lt;a href=&quot;https://dplyr.tidyverse.org&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tidyverse/dplyr/main/man/figures/logo.png&quot; align=&quot;right&quot; height=&quot;138&quot;&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;!-- badges: start --&gt; 
&lt;p&gt;&lt;a href=&quot;https://cran.r-project.org/package=dplyr&quot;&gt;&lt;img src=&quot;https://www.r-pkg.org/badges/version/dplyr&quot; alt=&quot;CRAN status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml&quot;&gt;&lt;img src=&quot;https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml/badge.svg?sanitize=true&quot; alt=&quot;R-CMD-check&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://app.codecov.io/gh/tidyverse/dplyr?branch=main&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/tidyverse/dplyr/branch/main/graph/badge.svg?sanitize=true&quot; alt=&quot;Codecov test coverage&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- badges: end --&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;dplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;mutate()&lt;/code&gt; adds new variables that are functions of existing variables&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;select()&lt;/code&gt; picks variables based on their names.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filter()&lt;/code&gt; picks cases based on their values.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;summarise()&lt;/code&gt; reduces multiple values down to a single summary.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;arrange()&lt;/code&gt; changes the ordering of the rows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;These all combine naturally with &lt;code&gt;group_by()&lt;/code&gt; which allows you to perform any operation “by group”. You can learn more about them in &lt;code&gt;vignette(&quot;dplyr&quot;)&lt;/code&gt;. As well as these single-table verbs, dplyr also provides a variety of two-table verbs, which you can learn about in &lt;code&gt;vignette(&quot;two-table&quot;)&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you are new to dplyr, the best place to start is the &lt;a href=&quot;https://r4ds.hadley.nz/data-transform&quot;&gt;data transformation chapter&lt;/a&gt; in R for Data Science.&lt;/p&gt; 
&lt;h2&gt;Backends&lt;/h2&gt; 
&lt;p&gt;In addition to data frames/tibbles, dplyr makes working with other computational backends accessible and efficient. Below is a list of alternative backends:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://arrow.apache.org/docs/r/&quot;&gt;arrow&lt;/a&gt; for larger-than-memory datasets, including on remote cloud storage like AWS S3, using the Apache Arrow C++ engine, &lt;a href=&quot;https://arrow.apache.org/docs/cpp/streaming_execution.html&quot;&gt;Acero&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://dtplyr.tidyverse.org/&quot;&gt;dtplyr&lt;/a&gt; for large, in-memory datasets. Translates your dplyr code to high performance &lt;a href=&quot;https://rdatatable.gitlab.io/data.table/&quot;&gt;data.table&lt;/a&gt; code.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://dbplyr.tidyverse.org/&quot;&gt;dbplyr&lt;/a&gt; for data stored in a relational database. Translates your dplyr code to SQL.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://tidyverse.github.io/duckplyr/&quot;&gt;duckplyr&lt;/a&gt; for using &lt;a href=&quot;https://duckdb.org&quot;&gt;duckdb&lt;/a&gt; on large, in-memory datasets with zero extra copies. Translates your dplyr code to high performance duckdb queries with an automatic R fallback when translation isn’t possible.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://duckdb.org/docs/api/r&quot;&gt;duckdb&lt;/a&gt; for large datasets that are still small enough to fit on your computer.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://spark.rstudio.com&quot;&gt;sparklyr&lt;/a&gt; for very large datasets stored in &lt;a href=&quot;https://spark.apache.org&quot;&gt;Apache Spark&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;# The easiest way to get dplyr is to install the whole tidyverse:
install.packages(&quot;tidyverse&quot;)

# Alternatively, install just dplyr:
install.packages(&quot;dplyr&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development version&lt;/h3&gt; 
&lt;p&gt;To get a bug fix or to use a feature from the development version, you can install the development version of dplyr from GitHub.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;# install.packages(&quot;pak&quot;)
pak::pak(&quot;tidyverse/dplyr&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Cheat Sheet&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/rstudio/cheatsheets/raw/main/data-transformation.pdf&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-transformation-cheatsheet-thumbs.png&quot; width=&quot;630&quot; height=&quot;252&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(dplyr)

starwars %&amp;gt;% 
  filter(species == &quot;Droid&quot;)
#&amp;gt; # A tibble: 6 × 14
#&amp;gt;   name   height  mass hair_color skin_color  eye_color birth_year sex   gender  
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   
#&amp;gt; 1 C-3PO     167    75 &amp;lt;NA&amp;gt;       gold        yellow           112 none  masculi…
#&amp;gt; 2 R2-D2      96    32 &amp;lt;NA&amp;gt;       white, blue red               33 none  masculi…
#&amp;gt; 3 R5-D4      97    32 &amp;lt;NA&amp;gt;       white, red  red               NA none  masculi…
#&amp;gt; 4 IG-88     200   140 none       metal       red               15 none  masculi…
#&amp;gt; 5 R4-P17     96    NA none       silver, red red, blue         NA none  feminine
#&amp;gt; # ℹ 1 more row
#&amp;gt; # ℹ 5 more variables: homeworld &amp;lt;chr&amp;gt;, species &amp;lt;chr&amp;gt;, films &amp;lt;list&amp;gt;,
#&amp;gt; #   vehicles &amp;lt;list&amp;gt;, starships &amp;lt;list&amp;gt;

starwars %&amp;gt;% 
  select(name, ends_with(&quot;color&quot;))
#&amp;gt; # A tibble: 87 × 4
#&amp;gt;   name           hair_color skin_color  eye_color
#&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;    
#&amp;gt; 1 Luke Skywalker blond      fair        blue     
#&amp;gt; 2 C-3PO          &amp;lt;NA&amp;gt;       gold        yellow   
#&amp;gt; 3 R2-D2          &amp;lt;NA&amp;gt;       white, blue red      
#&amp;gt; 4 Darth Vader    none       white       yellow   
#&amp;gt; 5 Leia Organa    brown      light       brown    
#&amp;gt; # ℹ 82 more rows

starwars %&amp;gt;% 
  mutate(name, bmi = mass / ((height / 100)  ^ 2)) %&amp;gt;%
  select(name:mass, bmi)
#&amp;gt; # A tibble: 87 × 4
#&amp;gt;   name           height  mass   bmi
#&amp;gt;   &amp;lt;chr&amp;gt;           &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1 Luke Skywalker    172    77  26.0
#&amp;gt; 2 C-3PO             167    75  26.9
#&amp;gt; 3 R2-D2              96    32  34.7
#&amp;gt; 4 Darth Vader       202   136  33.3
#&amp;gt; 5 Leia Organa       150    49  21.8
#&amp;gt; # ℹ 82 more rows

starwars %&amp;gt;% 
  arrange(desc(mass))
#&amp;gt; # A tibble: 87 × 14
#&amp;gt;   name      height  mass hair_color skin_color eye_color birth_year sex   gender
#&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
#&amp;gt; 1 Jabba De…    175  1358 &amp;lt;NA&amp;gt;       green-tan… orange         600   herm… mascu…
#&amp;gt; 2 Grievous     216   159 none       brown, wh… green, y…       NA   male  mascu…
#&amp;gt; 3 IG-88        200   140 none       metal      red             15   none  mascu…
#&amp;gt; 4 Darth Va…    202   136 none       white      yellow          41.9 male  mascu…
#&amp;gt; 5 Tarfful      234   136 brown      brown      blue            NA   male  mascu…
#&amp;gt; # ℹ 82 more rows
#&amp;gt; # ℹ 5 more variables: homeworld &amp;lt;chr&amp;gt;, species &amp;lt;chr&amp;gt;, films &amp;lt;list&amp;gt;,
#&amp;gt; #   vehicles &amp;lt;list&amp;gt;, starships &amp;lt;list&amp;gt;

starwars %&amp;gt;%
  group_by(species) %&amp;gt;%
  summarise(
    n = n(),
    mass = mean(mass, na.rm = TRUE)
  ) %&amp;gt;%
  filter(
    n &amp;gt; 1,
    mass &amp;gt; 50
  )
#&amp;gt; # A tibble: 9 × 3
#&amp;gt;   species      n  mass
#&amp;gt;   &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1 Droid        6  69.8
#&amp;gt; 2 Gungan       3  74  
#&amp;gt; 3 Human       35  81.3
#&amp;gt; 4 Kaminoan     2  88  
#&amp;gt; 5 Mirialan     2  53.1
#&amp;gt; # ℹ 4 more rows
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting help&lt;/h2&gt; 
&lt;p&gt;If you encounter a clear bug, please file an issue with a minimal reproducible example on &lt;a href=&quot;https://github.com/tidyverse/dplyr/issues&quot;&gt;GitHub&lt;/a&gt;. For questions and other discussion, please use &lt;a href=&quot;https://forum.posit.co/&quot;&gt;forum.posit.co&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Code of conduct&lt;/h2&gt; 
&lt;p&gt;Please note that this project is released with a &lt;a href=&quot;https://dplyr.tidyverse.org/CODE_OF_CONDUCT&quot;&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project you agree to abide by its terms.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>stuart-lab/signac</title>
      <link>https://github.com/stuart-lab/signac</link>
      <description>&lt;p&gt;R toolkit for the analysis of single-cell chromatin data&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Signac &lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/stuart-lab/signac/master/man/figures/logo.svg?sanitize=true&quot; style=&quot;height:100px;&quot;&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/stuart-lab/signac/actions&quot;&gt;&lt;img src=&quot;https://github.com/stuart-lab/signac/workflows/R-CMD-check/badge.svg?sanitize=true&quot; alt=&quot;R-CMD-check&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://cran.r-project.org/package=Signac&quot;&gt;&lt;img src=&quot;https://www.r-pkg.org/badges/version/Signac&quot; alt=&quot;CRAN Version&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://cran.r-project.org/package=Signac&quot;&gt;&lt;img src=&quot;https://cranlogs.r-pkg.org/badges/Signac&quot; alt=&quot;CRAN Downloads&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Signac is a comprehensive R package for the analysis of single-cell chromatin data. Signac includes functions for quality control, normalization, dimension reduction, clustering, differential activity, and more.&lt;/p&gt; 
&lt;p&gt;Documentation and tutorials can be found at &lt;a href=&quot;https://stuartlab.org/signac/&quot;&gt;https://stuartlab.org/signac/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install the latest release of Signac from CRAN:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;setRepositories(ind=1:3) # needed to automatically install Bioconductor dependencies
install.packages(&quot;Signac&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To release the latest develop version from GitHub:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;if (!requireNamespace(&quot;remotes&quot;, quietly = TRUE))
    install.packages(&quot;remotes&quot;)
remotes::install_github(&quot;stuart-lab/signac&quot;, ref = &quot;develop&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Release notes&lt;/h2&gt; 
&lt;p&gt;For a changelog please see the &lt;a href=&quot;https://github.com/stuart-lab/signac/raw/develop/NEWS.md&quot;&gt;NEWS file&lt;/a&gt;, also available on the &lt;a href=&quot;https://stuartlab.org/signac/news/index.html&quot;&gt;Signac website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the Signac package. Please see the &lt;a href=&quot;https://github.com/stuart-lab/signac/raw/develop/CONTRIBUTING.md&quot;&gt;contribution guide&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Getting help&lt;/h2&gt; 
&lt;p&gt;If you encounter a bug or have a feature request, please open an &lt;a href=&quot;https://github.com/stuart-lab/signac/issues&quot;&gt;issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you would like to discuss questions related to single-cell analysis, you can open a &lt;a href=&quot;https://github.com/stuart-lab/signac/discussions&quot;&gt;discussion&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Signac runs on a quarterly release schedule. Additional releases will be scheduled in the case of urgent bug fixes. The development roadmap can be viewed on GitHub &lt;a href=&quot;https://github.com/orgs/stuart-lab/projects/1&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Citing Signac&lt;/h2&gt; 
&lt;p&gt;If you use the Signac package in your work please cite &lt;a href=&quot;https://doi.org/10.1038/s41592-021-01282-5&quot;&gt;Stuart et al. 2021&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@ARTICLE{signac,
  title     = &quot;Single-cell chromatin state analysis with Signac&quot;,
  author    = &quot;Stuart, Tim and Srivastava, Avi and Madad, Shaista and Lareau,
               Caleb A and Satija, Rahul&quot;,
  journal   = &quot;Nat. Methods&quot;,
  publisher = &quot;Nature Publishing Group&quot;,
  pages     = &quot;1--9&quot;,
  month     =  nov,
  year      =  2021,
  url       = &quot;https://www.nature.com/articles/s41592-021-01282-5&quot;,
  language  = &quot;en&quot;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Related packages&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/satijalab/seurat&quot;&gt;Seurat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/satijalab/seurat-object&quot;&gt;SeuratObject&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mojaveazure/seurat-disk&quot;&gt;SeuratDisk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/satijalab/seurat-data&quot;&gt;SeuratData&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/satijalab/seurat-wrappers&quot;&gt;SeuratWrappers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/satijalab/azimuth&quot;&gt;Azimuth&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>broadinstitute/infercnv</title>
      <link>https://github.com/broadinstitute/infercnv</link>
      <description>&lt;p&gt;Inferring CNV from Single-Cell RNA-Seq&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Subclustering&lt;/h1&gt; 
&lt;p&gt;Subclustering resolution is one of the primary settings that will need to be adjusted in most runs to avoid oversplitting. The tutorial below explains how it works and details about it can also be found on the &lt;a href=&quot;https://github.com/broadinstitute/infercnv/wiki/infercnv-tumor-subclusters#tumor-subclustering-by-leiden-clustering-preferred&quot;&gt;wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;h3&gt;Full documentation&lt;/h3&gt; 
&lt;p&gt;Visit project &lt;a href=&quot;https://github.com/broadinstitute/inferCNV/wiki&quot;&gt;wiki&lt;/a&gt; for InferCNV documentation.&lt;/p&gt; 
&lt;h3&gt;Infercnv video tutorial&lt;/h3&gt; 
&lt;p&gt;A &lt;strong&gt;video&lt;/strong&gt; tutorial giving on overview of infercnv features and how to run an analysis can be found below &lt;strong&gt;(click on the image)&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=-qOcHAavZT8&quot; title=&quot;Tutorial: Running infercnv&quot;&gt;&lt;img src=&quot;http://img.youtube.com/vi/-qOcHAavZT8/0.jpg&quot; alt=&quot;Tutorial: Running infercnv&quot;&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kassambara/survminer</title>
      <link>https://github.com/kassambara/survminer</link>
      <description>&lt;p&gt;Survival Analysis and Visualization&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kassambara/survminer/actions/workflows/R-CMD-check.yaml&quot;&gt;&lt;img src=&quot;https://github.com/kassambara/survminer/actions/workflows/R-CMD-check.yaml/badge.svg?sanitize=true&quot; alt=&quot;R-CMD-check&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://cran.r-project.org/package=survminer&quot;&gt;&lt;img src=&quot;https://www.r-pkg.org/badges/version/survminer&quot; alt=&quot;CRAN_Status_Badge&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://cran.r-project.org/package=survminer&quot;&gt;&lt;img src=&quot;https://cranlogs.r-pkg.org/badges/survminer&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://cran.r-project.org/package=survminer&quot;&gt;&lt;img src=&quot;https://cranlogs.r-pkg.org/badges/grand-total/survminer?color=orange&quot; alt=&quot;Total Downloads&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#survminer-survival-analysis-and-visualization&quot;&gt;survminer: Survival Analysis and Visualization&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#installation-and-loading&quot;&gt;Installation and loading&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#ggsurvplot-drawing-survival-curves&quot;&gt;ggsurvplot: Drawing survival curves&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#fitting-survival-curves&quot;&gt;Fitting survival curves&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#basic-plots&quot;&gt;Basic plots&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#computing-and-passin-p-values&quot;&gt;Computing and passing p-values&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#customized-survival-curves&quot;&gt;Customized survival curves&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#more-customized-survival-curves&quot;&gt;More customized survival curves&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#uber-customized-survival-curves&quot;&gt;Uber customized survival curves&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#uber-platinum-customized-survival-curves&quot;&gt;Uber platinum customized survival curves&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#uber-platinum-premium-customized-survival-curves&quot;&gt;Uber platinum premium customized survival curves&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/#blog-posts&quot;&gt;Blog posts&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;survminer: Survival Analysis and Visualization&lt;/h1&gt; 
&lt;p&gt;The &lt;strong&gt;survminer&lt;/strong&gt; R package provides functions for facilitating &lt;strong&gt;survival analysis&lt;/strong&gt; and &lt;strong&gt;visualization&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;The main functions, in the package, are organized in different categories as follow.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Survival Curves&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;br&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ggsurvplot&lt;/strong&gt;(): Draws survival curves with the ‘number at risk’ table, the cumulative number of events table and the cumulative number of censored subjects table.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;arrange_ggsurvplots&lt;/strong&gt;(): Arranges multiple ggsurvplots on the same page.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ggsurvevents&lt;/strong&gt;(): Plots the distribution of event’s times.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;surv_summary&lt;/strong&gt;(): Summary of a survival curve. Compared to the default summary() function, surv_summary() creates a data frame containing a nice summary from survfit results.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;surv_cutpoint&lt;/strong&gt;(): Determines the optimal cutpoint for one or multiple continuous variables at once. Provides a value of a cutpoint that correspond to the most significant relation with survival.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pairwise_survdiff&lt;/strong&gt;(): Multiple comparisons of survival curves. Calculate pairwise comparisons between group levels with corrections for multiple testing.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Diagnostics of Cox Model&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;br&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ggcoxzph&lt;/strong&gt;(): Graphical test of proportional hazards. Displays a graph of the scaled Schoenfeld residuals, along with a smooth curve using ggplot2. Wrapper around plot.cox.zph().&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ggcoxdiagnostics&lt;/strong&gt;(): Displays diagnostics graphs presenting goodness of Cox Proportional Hazards Model fit.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ggcoxfunctional&lt;/strong&gt;(): Displays graphs of continuous explanatory variable against martingale residuals of null cox proportional hazards model. It helps to properly choose the functional form of continuous variable in cox model.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Summary of Cox Model&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;br&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ggforest&lt;/strong&gt;(): Draws forest plot for CoxPH model.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ggcoxadjustedcurves&lt;/strong&gt;(): Plots adjusted survival curves for coxph model.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Competing Risks&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;br&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ggcompetingrisks&lt;/strong&gt;(): Plots cumulative incidence curves for competing risks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Find out more at &lt;a href=&quot;https://rpkgs.datanovia.com/survminer/&quot;&gt;https://rpkgs.datanovia.com/survminer/&lt;/a&gt;, and check out the documentation and usage examples of each of the functions in survminer package.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Installation and loading&lt;/h2&gt; 
&lt;p&gt;Install from &lt;a href=&quot;https://cran.r-project.org/package=survminer&quot;&gt;CRAN&lt;/a&gt; as follow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;survminer&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, install the latest version from &lt;a href=&quot;https://github.com/kassambara/survminer&quot;&gt;GitHub&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;if(!require(devtools)) install.packages(&quot;devtools&quot;)
devtools::install_github(&quot;kassambara/survminer&quot;, build_vignettes = FALSE)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Load survminer:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;survminer&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ggsurvplot: Drawing survival curves&lt;/h2&gt; 
&lt;h3&gt;Fitting survival curves&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;require(&quot;survival&quot;)
fit &amp;lt;- survfit(Surv(time, status) ~ sex, data = lung)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Basic plots&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;ggsurvplot(fit, data = lung)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/tools/README-ggplot2-basic-survival-plot-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Censor shape can be changed as follow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;ggsurvplot(fit, data = lung, censor.shape=&quot;|&quot;, censor.size = 4)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Customized survival curves&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;ggsurvplot(
  fit, 
  data = lung, 
  size = 1,                 # change line size
  palette = 
    c(&quot;#E7B800&quot;, &quot;#2E9FDF&quot;),# custom color palettes
  conf.int = TRUE,          # Add confidence interval
  pval = TRUE,              # Add p-value
  risk.table = TRUE,        # Add risk table
  risk.table.col = &quot;strata&quot;,# Risk table color by groups
  legend.labs = 
    c(&quot;Male&quot;, &quot;Female&quot;),    # Change legend labels
  risk.table.height = 0.25, # Useful to change when you have multiple groups
  ggtheme = theme_bw()      # Change ggplot2 theme
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/tools/README-ggplot2-customized-survival-plot-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Note that, additional arguments are available to customize the main title, axis labels, the font style, axis limits, legends and the number at risk table.&lt;/p&gt; 
&lt;h3&gt;More customized survival curves&lt;/h3&gt; 
&lt;p&gt;Focus on &lt;code&gt;xlim&lt;/code&gt; and &lt;code&gt;break.time.by&lt;/code&gt; parameters which do not change the calculations of estimates of survival surves. Also note &lt;code&gt;risk.table.y.text.col = TRUE&lt;/code&gt; and &lt;code&gt;risk.table.y.text = FALSE&lt;/code&gt; that provide bars instead of names in text annotations of the legend of risk table.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;ggsurvplot(
   fit,                     # survfit object with calculated statistics.
   data = lung,             # data used to fit survival curves.
   risk.table = TRUE,       # show risk table.
   pval = TRUE,             # show p-value of log-rank test.
   conf.int = TRUE,         # show confidence intervals for 
                            # point estimates of survival curves.
   xlim = c(0,500),         # present narrower X axis, but not affect
                            # survival estimates.
   xlab = &quot;Time in days&quot;,   # customize X axis label.
   break.time.by = 100,     # break X axis in time intervals by 500.
   ggtheme = theme_light(), # customize plot and risk table with a theme.
 risk.table.y.text.col = T, # colour risk table text annotations.
  risk.table.y.text = FALSE # show bars instead of names in text annotations
                            # in legend of risk table
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/tools/README-ggplot2-more-customized-survival-plot-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Uber customized survival curves&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;ggsurv &amp;lt;- ggsurvplot(
           fit,                     # survfit object with calculated statistics.
           data = lung,             # data used to fit survival curves.
           risk.table = TRUE,       # show risk table.
           pval = TRUE,             # show p-value of log-rank test.
           conf.int = TRUE,         # show confidence intervals for 
                                    # point estimates of survival curves.
           palette = c(&quot;#E7B800&quot;, &quot;#2E9FDF&quot;),
           xlim = c(0,500),         # present narrower X axis, but not affect
                                    # survival estimates.
           xlab = &quot;Time in days&quot;,   # customize X axis label.
           break.time.by = 100,     # break X axis in time intervals by 500.
           ggtheme = theme_light(), # customize plot and risk table with a theme.
          risk.table.y.text.col = T,# colour risk table text annotations.
          risk.table.height = 0.25, # the height of the risk table
          risk.table.y.text = FALSE,# show bars instead of names in text annotations
                                    # in legend of risk table.
          ncensor.plot = TRUE,      # plot the number of censored subjects at time t
          ncensor.plot.height = 0.25,
          conf.int.style = &quot;step&quot;,  # customize style of confidence intervals
          surv.median.line = &quot;hv&quot;,  # add the median survival pointer.
          legend.labs = 
            c(&quot;Male&quot;, &quot;Female&quot;)    # change legend labels.
        )
ggsurv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/tools/README-ggplot2-uber-customized-survival-plot-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Uber platinum customized survival curves&lt;/h3&gt; 
&lt;p&gt;Helper function to customize plot labels:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;customize_labels &amp;lt;- function (p, font.title = NULL,
                              font.subtitle = NULL, font.caption = NULL,
                              font.x = NULL, font.y = NULL, font.xtickslab = NULL, font.ytickslab = NULL)
{
  original.p &amp;lt;- p
  if(is.ggplot(original.p)) list.plots &amp;lt;- list(original.p)
  else if(is.list(original.p)) list.plots &amp;lt;- original.p
  else stop(&quot;Can&#39;t handle an object of class &quot;, class (original.p))
  .set_font &amp;lt;- function(font){
    font &amp;lt;- ggpubr:::.parse_font(font)
    ggtext::element_markdown (size = font$size, face = font$face, colour = font$color)
  }
  for(i in 1:length(list.plots)){
    p &amp;lt;- list.plots[[i]]
    if(is.ggplot(p)){
      if (!is.null(font.title)) p &amp;lt;- p + theme(plot.title = .set_font(font.title))
      if (!is.null(font.subtitle)) p &amp;lt;- p + theme(plot.subtitle = .set_font(font.subtitle))
      if (!is.null(font.caption)) p &amp;lt;- p + theme(plot.caption = .set_font(font.caption))
      if (!is.null(font.x)) p &amp;lt;- p + theme(axis.title.x = .set_font(font.x))
      if (!is.null(font.y)) p &amp;lt;- p + theme(axis.title.y = .set_font(font.y))
      if (!is.null(font.xtickslab)) p &amp;lt;- p + theme(axis.text.x = .set_font(font.xtickslab))
      if (!is.null(font.ytickslab)) p &amp;lt;- p + theme(axis.text.y = .set_font(font.ytickslab))
      list.plots[[i]] &amp;lt;- p
    }
  }
  if(is.ggplot(original.p)) list.plots[[1]]
  else list.plots
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Customized plot labels:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;# Changing Labels
# %%%%%%%%%%%%%%%%%%%%%%%%%%
# Labels for Survival Curves (plot)
ggsurv$plot &amp;lt;- ggsurv$plot + labs(
  title    = &quot;Survival curves&quot;,                     
  subtitle = &quot;Based on Kaplan-Meier estimates&quot;,  
  caption  = &quot;created with survminer&quot;             
  )

# Labels for Risk Table 
ggsurv$table &amp;lt;- ggsurv$table + labs(
  title    = &quot;Note the risk set sizes&quot;,          
  subtitle = &quot;and remember about censoring.&quot;, 
  caption  = &quot;source code: website.com&quot;        
  )

# Labels for ncensor plot 
ggsurv$ncensor.plot &amp;lt;- ggsurv$ncensor.plot + labs( 
  title    = &quot;Number of censorings&quot;, 
  subtitle = &quot;over the time.&quot;,
  caption  = &quot;source code: website.com&quot;
  )

# Changing the font size, style and color
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Applying the same font style to all the components of ggsurv:
# survival curves, risk table and censor part

ggsurv &amp;lt;- customize_labels(
  ggsurv,
  font.title    = c(16, &quot;bold&quot;, &quot;darkblue&quot;),         
  font.subtitle = c(15, &quot;bold.italic&quot;, &quot;purple&quot;), 
  font.caption  = c(14, &quot;plain&quot;, &quot;orange&quot;),        
  font.x        = c(14, &quot;bold.italic&quot;, &quot;red&quot;),          
  font.y        = c(14, &quot;bold.italic&quot;, &quot;darkred&quot;),      
  font.xtickslab = c(12, &quot;plain&quot;, &quot;darkgreen&quot;)
)

ggsurv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/tools/README-ggplot2-uber-platinium-customized-survival-plot-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Uber platinum premium customized survival curves&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;# Using specific fonts for risk table and ncensor plots
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Font for Risk Table
ggsurv$table &amp;lt;- customize_labels(
  ggsurv$table,
  font.title    = c(13, &quot;bold.italic&quot;, &quot;green&quot;),
  font.subtitle = c(15, &quot;bold&quot;, &quot;pink&quot;),
  font.caption  = c(11, &quot;plain&quot;, &quot;darkgreen&quot;),
  font.x        = c(8, &quot;bold.italic&quot;, &quot;orange&quot;),
  font.y        = c(11, &quot;bold.italic&quot;, &quot;darkgreen&quot;),
  font.xtickslab = c(9, &quot;bold&quot;, &quot;red&quot;)
)


# Font for ncensor plot
ggsurv$ncensor.plot &amp;lt;- customize_labels(
  ggsurv$ncensor.plot,
  font.title    = c(13, &quot;bold.italic&quot;, &quot;green&quot;),
  font.subtitle = c(15, &quot;bold&quot;, &quot;pink&quot;),
  font.caption  = c(11, &quot;plain&quot;, &quot;darkgreen&quot;),
  font.x        = c(8, &quot;bold.italic&quot;, &quot;orange&quot;),
  font.y        = c(11, &quot;bold.italic&quot;, &quot;darkgreen&quot;),
  font.xtickslab = c(9, &quot;bold&quot;, &quot;red&quot;)
)

print(ggsurv)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/kassambara/survminer/master/tools/README-ggplot2-uber-platinium-premium-customized-survival-plot-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Blog posts&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;M. Kosiński. January 2017. &lt;a href=&quot;https://rpkgs.datanovia.com/survminer/articles/Specifiying_weights_in_log-rank_comparisons.html&quot;&gt;Weighted Log-rank Tests&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;A. Kassambara. STHDA December 2016. &lt;a href=&quot;http://www.sthda.com/english/wiki/survival-analysis-basics&quot;&gt;Survival Analysis Basics: Curves and Logrank Tests&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;A. Kassambara. STHDA December 2016. &lt;a href=&quot;http://www.sthda.com/english/wiki/cox-proportional-hazards-model&quot;&gt;Cox Proportional Hazards Model&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;A. Kassambara. STHDA December 2016. &lt;a href=&quot;http://www.sthda.com/english/wiki/cox-model-assumptions&quot;&gt;Cox Model Assumptions&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;M. Kosiński. May 2016. &lt;a href=&quot;https://rpkgs.datanovia.com/survminer/articles/Informative_Survival_Plots.html&quot;&gt;Survival plots have never been so informative&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;A. Kassambara. STHDA January 2016. &lt;a href=&quot;http://www.sthda.com/english/wiki/survminer-r-package-survival-data-analysis-and-visualization&quot;&gt;survminer R package: Survival Data Analysis and Visualization&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>hadley/r4ds</title>
      <link>https://github.com/hadley/r4ds</link>
      <description>&lt;p&gt;R for data science: a book&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;R for Data Science&lt;/h1&gt; 
&lt;!-- badges: start --&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/hadley/r4ds/actions/workflows/build_book.yaml&quot;&gt;&lt;img src=&quot;https://github.com/hadley/r4ds/actions/workflows/build_book.yaml/badge.svg?sanitize=true&quot; alt=&quot;Render and deploy Book to Netlify&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- badges: end --&gt; 
&lt;p&gt;This repository contains the source of &lt;a href=&quot;http://r4ds.hadley.nz&quot;&gt;R for Data Science&lt;/a&gt; book. The book is built using &lt;a href=&quot;https://quarto.org/&quot;&gt;Quarto&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Images&lt;/h2&gt; 
&lt;h3&gt;Omnigraffle drawings&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Font: 12pt Guardian Sans Condensed / Ubuntu mono&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Export as 300 dpi png.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Website font is 18 px = 13.5 pt, so scale dpi to match font sizes: 270 = 300 * 12 / 13.5. (I also verified this empirically by screenshotting.)&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;#| echo: FALSE
#| out.width: NULL
knitr::include_graphics(&quot;diagrams/transform.png&quot;, dpi = 270)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Screenshots&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Make sure you&#39;re using a light theme. For small interface elements (eg. toolbars), zoom in twice.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Screenshot with Cmd + Shift + 4.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Don&#39;t need to set dpi:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;#| echo: FALSE
#| out.width: NULL
knitr::include_graphics(&quot;screenshots/rstudio-wg.png&quot;)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;O&#39;Reilly&lt;/h3&gt; 
&lt;p&gt;To generate book for O&#39;Reilly, build the book then:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;# pak::pak(&quot;hadley/htmlbook&quot;)
htmlbook::convert_book()

html &amp;lt;- list.files(&quot;oreilly&quot;, pattern = &quot;[.]html$&quot;, full.names = TRUE)
file.copy(html, &quot;../r-for-data-science-2e/&quot;, overwrite = TRUE)

pngs &amp;lt;- list.files(&quot;oreilly&quot;, pattern = &quot;[.]png$&quot;, full.names = TRUE, recursive = TRUE)
dest &amp;lt;- gsub(&quot;oreilly&quot;, &quot;../r-for-data-science-2e/&quot;, pngs)
fs::dir_create(unique(dirname(dest)))
file.copy(pngs, dest, overwrite = TRUE)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then commit and push to atlas.&lt;/p&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;Please note that r4ds uses a &lt;a href=&quot;https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html&quot;&gt;Contributor Code of Conduct&lt;/a&gt;. By contributing to this book, you agree to abide by its terms.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rstudio/renv</title>
      <link>https://github.com/rstudio/renv</link>
      <description>&lt;p&gt;renv: Project environments for R.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;renv &lt;img src=&quot;https://raw.githubusercontent.com/rstudio/renv/main/man/figures/logo.svg?sanitize=true&quot; align=&quot;right&quot; height=&quot;115&quot;&gt;&lt;/h1&gt; 
&lt;!-- badges: start --&gt; 
&lt;p&gt;&lt;a href=&quot;https://lifecycle.r-lib.org/articles/stages.html&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/lifecycle-stable-brightgreen.svg?sanitize=true&quot; alt=&quot;Lifecycle: stable&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://CRAN.R-project.org/package=renv&quot;&gt;&lt;img src=&quot;https://www.r-pkg.org/badges/version/renv&quot; alt=&quot;CRAN status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml&quot;&gt;&lt;img src=&quot;https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml/badge.svg?sanitize=true&quot; alt=&quot;R-CMD-check&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- badges: end --&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;The renv package[^1] helps you create &lt;strong&gt;r&lt;/strong&gt;eproducible &lt;strong&gt;env&lt;/strong&gt;ironments for your R projects. Use renv to make your R projects more isolated, portable and reproducible.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Isolated&lt;/strong&gt;: Installing a new or updated package for one project won’t break your other projects, and vice versa. That’s because renv gives each project its own private library.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Portable&lt;/strong&gt;: Easily transport your projects from one computer to another, even across different platforms. renv makes it easy to install the packages your project depends on.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reproducible&lt;/strong&gt;: renv records the exact package versions you depend on, and ensures those exact versions are the ones that get installed wherever you go.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install the latest version of renv from CRAN with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;renv&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, install the development version from &lt;a href=&quot;https://rstudio.r-universe.dev/renv&quot;&gt;r-universe&lt;/a&gt; with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;renv&quot;, repos = &quot;https://rstudio.r-universe.dev&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Workflow&lt;/h2&gt; 
&lt;img src=&quot;https://raw.githubusercontent.com/rstudio/renv/main/vignettes/renv.png&quot; alt=&quot;A diagram showing the most important verbs and nouns of renv. Projects start with init(), which creates a project library using packages from the system library. snapshot() updates the lockfile using the packages installed in the project library, where restore() installs packages into the project library using the metadata from the lockfile, and status() compares the lockfile to the project library. You install and update packages from CRAN and GitHub using install() and update(), but because you&#39;ll need to do this for multiple projects, renv uses cache to make this fast.&quot; width=&quot;408&quot; style=&quot;display: block; margin: auto;&quot;&gt; 
&lt;p&gt;Use &lt;code&gt;renv::init()&lt;/code&gt; to initialize renv in a new or existing project. This will set up a &lt;strong&gt;project library&lt;/strong&gt;, containing all the packages you’re currently using. The packages (and all the metadata needed to reinstall them) are recorded into a &lt;strong&gt;lockfile&lt;/strong&gt;, &lt;code&gt;renv.lock&lt;/code&gt;, and a &lt;code&gt;.Rprofile&lt;/code&gt; ensures that the library is used every time you open that project.&lt;/p&gt; 
&lt;p&gt;As you continue to work on your project, you will install and upgrade packages, either using &lt;code&gt;install.packages()&lt;/code&gt; and &lt;code&gt;update.packages()&lt;/code&gt; or &lt;code&gt;renv::install()&lt;/code&gt; and &lt;code&gt;renv::update()&lt;/code&gt;. After you’ve confirmed your code works as expected, use &lt;code&gt;renv::snapshot()&lt;/code&gt; to record the packages and their sources in the lockfile.&lt;/p&gt; 
&lt;p&gt;Later, if you need to share your code with someone else or run your code on new machine, your collaborator (or you) can call &lt;code&gt;renv::restore()&lt;/code&gt; to reinstall the specific package versions recorded in the lockfile.&lt;/p&gt; 
&lt;h2&gt;Learning more&lt;/h2&gt; 
&lt;p&gt;If this is your first time using renv, we strongly recommend starting with the &lt;a href=&quot;https://rstudio.github.io/renv/articles/renv.html&quot;&gt;Introduction to renv&lt;/a&gt; vignette: this will help you understand the most important verbs and nouns of renv.&lt;/p&gt; 
&lt;p&gt;If you have a question about renv, please first check the &lt;a href=&quot;https://rstudio.github.io/renv/articles/faq.html&quot;&gt;FAQ&lt;/a&gt; to see whether your question has already been addressed. If it hasn’t, please feel free to ask on the &lt;a href=&quot;https://forum.posit.co&quot;&gt;Posit Forum&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you believe you’ve found a bug in renv, please file a bug (and, if possible, a &lt;a href=&quot;https://reprex.tidyverse.org&quot;&gt;reproducible example&lt;/a&gt;) at &lt;a href=&quot;https://github.com/rstudio/renv/issues&quot;&gt;https://github.com/rstudio/renv/issues&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;[^1]: Pronounced “R” “env”&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vegandevs/vegan</title>
      <link>https://github.com/vegandevs/vegan</link>
      <description>&lt;p&gt;R package for community ecologists: popular ordination methods, ecological null models &amp; diversity analysis&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;vegan: an R package for community ecologists&lt;/h1&gt; 
&lt;p&gt;Ordination methods, diversity analysis and other functions for community and vegetation ecologists.&lt;/p&gt; 
&lt;!-- badges: start --&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/vegandevs/vegan/actions/workflows/R-CMD-check.yaml&quot;&gt;&lt;img src=&quot;https://github.com/vegandevs/vegan/actions/workflows/R-CMD-check.yaml/badge.svg?sanitize=true&quot; alt=&quot;R-CMD-check&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://cran.r-project.org/package=vegan&quot;&gt;&lt;img src=&quot;https://www.r-pkg.org/badges/version/vegan&quot; alt=&quot;CRAN_Status_Badge&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://cran.rstudio.com/web/packages/vegan/index.html&quot;&gt;&lt;img src=&quot;https://cranlogs.r-pkg.org/badges/grand-total/vegan&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://vegandevs.r-universe.dev/vegan&quot;&gt;&lt;img src=&quot;https://vegandevs.r-universe.dev/badges/vegan&quot; alt=&quot;R-universe&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- badges: end --&gt; 
&lt;p&gt;Website for the development version of the &lt;strong&gt;vegan&lt;/strong&gt; package.&lt;/p&gt; 
&lt;p&gt;Vignettes are available on &lt;a href=&quot;https://vegandevs.r-universe.dev/vegan&quot;&gt;R-universe&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://vegandevs.r-universe.dev/vegan/doc/intro-vegan.pdf&quot;&gt;Introduction to ordination in vegan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://vegandevs.r-universe.dev/vegan/doc/partitioning.pdf&quot;&gt;Partition of Variation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://vegandevs.r-universe.dev/vegan/doc/diversity-vegan.pdf&quot;&gt;Diversity analysis in vegan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://vegandevs.r-universe.dev/vegan/doc/decision-vegan.pdf&quot;&gt;Design decisions and implementation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;To install the development version of &lt;strong&gt;vegan&lt;/strong&gt; you can use the usual &lt;code&gt;git&lt;/code&gt; and &lt;code&gt;R CMD build -&amp;gt; R CMD INSTALL&lt;/code&gt; dance on the cloned repo (or downloaded sources). You&#39;ll need to be able to install packages from source for that to work; if you don&#39;t have the relevant developer tools, you won&#39;t be able to install &lt;strong&gt;vegan&lt;/strong&gt; this way.&lt;/p&gt; 
&lt;h2&gt;Using &lt;strong&gt;remotes&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;If you do have the developer tools installed but don&#39;t want the hassle of keeping a local source code tree up-to-date, use the &lt;strong&gt;remotes&lt;/strong&gt; package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;remotes&quot;)
remotes::install_github(&quot;vegandevs/vegan&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installing binaries from R Universe&lt;/h2&gt; 
&lt;p&gt;If you just want to install a binary version of the packages, just as you would from CRAN, you can install from our R Universe repository. Run the following in your R session:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&#39;vegan&#39;,
    repos = c(&#39;https://vegandevs.r-universe.dev&#39;,&#39;https://cloud.r-project.org&#39;))
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>rdpeng/ProgrammingAssignment2</title>
      <link>https://github.com/rdpeng/ProgrammingAssignment2</link>
      <description>&lt;p&gt;Repository for Programming Assignment 2 for R Programming on Coursera&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;Introduction&lt;/h3&gt; 
&lt;p&gt;This second programming assignment will require you to write an R function that is able to cache potentially time-consuming computations. For example, taking the mean of a numeric vector is typically a fast operation. However, for a very long vector, it may take too long to compute the mean, especially if it has to be computed repeatedly (e.g. in a loop). If the contents of a vector are not changing, it may make sense to cache the value of the mean so that when we need it again, it can be looked up in the cache rather than recomputed. In this Programming Assignment you will take advantage of the scoping rules of the R language and how they can be manipulated to preserve state inside of an R object.&lt;/p&gt; 
&lt;h3&gt;Example: Caching the Mean of a Vector&lt;/h3&gt; 
&lt;p&gt;In this example we introduce the &lt;code&gt;&amp;lt;&amp;lt;-&lt;/code&gt; operator which can be used to assign a value to an object in an environment that is different from the current environment. Below are two functions that are used to create a special object that stores a numeric vector and caches its mean.&lt;/p&gt; 
&lt;p&gt;The first function, &lt;code&gt;makeVector&lt;/code&gt; creates a special &quot;vector&quot;, which is really a list containing a function to&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;set the value of the vector&lt;/li&gt; 
 &lt;li&gt;get the value of the vector&lt;/li&gt; 
 &lt;li&gt;set the value of the mean&lt;/li&gt; 
 &lt;li&gt;get the value of the mean&lt;/li&gt; 
&lt;/ol&gt; 
&lt;!-- --&gt; 
&lt;pre&gt;&lt;code&gt;makeVector &amp;lt;- function(x = numeric()) {
        m &amp;lt;- NULL
        set &amp;lt;- function(y) {
                x &amp;lt;&amp;lt;- y
                m &amp;lt;&amp;lt;- NULL
        }
        get &amp;lt;- function() x
        setmean &amp;lt;- function(mean) m &amp;lt;&amp;lt;- mean
        getmean &amp;lt;- function() m
        list(set = set, get = get,
             setmean = setmean,
             getmean = getmean)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The following function calculates the mean of the special &quot;vector&quot; created with the above function. However, it first checks to see if the mean has already been calculated. If so, it &lt;code&gt;get&lt;/code&gt;s the mean from the cache and skips the computation. Otherwise, it calculates the mean of the data and sets the value of the mean in the cache via the &lt;code&gt;setmean&lt;/code&gt; function.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cachemean &amp;lt;- function(x, ...) {
        m &amp;lt;- x$getmean()
        if(!is.null(m)) {
                message(&quot;getting cached data&quot;)
                return(m)
        }
        data &amp;lt;- x$get()
        m &amp;lt;- mean(data, ...)
        x$setmean(m)
        m
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Assignment: Caching the Inverse of a Matrix&lt;/h3&gt; 
&lt;p&gt;Matrix inversion is usually a costly computation and there may be some benefit to caching the inverse of a matrix rather than computing it repeatedly (there are also alternatives to matrix inversion that we will not discuss here). Your assignment is to write a pair of functions that cache the inverse of a matrix.&lt;/p&gt; 
&lt;p&gt;Write the following functions:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;makeCacheMatrix&lt;/code&gt;: This function creates a special &quot;matrix&quot; object that can cache its inverse.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cacheSolve&lt;/code&gt;: This function computes the inverse of the special &quot;matrix&quot; returned by &lt;code&gt;makeCacheMatrix&lt;/code&gt; above. If the inverse has already been calculated (and the matrix has not changed), then &lt;code&gt;cacheSolve&lt;/code&gt; should retrieve the inverse from the cache.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Computing the inverse of a square matrix can be done with the &lt;code&gt;solve&lt;/code&gt; function in R. For example, if &lt;code&gt;X&lt;/code&gt; is a square invertible matrix, then &lt;code&gt;solve(X)&lt;/code&gt; returns its inverse.&lt;/p&gt; 
&lt;p&gt;For this assignment, assume that the matrix supplied is always invertible.&lt;/p&gt; 
&lt;p&gt;In order to complete this assignment, you must do the following:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the GitHub repository containing the stub R files at &lt;a href=&quot;https://github.com/rdpeng/ProgrammingAssignment2&quot;&gt;https://github.com/rdpeng/ProgrammingAssignment2&lt;/a&gt; to create a copy under your own account.&lt;/li&gt; 
 &lt;li&gt;Clone your forked GitHub repository to your computer so that you can edit the files locally on your own machine.&lt;/li&gt; 
 &lt;li&gt;Edit the R file contained in the git repository and place your solution in that file (please do not rename the file).&lt;/li&gt; 
 &lt;li&gt;Commit your completed R file into YOUR git repository and push your git branch to the GitHub repository under your account.&lt;/li&gt; 
 &lt;li&gt;Submit to Coursera the URL to your GitHub repository that contains the completed R code for the assignment.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Grading&lt;/h3&gt; 
&lt;p&gt;This assignment will be graded via peer assessment.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rdatatable/data.table</title>
      <link>https://github.com/Rdatatable/data.table</link>
      <description>&lt;p&gt;R&#39;s data.table package extends data.frame:&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;data.table &lt;a href=&quot;https://r-datatable.com&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/Rdatatable/data.table/master/.graphics/logo.png&quot; align=&quot;right&quot; height=&quot;140&quot;&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;!-- badges: start --&gt; 
&lt;p&gt;&lt;a href=&quot;https://cran.r-project.org/web/checks/check_results_data.table.html&quot;&gt;&lt;img src=&quot;https://badges.cranchecks.info/flavor/release/data.table.svg?sanitize=true&quot; alt=&quot;CRAN status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/Rdatatable/data.table/actions&quot;&gt;&lt;img src=&quot;https://github.com/Rdatatable/data.table/workflows/R-CMD-check/badge.svg?sanitize=true&quot; alt=&quot;R-CMD-check&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://app.codecov.io/github/Rdatatable/data.table?branch=master&quot;&gt;&lt;img src=&quot;https://codecov.io/github/Rdatatable/data.table/coverage.svg?branch=master&quot; alt=&quot;Codecov test coverage&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://gitlab.com/Rdatatable/data.table/-/pipelines&quot;&gt;&lt;img src=&quot;https://gitlab.com/Rdatatable/data.table/badges/master/pipeline.svg?sanitize=true&quot; alt=&quot;GitLab CI build status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.rdocumentation.org/trends&quot;&gt;&lt;img src=&quot;https://cranlogs.r-pkg.org/badges/data.table&quot; alt=&quot;downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://gitlab.com/jangorecki/rdeps&quot;&gt;&lt;img src=&quot;https://jangorecki.gitlab.io/rdeps/data.table/CRAN_usage.svg?sanitize=true&quot; alt=&quot;CRAN usage&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://gitlab.com/jangorecki/rdeps&quot;&gt;&lt;img src=&quot;https://jangorecki.gitlab.io/rdeps/data.table/BioC_usage.svg?sanitize=true&quot; alt=&quot;BioC usage&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://gitlab.com/jangorecki/rdeps&quot;&gt;&lt;img src=&quot;https://jangorecki.gitlab.io/rdeps/data.table/indirect_usage.svg?sanitize=true&quot; alt=&quot;indirect usage&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- badges: end --&gt; 
&lt;p&gt;&lt;code&gt;data.table&lt;/code&gt; provides a high-performance version of &lt;a href=&quot;https://www.r-project.org/about.html&quot;&gt;base R&lt;/a&gt;&#39;s &lt;code&gt;data.frame&lt;/code&gt; with syntax and feature enhancements for ease of use, convenience and programming speed.&lt;/p&gt; 
&lt;h2&gt;Why &lt;code&gt;data.table&lt;/code&gt;?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;concise syntax: fast to type, fast to read&lt;/li&gt; 
 &lt;li&gt;fast speed&lt;/li&gt; 
 &lt;li&gt;memory efficient&lt;/li&gt; 
 &lt;li&gt;careful API lifecycle management&lt;/li&gt; 
 &lt;li&gt;community&lt;/li&gt; 
 &lt;li&gt;feature rich&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;fast and friendly delimited &lt;strong&gt;file reader&lt;/strong&gt;: &lt;strong&gt;&lt;a href=&quot;https://rdatatable.gitlab.io/data.table/reference/fread.html&quot;&gt;&lt;code&gt;?fread&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;, see also &lt;a href=&quot;https://github.com/Rdatatable/data.table/wiki/Convenience-features-of-fread&quot;&gt;convenience features for &lt;em&gt;small&lt;/em&gt; data&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;fast and feature rich delimited &lt;strong&gt;file writer&lt;/strong&gt;: &lt;strong&gt;&lt;a href=&quot;https://rdatatable.gitlab.io/data.table/reference/fwrite.html&quot;&gt;&lt;code&gt;?fwrite&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;low-level &lt;strong&gt;parallelism&lt;/strong&gt;: many common operations are internally parallelized to use multiple CPU threads&lt;/li&gt; 
 &lt;li&gt;fast and scalable aggregations; e.g. 100GB in RAM (see &lt;a href=&quot;https://duckdblabs.github.io/db-benchmark/&quot;&gt;benchmarks&lt;/a&gt; on up to &lt;strong&gt;two billion rows&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;fast and feature rich joins: &lt;strong&gt;ordered joins&lt;/strong&gt; (e.g. rolling forwards, backwards, nearest and limited staleness), &lt;strong&gt;&lt;a href=&quot;https://github.com/Rdatatable/data.table/wiki/talks/EARL2014_OverlapRangeJoin_Arun.pdf&quot;&gt;overlapping range joins&lt;/a&gt;&lt;/strong&gt; (similar to &lt;code&gt;IRanges::findOverlaps&lt;/code&gt;), &lt;strong&gt;&lt;a href=&quot;https://github.com/Rdatatable/data.table/wiki/talks/ArunSrinivasanUseR2016.pdf&quot;&gt;non-equi joins&lt;/a&gt;&lt;/strong&gt; (i.e. joins using operators &lt;code&gt;&amp;gt;, &amp;gt;=, &amp;lt;, &amp;lt;=&lt;/code&gt;), &lt;strong&gt;aggregate on join&lt;/strong&gt; (&lt;code&gt;by=.EACHI&lt;/code&gt;), &lt;strong&gt;update on join&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;fast add/update/delete columns &lt;strong&gt;by reference&lt;/strong&gt; by group using no copies at all&lt;/li&gt; 
 &lt;li&gt;fast and feature rich &lt;strong&gt;reshaping&lt;/strong&gt; data: &lt;strong&gt;&lt;a href=&quot;https://rdatatable.gitlab.io/data.table/reference/dcast.data.table.html&quot;&gt;&lt;code&gt;?dcast&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt; (&lt;em&gt;pivot/wider/spread&lt;/em&gt;) and &lt;strong&gt;&lt;a href=&quot;https://rdatatable.gitlab.io/data.table/reference/melt.data.table.html&quot;&gt;&lt;code&gt;?melt&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt; (&lt;em&gt;unpivot/longer/gather&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;any R function from any R package&lt;/strong&gt; can be used in queries not just the subset of functions made available by a database backend, also columns of type &lt;code&gt;list&lt;/code&gt; are supported&lt;/li&gt; 
 &lt;li&gt;has &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Dependency_hell&quot;&gt;no dependencies&lt;/a&gt;&lt;/strong&gt; at all other than base R itself, for simpler production/maintenance&lt;/li&gt; 
 &lt;li&gt;the R dependency is &lt;strong&gt;as old as possible for as long as possible&lt;/strong&gt;, dated April 2014, and we continuously test against that version; e.g. v1.11.0 released on 5 May 2018 bumped the dependency up from 5 year old R 3.0.0 to 4 year old R 3.1.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;data.table&quot;)

# latest development version (only if newer available)
data.table::update_dev_pkg()

# latest development version (force install)
install.packages(&quot;data.table&quot;, repos=&quot;https://rdatatable.gitlab.io/data.table&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href=&quot;https://github.com/Rdatatable/data.table/wiki/Installation&quot;&gt;the Installation wiki&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Use &lt;code&gt;data.table&lt;/code&gt; subset &lt;code&gt;[&lt;/code&gt; operator the same way you would use &lt;code&gt;data.frame&lt;/code&gt; one, but...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;no need to prefix each column with &lt;code&gt;DT$&lt;/code&gt; (like &lt;code&gt;subset()&lt;/code&gt; and &lt;code&gt;with()&lt;/code&gt; but built-in)&lt;/li&gt; 
 &lt;li&gt;any R expression using any package is allowed in &lt;code&gt;j&lt;/code&gt; argument, not just list of columns&lt;/li&gt; 
 &lt;li&gt;extra argument &lt;code&gt;by&lt;/code&gt; to compute &lt;code&gt;j&lt;/code&gt; expression by group&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(data.table)
DT = as.data.table(iris)

# FROM[WHERE, SELECT, GROUP BY]
# DT  [i,     j,      by]

DT[Petal.Width &amp;gt; 1.0, mean(Petal.Length), by = Species]
#      Species       V1
#1: versicolor 4.362791
#2:  virginica 5.552000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Getting started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://cran.r-project.org/package=data.table/vignettes/datatable-intro.html&quot;&gt;Introduction to data.table&lt;/a&gt; vignette&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Rdatatable/data.table/wiki/Getting-started&quot;&gt;Getting started&lt;/a&gt; wiki page&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://rdatatable.gitlab.io/data.table/reference/data.table.html#examples&quot;&gt;Examples&lt;/a&gt; produced by &lt;code&gt;example(data.table)&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cheatsheets&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rstudio/cheatsheets/master/datatable.pdf&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/rstudio/cheatsheets/master/pngs/datatable.png&quot; width=&quot;615&quot; height=&quot;242&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;data.table&lt;/code&gt; is widely used by the R community. It is being directly used by hundreds of CRAN and Bioconductor packages, and indirectly by thousands. It is one of the &lt;a href=&quot;https://medium.datadriveninvestor.com/most-starred-and-forked-github-repos-for-r-in-data-science-fb87a54d2a6a&quot;&gt;top most starred&lt;/a&gt; R packages on GitHub, and was highly rated by the &lt;a href=&quot;http://depsy.org/package/r/data.table&quot;&gt;Depsy project&lt;/a&gt;. If you need help, the &lt;code&gt;data.table&lt;/code&gt; community is active on &lt;a href=&quot;https://stackoverflow.com/questions/tagged/data.table&quot;&gt;StackOverflow&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;A list of packages that significantly support, extend, or make use of &lt;code&gt;data.table&lt;/code&gt; can be found in the &lt;a href=&quot;https://github.com/Rdatatable/data.table/raw/master/Seal_of_Approval.md&quot;&gt;Seal of Approval&lt;/a&gt; document.&lt;/p&gt; 
&lt;h3&gt;Stay up-to-date&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;click the &lt;strong&gt;Watch&lt;/strong&gt; button at the top and right of GitHub project page&lt;/li&gt; 
 &lt;li&gt;read &lt;a href=&quot;https://github.com/Rdatatable/data.table/raw/master/NEWS.md&quot;&gt;NEWS file&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;follow &lt;a href=&quot;https://twitter.com/hashtag/rdatatable&quot;&gt;#rdatatable&lt;/a&gt; and the &lt;a href=&quot;https://x.com/r_data_table&quot;&gt;r_data_table&lt;/a&gt; account on X/Twitter&lt;/li&gt; 
 &lt;li&gt;follow &lt;a href=&quot;https://fosstodon.org/tags/rdatatable&quot;&gt;#rdatatable&lt;/a&gt; and the &lt;a href=&quot;https://fosstodon.org/@r_data_table&quot;&gt;r_data_table account&lt;/a&gt; on fosstodon&lt;/li&gt; 
 &lt;li&gt;follow the &lt;a href=&quot;https://www.linkedin.com/company/data-table-community&quot;&gt;data.table community page&lt;/a&gt; on LinkedIn&lt;/li&gt; 
 &lt;li&gt;watch recent &lt;a href=&quot;https://github.com/Rdatatable/data.table/wiki/Presentations&quot;&gt;Presentations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;read recent &lt;a href=&quot;https://github.com/Rdatatable/data.table/wiki/Articles&quot;&gt;Articles&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;read posts on &lt;a href=&quot;https://rdatatable-community.github.io/The-Raft/&quot;&gt;The Raft&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Guidelines for filing issues / pull requests: &lt;a href=&quot;https://github.com/Rdatatable/data.table/raw/master/.github/CONTRIBUTING.md&quot;&gt;Contribution Guidelines&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>chris-mcginnis-ucsf/DoubletFinder</title>
      <link>https://github.com/chris-mcginnis-ucsf/DoubletFinder</link>
      <description>&lt;p&gt;R package for detecting doublets in single-cell RNA sequencing data&lt;/p&gt;&lt;hr&gt;&lt;p&gt;~~ Announcement (11/24/21) ~~ I&#39;m now a postdoc at Stanford and my UCSF email will be decommissioned soon. I also only check my github repos about once per month, so please reach out directly at cmcginni@stanford[dot]edu if you run into any issues.&lt;/p&gt; 
&lt;h1&gt;DoubletFinder&lt;/h1&gt; 
&lt;p&gt;DoubletFinder is an R package that predicts doublets in single-cell RNA sequencing data.&lt;/p&gt; 
&lt;p&gt;DoubletFinder is implemented to interface with Seurat &amp;gt;= 2.0 (&lt;a href=&quot;https://satijalab.org/seurat/&quot;&gt;https://satijalab.org/seurat/&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;DoubletFinder was published by Cell Systems in April, 2019: &lt;a href=&quot;https://www.cell.com/cell-systems/fulltext/S2405-4712(19)30073-0&quot;&gt;https://www.cell.com/cell-systems/fulltext/S2405-4712(19)30073-0&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;(02/02/2025) Haibo Liu (Senior Bioinformatician at UMass, @haibol2016) added as maintainer after his much-needed improvement updates to the package.&lt;/p&gt; 
&lt;p&gt;(11/21/2023) Made compatible with Seurat v5 and removed &#39;_v3&#39; flag from relevant function names.&lt;/p&gt; 
&lt;p&gt;(03/31/2020) Internalized functions normally in &#39;modes&#39; package to enable compatibility with R v3.6 and highger.&lt;/p&gt; 
&lt;p&gt;(06/21/2019) Added parallelization to paramSweep_v3 (thanks NathanSkeen!) -- Note: progress no longer updated, but the process is much faster! Fixed bug with smaller datasets. Updated readme.&lt;/p&gt; 
&lt;p&gt;(04/12/2019) Added SCTransform compatibilities to &#39;paramSweep_v3&#39; and &#39;doubletFinder_v3&#39;&lt;/p&gt; 
&lt;p&gt;(04/08/2019) Added &#39;PCs&#39; argument to &#39;doubletFinder&#39;, &#39;doubletFinder_v3&#39;, &#39;paramSweep&#39;, and &#39;paramSweep_v3&#39; to avoid conflicts with dimension reduction preferences. Updated readme.&lt;/p&gt; 
&lt;p&gt;(01/12/2019) Seurat V3 compatibility: &#39;doubletFinder_v3&#39; and &#39;paramSweep_v3&#39; functions added, other functions for parameter estimation remain compatible.&lt;/p&gt; 
&lt;h2&gt;DoubletFinder V2.0 (11/28/2018)&lt;/h2&gt; 
&lt;p&gt;New Features:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Increased computational efficiency during pANN computation&lt;/li&gt; 
 &lt;li&gt;Implemented strategy for determining optimal pK values for any scRNA-seq data using pN-pK parameter sweeps and mean-variance-normalized bimodality coefficient (BCmvn)&lt;/li&gt; 
 &lt;li&gt;Included vignette describing &#39;best-practices&#39; for applying DoubletFinder to scRNA-seq data generated without sample multiplexing&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Installation (in R/RStudio)&lt;/h2&gt; 
&lt;p&gt;remotes::install_github(&#39;chris-mcginnis-ucsf/DoubletFinder&#39;)&lt;/p&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;p&gt;DoubletFinder requires the following R packages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Seurat (&amp;gt;= 2.0)&lt;/li&gt; 
 &lt;li&gt;Matrix (1.2.14)&lt;/li&gt; 
 &lt;li&gt;fields (9.6)&lt;/li&gt; 
 &lt;li&gt;KernSmooth (2.23-15)&lt;/li&gt; 
 &lt;li&gt;ROCR (1.0-7)&lt;/li&gt; 
 &lt;li&gt;parallel (3.5.1)&lt;/li&gt; 
 &lt;li&gt;NOTE: These package versions were used in the bioRxiv paper, but other versions may work, as well.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; 
&lt;p&gt;Question: What is my anticipated doublet rate? Answer: This is dependent on your platform (10x, parse, etc.) and will vary with the number of input cells. It will not always be 7.5% as is used in the tutorial. This information is available in the user guides for each technology. See &lt;a href=&quot;https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/76&quot;&gt;https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/76&lt;/a&gt; and &lt;a href=&quot;https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/156&quot;&gt;https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/156&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Question: Can I run DoubletFinder on merged data from multiple 10x lanes? Answer: Technically yes but I would only do this if you were splitting the same sample across multiple lanes. You want to avoid instances where DoubletFinder is attempting to find doublets that do not actually exist in the data. I would also not advise running DF on integrated Seurat objects. See &lt;a href=&quot;https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/101&quot;&gt;https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/101&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Question: I see multiple potential pK values when visualizing BCmvn -- what should I do? Answer: I would spot check the results in GEX space to see what makes the most sense given your understanding of the data. See &lt;a href=&quot;https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/62&quot;&gt;https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/62&lt;/a&gt; and &lt;a href=&quot;https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/40&quot;&gt;https://github.com/chris-mcginnis-ucsf/DoubletFinder/issues/40&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;DoubletFinder Overview&lt;/h1&gt; 
&lt;p&gt;DoubletFinder can be broken up into 4 steps:&lt;/p&gt; 
&lt;p&gt;(1) Generate artificial doublets from existing scRNA-seq data&lt;/p&gt; 
&lt;p&gt;(2) Pre-process merged real-artificial data&lt;/p&gt; 
&lt;p&gt;(3) Perform PCA and use the PC distance matrix to find each cell&#39;s proportion of artificial k nearest neighbors (pANN)&lt;/p&gt; 
&lt;p&gt;(4) Rank order and threshold pANN values according to the expected number of doublets&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/chris-mcginnis-ucsf/DoubletFinder/master/DF.screenshots/DoubletFinderOverview.png&quot; alt=&quot;alternativetext&quot;&gt;&lt;/p&gt; 
&lt;p&gt;DoubletFinder takes the following arguments:&lt;/p&gt; 
&lt;p&gt;seu ~ This is a fully-processed Seurat object (i.e., after NormalizeData, FindVariableGenes, ScaleData, RunPCA, and RunTSNE have all been run).&lt;/p&gt; 
&lt;p&gt;PCs ~ The number of statistically-significant principal components, specified as a range (e.g., PCs = 1:10)&lt;/p&gt; 
&lt;p&gt;pN ~ This defines the number of generated artificial doublets, expressed as a proportion of the merged real-artificial data. Default is set to 25%, based on observation that DoubletFinder performance is largely pN-invariant (see McGinnis, Murrow and Gartner 2019, Cell Systems).&lt;/p&gt; 
&lt;p&gt;pK ~ This defines the PC neighborhood size used to compute pANN, expressed as a proportion of the merged real-artificial data. No default is set, as pK should be adjusted for each scRNA-seq dataset. Optimal pK values should be estimated using the strategy described below.&lt;/p&gt; 
&lt;p&gt;nExp ~ This defines the pANN threshold used to make final doublet/singlet predictions. This value can best be estimated from cell loading densities into the 10X/Drop-Seq device, and adjusted according to the estimated proportion of homotypic doublets.&lt;/p&gt; 
&lt;h2&gt;Application to Cell Hashing and Demuxlet data&lt;/h2&gt; 
&lt;p&gt;DoubletFinder successfully recapitulates ground-truth doublet classifications determined using antibody-barcode sample multiplexing (Cell Hashing) and SNP deconvolution (Demuxlet). DoubletFinder identifies false-negative Demuxlet classifications caused by doublets formed from cells with identical SNP profiles. DoubletFinder is insensitive to homotypic doublets -- i.e., doublets dervied from transcriptionally-similar cell states.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/chris-mcginnis-ucsf/DoubletFinder/master/DF.screenshots/Results_Demux.png&quot; alt=&quot;alternativetext&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/chris-mcginnis-ucsf/DoubletFinder/master/DF.screenshots/Results_Hashing.png&quot; alt=&quot;alternativetext&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&#39;Best-Practices&#39; for scRNA-seq data generated without sample multiplexing&lt;/h1&gt; 
&lt;h2&gt;Input scRNA-seq Data&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Do not apply DoubletFinder to aggregated scRNA-seq data representing multiple &lt;em&gt;distinct&lt;/em&gt; samples (e.g., multiple 10X lanes). For example, if you run DoubletFinder on aggregated data representing WT and mutant cell lines sequenced across different 10X lanes, artificial doublets will be generated from WT and mutant cells, which cannot exist in your data. These artificial doublets will skew results. Notably, it is okay to run DoubletFinder on data generated by splitting a single sample across multiple 10X lanes.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ensure that input data is cleared of low-quality cell clusters. There are a variety of ways to do this, but I usually use the following workflow:&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;Manually threshold raw gene expression matrices according to RNA nUMIs (especially important when dealing with super-loaded 10X data because of the way CellRanger threholds data -- See Lun et al., 2019, Genome Biology.&lt;/li&gt; 
 &lt;li&gt;Pre-process data using standard workflow.&lt;/li&gt; 
 &lt;li&gt;Identify clusters with (A) low RNA UMIs, (B) High % mitochondrial reads, and/or (C) Uninformative marker genes.&lt;/li&gt; 
 &lt;li&gt;Remove clusters, pre-process again, and run DoubletFinder.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;pK Selection&lt;/h2&gt; 
&lt;p&gt;ROC analysis across pN-pK parameter sweeps for Cell Hashing and Demuxlet datasets demonstrate that DoubletFinder performance is largely invariant of pN value selection:&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/chris-mcginnis-ucsf/DoubletFinder/master/DF.screenshots/ParamSweep_Schematic.png&quot; alt=&quot;alternativetext&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/chris-mcginnis-ucsf/DoubletFinder/master/DF.screenshots/ParamSweep_HeatMap.png&quot; alt=&quot;alternativetext&quot;&gt;&lt;/p&gt; 
&lt;p&gt;ROC analysis across pN-pK parameter sweeps for simulated scRNA-seq data with (I) Variable numbers of cell states and (II) Variable magnitudes of transcriptional heterogeneity demonstrates that (I) Optimal pK value selection depends on the total number of cell states and (II) DoubletFinder performance suffers when applied to transcriptionally-homogenous data. Simulated data was generated using a strategy similar to as described in Wolock, Lopex &amp;amp; Klein 2019, Cell Systems.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/chris-mcginnis-ucsf/DoubletFinder/master/DF.screenshots/Simulation_Schematic.png&quot; alt=&quot;alternativetext&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/chris-mcginnis-ucsf/DoubletFinder/master/DF.screenshots/Results_Simulation.png&quot; alt=&quot;alternativetext&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Simulated and sample-multiplexed data are unique in that ground-truth doublet classifications can be leveraged to characterize how DoubletFinder parameters must be &#39;fit&#39; to distinct scRNA-seq datasets. However, doublets remain unknown in real-world contexts -- which is likely why you are interested in DoubletFinder, at all!&lt;/p&gt; 
&lt;p&gt;To maximize the accuracy of DoubletFinder predictions, we sought a ground-truth-agnostic metric that coincides with pK values that maximize AUC in Cell Hashing and Demuxlet data. Mean-variance normalized bimodality coefficient (BCmvn) achieves this goal, featuring a single, easily-discernible maximum at pK values that optimize AUC.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/chris-mcginnis-ucsf/DoubletFinder/master/DF.screenshots/BCmvn.png&quot; alt=&quot;alternativetext&quot;&gt;&lt;/p&gt; 
&lt;p&gt;BCmvn distributions also feature a single maximum for scRNA-seq datasets generated without sample-multiplexing (e.g., Mouse pancreas, Byrnes et al., 2018, Nature Communcations; Mouse kidney, Park et al., 2018, Science), enabling pK selection.&lt;/p&gt; 
&lt;h2&gt;Doublet Number Estimation&lt;/h2&gt; 
&lt;p&gt;DoubletFinder is sensitive to heterotypic doublets -- i.e., doublets formed from transcriptionally-distinct cell states -- but is insensitive to homotypic doublets -- i.e., doublets formed from transcriptionally-similar cell states. In our original manuscript, we suggested using DoubletFinder to predict the number of doublets expected from Poisson statistical estimates realting to the droplet microfluidics cell loading density. However, Poisson estimates are agnostic of homotypic doublets, and will thus invariably overestimate the number of &lt;em&gt;detectable&lt;/em&gt; doublets.&lt;/p&gt; 
&lt;p&gt;To address this issue, we suggest users utilize literature-supported cell type annotations to model the proportion of homotypic doublets present in their data. As an example, we present an analysis of mouse kidney scRNA-seq data (Park et al., 2018, Science):&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/chris-mcginnis-ucsf/DoubletFinder/master/DF.screenshots/HomotypicAdjustment.png&quot; alt=&quot;alternativetext&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Notably, it is conceivable that literature-suppoted cell type annotations may not accurately recapitulate the magnitude of transcriptional divergence necessary for DoubletFinder sensitivity. For example, nominally-homogenous cells (e.g., CD4+ T-cells) may exist along a spectrum of gene expression states (e.g., distinct anatomical locations, disease states, naive/Tregs/Th17 cells, etc.), and doublets formed by cell sub-types may be detectable by DoubletFinder. Thus, we consider doublet number estimates based on Poisson statistics with and without homotypic doublet proportion adjustment to &#39;bookend&#39; the real detectable doublet rate.&lt;/p&gt; 
&lt;h2&gt;Example code for &#39;real-world&#39; applications&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-R&quot;&gt;## Pre-process Seurat object (standard) --------------------------------------------------------------------------------------
seu_kidney &amp;lt;- CreateSeuratObject(kidney.data)
seu_kidney &amp;lt;- NormalizeData(seu_kidney)
seu_kidney &amp;lt;- FindVariableFeatures(seu_kidney, selection.method = &quot;vst&quot;, nfeatures = 2000)
seu_kidney &amp;lt;- ScaleData(seu_kidney)
seu_kidney &amp;lt;- RunPCA(seu_kidney)
seu_kidney &amp;lt;- RunUMAP(seu_kidney, dims = 1:10)

## Pre-process Seurat object (sctransform) -----------------------------------------------------------------------------------
seu_kidney &amp;lt;- CreateSeuratObject(kidney.data)
seu_kidney &amp;lt;- SCTransform(seu_kidney)
seu_kidney &amp;lt;- RunPCA(seu_kidney)
seu_kidney &amp;lt;- RunUMAP(seu_kidney, dims = 1:10)

## pK Identification (no ground-truth) ---------------------------------------------------------------------------------------
sweep.res.list_kidney &amp;lt;- paramSweep(seu_kidney, PCs = 1:10, sct = FALSE)
sweep.stats_kidney &amp;lt;- summarizeSweep(sweep.res.list_kidney, GT = FALSE)
bcmvn_kidney &amp;lt;- find.pK(sweep.stats_kidney)

## pK Identification (ground-truth) ------------------------------------------------------------------------------------------
sweep.res.list_kidney &amp;lt;- paramSweep(seu_kidney, PCs = 1:10, sct = FALSE)
gt.calls &amp;lt;- seu_kidney@meta.data[rownames(sweep.res.list_kidney[[1]]), &quot;GT&quot;].   ## GT is a vector containing &quot;Singlet&quot; and &quot;Doublet&quot; calls recorded using sample multiplexing classification and/or in silico geneotyping results 
sweep.stats_kidney &amp;lt;- summarizeSweep(sweep.res.list_kidney, GT = TRUE, GT.calls = gt.calls)
bcmvn_kidney &amp;lt;- find.pK(sweep.stats_kidney)

## Homotypic Doublet Proportion Estimate -------------------------------------------------------------------------------------
homotypic.prop &amp;lt;- modelHomotypic(annotations)           ## ex: annotations &amp;lt;- seu_kidney@meta.data$ClusteringResults
nExp_poi &amp;lt;- round(0.075*nrow(seu_kidney@meta.data))  ## Assuming 7.5% doublet formation rate - tailor for your dataset
nExp_poi.adj &amp;lt;- round(nExp_poi*(1-homotypic.prop))

## Run DoubletFinder with varying classification stringencies ----------------------------------------------------------------
seu_kidney &amp;lt;- doubletFinder(seu_kidney, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi, reuse.pANN = NULL, sct = FALSE)
seu_kidney &amp;lt;- doubletFinder(seu_kidney, PCs = 1:10, pN = 0.25, pK = 0.09, nExp = nExp_poi.adj, reuse.pANN = &quot;pANN_0.25_0.09_913&quot;, sct = FALSE)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/chris-mcginnis-ucsf/DoubletFinder/master/DF.screenshots/DFkidney_low.vs.high.png&quot; alt=&quot;alternativetext&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Other Doublet Detection Methods&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/AllonKleinLab/scrublet&quot;&gt;Scrublet&lt;/a&gt; &lt;a href=&quot;https://github.com/EDePasquale/DoubletDecon&quot;&gt;DoubletDecon&lt;/a&gt; &lt;a href=&quot;https://github.com/JonathanShor/DoubletDetection&quot;&gt;DoubletDetection&lt;/a&gt; &lt;a href=&quot;https://github.com/calico/solo&quot;&gt;Solo&lt;/a&gt; &lt;a href=&quot;https://github.com/kostkalab/scds&quot;&gt;scds&lt;/a&gt; &lt;a href=&quot;https://github.com/plger/scDblFinder&quot;&gt;scDblFinder&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;References&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Stoeckius M, Zheng S, Houck-Loomis B, Hao S, Yeung BZ, Smibert P, Satija R. Cell Hashing with barcoded antibodies enables multiplexing and doublet detection for single cell genomics. Genome Biology. 2018. 19:224.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Kang HM, Subramaniam M, Targ S, Nguyen M, Maliskova L, McCarthy E, Wan E, Wong S, Byrnes L, Lanata CM, Gate RE, Mostafavi S, Marson A, Zaitlen N, Criswell LA, Ye JC. Multiplexed droplet single-cell RNA-sequencing using natural genetic variation. Nature Biotechnology. 2018. 36(1):89-94.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Wolock SL, Lopez R, Klein AM. Scrublet: Computational Identification of Cell Doublets in Single-Cell Transcriptomic Data. Cell Systems. 2019. 8(4):281-291.e9.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Park J, Shrestha R, Qiu C, Kondo A, Huang S, Werth M, Li M, Barasch J, Suszták K. Single-cell transcriptomics of the mouse kidney reveals potential cellular targets of kidney disease. Science. 2018. 360(6390):758-63.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Byrnes LE, Wong DM, Subramaniam M, Meyer NP, Gilchrist CL, Knox SM, Tward AD, Ye CJ, Sneddon JB. Lineage dynamics of murine pancreatic development at single-cell resolution. Nature Communications. 2018; 9:3922.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Bais AS, Kostka D. scds: computational annotation of doublets in single-cell RNA sequencing data. Bioinformatics. 2020. 36(4):1150-8.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Bernstein NJ, Fong NL, Lam I, Roy MA, Hendrickson DG, Kelley DR. Solo: Doublet Identification in Single-Cell RNA-Seq via Semi-Supervised Deep Learning. Cell Systems. 2020. S2405-4712(20)30195-2.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DePasquale EAK, Schnell DJ, Van Camp PJ, Valiente-Alandi I, Blaxall BC, Grimes HL, Singh H, Salomonis N. DoubletDecon: Deconvoluting Doublets from Single-Cell RNA-Sequencing Data. Cell Reports. 2019. 29(6):1718-27.e8.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>r-spatial/sf</title>
      <link>https://github.com/r-spatial/sf</link>
      <description>&lt;p&gt;Simple Features for R&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/r-spatial/sf/actions/workflows/R-CMD-check.yaml&quot;&gt;&lt;img src=&quot;https://github.com/r-spatial/sf/actions/workflows/R-CMD-check.yaml/badge.svg?sanitize=true&quot; alt=&quot;R-CMD-check&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/r-spatial/sf/actions/workflows/tic-db.yml&quot;&gt;&lt;img src=&quot;https://github.com/r-spatial/sf/actions/workflows/tic-db.yml/badge.svg?sanitize=true&quot; alt=&quot;tic-db&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://app.codecov.io/gh/r-spatial/sf&quot;&gt;&lt;img src=&quot;https://img.shields.io/codecov/c/github/r-spatial/sf/main.svg?sanitize=true&quot; alt=&quot;Coverage Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://www.gnu.org/licenses/gpl-2.0.html&quot;&gt;&lt;img src=&quot;http://img.shields.io/badge/license-GPL%20%28%3E=%202%29-brightgreen.svg?style=flat&quot; alt=&quot;License&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://cran.r-project.org/package=sf&quot;&gt;&lt;img src=&quot;https://www.r-pkg.org/badges/version/sf&quot; alt=&quot;CRAN&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://cran.r-project.org/web/checks/check_results_sf.html&quot;&gt;&lt;img src=&quot;https://badges.cranchecks.info/worst/sf.svg?sanitize=true&quot; alt=&quot;cran checks&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.r-pkg.org/pkg/sf&quot;&gt;&lt;img src=&quot;https://cranlogs.r-pkg.org/badges/sf?color=brightgreen&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://CRAN.R-project.org/package=sf&quot;&gt;&lt;img src=&quot;https://tinyverse.netlify.app/badge/sf&quot; alt=&quot;status&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- badges: end --&gt; 
&lt;h1&gt;Simple Features for R&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://gist.github.com/edzer/f461a3a95570c4ab7edf3125c2f19d20&quot;&gt;&lt;img align=&quot;right&quot; src=&quot;https://user-images.githubusercontent.com/520851/34887433-ce1d130e-f7c6-11e7-83fc-d60ad4fae6bd.gif&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A package that provides &lt;a href=&quot;https://en.wikipedia.org/wiki/Simple_Features&quot;&gt;simple features access&lt;/a&gt; for R.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/r-spatial/sf/main/#blogs-presentations-vignettes-sp-sf-wiki&quot;&gt;Blogs, links&lt;/a&gt; • &lt;a href=&quot;https://raw.githubusercontent.com/r-spatial/sf/main/#cheatsheet&quot;&gt;Cheatsheet&lt;/a&gt; • &lt;a href=&quot;https://raw.githubusercontent.com/r-spatial/sf/main/#installing&quot;&gt;Installing&lt;/a&gt; • &lt;a href=&quot;https://raw.githubusercontent.com/r-spatial/sf/main/#contributing&quot;&gt;Contributing&lt;/a&gt; • &lt;a href=&quot;https://raw.githubusercontent.com/r-spatial/sf/main/#acknowledgment&quot;&gt;Acknowledgment&lt;/a&gt; • &lt;a href=&quot;https://raw.githubusercontent.com/r-spatial/sf/main/#how-to-cite&quot;&gt;How to cite&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Package sf:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;represents simple features as records in a &lt;code&gt;data.frame&lt;/code&gt; or &lt;code&gt;tibble&lt;/code&gt; with a geometry list-column&lt;/li&gt; 
 &lt;li&gt;represents natively in R all 17 simple feature types for all dimensions (XY, XYZ, XYM, XYZM)&lt;/li&gt; 
 &lt;li&gt;interfaces to &lt;a href=&quot;https://libgeos.org&quot;&gt;GEOS&lt;/a&gt; for geometrical operations on projected coordinates, and (through R package &lt;a href=&quot;https://cran.r-project.org/package=s2&quot;&gt;s2&lt;/a&gt;) to &lt;a href=&quot;http://s2geometry.io/&quot;&gt;s2geometry&lt;/a&gt; for geometrical operations on ellipsoidal coordinates&lt;/li&gt; 
 &lt;li&gt;interfaces to &lt;a href=&quot;https://gdal.org/&quot;&gt;GDAL&lt;/a&gt;, supporting all driver options, &lt;code&gt;Date&lt;/code&gt; and &lt;code&gt;POSIXct&lt;/code&gt; and list-columns&lt;/li&gt; 
 &lt;li&gt;interfaces to &lt;a href=&quot;http://proj.org/&quot;&gt;PRØJ&lt;/a&gt; for coordinate reference system conversion and transformation&lt;/li&gt; 
 &lt;li&gt;uses &lt;a href=&quot;https://en.wikipedia.org/wiki/Well-known_text#Well-known_binary&quot;&gt;well-known-binary&lt;/a&gt; serialisations written in C++/Rcpp for fast I/O with GDAL and GEOS&lt;/li&gt; 
 &lt;li&gt;reads from and writes to spatial databases such as &lt;a href=&quot;http://postgis.net/&quot;&gt;PostGIS&lt;/a&gt; using &lt;a href=&quot;https://cran.r-project.org/package=DBI&quot;&gt;DBI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;is extended by 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://github.com/r-spatial/lwgeom/&quot;&gt;lwgeom&lt;/a&gt; for selected liblwgeom/PostGIS functions&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://github.com/r-spatial/stars/&quot;&gt;stars&lt;/a&gt; for raster data, and raster or vector data cubes (spatial time series)&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://luukvdmeer.github.io/sfnetworks/&quot;&gt;sfnetworks&lt;/a&gt; for geospatial network data&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://gist.github.com/edzer/442d74a5775abcd5068cf3e73b23687b&quot;&gt;&lt;img align=&quot;left&quot; src=&quot;https://user-images.githubusercontent.com/520851/50280460-e35c1880-044c-11e9-9ed7-cc46754e49db.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;(Illustration (c) 2018 by &lt;a href=&quot;https://twitter.com/allison_horst/status/1071456081308614656&quot;&gt;Allison Horst&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;Books, journal articles, blogs, presentations, vignettes, sp-sf wiki&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;an open access &lt;a href=&quot;https://journal.r-project.org/archive/2018/RJ-2018-009/index.html&quot;&gt;R Journal article&lt;/a&gt; summarizes the package&lt;/li&gt; 
 &lt;li&gt;two books: &lt;a href=&quot;https://r-spatial.org/book/&quot;&gt;Spatial Data Science: with applications in R&lt;/a&gt;, &lt;a href=&quot;https://r.geocompx.org/&quot;&gt;Geocomputation with R&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;package vignettes: &lt;a href=&quot;https://r-spatial.github.io/sf/articles/sf1.html&quot;&gt;first&lt;/a&gt;, &lt;a href=&quot;https://r-spatial.github.io/sf/articles/sf2.html&quot;&gt;second&lt;/a&gt;, &lt;a href=&quot;https://r-spatial.github.io/sf/articles/sf3.html&quot;&gt;third&lt;/a&gt;, &lt;a href=&quot;https://r-spatial.github.io/sf/articles/sf4.html&quot;&gt;fourth&lt;/a&gt;, &lt;a href=&quot;https://r-spatial.github.io/sf/articles/sf5.html&quot;&gt;fifth&lt;/a&gt;, &lt;a href=&quot;https://r-spatial.github.io/sf/articles/sf6.html&quot;&gt;sixth&lt;/a&gt;, &lt;a href=&quot;https://r-spatial.github.io/sf/articles/sf7.html&quot;&gt;seventh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;blog posts: &lt;a href=&quot;https://r-spatial.org/r/2016/02/15/simple-features-for-r.html&quot;&gt;first&lt;/a&gt;, &lt;a href=&quot;https://r-spatial.org/r/2016/07/18/sf2.html&quot;&gt;second&lt;/a&gt;, &lt;a href=&quot;https://r-spatial.org/r/2016/11/02/sfcran.html&quot;&gt;third&lt;/a&gt;, &lt;a href=&quot;https://r-spatial.org/r/2017/01/12/newssf.html&quot;&gt;fourth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the original R Consortium ISC &lt;a href=&quot;https://raw.githubusercontent.com/r-spatial/sf/main/PROPOSAL.md&quot;&gt;proposal&lt;/a&gt;, the R Consortium &lt;a href=&quot;https://www.r-consortium.org/blog/2017/01/03/simple-features-now-on-cran&quot;&gt;blog post&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;presentations: &lt;a href=&quot;https://edzer.github.io/rstudio_conf/#1&quot;&gt;rstudio::conf 2018&lt;/a&gt; (&lt;a href=&quot;https://posit.co/resources/videos/tidy-spatial-data-analysis/&quot;&gt;video&lt;/a&gt;), &lt;a href=&quot;http://pebesma.staff.ifgi.de/pebesma_sfr.pdf&quot;&gt;UseR! 2016&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;wiki page describing &lt;a href=&quot;https://github.com/r-spatial/sf/wiki/Migrating&quot;&gt;sp-sf migration&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cheatsheet&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://creativecommons.org/licenses/by/4.0/&quot;&gt;CC 4.0&lt;/a&gt; BY &lt;a href=&quot;https://github.com/ryangarnett&quot;&gt;Ryan Garnett&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/rstudio/cheatsheets/raw/main/sf.pdf&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/sf.png&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installing&lt;/h2&gt; 
&lt;p&gt;Install either from CRAN with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;sf&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will install binary packages on Windows and MacOS, unless you configured R such that it tries to install source packages; in that case, see below.&lt;/p&gt; 
&lt;p&gt;Install development versions from GitHub with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(remotes)
install_github(&quot;r-spatial/sf&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;Installing sf from source works under Windows when &lt;a href=&quot;https://cran.r-project.org/bin/windows/Rtools/&quot;&gt;Rtools&lt;/a&gt; is installed.&lt;/p&gt; 
&lt;h3&gt;MacOS&lt;/h3&gt; 
&lt;p&gt;MacOS users are strongly encouraged to install the &lt;code&gt;sf&lt;/code&gt; binary packages from CRAN, unless they are familiar with compilers, linking, C++ source code, and homebrew.&lt;/p&gt; 
&lt;p&gt;The easiest way to install &lt;code&gt;gdal&lt;/code&gt; is using Homebrew. Recent versions of Homebrew include a full-featured up-to-date &lt;a href=&quot;https://github.com/Homebrew/homebrew-core/raw/master/Formula/g/gdal.rb&quot;&gt;gdal formula&lt;/a&gt;, which installs &lt;code&gt;proj&lt;/code&gt; and &lt;code&gt;gdal&lt;/code&gt; at the same time:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;brew install pkg-config
brew install gdal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once gdal is installed, you will be able to install &lt;code&gt;sf&lt;/code&gt; package from source in R. With the current version of &lt;code&gt;proj&lt;/code&gt; on homebrew, installation requires additional configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;sf&quot;, type = &quot;source&quot;, configure.args = &quot;--with-proj-lib=$(brew --prefix)/lib/&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or the development version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(remotes)
install_github(&quot;r-spatial/sf&quot;, configure.args = &quot;--with-proj-lib=$(brew --prefix)/lib/&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using &lt;code&gt;sf&lt;/code&gt; and &lt;code&gt;rgdal&lt;/code&gt; together, it is necessary to install &lt;code&gt;rgdal&lt;/code&gt; from source using this configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;rgdal&quot;, type = &quot;source&quot;, configure.args = c(&quot;--with-proj-lib=$(brew --prefix)/lib/&quot;, &quot;--with-proj-include=$(brew --prefix)/include/&quot;))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, &lt;a href=&quot;https://stat.ethz.ch/pipermail/r-sig-mac/2017-June/012429.html&quot;&gt;these instructions&lt;/a&gt; explain how to install gdal using kyngchaos frameworks.&lt;/p&gt; 
&lt;p&gt;For Mac OS 11 Big Sur source install instruction, see &lt;a href=&quot;https://github.com/r-spatial/sf/issues/1536#issuecomment-727342736&quot;&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;p&gt;For Unix-alikes, GDAL (&amp;gt;= 2.0.1), GEOS (&amp;gt;= 3.4.0) and Proj.4 (&amp;gt;= 4.8.0) are required.&lt;/p&gt; 
&lt;h4&gt;Ubuntu&lt;/h4&gt; 
&lt;p&gt;Dependencies for recent versions of Ubuntu (18.04 and later) are available in the official repositories; you can install them with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;apt-get -y update &amp;amp;&amp;amp; apt-get install -y  libudunits2-dev libgdal-dev libgeos-dev libproj-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;However, to get more up-to-date versions of dependencies such as GDAL, we recommend adding the &lt;a href=&quot;http://ppa.launchpad.net/ubuntugis/ubuntugis-unstable/ubuntu/&quot;&gt;ubuntugis-unstable&lt;/a&gt; PPA to the package repositories and installing them as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable
sudo apt-get update
sudo apt-get install libudunits2-dev libgdal-dev libgeos-dev libproj-dev libsqlite0-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Adding this PPA is required for installing &lt;code&gt;sf&lt;/code&gt; on older versions of Ubuntu (e.g. Xenial).&lt;/p&gt; 
&lt;p&gt;Another option, for advanced users, is to install dependencies from source; see e.g. an older &lt;a href=&quot;https://github.com/r-spatial/sf/raw/593ee48b34001fe3b383ea73ea57063ecf690732/.travis.yml&quot;&gt;Travis&lt;/a&gt; config file for hints.&lt;/p&gt; 
&lt;h4&gt;Fedora&lt;/h4&gt; 
&lt;p&gt;The following command installs all required dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;sudo dnf install gdal-devel proj-devel geos-devel sqlite-devel udunits2-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Arch&lt;/h4&gt; 
&lt;p&gt;Get gdal, proj, geos and podofo from the main repos, and udunits from the AUR:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pacman -S gdal proj geos arrow podofo
yay/pacaur/yaourt/whatever -S udunits
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;code&gt;renv&lt;/code&gt; or &lt;code&gt;conda&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;There are several reports that &lt;code&gt;sf&lt;/code&gt; fails to install as a source package when R is used with &lt;code&gt;renv&lt;/code&gt;, or when R is installed in a &lt;code&gt;conda&lt;/code&gt; environment. If you experience this, please do not raise an issue here, but&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;try to sort this out with the &lt;code&gt;renv&lt;/code&gt; developers or the &lt;code&gt;conda&lt;/code&gt; maintainers, or&lt;/li&gt; 
 &lt;li&gt;try to use binary installs of the &lt;code&gt;sf&lt;/code&gt; package, e.g. from &lt;a href=&quot;https://github.com/eddelbuettel/r2u&quot;&gt;r2u&lt;/a&gt;, or the Posit package manager&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Other&lt;/h4&gt; 
&lt;p&gt;To install on Debian, the &lt;a href=&quot;https://github.com/rocker-org/geospatial&quot;&gt;rocker geospatial&lt;/a&gt; Dockerfiles may be helpful. Ubuntu Dockerfiles are found &lt;a href=&quot;https://github.com/r-spatial/sf/tree/main/inst/docker&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Multiple GDAL, GEOS and/or PROJ versions on your system&lt;/h3&gt; 
&lt;p&gt;If you use dynamic linking (installation from source) and have multiple versions of these libraries installed (e.g. one from ubuntugis-unstable, another installed from source in &lt;code&gt;/usr/local/lib&lt;/code&gt;) then this will in general not work, even when setting &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; manually. See &lt;a href=&quot;https://github.com/r-spatial/sf/issues/844&quot;&gt;here&lt;/a&gt; for the reason why.&lt;/p&gt; 
&lt;h3&gt;lwgeom&lt;/h3&gt; 
&lt;p&gt;Functions and methods that require &lt;code&gt;liblwgeom&lt;/code&gt;, including ellipsoidal (not spherical or Euclidean) metrics (area, distances), are provide by and used from &lt;a href=&quot;https://github.com/r-spatial/lwgeom&quot;&gt;lwgeom&lt;/a&gt;, which is also on &lt;a href=&quot;https://cran.r-project.org/package=lwgeom&quot;&gt;CRAN&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Contributions of all sorts are most welcome, issues and pull requests are the preferred ways of sharing them.&lt;/li&gt; 
 &lt;li&gt;When contributing pull requests, please adhere to the package style (in package code use &lt;code&gt;=&lt;/code&gt; rather than &lt;code&gt;&amp;lt;-&lt;/code&gt;; don&#39;t change indentation; tab stops of 4 spaces are preferred).&lt;/li&gt; 
 &lt;li&gt;This project is released with a &lt;a href=&quot;https://raw.githubusercontent.com/r-spatial/sf/main/CONDUCT.md&quot;&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project, you agree to abide by its terms.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to cite&lt;/h2&gt; 
&lt;p&gt;Package &lt;code&gt;sf&lt;/code&gt; can be cited as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Edzer Pebesma, 2018. Simple Features for R: Standardized Support for Spatial Vector Data. The R Journal &lt;a href=&quot;https://journal.r-project.org/archive/2018/RJ-2018-009/index.html&quot;&gt;10:1, 439-446.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Pebesma, E.; Bivand, R. (2023). &lt;a href=&quot;https://r-spatial.org/book/&quot;&gt;Spatial Data Science: With Applications in R&lt;/a&gt; (1st ed.). 314 pages. &lt;a href=&quot;https://doi.org/10.1201/9780429459016&quot;&gt;Chapman and Hall/CRC&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgment&lt;/h2&gt; 
&lt;p&gt;This project gratefully acknowledges financial &lt;a href=&quot;https://www.r-consortium.org/projects&quot;&gt;support&lt;/a&gt; from the&lt;/p&gt; 
&lt;a href=&quot;https://r-consortium.org/all-projects/2016-group-1.html#simple-features-for-r&quot;&gt; &lt;img src=&quot;https://r-consortium.org/images/RConsortium_Horizontal_Pantone.webp&quot; width=&quot;300&quot;&gt; &lt;/a&gt; 
&lt;!--
&lt;img src=&quot;http://pebesma.staff.ifgi.de/RConsortium_Horizontal_Pantone.png&quot; width=&quot;300&quot;&gt;
--&gt;</description>
    </item>
    
    <item>
      <title>satijalab/seurat</title>
      <link>https://github.com/satijalab/seurat</link>
      <description>&lt;p&gt;R toolkit for single cell genomics&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://cran.r-project.org/package=Seurat&quot;&gt;&lt;img src=&quot;https://www.r-pkg.org/badges/version/Seurat&quot; alt=&quot;CRAN Version&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://cran.r-project.org/package=Seurat&quot;&gt;&lt;img src=&quot;https://cranlogs.r-pkg.org/badges/Seurat&quot; alt=&quot;CRAN Downloads&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Seurat v5&lt;/h1&gt; 
&lt;p&gt;Seurat is an R toolkit for single cell genomics, developed and maintained by the Satija Lab at NYGC.&lt;/p&gt; 
&lt;p&gt;We are excited to release Seurat v5! This updates introduces new functionality for spatial, multimodal, and scalable single-cell analysis.&lt;/p&gt; 
&lt;p&gt;Seurat v5 is backwards-compatible with previous versions, so that users will continue to be able to re-run existing workflows.&lt;/p&gt; 
&lt;p&gt;Instructions, documentation, and tutorials can be found at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://satijalab.org/seurat&quot;&gt;https://satijalab.org/seurat&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Seurat is also hosted on GitHub, you can view and clone the repository at&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/satijalab/seurat&quot;&gt;https://github.com/satijalab/seurat&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Seurat has been successfully installed on Mac OS X, Linux, and Windows, using the devtools package to install directly from GitHub&lt;/p&gt; 
&lt;p&gt;Improvements and new features will be added on a regular basis, please post on the &lt;a href=&quot;https://github.com/satijalab/seurat&quot;&gt;github page&lt;/a&gt; with any questions or if you would like to contribute&lt;/p&gt; 
&lt;p&gt;For a version history/changelog, please see the &lt;a href=&quot;https://github.com/satijalab/seurat/raw/master/NEWS.md&quot;&gt;NEWS file&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>joey711/phyloseq</title>
      <link>https://github.com/joey711/phyloseq</link>
      <description>&lt;p&gt;phyloseq is a set of classes, wrappers, and tools (in R) to make it easier to import, store, and analyze phylogenetic sequencing data; and to reproducibly share that data and analysis with others. See the phyloseq front page:&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href=&quot;http://joey711.github.com/phyloseq/&quot;&gt;phyloseq&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://travis-ci.org/joey711/phyloseq&quot;&gt;&lt;img src=&quot;https://travis-ci.org/joey711/phyloseq.svg?branch=master&quot; alt=&quot;Travis-CI Build Status&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/joey711/phyloseq/master/inst/extdata/phyloseq.png&quot; alt=&quot;phyloseq&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Install&lt;/h2&gt; 
&lt;p&gt;In R terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;if(!requireNamespace(&quot;BiocManager&quot;)){
  install.packages(&quot;BiocManager&quot;)
}
BiocManager::install(&quot;phyloseq&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href=&quot;http://joey711.github.io/phyloseq/install.html&quot;&gt;the phyloseq installation page&lt;/a&gt; for further details, examples.&lt;/p&gt; 
&lt;h2&gt;Article on Improved Microbiome Analysis&lt;/h2&gt; 
&lt;p&gt;McMurdie and Holmes (2014) &lt;a href=&quot;http://dx.plos.org/10.1371/journal.pcbi.1003531&quot;&gt;Waste Not, Want Not: Why Rarefying Microbiome Data is Statistically Inadmissible&lt;/a&gt; &lt;em&gt;PLoS Computational Biology&lt;/em&gt; 10(4): e1003531&lt;/p&gt; 
&lt;p&gt;Presubmission versions ahead of acceptance (2013): &lt;a href=&quot;http://arxiv.org/pdf/1310.0424v2.pdf&quot;&gt;PDF version 2&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/pdf/1310.0424v1.pdf&quot;&gt;PDF version 1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Peer-reviewed articles about phyloseq&lt;/h2&gt; 
&lt;p&gt;McMurdie and Holmes (2014) &lt;a href=&quot;http://bioinformatics.oxfordjournals.org/content/early/2014/10/02/bioinformatics.btu616&quot;&gt;Shiny-phyloseq: Web Application for Interactive Microbiome Analysis with Provenance Tracking&lt;/a&gt;. &lt;em&gt;Bioinformatics (Oxford, England)&lt;/em&gt; 31(2), 282–283.&lt;/p&gt; 
&lt;p&gt;McMurdie and Holmes (2013) &lt;a href=&quot;http://dx.plos.org/10.1371/journal.pone.0061217&quot;&gt;phyloseq: An R package for reproducible interactive analysis and graphics of microbiome census data&lt;/a&gt; &lt;em&gt;PLoS ONE&lt;/em&gt; 8(4):e61217&lt;/p&gt; 
&lt;h2&gt;Other resources&lt;/h2&gt; 
&lt;p&gt;The phyloseq project also has a number of supporting online resources, including (but probably not limited to)&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;http://joey711.github.com/phyloseq/&quot;&gt;the phyloseq home page&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html&quot;&gt;the phyloseq FAQ&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;I recommend checking this page, and the issues tracker, before posting new issues.&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;http://bioconductor.org/packages/release/bioc/html/phyloseq.html&quot;&gt;Bioconductor stable release&lt;/a&gt;.&lt;/h3&gt; 
&lt;h3&gt;&lt;a href=&quot;https://github.com/joey711/phyloseq/issues&quot;&gt;the phyloseq Issue Tracker&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;This is the recommended location to post&lt;/p&gt; 
&lt;p&gt;(1) feature requests (2) bug reports (3) theoretical considerations (4) other issues, feedback (5) ask for help&lt;/p&gt; 
&lt;p&gt;Search previous posts, and check &lt;a href=&quot;https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html&quot;&gt;the phyloseq FAQ&lt;/a&gt; before posting a new issue.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
