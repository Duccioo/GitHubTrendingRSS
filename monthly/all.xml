<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>GitHub All Languages Monthly Trending</title>
    <description>Monthly Trending of All Languages in GitHub</description>
    <pubDate>Sun, 16 Mar 2025 01:56:58 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>n8n-io/n8n</title>
      <link>https://github.com/n8n-io/n8n</link>
      <description>&lt;p&gt;Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/10284570/173569848-c624317f-42b1-45a6-ab09-f0ea3c247648.png&quot; alt=&quot;Banner image&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;n8n - Secure Workflow Automation for Technical Teams&lt;/h1&gt; 
&lt;p&gt;n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot-readme.png&quot; alt=&quot;n8n.io - Screenshot&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Key Capabilities&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Code When You Need It&lt;/strong&gt;: Write JavaScript/Python, add npm packages, or use the visual interface&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI-Native Platform&lt;/strong&gt;: Build AI agent workflows based on LangChain with your own data and models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full Control&lt;/strong&gt;: Self-host with our fair-code license or use our &lt;a href=&quot;https://app.n8n.cloud/login&quot;&gt;cloud offering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise-Ready&lt;/strong&gt;: Advanced permissions, SSO, and air-gapped deployments&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Active Community&lt;/strong&gt;: 400+ integrations and 900+ ready-to-use &lt;a href=&quot;https://n8n.io/workflows&quot;&gt;templates&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Try n8n instantly with &lt;a href=&quot;https://docs.n8n.io/hosting/installation/npm/&quot;&gt;npx&lt;/a&gt; (requires &lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node.js&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npx n8n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or deploy with &lt;a href=&quot;https://docs.n8n.io/hosting/installation/docker/&quot;&gt;Docker&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker volume create n8n_data
docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the editor at &lt;a href=&quot;http://localhost:5678&quot;&gt;http://localhost:5678&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“š &lt;a href=&quot;https://docs.n8n.io&quot;&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;a href=&quot;https://n8n.io/integrations&quot;&gt;400+ Integrations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ’¡ &lt;a href=&quot;https://n8n.io/workflows&quot;&gt;Example Workflows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ¤– &lt;a href=&quot;https://docs.n8n.io/langchain/&quot;&gt;AI &amp;amp; LangChain Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ‘¥ &lt;a href=&quot;https://community.n8n.io&quot;&gt;Community Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ“– &lt;a href=&quot;https://community.n8n.io/c/tutorials/28&quot;&gt;Community Tutorials&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Need help? Our community forum is the place to get support and connect with other users: &lt;a href=&quot;https://community.n8n.io&quot;&gt;community.n8n.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;n8n is &lt;a href=&quot;https://faircode.io&quot;&gt;fair-code&lt;/a&gt; distributed under the &lt;a href=&quot;https://github.com/n8n-io/n8n/raw/master/LICENSE.md&quot;&gt;Sustainable Use License&lt;/a&gt; and &lt;a href=&quot;https://github.com/n8n-io/n8n/raw/master/LICENSE_EE.md&quot;&gt;n8n Enterprise License&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Source Available&lt;/strong&gt;: Always visible source code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-Hostable&lt;/strong&gt;: Deploy anywhere&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt;: Add your own nodes and functionality&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;mailto:license@n8n.io&quot;&gt;Enterprise licenses&lt;/a&gt; available for additional features and support.&lt;/p&gt; 
&lt;p&gt;Additional information about the license model can be found in the &lt;a href=&quot;https://docs.n8n.io/reference/license/&quot;&gt;docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Found a bug ğŸ› or have a feature idea âœ¨? Check our &lt;a href=&quot;https://github.com/n8n-io/n8n/raw/master/CONTRIBUTING.md&quot;&gt;Contributing Guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Join the Team&lt;/h2&gt; 
&lt;p&gt;Want to shape the future of automation? Check out our &lt;a href=&quot;https://n8n.io/careers&quot;&gt;job posts&lt;/a&gt; and join our team!&lt;/p&gt; 
&lt;h2&gt;What does n8n mean?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Short answer:&lt;/strong&gt; It means &quot;nodemation&quot; and is pronounced as n-eight-n.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Long answer:&lt;/strong&gt; &quot;I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. &#39;node-&#39; in the sense that it uses a Node-View and that it uses Node.js and &#39;-mation&#39; for &#39;automation&#39; which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on &#39;n8n&#39;.&quot; - &lt;strong&gt;Jan Oberhauser, Founder and CEO, n8n.io&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NirDiamant/GenAI_Agents</title>
      <link>https://github.com/NirDiamant/GenAI_Agents</link>
      <description>&lt;p&gt;This repository provides tutorials and implementations for various Generative AI Agent techniques, from basic to advanced. It serves as a comprehensive guide for building intelligent, interactive AI systems.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;http://makeapullrequest.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.linkedin.com/in/nir-diamant-759323134/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/LinkedIn-Connect-blue&quot; alt=&quot;LinkedIn&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/NirDiamantAI&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/NirDiamantAI?label=Follow%20@NirDiamantAI&amp;amp;style=social&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/cA6Aa4uyDX&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20our%20community-7289da?style=flat-square&amp;amp;logo=discord&amp;amp;logoColor=white&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸŒŸ &lt;strong&gt;Support This Project:&lt;/strong&gt; Your sponsorship fuels innovation in GenAI agent development. &lt;strong&gt;&lt;a href=&quot;https://github.com/sponsors/NirDiamant&quot;&gt;Become a sponsor&lt;/a&gt;&lt;/strong&gt; to help maintain and expand this valuable resource!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;GenAI Agents: Comprehensive Repository for Development and Implementation ğŸš€&lt;/h1&gt; 
&lt;p&gt;Welcome to one of the most extensive and dynamic collections of Generative AI (GenAI) agent tutorials and implementations available today. This repository serves as a comprehensive resource for learning, building, and sharing GenAI agents, ranging from simple conversational bots to complex, multi-agent systems.&lt;/p&gt; 
&lt;h2&gt;ğŸ“« Stay Updated!&lt;/h2&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align=&quot;center&quot;&gt;ğŸš€&lt;br&gt;&lt;b&gt;Cutting-edge&lt;br&gt;Updates&lt;/b&gt;&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;ğŸ’¡&lt;br&gt;&lt;b&gt;Expert&lt;br&gt;Insights&lt;/b&gt;&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;ğŸ¯&lt;br&gt;&lt;b&gt;Top 0.1%&lt;br&gt;Content&lt;/b&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;p&gt;&lt;a href=&quot;https://diamantai.substack.com/?r=336pe4&amp;amp;utm_campaign=pub-share-checklist&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/images/subscribe-button.svg?sanitize=true&quot; alt=&quot;Subscribe to DiamantAI Newsletter&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Join over 15,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!&lt;/em&gt; &lt;em&gt;&lt;strong&gt;Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href=&quot;https://diamantai.substack.com/?r=336pe4&amp;amp;utm_campaign=pub-share-checklist&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/images/substack_image.png&quot; alt=&quot;DiamantAI&#39;s newsletter&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Generative AI agents are at the forefront of artificial intelligence, revolutionizing the way we interact with and leverage AI technologies. This repository is designed to guide you through the development journey, from basic agent implementations to advanced, cutting-edge systems.&lt;/p&gt; 
&lt;p&gt;Our goal is to provide a valuable resource for everyone - from beginners taking their first steps in AI to seasoned practitioners pushing the boundaries of what&#39;s possible. By offering a range of examples from foundational to complex, we aim to facilitate learning, experimentation, and innovation in the rapidly evolving field of GenAI agents.&lt;/p&gt; 
&lt;p&gt;Furthermore, this repository serves as a platform for showcasing innovative agent creations. Whether you&#39;ve developed a novel agent architecture or found an innovative application for existing techniques, we encourage you to share your work with the community.&lt;/p&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;p&gt;ğŸ“š Dive into my &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_Techniques&quot;&gt;comprehensive guide on RAG techniques&lt;/a&gt;&lt;/strong&gt; to learn about integrating external knowledge into AI systems, enhancing their capabilities with up-to-date and relevant information retrieval.&lt;/p&gt; 
&lt;p&gt;ğŸ–‹ï¸ Explore my &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/Prompt_Engineering&quot;&gt;Prompt Engineering Techniques guide&lt;/a&gt;&lt;/strong&gt; for an extensive collection of prompting strategies, from fundamental concepts to advanced methods, improving your ability to communicate effectively with AI language models.&lt;/p&gt; 
&lt;h2&gt;A Community-Driven Knowledge Hub&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;This repository grows stronger with your contributions!&lt;/strong&gt; Join our vibrant Discord community â€” the central hub for shaping and advancing this project together ğŸ¤&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://discord.gg/cA6Aa4uyDX&quot;&gt;GenAI Agents Discord Community&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Whether you&#39;re a novice eager to learn or an expert ready to share your knowledge, your insights can shape the future of GenAI agents. Join us to propose ideas, get feedback, and collaborate on innovative implementations. For contribution guidelines, please refer to our &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/strong&gt; file. Let&#39;s advance GenAI agent technology together!&lt;/p&gt; 
&lt;p&gt;ğŸ”— For discussions on GenAI, agents, or to explore knowledge-sharing opportunities, feel free to &lt;strong&gt;&lt;a href=&quot;https://www.linkedin.com/in/nir-diamant-759323134/&quot;&gt;connect on LinkedIn&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“ Learn to build GenAI agents from beginner to advanced levels&lt;/li&gt; 
 &lt;li&gt;ğŸ§  Explore a wide range of agent architectures and applications&lt;/li&gt; 
 &lt;li&gt;ğŸ“š Step-by-step tutorials and comprehensive documentation&lt;/li&gt; 
 &lt;li&gt;ğŸ› ï¸ Practical, ready-to-use agent implementations&lt;/li&gt; 
 &lt;li&gt;ğŸŒŸ Regular updates with the latest advancements in GenAI&lt;/li&gt; 
 &lt;li&gt;ğŸ¤ Share your own agent creations with the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;GenAI Agent Implementations&lt;/h2&gt; 
&lt;p&gt;Explore our extensive list of GenAI agent implementations, sorted by categories:&lt;/p&gt; 
&lt;h3&gt;ğŸŒ± Beginner-Friendly Agents&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simple Conversational Agent&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_conversational_agent.ipynb&quot;&gt;LangChain&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_conversational_agent-pydanticai.ipynb&quot;&gt;PydanticAI&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A context-aware conversational AI maintains information across interactions, enabling more natural dialogues.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates a language model, prompt template, and history manager to generate contextual responses and track conversation sessions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_question_answering_agent.ipynb&quot;&gt;Simple Question Answering Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Answering (QA) agent using LangChain and OpenAI&#39;s language model understands user queries and provides relevant, concise answers.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Combines OpenAI&#39;s GPT model, a prompt template, and an LLMChain to process user questions and generate AI-driven responses in a streamlined manner.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simple Data Analysis Agent&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_data_analysis_agent_notebook.ipynb&quot;&gt;LangChain&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_data_analysis_agent_notebook-pydanticai.ipynb&quot;&gt;PydanticAI&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An AI-powered data analysis agent interprets and answers questions about datasets using natural language, combining language models with data manipulation tools for intuitive data exploration.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates a language model, data manipulation framework, and agent framework to process natural language queries and perform data analysis on a synthetic dataset, enabling accessible insights for non-technical users.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ”§ Framework Tutorial: LangGraph&lt;/h3&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/langgraph-tutorial.ipynb&quot;&gt;Introduction to LangGraph: Building Modular AI Workflows&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;This tutorial introduces LangGraph, a powerful framework for creating modular, graph-based AI workflows. Learn how to leverage LangGraph to build more complex and flexible AI agents that can handle multi-step processes efficiently.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Step-by-step guide on using LangGraph to create a StateGraph workflow. The tutorial covers key concepts such as state management, node creation, and graph compilation. It demonstrates these principles by constructing a simple text analysis pipeline, serving as a foundation for more advanced agent architectures.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/your-first-ai-agent-simpler-than?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ“ Educational and Research Agents&lt;/h3&gt; 
&lt;ol start=&quot;5&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/Academic_Task_Learning_Agent_LangGraph.ipynb&quot;&gt;ATLAS: Academic Task and Learning Agent System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;ATLAS demonstrates how to build an intelligent multi-agent system that transforms academic support through AI-powered assistance. The system leverages LangGraph&#39;s workflow framework to coordinate multiple specialized agents that provide personalized academic planning, note-taking, and advisory support.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a state-managed multi-agent architecture using four specialized agents (Coordinator, Planner, Notewriter, and Advisor) working in concert through LangGraph&#39;s workflow framework. The system features sophisticated workflows for profile analysis and academic support, with continuous adaptation based on student performance and feedback.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=yxowMLL2dDI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/atlas-when-artificial-intelligence?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/scientific_paper_agent_langgraph.ipynb&quot;&gt;Scientific Paper Agent - Literature Review&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent research assistant that helps users navigate, understand, and analyze scientific literature through an orchestrated workflow. The system combines academic APIs with sophisticated paper processing techniques to automate literature review tasks, enabling researchers to efficiently extract insights from academic papers while maintaining research rigor and quality control.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph to create a five-node workflow system including decision making, planning, tool execution, and quality validation nodes. The system integrates the CORE API for paper access, PDFplumber for document processing, and advanced language models for analysis. Key features include a retry mechanism for robust paper downloads, structured data handling through Pydantic models, and quality-focused improvement cycles with human-in-the-loop validation options.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://youtu.be/Bc4YtpHY6Ws&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/nexus-ai-the-revolutionary-research?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/chiron_learning_agent_langgraph.ipynb&quot;&gt;Chiron - A Feynman-Enhanced Learning Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An adaptive learning agent that guides users through educational content using a structured checkpoint system and Feynman-style teaching. The system processes learning materials (either user-provided or web-retrieved), verifies understanding through interactive checkpoints, and provides simplified explanations when needed, creating a personalized learning experience that mimics one-on-one tutoring.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Uses LangGraph to orchestrate a learning workflow that includes checkpoint definition, context building, understanding verification, and Feynman teaching nodes. The system integrates web search for dynamic content retrieval, employs semantic chunking for context processing, and manages embeddings for relevant information retrieval. Key features include a 70% understanding threshold for progression, interactive human-in-the-loop validation, and structured output through Pydantic models for consistent data handling.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qsdiTGkB8mk&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ’¼ Business and Professional Agents&lt;/h3&gt; 
&lt;ol start=&quot;8&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/customer_support_agent_langgraph.ipynb&quot;&gt;Customer Support Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent customer support agent using LangGraph categorizes queries, analyzes sentiment, and provides appropriate responses or escalates issues.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to create a workflow combining state management, query categorization, sentiment analysis, and response generation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/essay_grading_system_langgraph.ipynb&quot;&gt;Essay Grading Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An automated essay grading system using LangGraph and an LLM model evaluates essays based on relevance, grammar, structure, and depth of analysis.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes a state graph to define the grading workflow, incorporating separate grading functions for each criterion.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_travel_planner_langgraph.ipynb&quot;&gt;Travel Planning Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A Travel Planner using LangGraph demonstrates how to build a stateful, multi-step conversational AI application that collects user input and generates personalized travel itineraries.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes StateGraph to define the application flow, incorporates custom PlannerState for process management.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/agent_hackathon_genAI_career_assistant.ipynb&quot;&gt;GenAI Career Assistant Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;The GenAI Career Assistant demonstrates how to create a multi-agent system that provides personalized guidance for careers in Generative AI. Using LangGraph and Gemini LLM, the system delivers customized learning paths, resume assistance, interview preparation, and job search support.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages a multi-agent architecture using LangGraph to coordinate specialized agents (Learning, Resume, Interview, Job Search) through TypedDict-based state management. The system employs sophisticated query categorization and routing while integrating with external tools like DuckDuckGo for job searches and dynamic content generation.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=IcKh0ltXO_8&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/project_manager_assistant_agent.ipynb&quot;&gt;Project Manager Assistant Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An AI agent designed to assist in project management tasks by automating the process of creating actionable tasks from project descriptions, identifying dependencies, scheduling work, and assigning tasks to team members based on expertise. The system includes risk assessment and self-reflection capabilities to optimize project plans through multiple iterations, aiming to minimize overall project risk.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph to orchestrate a workflow of specialized nodes including task generation, dependency mapping, scheduling, allocation, and risk assessment. Each node uses GPT-4o-mini for structured outputs following Pydantic models. The system implements a feedback loop for self-improvement, where risk scores trigger reflection cycles that generate insights to optimize the project plan. Visualization tools display Gantt charts of the generated schedules across iterations.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=R7YWjzg3LpI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ClauseAI.ipynb&quot;&gt;Contract Analysis Assistant (ClauseAI)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;ClauseAI demonstrates how to build an AI-powered contract analysis system using a multi-agent approach. The system employs specialized AI agents for different aspects of contract review, from clause analysis to compliance checking, and leverages LangGraph for workflow orchestration and Pinecone for efficient clause retrieval and comparison.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a sophisticated state-based workflow using LangGraph to coordinate multiple AI agents through contract analysis stages. The system features Pydantic models for data validation, vector storage with Pinecone for clause comparison, and LLM-based analysis for generating comprehensive contract reports. The implementation includes parallel processing capabilities and customizable report generation based on user requirements.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=rP8uv_tXuSI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/e2e_testing_agent.ipynb&quot;&gt;E2E Testing Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;The E2E Testing Agent demonstrates how to build an AI-powered system that converts natural language test instructions into executable end-to-end web tests. Using LangGraph for workflow orchestration and Playwright for browser automation, the system enables users to specify test cases in plain English while handling the complexity of test generation and execution.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a structured workflow using LangGraph to coordinate test generation, validation, and execution. The system features TypedDict state management, integration with Playwright for browser automation, and LLM-based code generation for converting natural language instructions into executable test scripts. The implementation includes DOM state analysis, error handling, and comprehensive test reporting.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=jPXtpzcCtyA&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ¨ Creative and Content Generation Agents&lt;/h3&gt; 
&lt;ol start=&quot;15&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/gif_animation_generator_langgraph.ipynb&quot;&gt;GIF Animation Generator Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A GIF animation generator that integrates LangGraph for workflow management, GPT-4 for text generation, and DALL-E for image creation, producing custom animations from user prompts.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a workflow that generates character descriptions, plots, and image prompts using GPT-4, creates images with DALL-E 3, and assembles them into GIFs using PIL. Employs asynchronous programming for efficient parallel processing.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/tts_poem_generator_agent_langgraph.ipynb&quot;&gt;TTS Poem Generator Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An advanced text-to-speech (TTS) agent using LangGraph and OpenAI&#39;s APIs classifies input text, processes it based on content type, and generates corresponding speech output.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a workflow that classifies input text using GPT models, applies content-specific processing, and converts the processed text to speech using OpenAI&#39;s TTS API. The system adapts its output based on the identified content type (general, poem, news, or joke).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/music_compositor_agent_langgraph.ipynb&quot;&gt;Music Compositor Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An AI Music Compositor using LangGraph and OpenAI&#39;s language models generates custom musical compositions based on user input. The system processes the input through specialized components, each contributing to the final musical piece, which is then converted to a playable MIDI file.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;LangGraph orchestrates a workflow that transforms user input into a musical composition, using ChatOpenAI (GPT-4) to generate melody, harmony, and rhythm, which are then style-adapted. The final AI-generated composition is converted to a MIDI file using music21 and can be played back using pygame.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ContentIntelligence.ipynb&quot;&gt;Content Intelligence: Multi-Platform Content Generation Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Content Intelligence demonstrates how to build an advanced content generation system that transforms input text into platform-optimized content across multiple social media channels. The system employs LangGraph for workflow orchestration to analyze content, conduct research, and generate tailored content while maintaining brand consistency across different platforms.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a sophisticated workflow using LangGraph to coordinate multiple specialized nodes (Summary, Research, Platform-Specific) through the content generation process. The system features TypedDict and Pydantic models for state management, integration with Tavily Search for research enhancement, and platform-specific content generation using GPT-4. The implementation includes parallel processing for multiple platforms and customizable content templates.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=DPMtPbKmWnU&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/business_meme_generator.ipynb&quot;&gt;Business Meme Generator Using LangGraph and Memegen.link&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;The Business Meme Generator demonstrates how to create an AI-powered system that generates contextually relevant memes based on company website analysis. Using LangGraph for workflow orchestration, the system combines Groq&#39;s Llama model for text analysis and the Memegen.link API to automatically produce brand-aligned memes for digital marketing.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a state-managed workflow using LangGraph to coordinate website content analysis, meme concept generation, and image creation. The system features Pydantic models for data validation, asynchronous processing with aiohttp, and integration with external APIs (Groq, Memegen.link) to create a complete meme generation pipeline with customizable templates.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://youtu.be/lsdDaGmkSCw?si=oF3CGfhbRqz1_Vm8&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/murder_mystery_agent_langgraph.ipynb&quot;&gt;Murder Mystery Game with LLM Agents&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A text-based detective game that utilizes autonomous LLM agents as interactive characters in a procedurally generated murder mystery. Drawing inspiration from the UNBOUNDED paper, the system creates unique scenarios each time, with players taking on the role of Sherlock Holmes to solve the case through character interviews and deductive reasoning.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages two LangGraph workflows - a main game loop for story/character generation and game progression, and a conversation sub-graph for character interactions. The system uses a combination of LLM-powered narrative generation, character AI, and structured game mechanics to create an immersive investigative experience with replayable storylines.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=_3cJYlk2EmA&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ“Š Analysis and Information Processing Agents&lt;/h3&gt; 
&lt;ol start=&quot;21&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/memory_enhanced_conversational_agent.ipynb&quot;&gt;Memory-Enhanced Conversational Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A memory-enhanced conversational AI agent incorporates short-term and long-term memory systems to maintain context within conversations and across multiple sessions, improving interaction quality and personalization.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates a language model with separate short-term and long-term memory stores, utilizes a prompt template incorporating both memory types, and employs a memory manager for storage and retrieval. The system includes an interaction loop that updates and utilizes memories for each response.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/multi_agent_collaboration_system.ipynb&quot;&gt;Multi-Agent Collaboration System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A multi-agent collaboration system combining historical research with data analysis, leveraging large language models to simulate specialized agents working together to answer complex historical questions.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes a base Agent class to create specialized HistoryResearchAgent and DataAnalysisAgent, orchestrated by a HistoryDataCollaborationSystem. The system follows a five-step process: historical context provision, data needs identification, historical data provision, data analysis, and final synthesis.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/self_improving_agent.ipynb&quot;&gt;Self-Improving Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A Self-Improving Agent using LangChain engages in conversations, learns from interactions, and continuously improves its performance over time through reflection and adaptation.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates a language model with chat history management, response generation, and a reflection mechanism. The system employs a learning system that incorporates insights from reflection to enhance future performance, creating a continuous improvement loop.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/task_oriented_agent.ipynb&quot;&gt;Task-Oriented Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A language model application using LangChain that summarizes text and translates the summary to Spanish, combining custom functions, structured tools, and an agent for efficient text processing.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes custom functions for summarization and translation, wrapped as structured tools. Employs a prompt template to guide the agent, which orchestrates the use of tools. An agent executor manages the process, taking input text and producing both an English summary and its Spanish translation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/search_the_internet_and_summarize.ipynb&quot;&gt;Internet Search and Summarize Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent web research assistant that combines web search capabilities with AI-powered summarization, automating the process of gathering information from the internet and distilling it into concise, relevant summaries.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates a web search module using DuckDuckGo&#39;s API, a result parser, and a text summarization engine leveraging OpenAI&#39;s language models. The system performs site-specific or general searches, extracts relevant content, generates concise summaries, and compiles attributed results for efficient information retrieval and synthesis.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/research_team_autogen.ipynb&quot;&gt;Multi agent research team - Autogen&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;This technique explores a multi-agent system for collaborative research using the AutoGen library. It employs agents to solve tasks collaboratively, focusing on efficient execution and quality assurance. The system enhances research by distributing tasks among specialized agents.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Agents are configured with specific roles using the GPT-4 model, including admin, developer, planner, executor, and quality assurance. Interaction management ensures orderly communication with defined transitions. Task execution involves collaborative planning, coding, execution, and quality checking, demonstrating a scalable framework for various domains.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/yanivvak/dream-team&quot;&gt;comprehensive solution with UI&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/build-your-dream-team-with-autogen/ba-p/4157961&quot;&gt;Blogpost&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/sales_call_analyzer_agent.ipynb&quot;&gt;Sales Call Analyzer&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent system that automates the analysis of sales call recordings by combining audio transcription with advanced natural language processing. The analyzer transcribes audio using OpenAI&#39;s Whisper, processes the text using NLP techniques, and generates comprehensive reports including sentiment analysis, key phrases, pain points, and actionable recommendations to improve sales performance.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes multiple components in a structured workflow: OpenAI Whisper for audio transcription, CrewAI for task automation and agent management, and LangChain for orchestrating the analysis pipeline. The system processes audio through a series of steps from transcription to detailed analysis, leveraging custom agents and tasks to generate structured JSON reports containing insights about customer sentiment, sales opportunities, and recommended improvements.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=SKAt_PvznDw&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/Weather_Disaster_Management_AI_AGENT.ipynb&quot;&gt;Weather Emergency &amp;amp; Response System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A comprehensive system demonstrating two agent graph implementations for weather emergency response: a real-time graph processing live weather data, and a hybrid graph combining real and simulated data for testing high-severity scenarios. The system handles complete workflow from data gathering through emergency plan generation, with automated notifications and human verification steps.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph for orchestrating complex workflows with state management, integrating OpenWeatherMap API for real-time data, and Gemini for analysis and response generation. The system incorporates email notifications, social media monitoring simulation, and severity-based routing with configurable human verification for low/medium severity events.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=AgiOAJl_apw&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/self_healing_code.ipynb&quot;&gt;Self-Healing Codebase System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent system that automatically detects, diagnoses, and fixes runtime code errors using LangGraph workflow orchestration and ChromaDB vector storage. The system maintains a memory of encountered bugs and their fixes through vector embeddings, enabling pattern recognition for similar errors across the codebase.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes a state-based graph workflow that processes function definitions and runtime arguments through specialized nodes for error detection, code analysis, and fix generation. Incorporates ChromaDB for vector-based storage of bug patterns and fixes, with automated search and retrieval capabilities for similar error patterns, while maintaining code execution safety through structured validation steps.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ga7ShvIXOvE&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/database_discovery_fleet.ipynb&quot;&gt;DataScribe: AI-Powered Schema Explorer&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent agent system that enables intuitive exploration and querying of relational databases through natural language interactions. The system utilizes a fleet of specialized agents, coordinated by a stateful Supervisor, to handle schema discovery, query planning, and data analysis tasks while maintaining contextual understanding through vector-based relationship graphs.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph for orchestrating a multi-agent workflow including discovery, inference, and planning agents, with NetworkX for relationship graph visualization and management. The system incorporates dynamic state management through TypedDict classes, maintains database context between sessions using a db_graph attribute, and includes safety measures to prevent unauthorized database modifications.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ“° News and Information Agents&lt;/h3&gt; 
&lt;ol start=&quot;31&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/news_tldr_langgraph.ipynb&quot;&gt;News TL;DR using LangGraph&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A news summarization system that generates concise TL;DR summaries of current events based on user queries. The system leverages large language models for decision making and summarization while integrating with news APIs to access up-to-date content, allowing users to quickly catch up on topics of interest through generated bullet-point summaries.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a workflow combining multiple components: GPT-4o-mini for generating search terms and article summaries, NewsAPI for retrieving article metadata, BeautifulSoup for web scraping article content, and Asyncio for concurrent processing. The system follows a structured pipeline from query processing through article selection and summarization, managing the flow between components to produce relevant TL;DRs of current news articles.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=0fRxW6miybI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/stop-reading-start-understanding?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ainsight_langgraph.ipynb&quot;&gt;AInsight: AI/ML Weekly News Reporter&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;AInsight demonstrates how to build an intelligent news aggregation and summarization system using a multi-agent architecture. The system employs three specialized agents (NewsSearcher, Summarizer, Publisher) to automatically collect, process and summarize AI/ML news for general audiences through LangGraph-based workflow orchestration.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a state-managed multi-agent system using LangGraph to coordinate the news collection (Tavily API), technical content summarization (GPT-4), and report generation processes. The system features modular architecture with TypedDict-based state management, external API integration, and markdown report generation with customizable templates.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kH5S1is2D_0&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/journalism_focused_ai_assistant_langgraph.ipynb&quot;&gt;Journalism-Focused AI Assistant&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A specialized AI assistant that helps journalists tackle modern journalistic challenges like misinformation, bias, and information overload. The system integrates fact-checking, tone analysis, summarization, and grammar review tools to enhance the accuracy and efficiency of journalistic work while maintaining ethical reporting standards.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph to orchestrate a workflow of specialized components including language models for analysis and generation, web search integration via DuckDuckGo&#39;s API, document parsing tools like PyMuPDFLoader and WebBaseLoader, text splitting with RecursiveCharacterTextSplitter, and structured JSON outputs. Each component works together through a unified workflow to analyze content, verify facts, detect bias, extract quotes, and generate comprehensive reports.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/blog_writer_swarm.ipynb&quot;&gt;Blog Writer (Open AI Swarm)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A multi-agent system for collaborative blog post creation using OpenAI&#39;s Swarm package. It leverages specialized agents to perform research, planning, writing, and editing tasks efficiently.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes OpenAI&#39;s Swarm Package to manage agent interactions. Includes an admin, researcher, planner, writer, and editor, each with specific roles. The system follows a structured workflow: topic setting, outlining, research, drafting, and editing. This approach enhances content creation through task distribution, specialization, and collaborative problem-solving.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/openai/swarm&quot;&gt;Swarm Repo&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/generate_podcast_agent_langgraph.ipynb&quot;&gt;Podcast Internet Search and Generate Agent ğŸ™ï¸&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A two step agent that first searches the internet for a given topic and then generates a podcast on the topic found. The search step uses a search agent and search function to find the most relevant information. The second step uses a podcast generation agent and generation function to create a podcast on the topic found.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a two-step workflow. The first step involves a search agent and function to gather information from the internet. The second step uses a podcast generation agent and function to create a podcast based on the gathered information.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ›ï¸ Shopping and Product Analysis Agents&lt;/h3&gt; 
&lt;ol start=&quot;36&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ShopGenie.ipynb&quot;&gt;ShopGenie - Redefining Online Shopping Customer Experience&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An AI-powered shopping assistant that helps customers make informed purchasing decisions even without domain expertise. The system analyzes product information from multiple sources, compares specifications and reviews, identifies the best option based on user needs, and delivers recommendations through email with supporting video reviews, creating a comprehensive shopping experience.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Uses LangGraph to orchestrate a workflow combining Tavily for web search, Llama-3.1-70B for structured data analysis and product comparison, and YouTube API for review video retrieval. The system processes search results through multiple nodes including schema mapping, product comparison, review identification, and email generation. Key features include structured Pydantic models for consistent data handling, retry mechanisms for robust API interactions, and email delivery through SMTP for sharing recommendations.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Js0sK0u53dQ&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/car_buyer_agent_langgraph.ipynb&quot;&gt;Car Buyer AI Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;The Smart Product Buyer AI Agent demonstrates how to build an intelligent system that assists users in making informed purchasing decisions. Using LangGraph and LLM-based intelligence, the system processes user requirements, scrapes product listings from websites like AutoTrader, and provides detailed analysis and recommendations for car purchases.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a state-based workflow using LangGraph to coordinate user interaction, web scraping, and decision support. The system features TypedDict state management, async web scraping with Playwright, and integrates with external APIs for comprehensive product analysis. The implementation includes a Gradio interface for real-time chat interaction and modular scraper architecture for easy extension to additional product categories.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=I61I1fp0qys&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ¯ Task Management and Productivity Agents&lt;/h3&gt; 
&lt;ol start=&quot;38&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/taskifier.ipynb&quot;&gt;Taskifier - Intelligent Task Allocation &amp;amp; Management&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent task management system that analyzes user work styles and creates personalized task breakdown strategies, born from the observation that procrastination often stems from task ambiguity among students and early-career professionals. The system evaluates historical work patterns, gathers relevant task information through web search, and generates customized step-by-step approaches to optimize productivity and reduce workflow paralysis.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph for orchestrating a multi-step workflow including work style analysis, information gathering via Tavily API, and customized plan generation. The system maintains state through the process, integrating historical work pattern data with fresh task research to output detailed, personalized task execution plans aligned with the user&#39;s natural working style.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=1W_p_RVi9KE&amp;amp;t=25s&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/grocery_management_agents_system.ipynb&quot;&gt;Grocery Management Agents System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A multi-agent system built with CrewAI that automates grocery management tasks including receipt interpretation, expiration date tracking, inventory management, and recipe recommendations. The system uses specialized agents to extract data from receipts, estimate product shelf life, track consumption, and suggest recipes to minimize food waste.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements four specialized agents using CrewAI - a Receipt Interpreter that extracts item details from receipts, an Expiration Date Estimator that determines shelf life using online sources, a Grocery Tracker that maintains inventory based on consumption, and a Recipe Recommender that suggests meals using available ingredients. Each agent has specific tools and tasks orchestrated through a crew workflow.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=FlMu5pKSaHI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ” Quality Assurance and Testing Agents&lt;/h3&gt; 
&lt;ol start=&quot;40&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/graph_inspector_system_langgraph.ipynb&quot;&gt;LangGraph-Based Systems Inspector&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A comprehensive testing and validation tool for LangGraph-based applications that automatically analyzes system architecture, generates test cases, and identifies potential vulnerabilities through multi-agent inspection. The inspector employs specialized AI testers to evaluate different aspects of the system, from basic functionality to security concerns and edge cases.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates LangGraph for workflow orchestration, multiple LLM-powered testing agents, and a structured evaluation pipeline that includes static analysis, test case generation, and results verification. The system uses Pydantic for data validation, NetworkX for graph representation, and implements a modular architecture that allows for parallel test execution and comprehensive result analysis.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=fQd6lXc-Y9A&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/langgraph-systems-inspector-an-ai?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/EU_Green_Compliance_FAQ_Bot.ipynb&quot;&gt;EU Green Deal FAQ Bot&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;The EU Green Deal FAQ Bot demonstrates how to build a RAG-based AI agent that helps businesses understand EU green deal policies. The system processes complex regulatory documents into manageable chunks and provides instant, accurate answers to common questions about environmental compliance, emissions reporting, and waste management requirements.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a sophisticated RAG pipeline using FAISS vectorstore for document storage, semantic chunking for preprocessing, and multiple specialized agents (Retriever, Summarizer, Evaluator) for query processing. The system features query rephrasing for improved accuracy, cross-reference with gold Q&amp;amp;A datasets for answer validation, and comprehensive evaluation metrics to ensure response quality and relevance.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Av0kBQjwU-Y&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/systematic_review_of_scientific_articles.ipynb&quot;&gt;Systematic Review Automation System + Paper Draft Creation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A comprehensive system for automating academic systematic reviews using a directed graph architecture and LangChain components. The system generates complete, publication-ready systematic review papers, automatically processing everything from literature search through final draft generation with multiple revision cycles.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes a state-based graph workflow that handles paper search and selection (up to 3 papers), PDF processing, and generates a complete academic paper with all standard sections (abstract, introduction, methods, results, conclusions, references). The system incorporates multiple revision cycles with automated critique and improvement phases, all orchestrated through LangGraph state management.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qi35mGGkCtg&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸŒŸ Special Advanced Technique ğŸŒŸ&lt;/h3&gt; 
&lt;ol start=&quot;43&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/Controllable-RAG-Agent&quot;&gt;Sophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the &quot;brain&quot; ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To begin exploring and building GenAI agents:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repository: &lt;pre&gt;&lt;code&gt;git clone https://github.com/NirDiamant/GenAI_Agents.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to the technique you&#39;re interested in: &lt;pre&gt;&lt;code&gt;cd all_agents_tutorials/technique-name
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Follow the detailed implementation guide in each technique&#39;s notebook.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! If you have a new technique or improvement to suggest:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create your feature branch: &lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Commit your changes: &lt;code&gt;git commit -m &#39;Add some AmazingFeature&#39;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Push to the branch: &lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Open a pull request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/graphs/contributors&quot;&gt;&lt;img src=&quot;https://contrib.rocks/image?repo=NirDiamant/GenAI_Agents&quot; alt=&quot;Contributors&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under a custom non-commercial license - see the &lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;â­ï¸ If you find this repository helpful, please consider giving it a star!&lt;/p&gt; 
&lt;p&gt;Keywords: GenAI, Generative AI, Agents, NLP, AI, Machine Learning, Natural Language Processing, LLM, Conversational AI, Task-Oriented AI&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mendableai/firecrawl</title>
      <link>https://github.com/mendableai/firecrawl</link>
      <description>&lt;p&gt;ğŸ”¥ Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.&lt;/p&gt;&lt;hr&gt;&lt;h3 align=&quot;center&quot;&gt; &lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt; &lt;img src=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/img/firecrawl_logo.png&quot; height=&quot;200&quot;&gt; &lt;/h3&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://github.com/mendableai/firecrawl/raw/main/LICENSE&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/license/mendableai/firecrawl&quot; alt=&quot;License&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://pepy.tech/project/firecrawl-py&quot;&gt; &lt;img src=&quot;https://static.pepy.tech/badge/firecrawl-py&quot; alt=&quot;Downloads&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://GitHub.com/mendableai/firecrawl/graphs/contributors&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/contributors/mendableai/firecrawl.svg?sanitize=true&quot; alt=&quot;GitHub Contributors&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://firecrawl.dev&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/Visit-firecrawl.dev-orange&quot; alt=&quot;Visit firecrawl.dev&quot;&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://twitter.com/firecrawl_dev&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20X-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white&quot; alt=&quot;Follow on X&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://www.linkedin.com/company/104100957&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20LinkedIn-0077B5?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;logoColor=white&quot; alt=&quot;Follow on LinkedIn&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://discord.com/invite/gSmWdAkdwd&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/Join%20our%20Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&quot; alt=&quot;Join our Discord&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;ğŸ”¥ Firecrawl&lt;/h1&gt; 
&lt;p&gt;Empower your AI apps with clean data from any website. Featuring advanced scraping, crawling, and data extraction capabilities.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;This repository is in development, and weâ€™re still integrating custom modules into the mono repo. It&#39;s not fully ready for self-hosted deployment yet, but you can run it locally.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;What is Firecrawl?&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://firecrawl.dev?ref=github&quot;&gt;Firecrawl&lt;/a&gt; is an API service that takes a URL, crawls it, and converts it into clean markdown or structured data. We crawl all accessible subpages and give you clean data for each. No sitemap required. Check out our &lt;a href=&quot;https://docs.firecrawl.dev&quot;&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Pst. hey, you, join our stargazers :)&lt;/em&gt;&lt;/p&gt; 
&lt;a href=&quot;https://github.com/mendableai/firecrawl&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/stars/mendableai/firecrawl.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000&quot; alt=&quot;GitHub stars&quot;&gt; &lt;/a&gt; 
&lt;h2&gt;How to use it?&lt;/h2&gt; 
&lt;p&gt;We provide an easy to use API with our hosted version. You can find the playground and documentation &lt;a href=&quot;https://firecrawl.dev/playground&quot;&gt;here&lt;/a&gt;. You can also self host the backend if you&#39;d like.&lt;/p&gt; 
&lt;p&gt;Check out the following resources to get started:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;strong&gt;API&lt;/strong&gt;: &lt;a href=&quot;https://docs.firecrawl.dev/api-reference/introduction&quot;&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;strong&gt;SDKs&lt;/strong&gt;: &lt;a href=&quot;https://docs.firecrawl.dev/sdks/python&quot;&gt;Python&lt;/a&gt;, &lt;a href=&quot;https://docs.firecrawl.dev/sdks/node&quot;&gt;Node&lt;/a&gt;, &lt;a href=&quot;https://docs.firecrawl.dev/sdks/go&quot;&gt;Go&lt;/a&gt;, &lt;a href=&quot;https://docs.firecrawl.dev/sdks/rust&quot;&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;strong&gt;LLM Frameworks&lt;/strong&gt;: &lt;a href=&quot;https://python.langchain.com/docs/integrations/document_loaders/firecrawl/&quot;&gt;Langchain (python)&lt;/a&gt;, &lt;a href=&quot;https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl&quot;&gt;Langchain (js)&lt;/a&gt;, &lt;a href=&quot;https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader&quot;&gt;Llama Index&lt;/a&gt;, &lt;a href=&quot;https://docs.crewai.com/&quot;&gt;Crew.ai&lt;/a&gt;, &lt;a href=&quot;https://composio.dev/tools/firecrawl/all&quot;&gt;Composio&lt;/a&gt;, &lt;a href=&quot;https://docs.praison.ai/firecrawl/&quot;&gt;PraisonAI&lt;/a&gt;, &lt;a href=&quot;https://superinterface.ai/docs/assistants/functions/firecrawl&quot;&gt;Superinterface&lt;/a&gt;, &lt;a href=&quot;https://docs.vectorize.io/integrations/source-connectors/firecrawl&quot;&gt;Vectorize&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;strong&gt;Low-code Frameworks&lt;/strong&gt;: &lt;a href=&quot;https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl&quot;&gt;Dify&lt;/a&gt;, &lt;a href=&quot;https://docs.langflow.org/&quot;&gt;Langflow&lt;/a&gt;, &lt;a href=&quot;https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl&quot;&gt;Flowise AI&lt;/a&gt;, &lt;a href=&quot;https://docs.getcargo.io/integration/firecrawl&quot;&gt;Cargo&lt;/a&gt;, &lt;a href=&quot;https://pipedream.com/apps/firecrawl/&quot;&gt;Pipedream&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;strong&gt;Others&lt;/strong&gt;: &lt;a href=&quot;https://zapier.com/apps/firecrawl/integrations&quot;&gt;Zapier&lt;/a&gt;, &lt;a href=&quot;https://www.pabbly.com/connect/integrations/firecrawl/&quot;&gt;Pabbly Connect&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; Want an SDK or Integration? Let us know by opening an issue.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To run locally, refer to guide &lt;a href=&quot;https://github.com/mendableai/firecrawl/raw/main/CONTRIBUTING.md&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;API Key&lt;/h3&gt; 
&lt;p&gt;To use the API, you need to sign up on &lt;a href=&quot;https://firecrawl.dev&quot;&gt;Firecrawl&lt;/a&gt; and get an API key.&lt;/p&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/#scraping&quot;&gt;&lt;strong&gt;Scrape&lt;/strong&gt;&lt;/a&gt;: scrapes a URL and get its content in LLM-ready format (markdown, structured data via &lt;a href=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/#llm-extraction-beta&quot;&gt;LLM Extract&lt;/a&gt;, screenshot, html)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/#crawling&quot;&gt;&lt;strong&gt;Crawl&lt;/strong&gt;&lt;/a&gt;: scrapes all the URLs of a web page and return content in LLM-ready format&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/#map-alpha&quot;&gt;&lt;strong&gt;Map&lt;/strong&gt;&lt;/a&gt;: input a website and get all the website urls - extremely fast&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/#extract&quot;&gt;&lt;strong&gt;Extract&lt;/strong&gt;&lt;/a&gt;: get structured data from single page, multiple pages or entire websites with AI.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Powerful Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-ready formats&lt;/strong&gt;: markdown, structured data, screenshot, HTML, links, metadata&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The hard stuff&lt;/strong&gt;: proxies, anti-bot mechanisms, dynamic content (js-rendered), output parsing, orchestration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizability&lt;/strong&gt;: exclude tags, crawl behind auth walls with custom headers, max crawl depth, etc...&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Media parsing&lt;/strong&gt;: pdfs, docx, images&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliability first&lt;/strong&gt;: designed to get the data you need - no matter how hard it is&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Actions&lt;/strong&gt;: click, scroll, input, wait and more before extracting data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Batching (New)&lt;/strong&gt;: scrape thousands of URLs at the same time with a new async endpoint.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can find all of Firecrawl&#39;s capabilities and how to use them in our &lt;a href=&quot;https://docs.firecrawl.dev&quot;&gt;documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Crawling&lt;/h3&gt; 
&lt;p&gt;Used to crawl a URL and all accessible subpages. This submits a crawl job and returns a job ID to check the status of the crawl.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H &#39;Content-Type: application/json&#39; \
    -H &#39;Authorization: Bearer fc-YOUR_API_KEY&#39; \
    -d &#39;{
      &quot;url&quot;: &quot;https://docs.firecrawl.dev&quot;,
      &quot;limit&quot;: 10,
      &quot;scrapeOptions&quot;: {
        &quot;formats&quot;: [&quot;markdown&quot;, &quot;html&quot;]
      }
    }&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Returns a crawl job id and the url to check the status of the crawl.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;success&quot;: true,
  &quot;id&quot;: &quot;123-456-789&quot;,
  &quot;url&quot;: &quot;https://api.firecrawl.dev/v1/crawl/123-456-789&quot;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Check Crawl Job&lt;/h3&gt; 
&lt;p&gt;Used to check the status of a crawl job and get its result.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X GET https://api.firecrawl.dev/v1/crawl/123-456-789 \
  -H &#39;Content-Type: application/json&#39; \
  -H &#39;Authorization: Bearer YOUR_API_KEY&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;status&quot;: &quot;completed&quot;,
  &quot;total&quot;: 36,
  &quot;creditsUsed&quot;: 36,
  &quot;expiresAt&quot;: &quot;2024-00-00T00:00:00.000Z&quot;,
  &quot;data&quot;: [
    {
      &quot;markdown&quot;: &quot;[Firecrawl Docs home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/firecrawl/logo/light.svg)!...&quot;,
      &quot;html&quot;: &quot;&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html lang=\&quot;en\&quot; class=\&quot;js-focus-visible lg:[--scroll-mt:9.5rem]\&quot; data-js-focus-visible=\&quot;\&quot;&amp;gt;...&quot;,
      &quot;metadata&quot;: {
        &quot;title&quot;: &quot;Build a &#39;Chat with website&#39; using Groq Llama 3 | Firecrawl&quot;,
        &quot;language&quot;: &quot;en&quot;,
        &quot;sourceURL&quot;: &quot;https://docs.firecrawl.dev/learn/rag-llama3&quot;,
        &quot;description&quot;: &quot;Learn how to use Firecrawl, Groq Llama 3, and Langchain to build a &#39;Chat with your website&#39; bot.&quot;,
        &quot;ogLocaleAlternate&quot;: [],
        &quot;statusCode&quot;: 200
      }
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scraping&lt;/h3&gt; 
&lt;p&gt;Used to scrape a URL and get its content in the specified formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H &#39;Content-Type: application/json&#39; \
    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \
    -d &#39;{
      &quot;url&quot;: &quot;https://docs.firecrawl.dev&quot;,
      &quot;formats&quot; : [&quot;markdown&quot;, &quot;html&quot;]
    }&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;success&quot;: true,
  &quot;data&quot;: {
    &quot;markdown&quot;: &quot;Launch Week I is here! [See our Day 2 Release ğŸš€](https://www.firecrawl.dev/blog/launch-week-i-day-2-doubled-rate-limits)[ğŸ’¥ Get 2 months free...&quot;,
    &quot;html&quot;: &quot;&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html lang=\&quot;en\&quot; class=\&quot;light\&quot; style=\&quot;color-scheme: light;\&quot;&amp;gt;&amp;lt;body class=\&quot;__variable_36bd41 __variable_d7dc5d font-inter ...&quot;,
    &quot;metadata&quot;: {
      &quot;title&quot;: &quot;Home - Firecrawl&quot;,
      &quot;description&quot;: &quot;Firecrawl crawls and converts any website into clean markdown.&quot;,
      &quot;language&quot;: &quot;en&quot;,
      &quot;keywords&quot;: &quot;Firecrawl,Markdown,Data,Mendable,Langchain&quot;,
      &quot;robots&quot;: &quot;follow, index&quot;,
      &quot;ogTitle&quot;: &quot;Firecrawl&quot;,
      &quot;ogDescription&quot;: &quot;Turn any website into LLM-ready data.&quot;,
      &quot;ogUrl&quot;: &quot;https://www.firecrawl.dev/&quot;,
      &quot;ogImage&quot;: &quot;https://www.firecrawl.dev/og.png?123&quot;,
      &quot;ogLocaleAlternate&quot;: [],
      &quot;ogSiteName&quot;: &quot;Firecrawl&quot;,
      &quot;sourceURL&quot;: &quot;https://firecrawl.dev&quot;,
      &quot;statusCode&quot;: 200
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Map (Alpha)&lt;/h3&gt; 
&lt;p&gt;Used to map a URL and get urls of the website. This returns most links present on the website.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X POST https://api.firecrawl.dev/v1/map \
    -H &#39;Content-Type: application/json&#39; \
    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \
    -d &#39;{
      &quot;url&quot;: &quot;https://firecrawl.dev&quot;
    }&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;status&quot;: &quot;success&quot;,
  &quot;links&quot;: [
    &quot;https://firecrawl.dev&quot;,
    &quot;https://www.firecrawl.dev/pricing&quot;,
    &quot;https://www.firecrawl.dev/blog&quot;,
    &quot;https://www.firecrawl.dev/playground&quot;,
    &quot;https://www.firecrawl.dev/smart-crawl&quot;,
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Map with search&lt;/h4&gt; 
&lt;p&gt;Map with &lt;code&gt;search&lt;/code&gt; param allows you to search for specific urls inside a website.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X POST https://api.firecrawl.dev/v1/map \
    -H &#39;Content-Type: application/json&#39; \
    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \
    -d &#39;{
      &quot;url&quot;: &quot;https://firecrawl.dev&quot;,
      &quot;search&quot;: &quot;docs&quot;
    }&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Response will be an ordered list from the most relevant to the least relevant.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;status&quot;: &quot;success&quot;,
  &quot;links&quot;: [
    &quot;https://docs.firecrawl.dev&quot;,
    &quot;https://docs.firecrawl.dev/sdks/python&quot;,
    &quot;https://docs.firecrawl.dev/learn/rag-llama3&quot;,
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Extract&lt;/h3&gt; 
&lt;p&gt;Get structured data from entire websites with a prompt and/or a schema.&lt;/p&gt; 
&lt;p&gt;You can extract structured data from one or multiple URLs, including wildcards:&lt;/p&gt; 
&lt;p&gt;Single Page: Example: &lt;a href=&quot;https://firecrawl.dev/some-page&quot;&gt;https://firecrawl.dev/some-page&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Multiple Pages / Full Domain Example: &lt;a href=&quot;https://firecrawl.dev/&quot;&gt;https://firecrawl.dev/&lt;/a&gt;*&lt;/p&gt; 
&lt;p&gt;When you use /*, Firecrawl will automatically crawl and parse all URLs it can discover in that domain, then extract the requested data.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X POST https://api.firecrawl.dev/v1/extract \
    -H &#39;Content-Type: application/json&#39; \
    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \
    -d &#39;{
      &quot;urls&quot;: [
        &quot;https://firecrawl.dev/*&quot;, 
        &quot;https://docs.firecrawl.dev/&quot;, 
        &quot;https://www.ycombinator.com/companies&quot;
      ],
      &quot;prompt&quot;: &quot;Extract the company mission, whether it is open source, and whether it is in Y Combinator from the page.&quot;,
      &quot;schema&quot;: {
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
          &quot;company_mission&quot;: {
            &quot;type&quot;: &quot;string&quot;
          },
          &quot;is_open_source&quot;: {
            &quot;type&quot;: &quot;boolean&quot;
          },
          &quot;is_in_yc&quot;: {
            &quot;type&quot;: &quot;boolean&quot;
          }
        },
        &quot;required&quot;: [
          &quot;company_mission&quot;,
          &quot;is_open_source&quot;,
          &quot;is_in_yc&quot;
        ]
      }
    }&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;success&quot;: true,
  &quot;id&quot;: &quot;44aa536d-f1cb-4706-ab87-ed0386685740&quot;,
  &quot;urlTrace&quot;: []
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using the sdks, it will auto pull the response for you:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;success&quot;: true,
  &quot;data&quot;: {
    &quot;company_mission&quot;: &quot;Firecrawl is the easiest way to extract data from the web. Developers use us to reliably convert URLs into LLM-ready markdown or structured data with a single API call.&quot;,
    &quot;supports_sso&quot;: false,
    &quot;is_open_source&quot;: true,
    &quot;is_in_yc&quot;: true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;LLM Extraction (Beta)&lt;/h3&gt; 
&lt;p&gt;Used to extract structured data from scraped pages.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H &#39;Content-Type: application/json&#39; \
    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \
    -d &#39;{
      &quot;url&quot;: &quot;https://www.mendable.ai/&quot;,
      &quot;formats&quot;: [&quot;json&quot;],
      &quot;jsonOptions&quot;: {
        &quot;schema&quot;: {
          &quot;type&quot;: &quot;object&quot;,
          &quot;properties&quot;: {
            &quot;company_mission&quot;: {
                      &quot;type&quot;: &quot;string&quot;
            },
            &quot;supports_sso&quot;: {
                      &quot;type&quot;: &quot;boolean&quot;
            },
            &quot;is_open_source&quot;: {
                      &quot;type&quot;: &quot;boolean&quot;
            },
            &quot;is_in_yc&quot;: {
                      &quot;type&quot;: &quot;boolean&quot;
            }
          },
          &quot;required&quot;: [
            &quot;company_mission&quot;,
            &quot;supports_sso&quot;,
            &quot;is_open_source&quot;,
            &quot;is_in_yc&quot;
          ]
        }
      }
    }&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;success&quot;: true,
  &quot;data&quot;: {
    &quot;content&quot;: &quot;Raw Content&quot;,
    &quot;metadata&quot;: {
      &quot;title&quot;: &quot;Mendable&quot;,
      &quot;description&quot;: &quot;Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide&quot;,
      &quot;robots&quot;: &quot;follow, index&quot;,
      &quot;ogTitle&quot;: &quot;Mendable&quot;,
      &quot;ogDescription&quot;: &quot;Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide&quot;,
      &quot;ogUrl&quot;: &quot;https://mendable.ai/&quot;,
      &quot;ogImage&quot;: &quot;https://mendable.ai/mendable_new_og1.png&quot;,
      &quot;ogLocaleAlternate&quot;: [],
      &quot;ogSiteName&quot;: &quot;Mendable&quot;,
      &quot;sourceURL&quot;: &quot;https://mendable.ai/&quot;
    },
    &quot;json&quot;: {
      &quot;company_mission&quot;: &quot;Train a secure AI on your technical resources that answers customer and employee questions so your team doesn&#39;t have to&quot;,
      &quot;supports_sso&quot;: true,
      &quot;is_open_source&quot;: false,
      &quot;is_in_yc&quot;: true
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Extracting without a schema (New)&lt;/h3&gt; 
&lt;p&gt;You can now extract without a schema by just passing a &lt;code&gt;prompt&lt;/code&gt; to the endpoint. The llm chooses the structure of the data.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H &#39;Content-Type: application/json&#39; \
    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \
    -d &#39;{
      &quot;url&quot;: &quot;https://docs.firecrawl.dev/&quot;,
      &quot;formats&quot;: [&quot;json&quot;],
      &quot;jsonOptions&quot;: {
        &quot;prompt&quot;: &quot;Extract the company mission from the page.&quot;
      }
    }&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Interacting with the page with Actions (Cloud-only)&lt;/h3&gt; 
&lt;p&gt;Firecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.&lt;/p&gt; 
&lt;p&gt;Here is an example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H &#39;Content-Type: application/json&#39; \
    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \
    -d &#39;{
        &quot;url&quot;: &quot;google.com&quot;,
        &quot;formats&quot;: [&quot;markdown&quot;],
        &quot;actions&quot;: [
            {&quot;type&quot;: &quot;wait&quot;, &quot;milliseconds&quot;: 2000},
            {&quot;type&quot;: &quot;click&quot;, &quot;selector&quot;: &quot;textarea[title=\&quot;Search\&quot;]&quot;},
            {&quot;type&quot;: &quot;wait&quot;, &quot;milliseconds&quot;: 2000},
            {&quot;type&quot;: &quot;write&quot;, &quot;text&quot;: &quot;firecrawl&quot;},
            {&quot;type&quot;: &quot;wait&quot;, &quot;milliseconds&quot;: 2000},
            {&quot;type&quot;: &quot;press&quot;, &quot;key&quot;: &quot;ENTER&quot;},
            {&quot;type&quot;: &quot;wait&quot;, &quot;milliseconds&quot;: 3000},
            {&quot;type&quot;: &quot;click&quot;, &quot;selector&quot;: &quot;h3&quot;},
            {&quot;type&quot;: &quot;wait&quot;, &quot;milliseconds&quot;: 3000},
            {&quot;type&quot;: &quot;screenshot&quot;}
        ]
    }&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Batch Scraping Multiple URLs (New)&lt;/h3&gt; 
&lt;p&gt;You can now batch scrape multiple URLs at the same time. It is very similar to how the /crawl endpoint works. It submits a batch scrape job and returns a job ID to check the status of the batch scrape.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X POST https://api.firecrawl.dev/v1/batch/scrape \
    -H &#39;Content-Type: application/json&#39; \
    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \
    -d &#39;{
      &quot;urls&quot;: [&quot;https://docs.firecrawl.dev&quot;, &quot;https://docs.firecrawl.dev/sdks/overview&quot;],
      &quot;formats&quot; : [&quot;markdown&quot;, &quot;html&quot;]
    }&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Search&lt;/h3&gt; 
&lt;p&gt;The search endpoint combines web search with Firecrawlâ€™s scraping capabilities to return full page content for any query.&lt;/p&gt; 
&lt;p&gt;Include &lt;code&gt;scrapeOptions&lt;/code&gt; with &lt;code&gt;formats: [&quot;markdown&quot;]&lt;/code&gt; to get complete markdown content for each search result otherwise it defaults to getting SERP results (url, title, description).&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -X POST https://api.firecrawl.dev/v1/search \
    -H &#39;Content-Type: application/json&#39; \
    -H &#39;Authorization: Bearer YOUR_API_KEY&#39; \
    -d &#39;{
      &quot;query&quot;: &quot;What is Mendable?&quot;
    }&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;success&quot;: true,
  &quot;data&quot;: [
    {
      &quot;url&quot;: &quot;https://mendable.ai&quot;,
      &quot;title&quot;: &quot;Mendable | AI for CX and Sales&quot;,
      &quot;description&quot;: &quot;AI for CX and Sales&quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using Python SDK&lt;/h2&gt; 
&lt;h3&gt;Installing Python SDK&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install firecrawl-py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Crawl a website&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from firecrawl.firecrawl import FirecrawlApp

app = FirecrawlApp(api_key=&quot;fc-YOUR_API_KEY&quot;)

# Scrape a website:
scrape_status = app.scrape_url(
  &#39;https://firecrawl.dev&#39;, 
  params={&#39;formats&#39;: [&#39;markdown&#39;, &#39;html&#39;]}
)
print(scrape_status)

# Crawl a website:
crawl_status = app.crawl_url(
  &#39;https://firecrawl.dev&#39;, 
  params={
    &#39;limit&#39;: 100, 
    &#39;scrapeOptions&#39;: {&#39;formats&#39;: [&#39;markdown&#39;, &#39;html&#39;]}
  },
  poll_interval=30
)
print(crawl_status)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Extracting structured data from a URL&lt;/h3&gt; 
&lt;p&gt;With LLM extraction, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too. Here is how you to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;
from firecrawl.firecrawl import FirecrawlApp

app = FirecrawlApp(api_key=&quot;fc-YOUR_API_KEY&quot;)

class ArticleSchema(BaseModel):
    title: str
    points: int
    by: str
    commentsURL: str

class TopArticlesSchema(BaseModel):
    top: List[ArticleSchema] = Field(..., max_items=5, description=&quot;Top 5 stories&quot;)

data = app.scrape_url(&#39;https://news.ycombinator.com&#39;, {
    &#39;formats&#39;: [&#39;json&#39;],
    &#39;jsonOptions&#39;: {
        &#39;schema&#39;: TopArticlesSchema.model_json_schema()
    }
})
print(data[&quot;json&quot;])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using the Node SDK&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;To install the Firecrawl Node SDK, you can use npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;npm install @mendable/firecrawl-js
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Get an API key from &lt;a href=&quot;https://firecrawl.dev&quot;&gt;firecrawl.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Set the API key as an environment variable named &lt;code&gt;FIRECRAWL_API_KEY&lt;/code&gt; or pass it as a parameter to the &lt;code&gt;FirecrawlApp&lt;/code&gt; class.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;import FirecrawlApp, { CrawlParams, CrawlStatusResponse } from &#39;@mendable/firecrawl-js&#39;;

const app = new FirecrawlApp({apiKey: &quot;fc-YOUR_API_KEY&quot;});

// Scrape a website
const scrapeResponse = await app.scrapeUrl(&#39;https://firecrawl.dev&#39;, {
  formats: [&#39;markdown&#39;, &#39;html&#39;],
});

if (scrapeResponse) {
  console.log(scrapeResponse)
}

// Crawl a website
const crawlResponse = await app.crawlUrl(&#39;https://firecrawl.dev&#39;, {
  limit: 100,
  scrapeOptions: {
    formats: [&#39;markdown&#39;, &#39;html&#39;],
  }
} satisfies CrawlParams, true, 30) satisfies CrawlStatusResponse;

if (crawlResponse) {
  console.log(crawlResponse)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Extracting structured data from a URL&lt;/h3&gt; 
&lt;p&gt;With LLM extraction, you can easily extract structured data from any URL. We support zod schema to make it easier for you too. Here is how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;import FirecrawlApp from &quot;@mendable/firecrawl-js&quot;;
import { z } from &quot;zod&quot;;

const app = new FirecrawlApp({
  apiKey: &quot;fc-YOUR_API_KEY&quot;
});

// Define schema to extract contents into
const schema = z.object({
  top: z
    .array(
      z.object({
        title: z.string(),
        points: z.number(),
        by: z.string(),
        commentsURL: z.string(),
      })
    )
    .length(5)
    .describe(&quot;Top 5 stories on Hacker News&quot;),
});

const scrapeResult = await app.scrapeUrl(&quot;https://news.ycombinator.com&quot;, {
  jsonOptions: { extractionSchema: schema },
});

console.log(scrapeResult.data[&quot;json&quot;]);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Open Source vs Cloud Offering&lt;/h2&gt; 
&lt;p&gt;Firecrawl is open source available under the AGPL-3.0 license.&lt;/p&gt; 
&lt;p&gt;To deliver the best possible product, we offer a hosted version of Firecrawl alongside our open-source offering. The cloud solution allows us to continuously innovate and maintain a high-quality, sustainable service for all users.&lt;/p&gt; 
&lt;p&gt;Firecrawl Cloud is available at &lt;a href=&quot;https://firecrawl.dev&quot;&gt;firecrawl.dev&lt;/a&gt; and offers a range of features that are not available in the open source version:&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/img/open-source-cloud.png&quot; alt=&quot;Open Source vs Cloud Offering&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We love contributions! Please read our &lt;a href=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/CONTRIBUTING.md&quot;&gt;contributing guide&lt;/a&gt; before submitting a pull request. If you&#39;d like to self-host, refer to the &lt;a href=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/SELF_HOST.md&quot;&gt;self-hosting guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;It is the sole responsibility of the end users to respect websites&#39; policies when scraping, searching and crawling with Firecrawl. Users are advised to adhere to the applicable privacy policies and terms of use of the websites prior to initiating any scraping activities. By default, Firecrawl respects the directives specified in the websites&#39; robots.txt files when crawling. By utilizing Firecrawl, you expressly agree to comply with these conditions.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href=&quot;https://github.com/mendableai/firecrawl/graphs/contributors&quot;&gt; &lt;img alt=&quot;contributors&quot; src=&quot;https://contrib.rocks/image?repo=mendableai/firecrawl&quot;&gt; &lt;/a&gt; 
&lt;h2&gt;License Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is primarily licensed under the GNU Affero General Public License v3.0 (AGPL-3.0), as specified in the LICENSE file in the root directory of this repository. However, certain components of this project are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.&lt;/p&gt; 
&lt;p&gt;Please note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The AGPL-3.0 license applies to all parts of the project unless otherwise specified.&lt;/li&gt; 
 &lt;li&gt;The SDKs and some UI components are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.&lt;/li&gt; 
 &lt;li&gt;When using or contributing to this project, ensure you comply with the appropriate license terms for the specific component you are working with.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more details on the licensing of specific components, please refer to the LICENSE files in the respective directories or contact the project maintainers.&lt;/p&gt; 
&lt;p align=&quot;right&quot; style=&quot;font-size: 14px; color: #555; margin-top: 20px;&quot;&gt; &lt;a href=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/#readme-top&quot; style=&quot;text-decoration: none; color: #007bff; font-weight: bold;&quot;&gt; â†‘ Back to Top â†‘ &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>geekan/MetaGPT</title>
      <link>https://github.com/geekan/MetaGPT</link>
      <description>&lt;p&gt;ğŸŒŸ The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MetaGPT: The Multi-Agent Framework&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/resources/MetaGPT-new-log.png&quot; alt=&quot;MetaGPT logo: Enable GPT to work in a software company, collaborating to tackle more complex tasks.&quot; width=&quot;150px&quot;&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; [ &lt;b&gt;En&lt;/b&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/README_CN.md&quot;&gt;ä¸­&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/README_FR.md&quot;&gt;Fr&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/README_JA.md&quot;&gt;æ—¥&lt;/a&gt; ] &lt;b&gt;Assign different roles to GPTs to form a collaborative entity for complex tasks.&lt;/b&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true&quot; alt=&quot;License: MIT&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/DYn29wFk9z&quot;&gt;&lt;img src=&quot;https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat&quot; alt=&quot;Discord Follow&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/MetaGPT_&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/MetaGPT?style=social&quot; alt=&quot;Twitter Follow&quot;&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h4 align=&quot;center&quot;&gt; &lt;/h4&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;p&gt;ğŸš€ Mar. 10, 2025: ğŸ‰ &lt;a href=&quot;https://mgx.dev/&quot;&gt;mgx.dev&lt;/a&gt; is the #1 Product of the Week on @ProductHunt! ğŸ†&lt;/p&gt; 
&lt;p&gt;ğŸš€ Mar. &amp;nbsp; 4, 2025: ğŸ‰ &lt;a href=&quot;https://mgx.dev/&quot;&gt;mgx.dev&lt;/a&gt; is the #1 Product of the Day on @ProductHunt! ğŸ†&lt;/p&gt; 
&lt;p&gt;ğŸš€ Feb. 19, 2025: Today we are officially launching our natural language programming product: &lt;a href=&quot;https://mgx.dev/&quot;&gt;MGX (MetaGPT X)&lt;/a&gt; - the world&#39;s first AI agent development team. More details on &lt;a href=&quot;https://x.com/MetaGPT_/status/1892199535130329356&quot;&gt;Twitter&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;ğŸš€ Feb. 17, 2025: We introduced two papers: &lt;a href=&quot;https://arxiv.org/pdf/2502.06855&quot;&gt;SPO&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/pdf/2502.12018&quot;&gt;AOT&lt;/a&gt;, check the &lt;a href=&quot;https://raw.githubusercontent.com/geekan/MetaGPT/main/examples&quot;&gt;code&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;ğŸš€ Jan. 22, 2025: Our paper &lt;a href=&quot;https://openreview.net/forum?id=z5uVAKwmjf&quot;&gt;AFlow: Automating Agentic Workflow Generation&lt;/a&gt; accepted for &lt;strong&gt;oral presentation (top 1.8%)&lt;/strong&gt; at ICLR 2025, &lt;strong&gt;ranking #2&lt;/strong&gt; in the LLM-based Agent category.&lt;/p&gt; 
&lt;p&gt;ğŸ‘‰ğŸ‘‰ &lt;a href=&quot;https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/NEWS.md&quot;&gt;Earlier news&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Software Company as Multi-Agent System&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;MetaGPT takes a &lt;strong&gt;one line requirement&lt;/strong&gt; as input and outputs &lt;strong&gt;user stories / competitive analysis / requirements / data structures / APIs / documents, etc.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Internally, MetaGPT includes &lt;strong&gt;product managers / architects / project managers / engineers.&lt;/strong&gt; It provides the entire process of a &lt;strong&gt;software company along with carefully orchestrated SOPs.&lt;/strong&gt; 
  &lt;ol&gt; 
   &lt;li&gt;&lt;code&gt;Code = SOP(Team)&lt;/code&gt; is the core philosophy. We materialize SOP and apply it to teams composed of LLMs.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/resources/software_company_cd.jpeg&quot; alt=&quot;A software company consists of LLM-based roles&quot;&gt;&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt;Software Company Multi-Agent Schematic (Gradually Implementing)&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ensure that Python 3.9 or later, but less than 3.12, is installed on your system. You can check this by using: &lt;code&gt;python --version&lt;/code&gt;.&lt;br&gt; You can use conda like this: &lt;code&gt;conda create -n metagpt python=3.9 &amp;amp;&amp;amp; conda activate metagpt&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install --upgrade metagpt
# or `pip install --upgrade git+https://github.com/geekan/MetaGPT.git`
# or `git clone https://github.com/geekan/MetaGPT &amp;amp;&amp;amp; cd MetaGPT &amp;amp;&amp;amp; pip install --upgrade -e .`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Install &lt;a href=&quot;https://nodejs.org/en/download&quot;&gt;node&lt;/a&gt; and &lt;a href=&quot;https://pnpm.io/installation#using-npm&quot;&gt;pnpm&lt;/a&gt; before actual use.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;For detailed installation guidance, please refer to &lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/get_started/installation.html#install-stable-version&quot;&gt;cli_install&lt;/a&gt; or &lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/get_started/installation.html#install-with-docker&quot;&gt;docker_install&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;You can init the config of MetaGPT by running the following command, or manually create &lt;code&gt;~/.metagpt/config2.yaml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Check https://docs.deepwisdom.ai/main/en/guide/get_started/configuration.html for more details
metagpt --init-config  # it will create ~/.metagpt/config2.yaml, just modify it to your needs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can configure &lt;code&gt;~/.metagpt/config2.yaml&lt;/code&gt; according to the &lt;a href=&quot;https://github.com/geekan/MetaGPT/raw/main/config/config2.example.yaml&quot;&gt;example&lt;/a&gt; and &lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/get_started/configuration.html&quot;&gt;doc&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;llm:
  api_type: &quot;openai&quot;  # or azure / ollama / groq etc. Check LLMType for more options
  model: &quot;gpt-4-turbo&quot;  # or gpt-3.5-turbo
  base_url: &quot;https://api.openai.com/v1&quot;  # or forward url / other llm url
  api_key: &quot;YOUR_API_KEY&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;After installation, you can use MetaGPT at CLI&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;metagpt &quot;Create a 2048 game&quot;  # this will create a repo in ./workspace
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or use it as library&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from metagpt.software_company import generate_repo
from metagpt.utils.project_repo import ProjectRepo

repo: ProjectRepo = generate_repo(&quot;Create a 2048 game&quot;)  # or ProjectRepo(&quot;&amp;lt;path&amp;gt;&quot;)
print(repo)  # it will print the repo structure with files
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use &lt;a href=&quot;https://github.com/geekan/MetaGPT/tree/main/examples/di&quot;&gt;Data Interpreter&lt;/a&gt; to write code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import asyncio
from metagpt.roles.di.data_interpreter import DataInterpreter

async def main():
    di = DataInterpreter()
    await di.run(&quot;Run data analysis on sklearn Iris dataset, include a plot&quot;)

asyncio.run(main())  # or await main() in a jupyter notebook setting
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;QuickStart &amp;amp; Demo Video&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try it on &lt;a href=&quot;https://huggingface.co/spaces/deepwisdom/MetaGPT-SoftwareCompany&quot;&gt;MetaGPT Huggingface Space&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://youtu.be/uT75J_KG_aY&quot;&gt;Matthew Berman: How To Install MetaGPT - Build A Startup With One Prompt!!&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/geekan/MetaGPT/assets/2707039/5e8c1062-8c35-440f-bb20-2b0320f8d27d&quot;&gt;Official Demo Video&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/user-attachments/assets/888cb169-78c3-4a42-9d62-9d90ed3928c9&quot;&gt;https://github.com/user-attachments/assets/888cb169-78c3-4a42-9d62-9d90ed3928c9&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Tutorial&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ—’ &lt;a href=&quot;https://docs.deepwisdom.ai/main/en/&quot;&gt;Online Document&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ’» &lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/get_started/quickstart.html&quot;&gt;Usage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ” &lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/get_started/introduction.html&quot;&gt;What can MetaGPT do?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ›  How to build your own agents? 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/tutorials/agent_101.html&quot;&gt;MetaGPT Usage &amp;amp; Development Guide | Agent 101&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/tutorials/multi_agent_101.html&quot;&gt;MetaGPT Usage &amp;amp; Development Guide | MultiAgent 101&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ğŸ§‘â€ğŸ’» Contribution 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/ROADMAP.md&quot;&gt;Develop Roadmap&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ğŸ”– Use Cases 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/interpreter/intro.html&quot;&gt;Data Interpreter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/use_cases/multi_agent/debate.html&quot;&gt;Debate&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/researcher.html&quot;&gt;Researcher&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/receipt_assistant.html&quot;&gt;Receipt Assistant&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;â“ &lt;a href=&quot;https://docs.deepwisdom.ai/main/en/guide/faq.html&quot;&gt;FAQs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;h3&gt;Discord Join US&lt;/h3&gt; 
&lt;p&gt;ğŸ“¢ Join Our &lt;a href=&quot;https://discord.gg/ZRHeExS6xv&quot;&gt;Discord Channel&lt;/a&gt;! Looking forward to seeing you there! ğŸ‰&lt;/p&gt; 
&lt;h3&gt;Contributor form&lt;/h3&gt; 
&lt;p&gt;ğŸ“ &lt;a href=&quot;https://airtable.com/appInfdG0eJ9J4NNL/pagK3Fh1sGclBvVkV/form&quot;&gt;Fill out the form&lt;/a&gt; to become a contributor. We are looking forward to your participation!&lt;/p&gt; 
&lt;h3&gt;Contact Information&lt;/h3&gt; 
&lt;p&gt;If you have any questions or feedback about this project, please feel free to contact us. We highly appreciate your suggestions!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Email:&lt;/strong&gt; &lt;a href=&quot;mailto:alexanderwu@deepwisdom.ai&quot;&gt;alexanderwu@deepwisdom.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues:&lt;/strong&gt; For more technical inquiries, you can also create a new issue in our &lt;a href=&quot;https://github.com/geekan/metagpt/issues&quot;&gt;GitHub repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We will respond to all questions within 2-3 business days.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;To stay updated with the latest research and development, follow &lt;a href=&quot;https://twitter.com/MetaGPT_&quot;&gt;@MetaGPT_&lt;/a&gt; on Twitter.&lt;/p&gt; 
&lt;p&gt;To cite &lt;a href=&quot;https://openreview.net/forum?id=VtmBAGCN7o&quot;&gt;MetaGPT&lt;/a&gt; in publications, please use the following BibTeX entries.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@inproceedings{hong2024metagpt,
      title={Meta{GPT}: Meta Programming for A Multi-Agent Collaborative Framework},
      author={Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Jinlin Wang and Ceyao Zhang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and J{\&quot;u}rgen Schmidhuber},
      booktitle={The Twelfth International Conference on Learning Representations},
      year={2024},
      url={https://openreview.net/forum?id=VtmBAGCN7o}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more work, please refer to &lt;a href=&quot;https://raw.githubusercontent.com/geekan/MetaGPT/main/docs/ACADEMIC_WORK.md&quot;&gt;Academic Work&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>virattt/ai-hedge-fund</title>
      <link>https://github.com/virattt/ai-hedge-fund</link>
      <description>&lt;p&gt;An AI Hedge Fund Team&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Hedge Fund&lt;/h1&gt; 
&lt;p&gt;This is a proof of concept for an AI-powered hedge fund. The goal of this project is to explore the use of AI to make trading decisions. This project is for &lt;strong&gt;educational&lt;/strong&gt; purposes only and is not intended for real trading or investment.&lt;/p&gt; 
&lt;p&gt;This system employs several agents working together:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety&lt;/li&gt; 
 &lt;li&gt;Bill Ackman Agent - An activist investors, takes bold positions and pushes for change&lt;/li&gt; 
 &lt;li&gt;Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption&lt;/li&gt; 
 &lt;li&gt;Charlie Munger Agent - Warren Buffett&#39;s partner, only buys wonderful businesses at fair prices&lt;/li&gt; 
 &lt;li&gt;Stanley Druckenmiller Agent - Macro trading legend who hunts for asymmetric opportunities with explosive growth potential&lt;/li&gt; 
 &lt;li&gt;Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price&lt;/li&gt; 
 &lt;li&gt;Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Sentiment Agent - Analyzes market sentiment and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Fundamentals Agent - Analyzes fundamental data and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Technicals Agent - Analyzes technical indicators and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Risk Manager - Calculates risk metrics and sets position limits&lt;/li&gt; 
 &lt;li&gt;Portfolio Manager - Makes final trading decisions and generates orders&lt;/li&gt; 
&lt;/ol&gt; 
&lt;img width=&quot;1020&quot; alt=&quot;Screenshot 2025-03-08 at 4 45 22â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/d8ab891e-a083-4fed-b514-ccc9322a3e57&quot;&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: the system simulates trading decisions, it does not actually trade.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://twitter.com/virattt&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/virattt?style=social&quot; alt=&quot;Twitter Follow&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is for &lt;strong&gt;educational and research purposes only&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not intended for real trading or investment&lt;/li&gt; 
 &lt;li&gt;No warranties or guarantees provided&lt;/li&gt; 
 &lt;li&gt;Past performance does not indicate future results&lt;/li&gt; 
 &lt;li&gt;Creator assumes no liability for financial losses&lt;/li&gt; 
 &lt;li&gt;Consult a financial advisor for investment decisions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to use it solely for learning purposes.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#setup&quot;&gt;Setup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#usage&quot;&gt;Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#running-the-hedge-fund&quot;&gt;Running the Hedge Fund&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#running-the-backtester&quot;&gt;Running the Backtester&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#project-structure&quot;&gt;Project Structure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#feature-requests&quot;&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;p&gt;Clone the repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Poetry (if not already installed):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -sSL https://install.python-poetry.org | python3 -
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;poetry install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;Set up your environment variables:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Create .env file for your API keys
cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt;Set your API keys:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
# Get your OpenAI API key from https://platform.openai.com/
OPENAI_API_KEY=your-openai-api-key

# For running LLMs hosted by groq (deepseek, llama3, etc.)
# Get your Groq API key from https://groq.com/
GROQ_API_KEY=your-groq-api-key

# For getting financial data to power the hedge fund
# Get your Financial Datasets API key from https://financialdatasets.ai/
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: You must set &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;GROQ_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, or &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt; for the hedge fund to work. If you want to use LLMs from all providers, you will need to set all API keys.&lt;/p&gt; 
&lt;p&gt;Financial data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key.&lt;/p&gt; 
&lt;p&gt;For any other ticker, you will need to set the &lt;code&gt;FINANCIAL_DATASETS_API_KEY&lt;/code&gt; in the .env file.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Running the Hedge Fund&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example Output:&lt;/strong&gt; &lt;img width=&quot;992&quot; alt=&quot;Screenshot 2025-01-06 at 5 50 17â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b&quot;&gt;&lt;/p&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;--show-reasoning&lt;/code&gt; flag to print the reasoning of each agent to the console.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --show-reasoning
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can optionally specify the start and end dates to make decisions for a specific time period.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01 
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running the Backtester&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example Output:&lt;/strong&gt; &lt;img width=&quot;941&quot; alt=&quot;Screenshot 2025-01-06 at 5 47 52â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47&quot;&gt;&lt;/p&gt; 
&lt;p&gt;You can optionally specify the start and end dates to backtest over a specific time period.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Project Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;ai-hedge-fund/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                   # Agent definitions and workflow
â”‚   â”‚   â”œâ”€â”€ bill_ackman.py        # Bill Ackman agent
â”‚   â”‚   â”œâ”€â”€ fundamentals.py       # Fundamental analysis agent
â”‚   â”‚   â”œâ”€â”€ portfolio_manager.py  # Portfolio management agent
â”‚   â”‚   â”œâ”€â”€ risk_manager.py       # Risk management agent
â”‚   â”‚   â”œâ”€â”€ sentiment.py          # Sentiment analysis agent
â”‚   â”‚   â”œâ”€â”€ technicals.py         # Technical analysis agent
â”‚   â”‚   â”œâ”€â”€ valuation.py          # Valuation analysis agent
â”‚   â”‚   â”œâ”€â”€ warren_buffett.py     # Warren Buffett agent
â”‚   â”œâ”€â”€ tools/                    # Agent tools
â”‚   â”‚   â”œâ”€â”€ api.py                # API tools
â”‚   â”œâ”€â”€ backtester.py             # Backtesting tools
â”‚   â”œâ”€â”€ main.py # Main entry point
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Commit your changes&lt;/li&gt; 
 &lt;li&gt;Push to the branch&lt;/li&gt; 
 &lt;li&gt;Create a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Please keep your pull requests small and focused. This will make it easier to review and merge.&lt;/p&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;p&gt;If you have a feature request, please open an &lt;a href=&quot;https://github.com/virattt/ai-hedge-fund/issues&quot;&gt;issue&lt;/a&gt; and make sure it is tagged with &lt;code&gt;enhancement&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>78/xiaozhi-esp32</title>
      <link>https://github.com/78/xiaozhi-esp32</link>
      <description>&lt;p&gt;Build your own AI friend&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;å°æ™º AI èŠå¤©æœºå™¨äºº ï¼ˆXiaoZhi AI Chatbotï¼‰&lt;/h1&gt; 
&lt;p&gt;ï¼ˆä¸­æ–‡ | &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/README_en.md&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/README_ja.md&quot;&gt;æ—¥æœ¬èª&lt;/a&gt;ï¼‰&lt;/p&gt; 
&lt;p&gt;è¿™æ˜¯è™¾å“¥çš„ç¬¬ä¸€ä¸ªç¡¬ä»¶ä½œå“ã€‚&lt;/p&gt; 
&lt;p&gt;ğŸ‘‰ &lt;a href=&quot;https://www.bilibili.com/video/BV11msTenEH3/&quot;&gt;ESP32+SenseVoice+Qwen72Bæ‰“é€ ä½ çš„AIèŠå¤©ä¼´ä¾£ï¼ã€bilibiliã€‘&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ğŸ‘‰ &lt;a href=&quot;https://www.bilibili.com/video/BV1GQP6eNEFG/&quot;&gt;ç»™å°æ™ºè£…ä¸Š DeepSeek çš„èªæ˜å¤§è„‘ã€bilibiliã€‘&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ğŸ‘‰ &lt;a href=&quot;https://www.bilibili.com/video/BV1XnmFYLEJN/&quot;&gt;æ‰‹å·¥æ‰“é€ ä½ çš„ AI å¥³å‹ï¼Œæ–°æ‰‹å…¥é—¨æ•™ç¨‹ã€bilibiliã€‘&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;é¡¹ç›®ç›®çš„&lt;/h2&gt; 
&lt;p&gt;æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼Œä»¥ MIT è®¸å¯è¯å‘å¸ƒï¼Œå…è®¸ä»»ä½•äººå…è´¹ä½¿ç”¨ï¼Œå¹¶å¯ä»¥ç”¨äºå•†ä¸šç”¨é€”ã€‚&lt;/p&gt; 
&lt;p&gt;æˆ‘ä»¬å¸Œæœ›é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œèƒ½å¤Ÿå¸®åŠ©æ›´å¤šäººå…¥é—¨ AI ç¡¬ä»¶å¼€å‘ï¼Œäº†è§£å¦‚ä½•å°†å½“ä¸‹é£é€Ÿå‘å±•çš„å¤§è¯­è¨€æ¨¡å‹åº”ç”¨åˆ°å®é™…çš„ç¡¬ä»¶è®¾å¤‡ä¸­ã€‚æ— è®ºä½ æ˜¯å¯¹ AI æ„Ÿå…´è¶£çš„å­¦ç”Ÿï¼Œè¿˜æ˜¯æƒ³è¦æ¢ç´¢æ–°æŠ€æœ¯çš„å¼€å‘è€…ï¼Œéƒ½å¯ä»¥é€šè¿‡è¿™ä¸ªé¡¹ç›®è·å¾—å®è´µçš„å­¦ä¹ ç»éªŒã€‚&lt;/p&gt; 
&lt;p&gt;æ¬¢è¿æ‰€æœ‰äººå‚ä¸åˆ°é¡¹ç›®çš„å¼€å‘å’Œæ”¹è¿›ä¸­æ¥ã€‚å¦‚æœä½ æœ‰ä»»ä½•æƒ³æ³•æˆ–å»ºè®®ï¼Œè¯·éšæ—¶æå‡º Issue æˆ–åŠ å…¥ç¾¤èŠã€‚&lt;/p&gt; 
&lt;p&gt;å­¦ä¹ äº¤æµ QQ ç¾¤ï¼š376893254&lt;/p&gt; 
&lt;h2&gt;å·²å®ç°åŠŸèƒ½&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Wi-Fi / ML307 Cat.1 4G&lt;/li&gt; 
 &lt;li&gt;BOOT é”®å”¤é†’å’Œæ‰“æ–­ï¼Œæ”¯æŒç‚¹å‡»å’Œé•¿æŒ‰ä¸¤ç§è§¦å‘æ–¹å¼&lt;/li&gt; 
 &lt;li&gt;ç¦»çº¿è¯­éŸ³å”¤é†’ &lt;a href=&quot;https://github.com/espressif/esp-sr&quot;&gt;ESP-SR&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;æµå¼è¯­éŸ³å¯¹è¯ï¼ˆWebSocket æˆ– UDP åè®®ï¼‰&lt;/li&gt; 
 &lt;li&gt;æ”¯æŒå›½è¯­ã€ç²¤è¯­ã€è‹±è¯­ã€æ—¥è¯­ã€éŸ©è¯­ 5 ç§è¯­è¨€è¯†åˆ« &lt;a href=&quot;https://github.com/FunAudioLLM/SenseVoice&quot;&gt;SenseVoice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;å£°çº¹è¯†åˆ«ï¼Œè¯†åˆ«æ˜¯è°åœ¨å–Š AI çš„åå­— &lt;a href=&quot;https://github.com/modelscope/3D-Speaker&quot;&gt;3D Speaker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;å¤§æ¨¡å‹ TTSï¼ˆç«å±±å¼•æ“ æˆ– CosyVoiceï¼‰&lt;/li&gt; 
 &lt;li&gt;å¤§æ¨¡å‹ LLMï¼ˆQwen, DeepSeek, Doubaoï¼‰&lt;/li&gt; 
 &lt;li&gt;å¯é…ç½®çš„æç¤ºè¯å’ŒéŸ³è‰²ï¼ˆè‡ªå®šä¹‰è§’è‰²ï¼‰&lt;/li&gt; 
 &lt;li&gt;çŸ­æœŸè®°å¿†ï¼Œæ¯è½®å¯¹è¯åè‡ªæˆ‘æ€»ç»“&lt;/li&gt; 
 &lt;li&gt;OLED / LCD æ˜¾ç¤ºå±ï¼Œæ˜¾ç¤ºä¿¡å·å¼ºå¼±æˆ–å¯¹è¯å†…å®¹&lt;/li&gt; 
 &lt;li&gt;æ”¯æŒ LCD æ˜¾ç¤ºå›¾ç‰‡è¡¨æƒ…&lt;/li&gt; 
 &lt;li&gt;æ”¯æŒå¤šè¯­è¨€ï¼ˆä¸­æ–‡ã€è‹±æ–‡ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ç¡¬ä»¶éƒ¨åˆ†&lt;/h2&gt; 
&lt;h3&gt;é¢åŒ…æ¿æ‰‹å·¥åˆ¶ä½œå®è·µ&lt;/h3&gt; 
&lt;p&gt;è¯¦è§é£ä¹¦æ–‡æ¡£æ•™ç¨‹ï¼š&lt;/p&gt; 
&lt;p&gt;ğŸ‘‰ &lt;a href=&quot;https://ccnphfhqs21z.feishu.cn/wiki/F5krwD16viZoF0kKkvDcrZNYnhb?from=from_copylink&quot;&gt;ã€Šå°æ™º AI èŠå¤©æœºå™¨äººç™¾ç§‘å…¨ä¹¦ã€‹&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;é¢åŒ…æ¿æ•ˆæœå›¾å¦‚ä¸‹ï¼š&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/wiring2.jpg&quot; alt=&quot;é¢åŒ…æ¿æ•ˆæœå›¾&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;å·²æ”¯æŒçš„å¼€æºç¡¬ä»¶&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://oshwhub.com/li-chuang-kai-fa-ban/li-chuang-shi-zhan-pai-esp32-s3-kai-fa-ban&quot; target=&quot;_blank&quot; title=&quot;ç«‹åˆ›Â·å®æˆ˜æ´¾ ESP32-S3 å¼€å‘æ¿&quot;&gt;ç«‹åˆ›Â·å®æˆ˜æ´¾ ESP32-S3 å¼€å‘æ¿&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/espressif/esp-box&quot; target=&quot;_blank&quot; title=&quot;ä¹é‘« ESP32-S3-BOX3&quot;&gt;ä¹é‘« ESP32-S3-BOX3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.m5stack.com/zh_CN/core/CoreS3&quot; target=&quot;_blank&quot; title=&quot;M5Stack CoreS3&quot;&gt;M5Stack CoreS3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.m5stack.com/en/atom/Atomic%20Echo%20Base&quot; target=&quot;_blank&quot; title=&quot;AtomS3R + Echo Base&quot;&gt;AtomS3R + Echo Base&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.m5stack.com/en/core/ATOM%20Matrix&quot; target=&quot;_blank&quot; title=&quot;AtomMatrix + Echo Base&quot;&gt;AtomMatrix + Echo Base&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gf.bilibili.com/item/detail/1108782064&quot; target=&quot;_blank&quot; title=&quot;ç¥å¥‡æŒ‰é’® 2.4&quot;&gt;ç¥å¥‡æŒ‰é’® 2.4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.waveshare.net/shop/ESP32-S3-Touch-AMOLED-1.8.htm&quot; target=&quot;_blank&quot; title=&quot;å¾®é›ªç”µå­ ESP32-S3-Touch-AMOLED-1.8&quot;&gt;å¾®é›ªç”µå­ ESP32-S3-Touch-AMOLED-1.8&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Xinyuan-LilyGO/T-Circle-S3&quot; target=&quot;_blank&quot; title=&quot;LILYGO T-Circle-S3&quot;&gt;LILYGO T-Circle-S3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://oshwhub.com/tenclass01/xmini_c3&quot; target=&quot;_blank&quot; title=&quot;è™¾å“¥ Mini C3&quot;&gt;è™¾å“¥ Mini C3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://oshwhub.com/movecall/moji-xiaozhi-ai-derivative-editi&quot; target=&quot;_blank&quot; title=&quot;Movecall Moji ESP32S3&quot;&gt;Moji å°æ™ºAIè¡ç”Ÿç‰ˆ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/WMnologo/xingzhi-ai&quot; target=&quot;_blank&quot; title=&quot;æ— åç§‘æŠ€Nologo-æ˜Ÿæ™º-1.54&quot;&gt;æ— åç§‘æŠ€Nologo-æ˜Ÿæ™º-1.54TFT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/WMnologo/xingzhi-ai&quot; target=&quot;_blank&quot; title=&quot;æ— åç§‘æŠ€Nologo-æ˜Ÿæ™º-0.96&quot;&gt;æ— åç§‘æŠ€Nologo-æ˜Ÿæ™º-0.96TFT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.seeedstudio.com/SenseCAP-Watcher-W1-A-p-5979.html&quot; target=&quot;_blank&quot; title=&quot;SenseCAP Watcher&quot;&gt;SenseCAP Watcher&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div style=&quot;display: flex; justify-content: space-between;&quot;&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/lichuang-s3.jpg&quot; target=&quot;_blank&quot; title=&quot;ç«‹åˆ›Â·å®æˆ˜æ´¾ ESP32-S3 å¼€å‘æ¿&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/lichuang-s3.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/espbox3.jpg&quot; target=&quot;_blank&quot; title=&quot;ä¹é‘« ESP32-S3-BOX3&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/espbox3.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/m5cores3.jpg&quot; target=&quot;_blank&quot; title=&quot;M5Stack CoreS3&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/m5cores3.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/atoms3r.jpg&quot; target=&quot;_blank&quot; title=&quot;AtomS3R + Echo Base&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/atoms3r.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/magiclick.jpg&quot; target=&quot;_blank&quot; title=&quot;ç¥å¥‡æŒ‰é’® 2.4&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/magiclick.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/waveshare.jpg&quot; target=&quot;_blank&quot; title=&quot;å¾®é›ªç”µå­ ESP32-S3-Touch-AMOLED-1.8&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/waveshare.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/lilygo-t-circle-s3.jpg&quot; target=&quot;_blank&quot; title=&quot;LILYGO T-Circle-S3&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/lilygo-t-circle-s3.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/xmini-c3.jpg&quot; target=&quot;_blank&quot; title=&quot;è™¾å“¥ Mini C3&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/xmini-c3.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/movecall-moji-esp32s3.jpg&quot; target=&quot;_blank&quot; title=&quot;Movecall Moji å°æ™ºAIè¡ç”Ÿç‰ˆ&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/movecall-moji-esp32s3.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/wmnologo_xingzhi_1.54.jpg&quot; target=&quot;_blank&quot; title=&quot;æ— åç§‘æŠ€Nologo-æ˜Ÿæ™º-1.54&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/wmnologo_xingzhi_1.54.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/wmnologo_xingzhi_0.96.jpg&quot; target=&quot;_blank&quot; title=&quot;æ— åç§‘æŠ€Nologo-æ˜Ÿæ™º-0.96&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/wmnologo_xingzhi_0.96.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/sensecap_watcher.jpg&quot; target=&quot;_blank&quot; title=&quot;SenseCAP Watcher&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/v1/sensecap_watcher.jpg&quot; width=&quot;240&quot;&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;å›ºä»¶éƒ¨åˆ†&lt;/h2&gt; 
&lt;h3&gt;å…å¼€å‘ç¯å¢ƒçƒ§å½•&lt;/h3&gt; 
&lt;p&gt;æ–°æ‰‹ç¬¬ä¸€æ¬¡æ“ä½œå»ºè®®å…ˆä¸è¦æ­å»ºå¼€å‘ç¯å¢ƒï¼Œç›´æ¥ä½¿ç”¨å…å¼€å‘ç¯å¢ƒçƒ§å½•çš„å›ºä»¶ã€‚&lt;/p&gt; 
&lt;p&gt;å›ºä»¶é»˜è®¤æ¥å…¥ &lt;a href=&quot;https://xiaozhi.me&quot;&gt;xiaozhi.me&lt;/a&gt; å®˜æ–¹æœåŠ¡å™¨ï¼Œç›®å‰ä¸ªäººç”¨æˆ·æ³¨å†Œè´¦å·å¯ä»¥å…è´¹ä½¿ç”¨ Qwen å®æ—¶æ¨¡å‹ã€‚&lt;/p&gt; 
&lt;p&gt;ğŸ‘‰ &lt;a href=&quot;https://ccnphfhqs21z.feishu.cn/wiki/Zpz4wXBtdimBrLk25WdcXzxcnNS&quot;&gt;Flashçƒ§å½•å›ºä»¶ï¼ˆæ— IDFå¼€å‘ç¯å¢ƒï¼‰&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;å¼€å‘ç¯å¢ƒ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cursor æˆ– VSCode&lt;/li&gt; 
 &lt;li&gt;å®‰è£… ESP-IDF æ’ä»¶ï¼Œé€‰æ‹© SDK ç‰ˆæœ¬ 5.3 æˆ–ä»¥ä¸Š&lt;/li&gt; 
 &lt;li&gt;Linux æ¯” Windows æ›´å¥½ï¼Œç¼–è¯‘é€Ÿåº¦å¿«ï¼Œä¹Ÿå…å»é©±åŠ¨é—®é¢˜çš„å›°æ‰°&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨ Google C++ ä»£ç é£æ ¼ï¼Œæäº¤ä»£ç æ—¶è¯·ç¡®ä¿ç¬¦åˆè§„èŒƒ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;æ™ºèƒ½ä½“é…ç½®&lt;/h2&gt; 
&lt;p&gt;å¦‚æœä½ å·²ç»æ‹¥æœ‰ä¸€ä¸ªå°æ™º AI èŠå¤©æœºå™¨äººè®¾å¤‡ï¼Œå¯ä»¥ç™»å½• &lt;a href=&quot;https://xiaozhi.me&quot;&gt;xiaozhi.me&lt;/a&gt; æ§åˆ¶å°è¿›è¡Œé…ç½®ã€‚&lt;/p&gt; 
&lt;p&gt;ğŸ‘‰ &lt;a href=&quot;https://www.bilibili.com/video/BV1jUCUY2EKM/&quot;&gt;åå°æ“ä½œè§†é¢‘æ•™ç¨‹ï¼ˆæ—§ç‰ˆç•Œé¢ï¼‰&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;æŠ€æœ¯åŸç†ä¸ç§æœ‰åŒ–éƒ¨ç½²&lt;/h2&gt; 
&lt;p&gt;ğŸ‘‰ &lt;a href=&quot;https://raw.githubusercontent.com/78/xiaozhi-esp32/main/docs/websocket.md&quot;&gt;ä¸€ä»½è¯¦ç»†çš„ WebSocket é€šä¿¡åè®®æ–‡æ¡£&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;åœ¨ä¸ªäººç”µè„‘ä¸Šéƒ¨ç½²æœåŠ¡å™¨ï¼Œå¯ä»¥å‚è€ƒå¦ä¸€ä½ä½œè€…åŒæ ·ä»¥ MIT è®¸å¯è¯å¼€æºçš„é¡¹ç›® &lt;a href=&quot;https://github.com/xinnan-tech/xiaozhi-esp32-server&quot;&gt;xiaozhi-esp32-server&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href=&quot;https://star-history.com/#78/xiaozhi-esp32&amp;amp;Date&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=78/xiaozhi-esp32&amp;amp;type=Date&amp;amp;theme=dark&quot;&gt; 
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=78/xiaozhi-esp32&amp;amp;type=Date&quot;&gt; 
  &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=78/xiaozhi-esp32&amp;amp;type=Date&quot;&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>FujiwaraChoki/MoneyPrinterV2</title>
      <link>https://github.com/FujiwaraChoki/MoneyPrinterV2</link>
      <description>&lt;p&gt;Automate the process of making money online.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MoneyPrinter V2&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;â™¥ï¸ If you&#39;re interested in using a hosted version, sign up here &lt;a href=&quot;https://www.shiori.ai&quot;&gt;shiori.ai&lt;/a&gt;, an AI tool that combines all other AI tools into one.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğ• Also, follow me on X: &lt;a href=&quot;https://x.com/DevBySami&quot;&gt;@DevBySami&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/FujiwaraChoki/MoneyPrinterV2&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/made_with-%E2%9D%A4-red?style=for-the-badge&amp;amp;labelColor=orange&quot; alt=&quot;madewithlove&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.buymeacoffee.com/fujicodes&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Buy%20Me%20A%20Coffee-Donate-brightgreen?logo=buymeacoffee&quot; alt=&quot;Buy Me A Coffee&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/FujiwaraChoki/MoneyPrinterV2/raw/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/FujiwaraChoki/MoneyPrinterV2?style=for-the-badge&quot; alt=&quot;GitHub license&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/FujiwaraChoki/MoneyPrinterV2/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/FujiwaraChoki/MoneyPrinterV2?style=for-the-badge&quot; alt=&quot;GitHub issues&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/FujiwaraChoki/MoneyPrinterV2/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/FujiwaraChoki/MoneyPrinterV2?style=for-the-badge&quot; alt=&quot;GitHub stars&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://dsc.gg/fuji-community&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1134848537704804432?style=for-the-badge&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Follow me on &lt;a href=&quot;https://x.com/DevBySami&quot;&gt;X&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;An Application that automates the process of making money online. MPV2 (MoneyPrinter Version 2) is, as the name suggests, the second version of the MoneyPrinter project. It is a complete rewrite of the original project, with a focus on a wider range of features and a more modular architecture.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; MPV2 needs Python 3.9 to function effectively. Watch the YouTube video &lt;a href=&quot;https://youtu.be/wAZ_ZSuIqfk&quot;&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Twitter Bot (with CRON Jobs =&amp;gt; &lt;code&gt;scheduler&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; YouTube Shorts Automater (with CRON Jobs =&amp;gt; &lt;code&gt;scheduler&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Affiliate Marketing (Amazon + Twitter)&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Find local businesses &amp;amp; cold outreach&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Versions&lt;/h2&gt; 
&lt;p&gt;MoneyPrinter has different versions for multiple languages developed by the community for the community. Here are some known versions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chinese: &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo&quot;&gt;MoneyPrinterTurbo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you would like to submit your own version/fork of MoneyPrinter, please open an issue describing the changes you made to the fork.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Please install &lt;a href=&quot;https://visualstudio.microsoft.com/de/visual-cpp-build-tools/&quot;&gt;Microsoft Visual C++ build tools&lt;/a&gt; first, so that CoquiTTS can function correctly.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ If you are planning to reach out to scraped businesses per E-Mail, please first install the &lt;a href=&quot;https://golang.org/&quot;&gt;Go Programming Language&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/FujiwaraChoki/MoneyPrinterV2.git

cd MoneyPrinterV2
# Copy Example Configuration and fill out values in config.json
cp config.example.json config.json

# Create a virtual environment
python -m venv venv

# Activate the virtual environment - Windows
.\venv\Scripts\activate

# Activate the virtual environment - Unix
source venv/bin/activate

# Install the requirements
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Run the application
python src/main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;All relevant document can be found &lt;a href=&quot;https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/docs/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Scripts&lt;/h2&gt; 
&lt;p&gt;For easier usage, there are some scripts in the &lt;code&gt;scripts&lt;/code&gt; directory, that can be used to directly access the core functionality of MPV2, without the need of user interaction.&lt;/p&gt; 
&lt;p&gt;All scripts need to be run from the root directory of the project, e.g. &lt;code&gt;bash scripts/upload_video.sh&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href=&quot;https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; for details on our code of conduct, and the process for submitting pull requests to us. Check out &lt;a href=&quot;https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/docs/Roadmap.md&quot;&gt;docs/Roadmap.md&lt;/a&gt; for a list of features that need to be implemented.&lt;/p&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href=&quot;https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/CODE_OF_CONDUCT.md&quot;&gt;CODE_OF_CONDUCT.md&lt;/a&gt; for details on our code of conduct, and the process for submitting pull requests to us.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MoneyPrinterV2 is licensed under &lt;code&gt;Affero General Public License v3.0&lt;/code&gt;. See &lt;a href=&quot;https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/coqui-ai/TTS&quot;&gt;CoquiTTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/xtekky/gpt4free&quot;&gt;gpt4free&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is for educational purposes only. The author will not be responsible for any misuse of the information provided. All the information on this website is published in good faith and for general information purpose only. The author does not make any warranties about the completeness, reliability, and accuracy of this information. Any action you take upon the information you find on this website (FujiwaraChoki/MoneyPrinterV2), is strictly at your own risk. The author will not be liable for any losses and/or damages in connection with the use of our website.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>docmost/docmost</title>
      <link>https://github.com/docmost/docmost</link>
      <description>&lt;p&gt;Docmost is an open-source collaborative wiki and documentation software. It is an open-source alternative to Confluence and Notion.&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;h1&gt;&lt;b&gt;Docmost&lt;/b&gt;&lt;/h1&gt; 
 &lt;p&gt; Open-source collaborative wiki and documentation software. &lt;br&gt; &lt;a href=&quot;https://docmost.com&quot;&gt;&lt;strong&gt;Website&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://docmost.com/docs&quot;&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br&gt; Docmost is currently in &lt;strong&gt;beta&lt;/strong&gt;. We value your feedback as we progress towards a stable release.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;To get started with Docmost, please refer to our &lt;a href=&quot;https://docmost.com/docs&quot;&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Real-time collaboration&lt;/li&gt; 
 &lt;li&gt;Diagrams (Draw.io, Excalidraw and Mermaid)&lt;/li&gt; 
 &lt;li&gt;Spaces&lt;/li&gt; 
 &lt;li&gt;Permissions management&lt;/li&gt; 
 &lt;li&gt;Groups&lt;/li&gt; 
 &lt;li&gt;Comments&lt;/li&gt; 
 &lt;li&gt;Page history&lt;/li&gt; 
 &lt;li&gt;Search&lt;/li&gt; 
 &lt;li&gt;File attachments&lt;/li&gt; 
 &lt;li&gt;Embeds (Airtable, Loom, Miro and more)&lt;/li&gt; 
 &lt;li&gt;Translations (10+ languages)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Screenshots&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img alt=&quot;home&quot; src=&quot;https://docmost.com/screenshots/home.png&quot; width=&quot;70%&quot;&gt; &lt;img alt=&quot;editor&quot; src=&quot;https://docmost.com/screenshots/editor.png&quot; width=&quot;70%&quot;&gt; &lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;Docmost core is licensed under the open-source AGPL 3.0 license.&lt;br&gt; Enterprise features are available under an enterprise license (Enterprise Edition).&lt;/p&gt; 
&lt;p&gt;All files in the following directories are licensed under the Docmost Enterprise license defined in &lt;code&gt;packages/ee/License&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;apps/server/src/ee&lt;/li&gt; 
 &lt;li&gt;apps/client/src/ee&lt;/li&gt; 
 &lt;li&gt;packages/ee&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://docmost.com/docs/self-hosting/development&quot;&gt;development documentation&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>langgenius/dify</title>
      <link>https://github.com/langgenius/dify</link>
      <description>&lt;p&gt;Dify is an open-source LLM app development platform. Dify&#39;s intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/langgenius/dify/assets/13230914/f9e19af5-61ba-4119-b926-d10c4c06ebab&quot; alt=&quot;cover-v5-optimized&quot;&gt;&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; ğŸ“Œ &lt;a href=&quot;https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast&quot;&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://cloud.dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; Â· &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted&quot;&gt;Self-hosting&lt;/a&gt; Â· &lt;a href=&quot;https://docs.dify.ai&quot;&gt;Documentation&lt;/a&gt; Â· &lt;a href=&quot;https://udify.app/chat/22L1zSxg6yW1cWQg&quot;&gt;Enterprise inquiry&lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://dify.ai&quot; target=&quot;_blank&quot;&gt; &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Product-F04438&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://dify.ai/pricing&quot; target=&quot;_blank&quot;&gt; &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/free-pricing?logo=free&amp;amp;color=%20%23155EEF&amp;amp;label=pricing&amp;amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/discord/1082486657678311454?logo=discord&amp;amp;labelColor=%20%235462eb&amp;amp;logoColor=%20%23f5f5f5&amp;amp;color=%20%235462eb&quot; alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://reddit.com/r/difyai&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;amp;logo=reddit&amp;amp;label=r%2Fdifyai&amp;amp;labelColor=white&quot; alt=&quot;join Reddit&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=dify_ai&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;amp;color=%20%23f5f5f5&quot; alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.linkedin.com/company/langgenius/&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;amp;logoColor=fff&quot; alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://hub.docker.com/u/langgenius&quot; target=&quot;_blank&quot;&gt; &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;amp;color=%20%23f79009&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/langgenius/dify/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt; &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/langgenius/dify/&quot; target=&quot;_blank&quot;&gt; &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;amp;label=issues%20closed&amp;amp;labelColor=%20%237d89b0&amp;amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/langgenius/dify/discussions/&quot; target=&quot;_blank&quot;&gt; &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_TW.md&quot;&gt;&lt;img alt=&quot;ç¹é«”ä¸­æ–‡æ–‡ä»¶&quot; src=&quot;https://img.shields.io/badge/%E7%B9%81%E9%AB%94%E4%B8%AD%E6%96%87-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_CN.md&quot;&gt;&lt;img alt=&quot;ç®€ä½“ä¸­æ–‡ç‰ˆè‡ªè¿°æ–‡ä»¶&quot; src=&quot;https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_JA.md&quot;&gt;&lt;img alt=&quot;æ—¥æœ¬èªã®README&quot; src=&quot;https://img.shields.io/badge/%E6%97%A5%E6%9C%AC%E8%AA%9E-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_ES.md&quot;&gt;&lt;img alt=&quot;README en EspaÃ±ol&quot; src=&quot;https://img.shields.io/badge/Espa%C3%B1ol-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_FR.md&quot;&gt;&lt;img alt=&quot;README en FranÃ§ais&quot; src=&quot;https://img.shields.io/badge/Fran%C3%A7ais-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_KL.md&quot;&gt;&lt;img alt=&quot;README tlhIngan Hol&quot; src=&quot;https://img.shields.io/badge/Klingon-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_KR.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/%ED%95%9C%EA%B5%AD%EC%96%B4-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_AR.md&quot;&gt;&lt;img alt=&quot;README Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©&quot; src=&quot;https://img.shields.io/badge/%D8%A7%D9%84%D8%B9%D8%B1%D8%A8%D9%8A%D8%A9-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_TR.md&quot;&gt;&lt;img alt=&quot;TÃ¼rkÃ§e README&quot; src=&quot;https://img.shields.io/badge/T%C3%BCrk%C3%A7e-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_VI.md&quot;&gt;&lt;img alt=&quot;README Tiáº¿ng Viá»‡t&quot; src=&quot;https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_DE.md&quot;&gt;&lt;img alt=&quot;README in Deutsch&quot; src=&quot;https://img.shields.io/badge/German-d9d9d9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/README_BN.md&quot;&gt;&lt;img alt=&quot;README in à¦¬à¦¾à¦‚à¦²à¦¾&quot; src=&quot;https://img.shields.io/badge/%E0%A6%AC%E0%A6%BE%E0%A6%82%E0%A6%B2%E0%A6%BE-d9d9d9&quot;&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Dify is an open-source LLM app development platform. Its intuitive interface combines agentic AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.&lt;/p&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Before installing Dify, make sure your machine meets the following minimum system requirements:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CPU &amp;gt;= 2 Core&lt;/li&gt; 
  &lt;li&gt;RAM &amp;gt;= 4 GiB&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;br&gt; 
&lt;p&gt;The easiest way to start the Dify server is through &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/docker/docker-compose.yaml&quot;&gt;docker compose&lt;/a&gt;. Before running Dify with the following commands, make sure that &lt;a href=&quot;https://docs.docker.com/get-docker/&quot;&gt;Docker&lt;/a&gt; and &lt;a href=&quot;https://docs.docker.com/compose/install/&quot;&gt;Docker Compose&lt;/a&gt; are installed on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd dify
cd docker
cp .env.example .env
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After running, you can access the Dify dashboard in your browser at &lt;a href=&quot;http://localhost/install&quot;&gt;http://localhost/install&lt;/a&gt; and start the initialization process.&lt;/p&gt; 
&lt;h4&gt;Seeking help&lt;/h4&gt; 
&lt;p&gt;Please refer to our &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted/faqs&quot;&gt;FAQ&lt;/a&gt; if you encounter problems setting up Dify. Reach out to &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/#community--contact&quot;&gt;the community and us&lt;/a&gt; if you are still having issues.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you&#39;d like to contribute to Dify or do additional development, refer to our &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted/local-source-code&quot;&gt;guide to deploying from source code&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Key features&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Workflow&lt;/strong&gt;: Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/langgenius/dify/assets/13230914/356df23e-1604-483d-80a6-9517ece318aa&quot;&gt;https://github.com/langgenius/dify/assets/13230914/356df23e-1604-483d-80a6-9517ece318aa&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Comprehensive model support&lt;/strong&gt;: Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found &lt;a href=&quot;https://docs.dify.ai/getting-started/readme/model-providers&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3&quot; alt=&quot;providers-v5&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. Prompt IDE&lt;/strong&gt;: Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4. RAG Pipeline&lt;/strong&gt;: Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5. Agent capabilities&lt;/strong&gt;: You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALLÂ·E, Stable Diffusion and WolframAlpha.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6. LLMOps&lt;/strong&gt;: Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;7. Backend-as-a-Service&lt;/strong&gt;: All of Dify&#39;s offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.&lt;/p&gt; 
&lt;h2&gt;Feature Comparison&lt;/h2&gt; 
&lt;table style=&quot;width: 100%;&quot;&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;Feature&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;Dify.AI&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;LangChain&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;Flowise&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;OpenAI Assistants API&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;Programming Approach&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;API + App-oriented&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Python Code&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;App-oriented&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;API-oriented&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;Supported LLMs&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;OpenAI-only&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;RAG Engine&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;Agent&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âŒ&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;Workflow&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âŒ&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;Observability&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âŒ&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;Enterprise Feature (SSO/Access control)&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âŒ&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âŒ&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;Local Deployment&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âœ…&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Using Dify&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cloud &lt;br&gt;&lt;/strong&gt; We host a &lt;a href=&quot;https://dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self-hosting Dify Community Edition&lt;br&gt;&lt;/strong&gt; Quickly get Dify running in your environment with this &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/#quick-start&quot;&gt;starter guide&lt;/a&gt;. Use our &lt;a href=&quot;https://docs.dify.ai&quot;&gt;documentation&lt;/a&gt; for further references and more in-depth instructions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dify for enterprise / organizations&lt;br&gt;&lt;/strong&gt; We provide additional enterprise-centric features. &lt;a href=&quot;https://udify.app/chat/22L1zSxg6yW1cWQg&quot;&gt;Log your questions for us through this chatbot&lt;/a&gt; or &lt;a href=&quot;mailto:business@dify.ai?subject=%5BGitHub%5DBusiness%20License%20Inquiry&quot;&gt;send us an email&lt;/a&gt; to discuss enterprise needs. &lt;br&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;For startups and small businesses using AWS, check out &lt;a href=&quot;https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6&quot;&gt;Dify Premium on AWS Marketplace&lt;/a&gt; and deploy it to your own AWS VPC with one-click. It&#39;s an affordable AMI offering with the option to create apps with custom logo and branding.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Staying ahead&lt;/h2&gt; 
&lt;p&gt;Star Dify on GitHub and be instantly notified of new releases.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4&quot; alt=&quot;star-us&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Advanced Setup&lt;/h2&gt; 
&lt;p&gt;If you need to customize the configuration, please refer to the comments in our &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/docker/.env.example&quot;&gt;.env.example&lt;/a&gt; file and update the corresponding values in your &lt;code&gt;.env&lt;/code&gt; file. Additionally, you might need to make adjustments to the &lt;code&gt;docker-compose.yaml&lt;/code&gt; file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run &lt;code&gt;docker-compose up -d&lt;/code&gt;. You can find the full list of available environment variables &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted/environments&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you&#39;d like to configure a highly-available setup, there are community-contributed &lt;a href=&quot;https://helm.sh/&quot;&gt;Helm Charts&lt;/a&gt; and YAML files which allow Dify to be deployed on Kubernetes.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/douban/charts/tree/master/charts/dify&quot;&gt;Helm Chart by @LeoQuote&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/BorisPolonsky/dify-helm&quot;&gt;Helm Chart by @BorisPolonsky&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Winson-030/dify-kubernetes&quot;&gt;YAML file by @Winson-030&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using Terraform for Deployment&lt;/h4&gt; 
&lt;p&gt;Deploy Dify to Cloud Platform with a single click using &lt;a href=&quot;https://www.terraform.io/&quot;&gt;terraform&lt;/a&gt;&lt;/p&gt; 
&lt;h5&gt;Azure Global&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/nikawang/dify-azure-terraform&quot;&gt;Azure Terraform by @nikawang&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Google Cloud&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/DeNA/dify-google-cloud-terraform&quot;&gt;Google Cloud Terraform by @sotazum&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using AWS CDK for Deployment&lt;/h4&gt; 
&lt;p&gt;Deploy Dify to AWS with &lt;a href=&quot;https://aws.amazon.com/cdk/&quot;&gt;CDK&lt;/a&gt;&lt;/p&gt; 
&lt;h5&gt;AWS&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/aws-samples/solution-for-deploying-dify-on-aws&quot;&gt;AWS CDK by @KevinZhao&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;For those who&#39;d like to contribute code, see our &lt;a href=&quot;https://github.com/langgenius/dify/raw/main/CONTRIBUTING.md&quot;&gt;Contribution Guide&lt;/a&gt;. At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We are looking for contributors to help with translating Dify to languages other than Mandarin or English. If you are interested in helping, please see the &lt;a href=&quot;https://github.com/langgenius/dify/raw/main/web/i18n/README.md&quot;&gt;i18n README&lt;/a&gt; for more information, and leave us a comment in the &lt;code&gt;global-users&lt;/code&gt; channel of our &lt;a href=&quot;https://discord.gg/8Tpq4AcN9c&quot;&gt;Discord Community Server&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Community &amp;amp; contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/langgenius/dify/discussions&quot;&gt;Github Discussion&lt;/a&gt;. Best for: sharing feedback and asking questions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/langgenius/dify/issues&quot;&gt;GitHub Issues&lt;/a&gt;. Best for: bugs you encounter using Dify.AI, and feature proposals. See our &lt;a href=&quot;https://github.com/langgenius/dify/raw/main/CONTRIBUTING.md&quot;&gt;Contribution Guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot;&gt;Discord&lt;/a&gt;. Best for: sharing your applications and hanging out with the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://twitter.com/dify_ai&quot;&gt;X(Twitter)&lt;/a&gt;. Best for: sharing your applications and hanging out with the community.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Contributors&lt;/strong&gt;&lt;/p&gt; 
&lt;a href=&quot;https://github.com/langgenius/dify/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=langgenius/dify&quot;&gt; &lt;/a&gt; 
&lt;h2&gt;Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://star-history.com/#langgenius/dify&amp;amp;Date&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=langgenius/dify&amp;amp;type=Date&quot; alt=&quot;Star History Chart&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Security disclosure&lt;/h2&gt; 
&lt;p&gt;To protect your privacy, please avoid posting security issues on GitHub. Instead, send your questions to &lt;a href=&quot;mailto:security@dify.ai&quot;&gt;security@dify.ai&lt;/a&gt; and we will provide you with a more detailed answer.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is available under the &lt;a href=&quot;https://raw.githubusercontent.com/langgenius/dify/main/LICENSE&quot;&gt;Dify Open Source License&lt;/a&gt;, which is essentially Apache 2.0 with a few additional restrictions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>codecrafters-io/build-your-own-x</title>
      <link>https://github.com/codecrafters-io/build-your-own-x</link>
      <description>&lt;p&gt;Master programming by recreating your favorite technologies from scratch.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://codecrafters.io/github-banner&quot;&gt;&lt;img src=&quot;https://codecrafters.io/images/byox-banner.gif&quot; alt=&quot;Banner&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Build your own &amp;lt;insert-technology-here&amp;gt;&lt;/h2&gt; 
&lt;p&gt;This repository is a compilation of well-written, step-by-step guides for re-creating our favorite technologies from scratch.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;What I cannot create, I do not understand â€” Richard Feynman.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;It&#39;s a great way to learn.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-3d-renderer&quot;&gt;3D Renderer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-augmented-reality&quot;&gt;Augmented Reality&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-bittorrent-client&quot;&gt;BitTorrent Client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-blockchain--cryptocurrency&quot;&gt;Blockchain / Cryptocurrency&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-bot&quot;&gt;Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-command-line-tool&quot;&gt;Command-Line Tool&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-database&quot;&gt;Database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-docker&quot;&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-emulator--virtual-machine&quot;&gt;Emulator / Virtual Machine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-front-end-framework--library&quot;&gt;Front-end Framework / Library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-game&quot;&gt;Game&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-git&quot;&gt;Git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-network-stack&quot;&gt;Network Stack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-neural-network&quot;&gt;Neural Network&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-operating-system&quot;&gt;Operating System&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-physics-engine&quot;&gt;Physics Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-programming-language&quot;&gt;Programming Language&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-regex-engine&quot;&gt;Regex Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-search-engine&quot;&gt;Search Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-shell&quot;&gt;Shell&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-template-engine&quot;&gt;Template Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-text-editor&quot;&gt;Text Editor&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-visual-recognition-system&quot;&gt;Visual Recognition System&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-voxel-engine&quot;&gt;Voxel Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-web-browser&quot;&gt;Web Browser&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#build-your-own-web-server&quot;&gt;Web Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/codecrafters-io/build-your-own-x/master/#uncategorized&quot;&gt;Uncategorized&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tutorials&lt;/h2&gt; 
&lt;h4&gt;Build your own &lt;code&gt;3D Renderer&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-ray-tracing/how-does-it-work&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Introduction to Ray Tracing: a Simple Method for Creating 3D Images&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ssloy/tinyrenderer/wiki&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;How OpenGL works: software rendering in 500 lines of code&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://lodev.org/cgtutor/raycasting.html&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Raycasting engine of Wolfenstein 3D&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.pbr-book.org/&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Physically Based Rendering:From Theory To Implementation&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raytracing.github.io/books/RayTracingInOneWeekend.html&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Ray Tracing in One Weekend&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/overview-rasterization-algorithm&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Rasterization: a Practical Implementation&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.davrous.com/2013/06/13/tutorial-series-learning-how-to-write-a-3d-soft-engine-from-scratch-in-c-typescript-or-javascript/&quot;&gt;&lt;strong&gt;C# / TypeScript / JavaScript&lt;/strong&gt;: &lt;em&gt;Learning how to write a 3D soft engine from scratch in C#, TypeScript or JavaScript&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://avik-das.github.io/build-your-own-raytracer/&quot;&gt;&lt;strong&gt;Java / JavaScript&lt;/strong&gt;: &lt;em&gt;Build your own 3D renderer&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://blog.rogach.org/2015/08/how-to-create-your-own-simple-3d-render.html&quot;&gt;&lt;strong&gt;Java&lt;/strong&gt;: &lt;em&gt;How to create your own simple 3D render engine in pure Java&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.gabrielgambetta.com/computer-graphics-from-scratch/introduction.html&quot;&gt;&lt;strong&gt;JavaScript / Pseudocode&lt;/strong&gt;: &lt;em&gt;Computer Graphics from scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/a-3d-modeller.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;A 3D Modeller&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Augmented Reality&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=uXNjNcqW4kY&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;How To: Augmented Reality App Tutorial for Beginners with Vuforia and Unity 3D&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLKIKuXdn4ZMjuUAtdQfK1vwTZPQn_rgSv&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;How To Unity ARCore&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLPCqNOwwN794Gz5fzUSi1p4OqLU0HTmvn&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;AR Portal Tutorial with Unity&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qTSDPkPyPqs&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;How to create a Dragon in Augmented Reality in Unity ARCore&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Z5AmqMuNi08&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;How to Augmented Reality AR Tutorial: ARKit Portal to the Upside Down&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://bitesofcode.wordpress.com/2017/09/12/augmented-reality-with-python-and-opencv-part-1/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Augmented Reality with Python and OpenCV&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;BitTorrent Client&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.seanjoflynn.com/research/bittorrent.html&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;Building a BitTorrent client from scratch in C#&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.jse.li/posts/torrent/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Building a BitTorrent client from the ground up in Go&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://xmonader.github.io/nimdays/day02_bencode.html&quot;&gt;&lt;strong&gt;Nim&lt;/strong&gt;: &lt;em&gt;Writing a Bencode Parser&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://allenkim67.github.io/programming/2016/05/04/how-to-make-your-own-bittorrent-client.html&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;Write your own bittorrent client&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://markuseliasson.se/article/bittorrent-in-python/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;A BitTorrent client in Python 3.5&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Blockchain / Cryptocurrency&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://beta.observablehq.com/@galletti94/functional-blockchain&quot;&gt;&lt;strong&gt;ATS&lt;/strong&gt;: &lt;em&gt;Functional Blockchain&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://programmingblockchain.gitbooks.io/programmingblockchain/&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;Programming The Blockchain in C#&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@bradford_hamilton/write-your-own-blockchain-and-pow-algorithm-using-crystal-d53d5d9d0c52&quot;&gt;&lt;strong&gt;Crystal&lt;/strong&gt;: &lt;em&gt;Write your own blockchain and PoW algorithm using Crystal&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://jeiwan.net/posts/building-blockchain-in-go-part-1/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Building Blockchain in Go&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@mycoralhealth/code-your-own-blockchain-in-less-than-200-lines-of-go-e296282bcffc&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Code your own blockchain in less than 200 lines of Go&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/programmers-blockchain/create-simple-blockchain-java-tutorial-from-scratch-6eeed3cb03fa&quot;&gt;&lt;strong&gt;Java&lt;/strong&gt;: &lt;em&gt;Creating Your First Blockchain with Java&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/conradoqg/naivecoin&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;A cryptocurrency implementation in less than 1500 lines of code&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/nambrot/blockchain-in-js&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build your own Blockchain in JavaScript&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/digital-alchemy-holdings/learn-build-a-javascript-blockchain-part-1-ca61c285821e&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Learn &amp;amp; Build a JavaScript Blockchain&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/SavjeeTutorials/SavjeeCoin&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Creating a blockchain with JavaScript&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hackernoon.com/how-to-launch-your-own-production-ready-cryptocurrency-ab97cb773371&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;How To Launch Your Own Production-Ready Cryptocurrency&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.smashingmagazine.com/2020/02/cryptocurrency-blockchain-node-js/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Writing a Blockchain in Node.js&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@vasilyf/lets-implement-a-cryptocurrency-in-kotlin-part-1-blockchain-8704069f8580&quot;&gt;&lt;strong&gt;Kotlin&lt;/strong&gt;: &lt;em&gt;Letâ€™s implement a cryptocurrency in Kotlin&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hackernoon.com/learn-blockchains-by-building-one-117428612f46&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Learn Blockchains by Building One&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://ecomunsing.com/build-your-own-blockchain&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Build your own blockchain: a Python tutorial&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://adilmoujahid.com/posts/2018/03/intro-blockchain-bitcoin-python/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;A Practical Introduction to Blockchain with Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/crypto-currently/lets-build-the-tiniest-blockchain-e70965a248b&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Letâ€™s Build the Tiniest Blockchain&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/yukimotopress/programming-blockchains-step-by-step&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;Programming Blockchains Step-by-Step (Manuscripts Book Edition)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.freecodecamp.org/how-to-build-a-simple-actor-based-blockchain-aac1e996c177&quot;&gt;&lt;strong&gt;Scala&lt;/strong&gt;: &lt;em&gt;How to build a simple actor-based blockchain&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://lhartikk.github.io/&quot;&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;: &lt;em&gt;Naivecoin: a tutorial for building a cryptocurrency&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://naivecoinstake.learn.uno/&quot;&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;: &lt;em&gt;NaivecoinStake: a tutorial for building a cryptocurrency with the Proof of Stake consensus&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hackernoon.com/building-a-blockchain-in-rust-and-substrate-a-step-by-step-guide-for-developers-kc223ybp&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Building A Blockchain in Rust &amp;amp; Substrate&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Bot&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://wiki.haskell.org/Roll_your_own_IRC_bot&quot;&gt;&lt;strong&gt;Haskell&lt;/strong&gt;: &lt;em&gt;Roll your own IRC bot&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tutorials.botsfloor.com/creating-a-simple-facebook-messenger-ai-bot-with-api-ai-in-node-js-50ae2fa5c80d&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;Creating a Simple Facebook Messenger AI Bot with API.ai in Node.js&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.sohamkamani.com/blog/2016/09/21/making-a-telegram-bot/&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;How to make a responsive telegram bot&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://discordjs.guide/&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;Create a Discord bot&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.scottlogic.com/2017/05/22/gifbot-github-integration.html&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;gifbot - Building a GitHub App&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.smashingmagazine.com/2017/08/ai-chatbot-web-speech-api-node-js/&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;Building A Simple AI Chatbot With Web Speech API And Node.js&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.fullstackpython.com/blog/build-first-slack-bot-python.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;How to Build Your First Slack Bot with Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/freehunch/how-to-build-a-slack-bot-with-python-using-slack-events-api-django-under-20-minute-code-included-269c3a9bf64e&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;How to build a Slack Bot with Python using Slack Events API &amp;amp; Django under 20 minute&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://pythonforengineers.com/build-a-reddit-bot-part-1/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Build a Reddit Bot&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=krTUf7BpTc0&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;How To Make A Reddit Bot&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.freecodecamp.org/news/how-to-create-a-telegram-bot-using-python/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;How To Create a Telegram Bot Using Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.freecodecamp.org/creating-a-twitter-bot-in-python-with-tweepy-ac524157a607&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Create a Twitter Bot in Python Using Tweepy&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLIFBTFgFpoJ9vmYYlfxRFV6U_XhG-4fpP&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Creating Reddit Bot with Python &amp;amp; PRAW&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/build-a-cryptocurrency-trading-bot-with-r-1445c429e1b1&quot;&gt;&lt;strong&gt;R&lt;/strong&gt;: &lt;em&gt;Build A Cryptocurrency Trading Bot with R&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://habr.com/en/post/436254/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;A bot for Starcraft in Rust, C or any other language&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Command-Line Tool&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://flaviocopes.com/go-git-contributions/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Visualize your local git contributions with Go&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://flaviocopes.com/go-tutorial-lolcat/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Build a command line app with Go: lolcat&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://flaviocopes.com/go-tutorial-cowsay/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Building a cli command with Go: cowsay&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://flaviocopes.com/go-tutorial-fortune/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Go CLI tutorial: fortune clone&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://xmonader.github.io/nimdays/day06_nistow.html&quot;&gt;&lt;strong&gt;Nim&lt;/strong&gt;: &lt;em&gt;Writing a stow alternative to manage dotfiles&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://citw.dev/tutorial/create-your-own-cli-tool&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;Create a CLI tool in Javascript&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://rust-cli.github.io/book/index.html&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Command line apps in Rust&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://mattgathu.dev/2017/08/29/writing-cli-app-rust.html&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Writing a Command Line Tool in Rust&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Database&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://cstack.github.io/db_tutorial/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Let&#39;s Build a Simple Database&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://build-your-own.org/redis&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Build Your Own Redis from Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.codeproject.com/Articles/1029838/Build-Your-Own-Database&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;Build Your Own Database&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/an-archaeology-inspired-database.html&quot;&gt;&lt;strong&gt;Clojure&lt;/strong&gt;: &lt;em&gt;An Archaeology-Inspired Database&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@marceloboeira/why-you-should-build-your-own-nosql-database-9bbba42039f5&quot;&gt;&lt;strong&gt;Crystal&lt;/strong&gt;: &lt;em&gt;Why you should build your own NoSQL Database&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://build-your-own.org/database/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Build Your Own Database from Scratch: Persistence, Indexing, Concurrency&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.build-redis-from-scratch.dev/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Build Your Own Redis from Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/dagoba-an-in-memory-graph-database.html&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Dagoba: an in-memory graph database&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/dbdb-dog-bed-database.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;DBDB: Dog Bed Database&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://charlesleifer.com/blog/building-a-simple-redis-server-with-python/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Write your own miniature Redis with Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dineshgowda.com/posts/build-your-own-persistent-kv-store/&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;Build your own fast, persistent KV store in Ruby&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tokio.rs/tokio/tutorial/setup&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Build your own Redis client and server&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Docker&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.lizzie.io/linux-containers-in-500-loc.html&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Linux containers in 500 lines of code&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/articles/build-a-container-golang&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Build Your Own Container Using Less than 100 Lines of Go&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=8fi7uSYlOdc&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Building a container from scratch in Go&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Fewbytes/rubber-docker&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;A workshop on Linux containers: Rebuild Docker from Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/tonybaloney/mocker&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;A proof-of-concept imitation of Docker, written in 100% Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/p8952/bocker&quot;&gt;&lt;strong&gt;Shell&lt;/strong&gt;: &lt;em&gt;Docker implemented in around 100 lines of bash&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Emulator / Virtual Machine&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/bumble-tech/home-grown-bytecode-interpreters-51e12d59b25c&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Home-grown bytecode interpreters&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://web.archive.org/web/20200121100942/https://blog.felixangell.com/virtual-machine-in-c/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Virtual machine in C&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://justinmeiners.github.io/lc3-vm/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Write your Own Virtual Machine&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://cturt.github.io/cinoop.html&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Writing a Game Boy emulator, Cinoop&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.multigesture.net/articles/how-to-write-an-emulator-chip-8-interpreter/&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;How to write an emulator (CHIP-8 interpreter)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.codeslinger.co.uk/pages/projects/chip8.html&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Emulation tutorial (CHIP-8 interpreter)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.codeslinger.co.uk/pages/projects/gameboy.html&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Emulation tutorial (GameBoy emulator)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.codeslinger.co.uk/pages/projects/mastersystem/memory.html&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Emulation tutorial (Master System emulator)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLrOv9FMX8xJHqMvSGB_9G9nZZ_4IgteYf&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;NES Emulator From Scratch&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stevelosh.com/blog/2016/12/chip8-cpu/&quot;&gt;&lt;strong&gt;Common Lisp&lt;/strong&gt;: &lt;em&gt;CHIP-8 in Common Lisp&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://imrannazar.com/GameBoy-Emulation-in-JavaScript&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;GameBoy Emulation in JavaScript&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://omokute.blogspot.com.br/2012/06/emulation-basics-write-your-own-chip-8.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Emulation Basics: Write your own Chip 8 Emulator/Interpreter&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://jeremybanks.github.io/0dmg/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;0dmg: Learning Rust by building a partial Game Boy emulator&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Front-end Framework / Library&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://jasonformat.com/wtf-is-jsx/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;WTF is JSX (Let&#39;s Build a JSX Renderer)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/hexacta/didact&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;A DIY guide to build your own React&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=_MAD4Oly9yg&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Building React From Scratch&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@sweetpalma/gooact-react-in-160-lines-of-javascript-44e0742ad60f&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Gooact: React in 160 lines of JavaScript&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hackernoon.com/learn-you-some-custom-react-renderers-aed7164a4199&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Learn how React Reconciler package works by building your own lightweight React DOM&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://zapier.com/engineering/how-to-build-redux/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build Yourself a Redux&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.jamasoftware.com/blog/lets-write-redux/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Letâ€™s Write Redux!&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://egghead.io/lessons/react-redux-implementing-store-from-scratch&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Redux: Implementing Store from Scratch&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.mgechev.com/2015/03/09/build-learn-your-own-light-lightweight-angularjs/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build Your own Simplified AngularJS in 200 Lines of JavaScript&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://teropa.info/blog/2013/11/03/make-your-own-angular-part-1-scopes-and-digest.html&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Make Your Own AngularJS&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@deathmood/how-to-write-your-own-virtual-dom-ee74acc13060&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;How to write your own Virtual DOM&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://mfrachet.github.io/create-frontend-framework/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Building a frontend framework, from scratch, with components (templating, state, VDOM)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pomb.us/build-your-own-react/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build your own React&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://youtu.be/CGpMlWVcHok&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Building a Custom React Renderer&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Game&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://handmadehero.org/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Handmade Hero&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://nesdoug.com/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;How to Program an NES game in C&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLZ1QII7yudbc-Ky058TEaOstZHVbT-2hg&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Chess Engine In C&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLSkJey49cOgTSj465v2KbLZ7LMn10bCF9&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Let&#39;s Make: Dangerous Dave&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLT6WFYYZE6uLMcPGS3qfpYm7T_gViYMMt&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Learn Video Game Programming in C&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLkTXsX7igf8edTYU92nU-f5Ntzuf-RKvW&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Coding A Sudoku Solver in C&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLkTXsX7igf8erbWGYT4iSAhpnJLJ0Nk5G&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Coding a Rogue/Nethack RPG in C&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://brennan.io/2015/06/12/tetris-reimplementation/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;On Tetris and Reimplementation&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://learnopengl.com/In-Practice/2D-Game/Breakout&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Breakout&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://lazyfoo.net/tutorials/SDL/&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Beginning Game Programming v2.0&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://javilop.com/gamedev/tetris-tutorial-in-c-platform-independent-focused-in-game-logic-for-beginners/&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Tetris tutorial in C++ platform independent focused in game logic for beginners&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ETvApbD5xRo&amp;amp;list=PLNOBk_id22bw6LXhrGfhVwqQIa-M2MsLa&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Remaking Cavestory in C++&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PL006xsVEsbKjSKBmLu1clo85yLrwjY67X&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Reconstructing Cave Story&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://nicktasios.nl/posts/space-invaders-from-scratch-part-1.html&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Space Invaders from Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://scottlilly.com/learn-c-by-building-a-simple-rpg-index/&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;Learn C# by Building a Simple RPG&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://roguesharp.wordpress.com/&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;Creating a Roguelike Game in C#&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://scottlilly.com/build-a-cwpf-rpg/&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;Build a C#/WPF RPG&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLDZujg-VgQlZUy1iCqBbe5faZLMkA3g2x&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Games With Go&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=025QFeZfeyM&quot;&gt;&lt;strong&gt;Java&lt;/strong&gt;: &lt;em&gt;Code a 2D Game Engine using Java - Full Course for Beginners&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://lwjglgamedev.gitbooks.io/3d-game-development-with-lwjgl/content/&quot;&gt;&lt;strong&gt;Java&lt;/strong&gt;: &lt;em&gt;3D Game Development with LWJGL 3&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Games/Tutorials/2D_breakout_game_Phaser&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;2D breakout game using Phaser&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.lessmilk.com/tutorial/flappy-bird-phaser-1&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;How to Make Flappy Bird in HTML5 With Phaser&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://auth0.com/blog/developing-games-with-react-redux-and-svg-part-1/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Developing Games with React, Redux, and SVG&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=aXwCrtAo4Wc&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build your own 8-Ball Pool game from scratch&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gamedevelopment.tutsplus.com/tutorials/how-to-make-your-first-roguelike--gamedev-13677&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;How to Make Your First Roguelike&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.freecodecamp.org/think-like-a-programmer-how-to-build-snake-using-only-javascript-html-and-css-7b1479c3339e&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Think like a programmer: How to build Snake using only JavaScript, HTML &amp;amp; CSS&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/SSYGEN/blog/issues/30&quot;&gt;&lt;strong&gt;Lua&lt;/strong&gt;: &lt;em&gt;BYTEPATH&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pythonprogramming.net/pygame-python-3-part-1-intro/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Developing Games With PyGame&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://inventwithpython.com/makinggames.pdf&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Making Games with Python &amp;amp; Pygame&lt;/em&gt;&lt;/a&gt; [pdf]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://rogueliketutorials.com/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Roguelike Tutorial Revised&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://leanpub.com/developing-games-with-ruby/read&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;Developing Games With Ruby&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.diatomenterprises.com/gamedev-on-ruby-why-not/&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;Ruby Snake&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://a5huynh.github.io/posts/2018/adventures-in-rust/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Adventures in Rust: A Basic 2D Game&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tomassedovic.github.io/roguelike-tutorial/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Roguelike Tutorial in Rust + tcod&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Git&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/&quot;&gt;&lt;strong&gt;Haskell&lt;/strong&gt;: &lt;em&gt;Reimplementing â€œgit cloneâ€ in Haskell from the bottom up&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://gitlet.maryrosecook.com/docs/gitlet.html&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Gitlet&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kushagra.dev/blog/build-git-learn-git/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build GIT - Learn GIT&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://benhoyt.com/writings/pygit/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Just enough of a Git client to create a repo, commit, and push itself to GitHub&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://wyag.thb.lt/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Write yourself a Git!&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.leshenko.net/p/ugit/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;ugit: Learn Git Internals by Building Git Yourself&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://robots.thoughtbot.com/rebuilding-git-in-ruby&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;Rebuilding Git in Ruby&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Network Stack&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://beej.us/guide/bgnet/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Beej&#39;s Guide to Network Programming&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.saminiir.com/lets-code-tcp-ip-stack-1-ethernet-arp/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Let&#39;s code a TCP/IP stack&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/peiyuanix/build-your-own-zerotier&quot;&gt;&lt;strong&gt;C / Python&lt;/strong&gt;: &lt;em&gt;Build your own VPN/Virtual Switch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/geckoboard-under-the-hood/how-to-build-a-network-stack-in-ruby-f73aeb1b661b&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;How to build a network stack in Ruby&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Neural Network&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.codeproject.com/Articles/11285/Neural-Network-OCR&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;Neural Network OCR&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/building-neural-networks-in-f-part-1-a2832ae972e6&quot;&gt;&lt;strong&gt;F#&lt;/strong&gt;: &lt;em&gt;Building Neural Networks in F#&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://made2591.github.io/posts/neuralnetwork&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Build a multilayer perceptron with Golang&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://sausheong.github.io/posts/how-to-build-a-simple-artificial-neural-network-with-go/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;How to build a simple artificial neural network with Go&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://datadan.io/blog/neural-net-with-go&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Building a Neural Net from Scratch in Go&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLRqwX-V7Uu6aCibgK1PTWWu9by6XFdCfh&quot;&gt;&lt;strong&gt;JavaScript / Java&lt;/strong&gt;: &lt;em&gt;Neural Networks - The Nature of Code&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hackernoon.com/neural-networks-from-scratch-for-javascript-linguists-part1-the-perceptron-632a4d1fbad2&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Neural networks from scratch for JavaScript linguists (Part1â€Šâ€”â€ŠThe Perceptron)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://iamtrask.github.io/2015/07/12/basic-python-network/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;A Neural Network in 11 lines of Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://victorzhou.com/blog/intro-to-neural-networks/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Implement a Neural Network from Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/optical-character-recognition-ocr.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Optical Character Recognition (OCR)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://navoshta.com/traffic-signs-classification/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Traffic signs classification with a convolutional network&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Generate Music using LSTM Neural Network in Keras&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://victorzhou.com/blog/intro-to-cnns-part-1/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;An Introduction to Convolutional Neural Networks&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Neural Networks: Zero to Hero&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Operating System&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://joebergeron.io/posts/post_two.html&quot;&gt;&lt;strong&gt;Assembly&lt;/strong&gt;: &lt;em&gt;Writing a Tiny x86 Bootloader&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.cl.cam.ac.uk/projects/raspberrypi/tutorials/os/index.html&quot;&gt;&lt;strong&gt;Assembly&lt;/strong&gt;: &lt;em&gt;Baking Pi â€“ Operating Systems Development&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ZjwvMcP3Nf0&amp;amp;list=PLU94OURih-CiP4WxKSMt3UcwMSDM3aTtX&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Building a software and hardware stack for a simple computer from scratch&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tuhdo.github.io/os01/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Operating Systems: From 0 to 1&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://littleosbook.github.io/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;The little book about OS development&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://jamesmolloy.co.uk/tutorial_html/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Roll your own toy UNIX-clone OS&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://arjunsreedharan.org/post/82710718100/kernel-101-lets-write-a-kernel&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Kernel 101 â€“ Letâ€™s write a Kernel&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://arjunsreedharan.org/post/99370248137/kernel-201-lets-write-a-kernel-with-keyboard&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Kernel 201 â€“ Letâ€™s write a Kernel with keyboard and screen support&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jserv/mini-arm-os&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Build a minimal multi-tasking kernel for ARM from scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/cfenollosa/os-tutorial&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;How to create an OS from scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://danluu.com/malloc-tutorial/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Malloc tutorial&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.holbertonschool.com/hack-the-virtual-memory-c-strings-proc/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Hack the virtual memory&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/s-matyukevich/raspberry-pi-os&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Learning operating system development using Linux kernel and Raspberry Pi&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@lduck11007/operating-systems-development-for-dummies-3d4d786e8ac&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Operating systems development for Dummies&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLHh55M_Kq4OApWScZyPl5HhgsTJS9MZ6M&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Write your own Operating System&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://3zanders.co.uk/2017/10/13/writing-a-bootloader/&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Writing a Bootloader&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Writing an OS in Rust&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://osblog.stephenmarz.com/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Add RISC-V Rust Operating System Tutorial&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://linuxfromscratch.org/lfs&quot;&gt;&lt;strong&gt;(any)&lt;/strong&gt;: &lt;em&gt;Linux from scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Physics Engine&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.toptal.com/game/video-game-physics-part-i-an-introduction-to-rigid-body-dynamics&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Video Game Physics Tutorial&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://allenchou.net/game-physics-series/&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Game physics series by Allen Chou&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gamedevelopment.tutsplus.com/series/how-to-create-a-custom-physics-engine--gamedev-12715&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;How to Create a Custom Physics Engine&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLEETnX-uPtBXm1KEr_2zQ6K_0hoGH6JJ0&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;3D Physics Engine Tutorial&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://buildnewgames.com/gamephysics/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;How Physics Engines Work&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://buildnewgames.com/broad-phase-collision-detection/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Broad Phase Collision Detection Using Spatial Partitioning&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://developer.ibm.com/tutorials/wa-build2dphysicsengine/?mhsrc=ibmsearch_a&amp;amp;mhq=2dphysic&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build a simple 2D physics engine for JavaScript games&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Programming Language&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kanaka/mal#mal---make-a-lisp&quot;&gt;&lt;strong&gt;(any)&lt;/strong&gt;: &lt;em&gt;mal - Make a Lisp&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/nornagon/jonesforth/raw/master/jonesforth.S&quot;&gt;&lt;strong&gt;Assembly&lt;/strong&gt;: &lt;em&gt;Jonesforth&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Baby&#39;s First Garbage Collector&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.buildyourownlisp.com/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Build Your Own Lisp: Learn C and build your own programming language in 1000 lines of code&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://maplant.com/gc.html&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Writing a Simple Garbage Collector in C&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/lotabout/write-a-C-interpreter&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;C interpreter that interprets itself.&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/lotabout/Let-s-build-a-compiler&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;A C &amp;amp; x86 version of the &quot;Let&#39;s Build a Compiler&quot; by Jack Crenshaw&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/DoctorWkt/acwj&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;A journey explaining how to build a compiler from scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gnuu.org/2009/09/18/writing-your-own-toy-compiler/&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Writing Your Own Toy Compiler Using Flex&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=eF9qWbuQLuw&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;How to Create a Compiler&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/index.html&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Kaleidoscope: Implementing a Language with LLVM&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://fsharpforfunandprofit.com/posts/understanding-parser-combinators/&quot;&gt;&lt;strong&gt;F#&lt;/strong&gt;: &lt;em&gt;Understanding Parser Combinators&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=zMJYoYwOCd4&quot;&gt;&lt;strong&gt;Elixir&lt;/strong&gt;: &lt;em&gt;Demystifying compilers by writing your own&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/hazbo/the-super-tiny-compiler&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;The Super Tiny Compiler&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=HxaD_trXwRE&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Lexical Scanning in Go&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://g-ford.github.io/cradle/&quot;&gt;&lt;strong&gt;Haskell&lt;/strong&gt;: &lt;em&gt;Let&#39;s Build a Compiler&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://dev.stephendiehl.com/fun/&quot;&gt;&lt;strong&gt;Haskell&lt;/strong&gt;: &lt;em&gt;Write You a Haskell&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours&quot;&gt;&lt;strong&gt;Haskell&lt;/strong&gt;: &lt;em&gt;Write Yourself a Scheme in 48 Hours&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.wespiser.com/writings/wyas/home.html&quot;&gt;&lt;strong&gt;Haskell&lt;/strong&gt;: &lt;em&gt;Write You A Scheme&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.craftinginterpreters.com/&quot;&gt;&lt;strong&gt;Java&lt;/strong&gt;: &lt;em&gt;Crafting interpreters: A handbook for making programming languages&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://jakubdziworski.github.io/categories.html#Enkel-ref&quot;&gt;&lt;strong&gt;Java&lt;/strong&gt;: &lt;em&gt;Creating JVM Language&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jamiebuilds/the-super-tiny-compiler&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;The Super Tiny Compiler&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/keyanzhang/the-super-tiny-interpreter&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;The Super Tiny Interpreter&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://maryrosecook.com/blog/post/little-lisp-interpreter&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Little Lisp interpreter&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://lisperator.net/pltut/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;How to implement a programming language in JavaScript&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://idiocy.org/lets-go-write-a-lisp/part-1.html&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Letâ€™s go write a Lisp&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://norasandler.com/2017/11/29/Write-a-Compiler.html&quot;&gt;&lt;strong&gt;OCaml&lt;/strong&gt;: &lt;em&gt;Writing a C Compiler&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://bernsteinbear.com/blog/lisp/&quot;&gt;&lt;strong&gt;OCaml&lt;/strong&gt;: &lt;em&gt;Writing a Lisp, the series&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://compilers.iecc.com/crenshaw/&quot;&gt;&lt;strong&gt;Pascal&lt;/strong&gt;: &lt;em&gt;Let&#39;s Build a Compiler&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/a-python-interpreter-written-in-python.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;A Python Interpreter Written in Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://khamidou.com/compilers/lisp.py/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;lisp.py: Make your own Lisp interpreter&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://norvig.com/lispy.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;How to Write a Lisp Interpreter in Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ruslanspivak.com/lsbasi-part1/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Letâ€™s Build A Simple Interpreter&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=dj9CBS3ikGA&amp;amp;list=PLZQftyCk7_SdoVexSmwy_tBgs7P0b97yD&amp;amp;index=1&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Make Your Own Simple Interpreted Programming Language&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://build-your-own.org/compiler/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;From Source Code To Machine Code: Build Your Own Compiler From Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://beautifulracket.com/&quot;&gt;&lt;strong&gt;Racket&lt;/strong&gt;: &lt;em&gt;Beautiful Racket: How to make your own programming languages with Racket&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.destroyallsoftware.com/screencasts/catalog/a-compiler-from-scratch&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;A Compiler From Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.beezwax.net/2017/07/07/writing-a-markdown-compiler/&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;Markdown compiler from scratch in Ruby&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.subnetzero.io/post/building-language-vm-part-00/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;So You Want to Build a Language VM&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://bodil.lol/parser-combinators/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Learning Parser Combinators With Rust&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.uraimo.com/2017/02/05/building-a-lisp-from-scratch-with-swift/&quot;&gt;&lt;strong&gt;Swift&lt;/strong&gt;: &lt;em&gt;Building a LISP from scratch with Swift&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.scottlogic.com/2019/05/17/webassembly-compiler.html&quot;&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;: &lt;em&gt;Build your own WebAssembly Compiler&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Regex Engine&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.cs.princeton.edu/courses/archive/spr09/cos333/beautiful.html&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;A Regular Expression Matcher&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://swtch.com/~rsc/regexp/regexp1.html&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Regular Expression Matching Can Be Simple And Fast&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://rhaeguard.github.io/posts/regex&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;How to build a regex engine from scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://nickdrane.com/build-your-own-regex/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build a Regex Engine in Less than 40 Lines of Code&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://dpk.io/dregs/toydregs&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;How to implement regular expressions in functional javascript using derivatives&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://deniskyashif.com/2019/02/17/implementing-a-regular-expression-engine/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Implementing a Regular Expression Engine&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://perl.plover.com/Regex/article.html&quot;&gt;&lt;strong&gt;Perl&lt;/strong&gt;: &lt;em&gt;How Regexes Work&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://build-your-own.org/b2a/r0_intro&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Build Your Own Regular Expression Engines: Backtracking, NFA, DFA&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://rcoh.svbtle.com/no-magic-regular-expressions&quot;&gt;&lt;strong&gt;Scala&lt;/strong&gt;: &lt;em&gt;No Magic: Regular Expressions&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Search Engine&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://stories.algolia.com/a-search-engine-in-css-b5ec4e902e97&quot;&gt;&lt;strong&gt;CSS&lt;/strong&gt;: &lt;em&gt;A search engine in CSS&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.dr-josiah.com/2010/07/building-search-engine-using-redis-and.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Building a search engine using Redis and redis-py&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://boyter.org/2010/08/build-vector-space-search-engine-python/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Building a Vector Space Indexing Engine in Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=cY7pE7vX6MU&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Building A Python-Based Search Engine&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/filament-ai/making-text-search-learn-from-feedback-4fe210fd87b0&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Making text search learn from feedback&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://stevenloria.com/tf-idf/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Finding Important Words in Text Using TF-IDF&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Shell&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://brennan.io/2015/01/16/write-a-shell-in-c/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Tutorial - Write a Shell in C&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kamalmarhubi/shell-workshop&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Let&#39;s build a shell!&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://indradhanush.github.io/blog/writing-a-unix-shell-part-1/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Writing a UNIX Shell&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/tokenrove/build-your-own-shell&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Build Your Own Shell&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://danishpraka.sh/posts/write-a-shell/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: Write a shell in C&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://sj14.gitlab.io/post/2018-07-01-go-unix-shell/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Writing a simple shell in Go&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.joshmcguigan.com/blog/build-your-own-shell-rust/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Build Your Own Shell using Rust&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Template Engine&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://krasimirtsonev.com/blog/article/Javascript-template-engine-in-just-20-line&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;JavaScript template engine in just 20 lines&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/wdstack/understanding-javascript-micro-templating-f37a37b3b40e&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Understanding JavaScript Micro-Templating&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://alexmic.net/building-a-template-engine/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Approach: Building a toy template engine in Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/a-template-engine.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;A Template Engine&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://bits.citrusbyte.com/how-to-write-a-template-library/&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;How to write a template engine in less than 30 lines of code&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Text Editor&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://viewsourcecode.org/snaptoken/kilo/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Build Your Own Text Editor&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.fltk.org/doc-1.1/editor.html&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Designing a Simple Text Editor&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=xqDonHEYPgA&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Python Tutorial: Make Your Own Text Editor&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.instructables.com/id/Create-a-Simple-Python-Text-Editor/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Create a Simple Python Text Editor!&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.aha.io/text-editor/&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;Build a Collaborative Text Editor Using Rails&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.flenker.blog/hecto/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Hecto: Build your own text editor in Rust&lt;/em&gt; &lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Visual Recognition System&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/devcenter/developing-a-license-plate-recognition-system-with-machine-learning-in-python-787833569ccd&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Developing a License Plate Recognition System with Machine Learning in Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hackernoon.com/building-a-facial-recognition-pipeline-with-deep-learning-in-tensorflow-66e7645015b8&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Building a Facial Recognition Pipeline with Deep Learning in Tensorflow&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Voxel Engine&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://sites.google.com/site/letsmakeavoxelengine/home&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Let&#39;s Make a Voxel Engine&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=QZ4Vk2PkPZk&amp;amp;list=PL80Zqpd23vJfyWQi-8FKDbeO_ZQamLKJL&quot;&gt;&lt;strong&gt;Java&lt;/strong&gt;: &lt;em&gt;Java Voxel Engine Tutorial&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Web Browser&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://limpet.net/mbrubeck/2014/08/08/toy-layout-engine-1.html&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Let&#39;s build a browser engine&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://browser.engineering&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Browser Engineering&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Build your own &lt;code&gt;Web Server&lt;/code&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.codeproject.com/Articles/859108/Writing-a-Web-Server-from-Scratch&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;Writing a Web Server from Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://build-your-own.org/webserver/&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;Build Your Own Web Server From Scratch In JavaScript&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.codementor.io/@ziad-saab/let-s-code-a-web-server-from-scratch-with-nodejs-streams-h4uc9utji&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;Let&#39;s code a web server from scratch with NodeJS Streams&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/antoaravinth/lets-build-express&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;lets-build-express&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://station.clancats.com/writing-a-webserver-in-pure-php/&quot;&gt;&lt;strong&gt;PHP&lt;/strong&gt;: &lt;em&gt;Writing a webserver in pure PHP&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/a-simple-web-server.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;A Simple Web Server&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ruslanspivak.com/lsbaws-part1/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Letâ€™s Build A Web Server.&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://defn.io/2018/02/25/web-app-from-scratch-01/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Web application from scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://joaoventura.net/blog/2017/python-webserver/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Building a basic HTTP Server from scratch in Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://blog.luisrei.com/articles/flaskrest.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Implementing a RESTful Web API with Python &amp;amp; Flask&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://blog.honeybadger.io/building-a-simple-websockets-server-from-scratch-in-ruby/&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;Building a simple websockets server from scratch in Ruby&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Uncategorized&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://nand2tetris.org/&quot;&gt;&lt;strong&gt;(any)&lt;/strong&gt;: &lt;em&gt;From NAND to Tetris: Building a Modern Computer From First Principles&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/the-same-origin-policy.html&quot;&gt;&lt;strong&gt;Alloy&lt;/strong&gt;: &lt;em&gt;The Same-Origin Policy&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://dranger.com/ffmpeg/ffmpeg.html&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;How to Write a Video Player in Less Than 1000 Lines&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jamesroutley/write-a-hash-table&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Learn how to write a hash table in C&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.uninformativ.de/blog/postings/2018-02-24/0/POSTING-en.html&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;The very basics of a terminal emulator&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://brennan.io/2016/11/14/kernel-dev-ep3/&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Write a System Call&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://codepr.github.io/posts/sol-mqtt-broker&quot;&gt;&lt;strong&gt;C&lt;/strong&gt;: &lt;em&gt;Sol - An MQTT broker from scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/relativty/Relativ&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Build your own VR headset for $200&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://seasonofcode.com/posts/how-x-window-managers-work-and-how-to-write-one-part-i.html&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;How X Window Managers work and how to write one&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.tartanllama.xyz/writing-a-linux-debugger-setup/&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Writing a Linux Debugger&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.lofibucket.com/articles/64k_intro.html&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;How a 64k intro is made&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLlrATfBNZ98dC-V-N3m0Go4deliWHPFwT&quot;&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;em&gt;Make your own Game Engine&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://16bpp.net/tutorials/csharp-networking&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;C# Networking: Create a TCP chater server, TCP games, UDP Pong and more&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.seanjoflynn.com/research/skeletal-animation.html&quot;&gt;&lt;strong&gt;C#&lt;/strong&gt;: &lt;em&gt;Loading and rendering 3D skeletal animations from scratch in C# and GLSL&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://bernhardwenzel.com/articles/clojure-spellchecker/&quot;&gt;&lt;strong&gt;Clojure&lt;/strong&gt;: &lt;em&gt;Building a spell-checker&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ishuah.com/2021/03/10/build-a-terminal-emulator-in-100-lines-of-go/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Build A Simple Terminal Emulator In 100 Lines of Golang&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kasvith.me/posts/lets-create-a-simple-lb-go/&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Let&#39;s Create a Simple Load Balancer&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kevmo314/codec-from-scratch&quot;&gt;&lt;strong&gt;Go&lt;/strong&gt;: &lt;em&gt;Video Encoding from Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLgCYzUzKIBE9HUJU-upNvl3TRVAo9W47y&quot;&gt;&lt;strong&gt;Java&lt;/strong&gt;: &lt;em&gt;How to Build an Android Reddit App&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ronami/minipack&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build Your Own Module Bundler - Minipack&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://levelup.gitconnected.com/understand-javascript-promises-by-building-a-promise-from-scratch-84c0fd855720&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Learn JavaScript Promises by Building a Promise from Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.mauriciopoppe.com/notes/computer-science/computation/promises/&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Implementing promises from scratch (TDD way)&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.usejournal.com/implement-your-own-call-apply-and-bind-method-in-javascript-42cc85dba1b&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Implement your ownâ€Šâ€”â€Šcall(), apply() and bind() method in JavaScript&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/trekhleb/javascript-algorithms&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;JavaScript Algorithms and Data Structures&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pusher.com/tutorials/ride-hailing-react-native&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build a ride hailing app with React Native&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://levelup.gitconnected.com/building-your-own-adblocker-in-literally-10-minutes-1eec093b04cd&quot;&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: &lt;em&gt;Build Your Own AdBlocker in (Literally) 10 Minutes&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kezhenxu94/cache-lite&quot;&gt;&lt;strong&gt;Kotlin&lt;/strong&gt;: &lt;em&gt;Build Your Own Cache&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/leandromoreira/cdn-up-and-running&quot;&gt;&lt;strong&gt;Lua&lt;/strong&gt;: &lt;em&gt;Building a CDN from Scratch to Learn about CDN&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://xmonader.github.io/nimdays/day12_resp.html&quot;&gt;&lt;strong&gt;Nim&lt;/strong&gt;: &lt;em&gt;Writing a Redis Protocol Parser&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://xmonader.github.io/nimdays/day11_buildsystem.html&quot;&gt;&lt;strong&gt;Nim&lt;/strong&gt;: &lt;em&gt;Writing a Build system&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://xmonader.github.io/nimdays/day08_minitest.html&quot;&gt;&lt;strong&gt;Nim&lt;/strong&gt;: &lt;em&gt;Writing a MiniTest Framework&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://xmonader.github.io/nimdays/day01_dmidecode.html&quot;&gt;&lt;strong&gt;Nim&lt;/strong&gt;: &lt;em&gt;Writing a DMIDecode Parser&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://xmonader.github.io/nimdays/day05_iniparser.html&quot;&gt;&lt;strong&gt;Nim&lt;/strong&gt;: &lt;em&gt;Writing a INI Parser&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://xmonader.github.io/nimdays/day04_asynclinkschecker.html&quot;&gt;&lt;strong&gt;Nim&lt;/strong&gt;: &lt;em&gt;Writing a Link Checker&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://xmonader.github.io/nimdays/day07_shorturl.html&quot;&gt;&lt;strong&gt;Nim&lt;/strong&gt;: &lt;em&gt;Writing a URL Shortening Service&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.webdevdrops.com/en/build-static-site-generator-nodejs-8969ebe34b22/&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;Build a static site generator in 40 lines with Node.js&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://codeburst.io/building-a-simple-single-sign-on-sso-server-and-solution-from-scratch-in-node-js-ea6ee5fdf340&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;Building A Simple Single Sign On(SSO) Server And Solution From Scratch In Node.js.&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;How to create a real-world Node CLI app with Node&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://engineerhead.github.io/dns-server/&quot;&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: &lt;em&gt;Build a DNS Server in Node.js&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://chaitya62.github.io/2018/04/29/Writing-your-own-MVC-from-Scratch-in-PHP.html&quot;&gt;&lt;strong&gt;PHP&lt;/strong&gt;: &lt;em&gt;Write your own MVC from scratch in PHP&lt;/em&gt; &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ilovephp.jondh.me.uk/en/tutorial/make-your-own-blog&quot;&gt;&lt;strong&gt;PHP&lt;/strong&gt;: &lt;em&gt;Make your own blog&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kevinsmith.io/modern-php-without-a-framework&quot;&gt;&lt;strong&gt;PHP&lt;/strong&gt;: &lt;em&gt;Modern PHP Without a Framework&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://boyter.org/2013/01/code-for-a-search-engine-in-php-part-1/&quot;&gt;&lt;strong&gt;PHP&lt;/strong&gt;: &lt;em&gt;Code a Web Search Engine in PHP&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=o64FV-ez6Gw&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Build a Deep Learning Library&lt;/em&gt;&lt;/a&gt; [video]&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.pyimagesearch.com/2014/09/01/build-kick-ass-mobile-document-scanner-just-5-minutes/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;How to Build a Kick-Ass Mobile Document Scanner in Just 5 Minutes&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/a-continuous-integration-system.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Continuous Integration System&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.datacamp.com/community/tutorials/recommender-systems-python&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Recommender Systems in Python: Beginner Tutorial&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@kopilov.vlad/detect-sms-spam-in-kaggle-with-scikit-learn-5f6afa7a3ca2&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Write SMS-spam detector with Scikit-learn&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://blog.untrod.com/2016/06/simple-similar-products-recommendation-engine-in-python.html&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;A Simple Content-Based Recommendation Engine in Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.datacamp.com/community/tutorials/lstm-python-stock-market&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Stock Market Predictions with LSTM in Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.paperspace.com/implementing-gans-in-tensorflow/&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Building a simple Generative Adversarial Network (GAN) using Tensorflow&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://lethalbrains.com/learn-ml-algorithms-by-coding-decision-trees-439ac503c9a4&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Learn ML Algorithms by coding: Decision Trees&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/cheery/json-algorithm&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;JSON Decoding Algorithm&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://joshburns-xyz.vercel.app/posts/build-your-own-git-plugin&quot;&gt;&lt;strong&gt;Python&lt;/strong&gt;: &lt;em&gt;Build your own Git plugin with python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aosabook.org/en/500L/a-pedometer-in-the-real-world.html&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;A Pedometer in the Real World&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://iridakos.com/tutorials/2018/01/25/creating-a-gtk-todo-application-with-ruby&quot;&gt;&lt;strong&gt;Ruby&lt;/strong&gt;: &lt;em&gt;Creating a Linux Desktop application with Ruby&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/EmilHernvall/dnsguide/raw/master/README.md&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Building a DNS server in Rust&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://nbaksalyar.github.io/2015/07/10/writing-chat-in-rust.html&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;Writing Scalable Chat Service from Scratch&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.chinedufn.com/3d-webgl-basic-water-tutorial/&quot;&gt;&lt;strong&gt;Rust&lt;/strong&gt;: &lt;em&gt;WebGL + Rust: Basic Water Tutorial&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/g-plane/tiny-package-manager&quot;&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;: &lt;em&gt;Tiny Package Manager: Learns how npm or Yarn works&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Submissions welcome, just send a PR, or &lt;a href=&quot;https://github.com/codecrafters-io/build-your-own-x/issues/new&quot;&gt;create an issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Help us review &lt;a href=&quot;https://github.com/codecrafters-io/build-your-own-x/issues&quot;&gt;pending submissions&lt;/a&gt; by leaving comments and &quot;reactions&quot;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Origins &amp;amp; License&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://creativecommons.org/publicdomain/zero/1.0/&quot;&gt;&lt;img src=&quot;https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg?sanitize=true&quot; alt=&quot;CC0&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repository is the work of &lt;a href=&quot;https://github.com/codecrafters-io/build-your-own-x/graphs/contributors&quot;&gt;many contributors&lt;/a&gt;. It was started by &lt;a href=&quot;https://github.com/danistefanovic&quot;&gt;Daniel Stefanovic&lt;/a&gt;, and is now maintained by &lt;a href=&quot;https://codecrafters.io&quot;&gt;CodeCrafters, Inc.&lt;/a&gt; To the extent possible under law, &lt;a href=&quot;https://codecrafters.io&quot;&gt;CodeCrafters, Inc.&lt;/a&gt; has waived all copyright and related or neighboring rights to this work.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hiyouga/LLaMA-Factory</title>
      <link>https://github.com/hiyouga/LLaMA-Factory</link>
      <description>&lt;p&gt;Unified Efficient Fine-Tuning of 100+ LLMs &amp; VLMs (ACL 2024)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/logo.png&quot; alt=&quot;# LLaMA Factory&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/hiyouga/LLaMA-Factory/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social&quot; alt=&quot;GitHub Repo stars&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/hiyouga/LLaMA-Factory/commits/main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory&quot; alt=&quot;GitHub last commit&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/hiyouga/LLaMA-Factory/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange&quot; alt=&quot;GitHub contributors&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml&quot;&gt;&lt;img src=&quot;https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub workflow&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/llamafactory/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/llamafactory&quot; alt=&quot;PyPI&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://scholar.google.com/scholar?cites=12620864006390196564&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/citation-349-green&quot; alt=&quot;Citation&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/hiyouga/LLaMA-Factory/pulls&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-blue&quot; alt=&quot;GitHub pull request&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://twitter.com/llamafactory_ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/llamafactory_ai&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/rKfvV9r9FK&quot;&gt;&lt;img src=&quot;https://dcbadge.vercel.app/api/server/rKfvV9r9FK?compact=true&amp;amp;style=flat&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://gitcode.com/zhengyaowei/LLaMA-Factory&quot;&gt;&lt;img src=&quot;https://gitcode.com/zhengyaowei/LLaMA-Factory/star/badge.svg?sanitize=true&quot; alt=&quot;GitCode&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;Open in Colab&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory&quot;&gt;&lt;img src=&quot;https://gallery.pai-ml.com/assets/open-in-dsw.svg?sanitize=true&quot; alt=&quot;Open in DSW&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://huggingface.co/spaces/hiyouga/LLaMA-Board&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%F0%9F%A4%97-Open%20in%20Spaces-blue&quot; alt=&quot;Spaces&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://modelscope.cn/studios/hiyouga/LLaMA-Board&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue&quot; alt=&quot;Studios&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/SageMaker-Open%20in%20AWS-blue&quot; alt=&quot;SageMaker&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3 align=&quot;center&quot;&gt; Easily fine-tune 100+ large language models with zero-code &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#quickstart&quot;&gt;CLI&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#fine-tuning-with-llama-board-gui-powered-by-gradio&quot;&gt;Web UI&lt;/a&gt; &lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; 
 &lt;picture&gt; 
  &lt;img alt=&quot;Github trend&quot; src=&quot;https://trendshift.io/api/badge/repositories/4535&quot;&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p&gt;ğŸ‘‹ Join our &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/wechat.jpg&quot;&gt;WeChat&lt;/a&gt; or &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/wechat_npu.jpg&quot;&gt;NPU user group&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;[ English | &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/README_zh.md&quot;&gt;ä¸­æ–‡&lt;/a&gt; ]&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Fine-tuning a large language model can be easy as...&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/user-attachments/assets/319abcde-7b31-4874-8969-b30b0f64c96a&quot;&gt;https://github.com/user-attachments/assets/319abcde-7b31-4874-8969-b30b0f64c96a&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Choose your path:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href=&quot;https://llamafactory.readthedocs.io/en/latest/&quot;&gt;https://llamafactory.readthedocs.io/en/latest/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Colab (free)&lt;/strong&gt;: &lt;a href=&quot;https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing&quot;&gt;https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Local machine&lt;/strong&gt;: Please refer to &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#getting-started&quot;&gt;usage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PAI-DSW (free trial)&lt;/strong&gt;: &lt;a href=&quot;https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory&quot;&gt;Llama3 Example&lt;/a&gt; | &lt;a href=&quot;https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl&quot;&gt;Qwen2-VL Example&lt;/a&gt; | &lt;a href=&quot;https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b&quot;&gt;DeepSeek-R1-Distill Example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Amazon SageMaker&lt;/strong&gt;: &lt;a href=&quot;https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/&quot;&gt;Blog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Except for the above links, all other websites are unauthorized third-party websites. Please carefully use them.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#features&quot;&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#benchmark&quot;&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#changelog&quot;&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#supported-models&quot;&gt;Supported Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#supported-training-approaches&quot;&gt;Supported Training Approaches&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#provided-datasets&quot;&gt;Provided Datasets&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#requirement&quot;&gt;Requirement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#getting-started&quot;&gt;Getting Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#data-preparation&quot;&gt;Data Preparation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#quickstart&quot;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#fine-tuning-with-llama-board-gui-powered-by-gradio&quot;&gt;Fine-Tuning with LLaMA Board GUI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#build-docker&quot;&gt;Build Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#deploy-with-openai-style-api-and-vllm&quot;&gt;Deploy with OpenAI-style API and vLLM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelscope-hub&quot;&gt;Download from ModelScope Hub&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelers-hub&quot;&gt;Download from Modelers Hub&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#use-wb-logger&quot;&gt;Use W&amp;amp;B Logger&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#use-swanlab-logger&quot;&gt;Use SwanLab Logger&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#projects-using-llama-factory&quot;&gt;Projects using LLaMA Factory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#citation&quot;&gt;Citation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#acknowledgement&quot;&gt;Acknowledgement&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Various models&lt;/strong&gt;: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Qwen2-VL, DeepSeek, Yi, Gemma, ChatGLM, Phi, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integrated methods&lt;/strong&gt;: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable resources&lt;/strong&gt;: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced algorithms&lt;/strong&gt;: &lt;a href=&quot;https://github.com/jiaweizzhao/GaLore&quot;&gt;GaLore&lt;/a&gt;, &lt;a href=&quot;https://github.com/Ledzy/BAdam&quot;&gt;BAdam&lt;/a&gt;, &lt;a href=&quot;https://github.com/zhuhanqing/APOLLO&quot;&gt;APOLLO&lt;/a&gt;, &lt;a href=&quot;https://github.com/zyushun/Adam-mini&quot;&gt;Adam-mini&lt;/a&gt;, DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ and PiSSA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Practical tricks&lt;/strong&gt;: &lt;a href=&quot;https://github.com/Dao-AILab/flash-attention&quot;&gt;FlashAttention-2&lt;/a&gt;, &lt;a href=&quot;https://github.com/unslothai/unsloth&quot;&gt;Unsloth&lt;/a&gt;, &lt;a href=&quot;https://github.com/linkedin/Liger-Kernel&quot;&gt;Liger Kernel&lt;/a&gt;, RoPE scaling, NEFTune and rsLoRA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wide tasks&lt;/strong&gt;: Multi-turn dialogue, tool using, image understanding, visual grounding, video recognition, audio understanding, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Experiment monitors&lt;/strong&gt;: LlamaBoard, TensorBoard, Wandb, MLflow, &lt;a href=&quot;https://github.com/SwanHubX/SwanLab&quot;&gt;SwanLab&lt;/a&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Faster inference&lt;/strong&gt;: OpenAI-style API, Gradio UI and CLI with &lt;a href=&quot;https://github.com/vllm-project/vllm&quot;&gt;vLLM worker&lt;/a&gt; or &lt;a href=&quot;https://github.com/sgl-project/sglang&quot;&gt;SGLang worker&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Day-N Support for Fine-Tuning Cutting-Edge Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Support Date&lt;/th&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Day 0&lt;/td&gt; 
   &lt;td&gt;Qwen2.5 / Qwen2.5-VL / Gemma 3 / InternLM 3 / MiniCPM-o-2.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Day 1&lt;/td&gt; 
   &lt;td&gt;Llama 3 / GLM-4 / Mistral Small / PaliGemma2&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;Compared to ChatGLM&#39;s &lt;a href=&quot;https://github.com/THUDM/ChatGLM2-6B/tree/main/ptuning&quot;&gt;P-Tuning&lt;/a&gt;, LLaMA Factory&#39;s LoRA tuning offers up to &lt;strong&gt;3.7 times faster&lt;/strong&gt; training speed with a better Rouge score on the advertising text generation task. By leveraging 4-bit quantization technique, LLaMA Factory&#39;s QLoRA further improves the efficiency regarding the GPU memory.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/benchmark.svg?sanitize=true&quot; alt=&quot;benchmark&quot;&gt;&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Definitions&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Training Speed&lt;/strong&gt;: the number of training samples processed per second during the training. (bs=4, cutoff_len=1024)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Rouge Score&lt;/strong&gt;: Rouge-2 score on the development set of the &lt;a href=&quot;https://aclanthology.org/D19-1321.pdf&quot;&gt;advertising text generation&lt;/a&gt; task. (bs=4, cutoff_len=1024)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;GPU Memory&lt;/strong&gt;: Peak GPU memory usage in 4-bit quantized training. (bs=1, cutoff_len=1024)&lt;/li&gt; 
  &lt;li&gt;We adopt &lt;code&gt;pre_seq_len=128&lt;/code&gt; for ChatGLM&#39;s P-Tuning and &lt;code&gt;lora_rank=32&lt;/code&gt; for LLaMA Factory&#39;s LoRA tuning.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;[25/03/15] We supported &lt;strong&gt;&lt;a href=&quot;https://github.com/sgl-project/sglang&quot;&gt;SGLang&lt;/a&gt;&lt;/strong&gt; as inference backend. Try &lt;code&gt;infer_backend: sglang&lt;/code&gt; to accelerate inference.&lt;/p&gt; 
&lt;p&gt;[25/03/12] We supported fine-tuning the &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/blog/gemma3&quot;&gt;Gemma-3&lt;/a&gt;&lt;/strong&gt; model.&lt;/p&gt; 
&lt;p&gt;[25/02/24] Announcing &lt;strong&gt;&lt;a href=&quot;https://github.com/hiyouga/EasyR1&quot;&gt;EasyR1&lt;/a&gt;&lt;/strong&gt;, an efficient, scalable and multi-modality RL training framework for efficient GRPO training.&lt;/p&gt; 
&lt;p&gt;[25/02/11] We supported saving the &lt;strong&gt;&lt;a href=&quot;https://github.com/ollama/ollama&quot;&gt;Ollama&lt;/a&gt;&lt;/strong&gt; modelfile when exporting the model checkpoints. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
&lt;p&gt;[25/02/05] We supported fine-tuning the &lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/Qwen/Qwen2-Audio-7B-Instruct&quot;&gt;Qwen2-Audio&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/openbmb/MiniCPM-o-2_6&quot;&gt;MiniCPM-o-2.6&lt;/a&gt;&lt;/strong&gt; on audio understanding tasks.&lt;/p&gt; 
&lt;p&gt;[25/01/31] We supported fine-tuning the &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-R1&quot;&gt;DeepSeek-R1&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct&quot;&gt;Qwen2.5-VL&lt;/a&gt;&lt;/strong&gt; model.&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Full Changelog&lt;/summary&gt; 
 &lt;p&gt;[25/01/15] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2412.05270&quot;&gt;APOLLO&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[25/01/14] We supported fine-tuning the &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/openbmb/MiniCPM-o-2_6&quot;&gt;MiniCPM-o-2.6&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/openbmb/MiniCPM-V-2_6&quot;&gt;MiniCPM-V-2.6&lt;/a&gt;&lt;/strong&gt; models. Thank &lt;a href=&quot;https://github.com/BUAADreamer&quot;&gt;@BUAADreamer&lt;/a&gt;&#39;s PR.&lt;/p&gt; 
 &lt;p&gt;[25/01/14] We supported fine-tuning the &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/collections/internlm/&quot;&gt;InternLM 3&lt;/a&gt;&lt;/strong&gt; models. Thank &lt;a href=&quot;https://github.com/hhaAndroid&quot;&gt;@hhaAndroid&lt;/a&gt;&#39;s PR.&lt;/p&gt; 
 &lt;p&gt;[25/01/10] We supported fine-tuning the &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/microsoft/phi-4&quot;&gt;Phi-4&lt;/a&gt;&lt;/strong&gt; model.&lt;/p&gt; 
 &lt;p&gt;[24/12/21] We supported using &lt;strong&gt;&lt;a href=&quot;https://github.com/SwanHubX/SwanLab&quot;&gt;SwanLab&lt;/a&gt;&lt;/strong&gt; for experiment tracking and visualization. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#use-swanlab-logger&quot;&gt;this section&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[24/11/27] We supported fine-tuning the &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B&quot;&gt;Skywork-o1&lt;/a&gt;&lt;/strong&gt; model and the &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT&quot;&gt;OpenO1&lt;/a&gt;&lt;/strong&gt; dataset.&lt;/p&gt; 
 &lt;p&gt;[24/10/09] We supported downloading pre-trained models and datasets from the &lt;strong&gt;&lt;a href=&quot;https://modelers.cn/models&quot;&gt;Modelers Hub&lt;/a&gt;&lt;/strong&gt;. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelers-hub&quot;&gt;this tutorial&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/09/19] We supported fine-tuning the &lt;strong&gt;&lt;a href=&quot;https://qwenlm.github.io/blog/qwen2.5/&quot;&gt;Qwen2.5&lt;/a&gt;&lt;/strong&gt; models.&lt;/p&gt; 
 &lt;p&gt;[24/08/30] We supported fine-tuning the &lt;strong&gt;&lt;a href=&quot;https://qwenlm.github.io/blog/qwen2-vl/&quot;&gt;Qwen2-VL&lt;/a&gt;&lt;/strong&gt; models. Thank &lt;a href=&quot;https://github.com/simonJJJ&quot;&gt;@simonJJJ&lt;/a&gt;&#39;s PR.&lt;/p&gt; 
 &lt;p&gt;[24/08/27] We supported &lt;strong&gt;&lt;a href=&quot;https://github.com/linkedin/Liger-Kernel&quot;&gt;Liger Kernel&lt;/a&gt;&lt;/strong&gt;. Try &lt;code&gt;enable_liger_kernel: true&lt;/code&gt; for efficient training.&lt;/p&gt; 
 &lt;p&gt;[24/08/09] We supported &lt;strong&gt;&lt;a href=&quot;https://github.com/zyushun/Adam-mini&quot;&gt;Adam-mini&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage. Thank &lt;a href=&quot;https://github.com/relic-yuexi&quot;&gt;@relic-yuexi&lt;/a&gt;&#39;s PR.&lt;/p&gt; 
 &lt;p&gt;[24/07/04] We supported &lt;a href=&quot;https://github.com/MeetKai/functionary/tree/main/functionary/train/packing&quot;&gt;contamination-free packed training&lt;/a&gt;. Use &lt;code&gt;neat_packing: true&lt;/code&gt; to activate it. Thank &lt;a href=&quot;https://github.com/chuan298&quot;&gt;@chuan298&lt;/a&gt;&#39;s PR.&lt;/p&gt; 
 &lt;p&gt;[24/06/16] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.02948&quot;&gt;PiSSA&lt;/a&gt;&lt;/strong&gt; algorithm. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/06/07] We supported fine-tuning the &lt;strong&gt;&lt;a href=&quot;https://qwenlm.github.io/blog/qwen2/&quot;&gt;Qwen2&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&quot;https://github.com/THUDM/GLM-4&quot;&gt;GLM-4&lt;/a&gt;&lt;/strong&gt; models.&lt;/p&gt; 
 &lt;p&gt;[24/05/26] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.14734&quot;&gt;SimPO&lt;/a&gt;&lt;/strong&gt; algorithm for preference learning. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/05/20] We supported fine-tuning the &lt;strong&gt;PaliGemma&lt;/strong&gt; series models. Note that the PaliGemma models are pre-trained models, you need to fine-tune them with &lt;code&gt;paligemma&lt;/code&gt; template for chat completion.&lt;/p&gt; 
 &lt;p&gt;[24/05/18] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.01306&quot;&gt;KTO&lt;/a&gt;&lt;/strong&gt; algorithm for preference learning. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/05/14] We supported training and inference on the Ascend NPU devices. Check &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#installation&quot;&gt;installation&lt;/a&gt; section for details.&lt;/p&gt; 
 &lt;p&gt;[24/04/26] We supported fine-tuning the &lt;strong&gt;LLaVA-1.5&lt;/strong&gt; multimodal LLMs. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/04/22] We provided a &lt;strong&gt;&lt;a href=&quot;https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing&quot;&gt;Colab notebook&lt;/a&gt;&lt;/strong&gt; for fine-tuning the Llama-3 model on a free T4 GPU. Two Llama-3-derived models fine-tuned using LLaMA Factory are available at Hugging Face, check &lt;a href=&quot;https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat&quot;&gt;Llama3-8B-Chinese-Chat&lt;/a&gt; and &lt;a href=&quot;https://huggingface.co/zhichen/Llama3-Chinese&quot;&gt;Llama3-Chinese&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[24/04/21] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.02258&quot;&gt;Mixture-of-Depths&lt;/a&gt;&lt;/strong&gt; according to &lt;a href=&quot;https://github.com/astramind-ai/Mixture-of-depths&quot;&gt;AstraMindAI&#39;s implementation&lt;/a&gt;. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/04/16] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.02827&quot;&gt;BAdam&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/04/16] We supported &lt;strong&gt;&lt;a href=&quot;https://github.com/unslothai/unsloth&quot;&gt;unsloth&lt;/a&gt;&lt;/strong&gt;&#39;s long-sequence training (Llama-2-7B-56k within 24GB). It achieves &lt;strong&gt;117%&lt;/strong&gt; speed and &lt;strong&gt;50%&lt;/strong&gt; memory compared with FlashAttention-2, more benchmarks can be found in &lt;a href=&quot;https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison&quot;&gt;this page&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;[24/03/31] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2403.07691&quot;&gt;ORPO&lt;/a&gt;&lt;/strong&gt;. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/21] Our paper &quot;&lt;a href=&quot;https://arxiv.org/abs/2403.13372&quot;&gt;LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models&lt;/a&gt;&quot; is available at arXiv!&lt;/p&gt; 
 &lt;p&gt;[24/03/20] We supported &lt;strong&gt;FSDP+QLoRA&lt;/strong&gt; that fine-tunes a 70B model on 2x24GB GPUs. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/13] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.12354&quot;&gt;LoRA+&lt;/a&gt;&lt;/strong&gt;. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/07] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2403.03507&quot;&gt;GaLore&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/07] We integrated &lt;strong&gt;&lt;a href=&quot;https://github.com/vllm-project/vllm&quot;&gt;vLLM&lt;/a&gt;&lt;/strong&gt; for faster and concurrent inference. Try &lt;code&gt;infer_backend: vllm&lt;/code&gt; to enjoy &lt;strong&gt;270%&lt;/strong&gt; inference speed.&lt;/p&gt; 
 &lt;p&gt;[24/02/28] We supported weight-decomposed LoRA (&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.09353&quot;&gt;DoRA&lt;/a&gt;&lt;/strong&gt;). Try &lt;code&gt;use_dora: true&lt;/code&gt; to activate DoRA training.&lt;/p&gt; 
 &lt;p&gt;[24/02/15] We supported &lt;strong&gt;block expansion&lt;/strong&gt; proposed by &lt;a href=&quot;https://github.com/TencentARC/LLaMA-Pro&quot;&gt;LLaMA Pro&lt;/a&gt;. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/02/05] Qwen1.5 (Qwen2 beta version) series models are supported in LLaMA-Factory. Check this &lt;a href=&quot;https://qwenlm.github.io/blog/qwen1.5/&quot;&gt;blog post&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[24/01/18] We supported &lt;strong&gt;agent tuning&lt;/strong&gt; for most models, equipping model with tool using abilities by fine-tuning with &lt;code&gt;dataset: glaive_toolcall_en&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;[23/12/23] We supported &lt;strong&gt;&lt;a href=&quot;https://github.com/unslothai/unsloth&quot;&gt;unsloth&lt;/a&gt;&lt;/strong&gt;&#39;s implementation to boost LoRA tuning for the LLaMA, Mistral and Yi models. Try &lt;code&gt;use_unsloth: true&lt;/code&gt; argument to activate unsloth patch. It achieves &lt;strong&gt;170%&lt;/strong&gt; speed in our benchmark, check &lt;a href=&quot;https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison&quot;&gt;this page&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[23/12/12] We supported fine-tuning the latest MoE model &lt;strong&gt;&lt;a href=&quot;https://huggingface.co/mistralai/Mixtral-8x7B-v0.1&quot;&gt;Mixtral 8x7B&lt;/a&gt;&lt;/strong&gt; in our framework. See hardware requirement &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#hardware-requirement&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;[23/12/01] We supported downloading pre-trained models and datasets from the &lt;strong&gt;&lt;a href=&quot;https://modelscope.cn/models&quot;&gt;ModelScope Hub&lt;/a&gt;&lt;/strong&gt;. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelscope-hub&quot;&gt;this tutorial&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[23/10/21] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2310.05914&quot;&gt;NEFTune&lt;/a&gt;&lt;/strong&gt; trick for fine-tuning. Try &lt;code&gt;neftune_noise_alpha: 5&lt;/code&gt; argument to activate NEFTune.&lt;/p&gt; 
 &lt;p&gt;[23/09/27] We supported &lt;strong&gt;$S^2$-Attn&lt;/strong&gt; proposed by &lt;a href=&quot;https://github.com/dvlab-research/LongLoRA&quot;&gt;LongLoRA&lt;/a&gt; for the LLaMA models. Try &lt;code&gt;shift_attn: true&lt;/code&gt; argument to enable shift short attention.&lt;/p&gt; 
 &lt;p&gt;[23/09/23] We integrated MMLU, C-Eval and CMMLU benchmarks in this repo. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[23/09/10] We supported &lt;strong&gt;&lt;a href=&quot;https://github.com/Dao-AILab/flash-attention&quot;&gt;FlashAttention-2&lt;/a&gt;&lt;/strong&gt;. Try &lt;code&gt;flash_attn: fa2&lt;/code&gt; argument to enable FlashAttention-2 if you are using RTX4090, A100 or H100 GPUs.&lt;/p&gt; 
 &lt;p&gt;[23/08/12] We supported &lt;strong&gt;RoPE scaling&lt;/strong&gt; to extend the context length of the LLaMA models. Try &lt;code&gt;rope_scaling: linear&lt;/code&gt; argument in training and &lt;code&gt;rope_scaling: dynamic&lt;/code&gt; argument at inference to extrapolate the position embeddings.&lt;/p&gt; 
 &lt;p&gt;[23/08/11] We supported &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2305.18290&quot;&gt;DPO training&lt;/a&gt;&lt;/strong&gt; for instruction-tuned models. See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[23/07/31] We supported &lt;strong&gt;dataset streaming&lt;/strong&gt;. Try &lt;code&gt;streaming: true&lt;/code&gt; and &lt;code&gt;max_steps: 10000&lt;/code&gt; arguments to load your dataset in streaming mode.&lt;/p&gt; 
 &lt;p&gt;[23/07/29] We released two instruction-tuned 13B models at Hugging Face. See these Hugging Face Repos (&lt;a href=&quot;https://huggingface.co/hiyouga/Llama-2-Chinese-13b-chat&quot;&gt;LLaMA-2&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/hiyouga/Baichuan-13B-sft&quot;&gt;Baichuan&lt;/a&gt;) for details.&lt;/p&gt; 
 &lt;p&gt;[23/07/18] We developed an &lt;strong&gt;all-in-one Web UI&lt;/strong&gt; for training, evaluation and inference. Try &lt;code&gt;train_web.py&lt;/code&gt; to fine-tune models in your Web browser. Thank &lt;a href=&quot;https://github.com/KanadeSiina&quot;&gt;@KanadeSiina&lt;/a&gt; and &lt;a href=&quot;https://github.com/codemayq&quot;&gt;@codemayq&lt;/a&gt; for their efforts in the development.&lt;/p&gt; 
 &lt;p&gt;[23/07/09] We released &lt;strong&gt;&lt;a href=&quot;https://github.com/hiyouga/FastEdit&quot;&gt;FastEdit&lt;/a&gt;&lt;/strong&gt; âš¡ğŸ©¹, an easy-to-use package for editing the factual knowledge of large language models efficiently. Please follow &lt;a href=&quot;https://github.com/hiyouga/FastEdit&quot;&gt;FastEdit&lt;/a&gt; if you are interested.&lt;/p&gt; 
 &lt;p&gt;[23/06/29] We provided a &lt;strong&gt;reproducible example&lt;/strong&gt; of training a chat model using instruction-following datasets, see &lt;a href=&quot;https://huggingface.co/hiyouga/Baichuan-7B-sft&quot;&gt;Baichuan-7B-sft&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[23/06/22] We aligned the &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/api_demo.py&quot;&gt;demo API&lt;/a&gt; with the &lt;a href=&quot;https://platform.openai.com/docs/api-reference/chat&quot;&gt;OpenAI&#39;s&lt;/a&gt; format where you can insert the fine-tuned model in &lt;strong&gt;arbitrary ChatGPT-based applications&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;[23/06/03] We supported quantized training and inference (aka &lt;strong&gt;&lt;a href=&quot;https://github.com/artidoro/qlora&quot;&gt;QLoRA&lt;/a&gt;&lt;/strong&gt;). See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Model size&lt;/th&gt; 
   &lt;th&gt;Template&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/baichuan-inc&quot;&gt;Baichuan 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B&lt;/td&gt; 
   &lt;td&gt;baichuan2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/bigscience&quot;&gt;BLOOM/BLOOMZ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;560M/1.1B/1.7B/3B/7.1B/176B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/THUDM&quot;&gt;ChatGLM3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;6B&lt;/td&gt; 
   &lt;td&gt;chatglm3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/CohereForAI&quot;&gt;Command R&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;35B/104B&lt;/td&gt; 
   &lt;td&gt;cohere&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/deepseek-ai&quot;&gt;DeepSeek (Code/MoE)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/16B/67B/236B&lt;/td&gt; 
   &lt;td&gt;deepseek&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/deepseek-ai&quot;&gt;DeepSeek 2.5/3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;236B/671B&lt;/td&gt; 
   &lt;td&gt;deepseek3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/deepseek-ai&quot;&gt;DeepSeek R1 (Distill)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5B/7B/8B/14B/32B/70B/671B&lt;/td&gt; 
   &lt;td&gt;deepseek3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/tiiuae&quot;&gt;Falcon&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/11B/40B/180B&lt;/td&gt; 
   &lt;td&gt;falcon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/google&quot;&gt;Gemma/Gemma 2/CodeGemma&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2B/7B/9B/27B&lt;/td&gt; 
   &lt;td&gt;gemma&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/google&quot;&gt;Gemma 3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/4B/12B/27B&lt;/td&gt; 
   &lt;td&gt;gemma3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/THUDM&quot;&gt;GLM-4&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;9B&lt;/td&gt; 
   &lt;td&gt;glm4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/openai-community&quot;&gt;GPT-2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.1B/0.4B/0.8B/1.5B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/ibm-granite&quot;&gt;Granite 3.0-3.1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/2B/3B/8B&lt;/td&gt; 
   &lt;td&gt;granite3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/IndexTeam&quot;&gt;Index&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.9B&lt;/td&gt; 
   &lt;td&gt;index&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/tencent/&quot;&gt;Hunyuan&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;hunyuan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/internlm&quot;&gt;InternLM 2-3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/8B/20B&lt;/td&gt; 
   &lt;td&gt;intern2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/facebookresearch/llama&quot;&gt;Llama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B/33B/65B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/meta-llama&quot;&gt;Llama 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B/70B&lt;/td&gt; 
   &lt;td&gt;llama2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/meta-llama&quot;&gt;Llama 3-3.3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/3B/8B/70B&lt;/td&gt; 
   &lt;td&gt;llama3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/meta-llama&quot;&gt;Llama 3.2 Vision&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11B/90B&lt;/td&gt; 
   &lt;td&gt;mllama&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/llava-hf&quot;&gt;LLaVA-1.5&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B&lt;/td&gt; 
   &lt;td&gt;llava&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/llava-hf&quot;&gt;LLaVA-NeXT&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/8B/13B/34B/72B/110B&lt;/td&gt; 
   &lt;td&gt;llava_next&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/llava-hf&quot;&gt;LLaVA-NeXT-Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/34B&lt;/td&gt; 
   &lt;td&gt;llava_next_video&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/openbmb&quot;&gt;MiniCPM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/2B/4B&lt;/td&gt; 
   &lt;td&gt;cpm/cpm3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/openbmb&quot;&gt;MiniCPM-o-2.6/MiniCPM-V-2.6&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;minicpm_o/minicpm_v&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/mistralai&quot;&gt;Ministral/Mistral-Nemo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B/12B&lt;/td&gt; 
   &lt;td&gt;ministral&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/mistralai&quot;&gt;Mistral/Mixtral&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/8x7B/8x22B&lt;/td&gt; 
   &lt;td&gt;mistral&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/mistralai&quot;&gt;Mistral Small&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;24B&lt;/td&gt; 
   &lt;td&gt;mistral_small&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/allenai&quot;&gt;OLMo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/7B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/google&quot;&gt;PaliGemma/PaliGemma2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/10B/28B&lt;/td&gt; 
   &lt;td&gt;paligemma&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/microsoft&quot;&gt;Phi-1.5/Phi-2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.3B/2.7B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/microsoft&quot;&gt;Phi-3/Phi-3.5&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;4B/14B&lt;/td&gt; 
   &lt;td&gt;phi&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/microsoft&quot;&gt;Phi-3-small&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;phi_small&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/microsoft&quot;&gt;Phi-4&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;phi4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/mistralai&quot;&gt;Pixtral&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12B&lt;/td&gt; 
   &lt;td&gt;pixtral&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/Qwen&quot;&gt;Qwen/QwQ (1-2.5) (Code/Math/MoE)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.5B/1.5B/3B/7B/14B/32B/72B/110B&lt;/td&gt; 
   &lt;td&gt;qwen&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/Qwen&quot;&gt;Qwen2-Audio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;qwen2_audio&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/Qwen&quot;&gt;Qwen2-VL/Qwen2.5-VL/QVQ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2B/3B/7B/72B&lt;/td&gt; 
   &lt;td&gt;qwen2_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/Skywork&quot;&gt;Skywork o1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;skywork_o1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/bigcode&quot;&gt;StarCoder 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/7B/15B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/Tele-AI&quot;&gt;TeleChat2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/7B/35B/115B&lt;/td&gt; 
   &lt;td&gt;telechat2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/xverse&quot;&gt;XVERSE&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B/65B&lt;/td&gt; 
   &lt;td&gt;xverse&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/01-ai&quot;&gt;Yi/Yi-1.5 (Code)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5B/6B/9B/34B&lt;/td&gt; 
   &lt;td&gt;yi&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/01-ai&quot;&gt;Yi-VL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;6B/34B&lt;/td&gt; 
   &lt;td&gt;yi_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/IEITYuan&quot;&gt;Yuan 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2B/51B/102B&lt;/td&gt; 
   &lt;td&gt;yuan&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] For the &quot;base&quot; models, the &lt;code&gt;template&lt;/code&gt; argument can be chosen from &lt;code&gt;default&lt;/code&gt;, &lt;code&gt;alpaca&lt;/code&gt;, &lt;code&gt;vicuna&lt;/code&gt; etc. But make sure to use the &lt;strong&gt;corresponding template&lt;/strong&gt; for the &quot;instruct/chat&quot; models.&lt;/p&gt; 
 &lt;p&gt;Remember to use the &lt;strong&gt;SAME&lt;/strong&gt; template in training and inference.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Please refer to &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/llamafactory/extras/constants.py&quot;&gt;constants.py&lt;/a&gt; for a full list of models we supported.&lt;/p&gt; 
&lt;p&gt;You also can add a custom chat template to &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/llamafactory/data/template.py&quot;&gt;template.py&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Supported Training Approaches&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Approach&lt;/th&gt; 
   &lt;th&gt;Full-tuning&lt;/th&gt; 
   &lt;th&gt;Freeze-tuning&lt;/th&gt; 
   &lt;th&gt;LoRA&lt;/th&gt; 
   &lt;th&gt;QLoRA&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pre-Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Supervised Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Reward Modeling&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KTO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ORPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SimPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ…&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The implementation details of PPO can be found in &lt;a href=&quot;https://newfacade.github.io/notes-on-reinforcement-learning/17-ppo-trl.html&quot;&gt;this blog&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Provided Datasets&lt;/h2&gt; 
&lt;details&gt;
 &lt;summary&gt;Pre-training datasets&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/wiki_demo.txt&quot;&gt;Wiki Demo (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/tiiuae/falcon-refinedweb&quot;&gt;RefinedWeb (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2&quot;&gt;RedPajama V2 (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/olm/olm-wikipedia-20221220&quot;&gt;Wikipedia (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered&quot;&gt;Wikipedia (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/EleutherAI/pile&quot;&gt;Pile (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/Skywork/SkyPile-150B&quot;&gt;SkyPile (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/HuggingFaceFW/fineweb&quot;&gt;FineWeb (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu&quot;&gt;FineWeb-Edu (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/bigcode/the-stack&quot;&gt;The Stack (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/bigcode/starcoderdata&quot;&gt;StarCoder (en)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Supervised fine-tuning datasets&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/identity.json&quot;&gt;Identity (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/tatsu-lab/stanford_alpaca&quot;&gt;Stanford Alpaca (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3&quot;&gt;Stanford Alpaca (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM&quot;&gt;Alpaca GPT4 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2&quot;&gt;Glaive Function Calling V2 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/GAIR/lima&quot;&gt;LIMA (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/JosephusCheung/GuanacoDataset&quot;&gt;Guanaco Dataset (multilingual)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/BelleGroup/train_2M_CN&quot;&gt;BELLE 2M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/BelleGroup/train_1M_CN&quot;&gt;BELLE 1M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/BelleGroup/train_0.5M_CN&quot;&gt;BELLE 0.5M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M&quot;&gt;BELLE Dialogue 0.4M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/BelleGroup/school_math_0.25M&quot;&gt;BELLE School Math 0.25M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M&quot;&gt;BELLE Multiturn Chat 0.8M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/thunlp/UltraChat&quot;&gt;UltraChat (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/garage-bAInd/Open-Platypus&quot;&gt;OpenPlatypus (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k&quot;&gt;CodeAlpaca 20k (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/QingyiSi/Alpaca-CoT&quot;&gt;Alpaca CoT (multilingual)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/Open-Orca/OpenOrca&quot;&gt;OpenOrca (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/Open-Orca/SlimOrca&quot;&gt;SlimOrca (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/TIGER-Lab/MathInstruct&quot;&gt;MathInstruct (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M&quot;&gt;Firefly 1.1M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/wiki_qa&quot;&gt;Wiki QA (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/suolyer/webqa&quot;&gt;Web QA (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/zxbsmk/webnovel_cn&quot;&gt;WebNovel (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/berkeley-nest/Nectar&quot;&gt;Nectar (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data&quot;&gt;deepctrl (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/HasturOfficial/adgen&quot;&gt;Advertise Generating (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/totally-not-an-llm/sharegpt-hyperfiltered-3k&quot;&gt;ShareGPT Hyperfiltered (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/shibing624/sharegpt_gpt4&quot;&gt;ShareGPT4 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k&quot;&gt;UltraChat 200k (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/THUDM/AgentInstruct&quot;&gt;AgentInstruct (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/lmsys/lmsys-chat-1m&quot;&gt;LMSYS Chat 1M (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k&quot;&gt;Evol Instruct V2 (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/HuggingFaceTB/cosmopedia&quot;&gt;Cosmopedia (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/hfl/stem_zh_instruction&quot;&gt;STEM (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/hfl/ruozhiba_gpt4_turbo&quot;&gt;Ruozhiba (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/m-a-p/neo_sft_phase2&quot;&gt;Neo-sft (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-300K-Filtered&quot;&gt;Magpie-Pro-300K-Filtered (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/argilla/magpie-ultra-v0.1&quot;&gt;Magpie-ultra-v0.1 (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/TIGER-Lab/WebInstructSub&quot;&gt;WebInstructSub (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT&quot;&gt;OpenO1-SFT (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k&quot;&gt;Open-Thoughts (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/open-r1/OpenR1-Math-220k&quot;&gt;Open-R1-Math (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT&quot;&gt;Chinese-DeepSeek-R1-Distill (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k&quot;&gt;LLaVA mixed (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions&quot;&gt;Pokemon-gpt4o-captions (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/mayflowergmbh/oasst_de&quot;&gt;Open Assistant (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/mayflowergmbh/dolly-15k_de&quot;&gt;Dolly 15k (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/mayflowergmbh/alpaca-gpt4_de&quot;&gt;Alpaca GPT4 (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/mayflowergmbh/openschnabeltier_de&quot;&gt;OpenSchnabeltier (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/mayflowergmbh/evol-instruct_de&quot;&gt;Evol Instruct (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/mayflowergmbh/dolphin_de&quot;&gt;Dolphin (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/mayflowergmbh/booksum_de&quot;&gt;Booksum (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/mayflowergmbh/airoboros-3.0_de&quot;&gt;Airoboros (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/mayflowergmbh/ultra-chat_de&quot;&gt;Ultrachat (de)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Preference datasets&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k&quot;&gt;DPO mixed (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized&quot;&gt;UltraFeedback (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/openbmb/RLHF-V-Dataset&quot;&gt;RLHF-V (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/Zhihui/VLFeedback&quot;&gt;VLFeedback (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/Intel/orca_dpo_pairs&quot;&gt;Orca DPO Pairs (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/Anthropic/hh-rlhf&quot;&gt;HH-RLHF (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/berkeley-nest/Nectar&quot;&gt;Nectar (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/mayflowergmbh/intel_orca_dpo_pairs_de&quot;&gt;Orca DPO (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/datasets/argilla/kto-mix-15k&quot;&gt;KTO mixed (en)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;Some datasets require confirmation before using them, so we recommend logging in with your Hugging Face account using these commands.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install --upgrade huggingface_hub
huggingface-cli login
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Requirement&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Mandatory&lt;/th&gt; 
   &lt;th&gt;Minimum&lt;/th&gt; 
   &lt;th&gt;Recommend&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;python&lt;/td&gt; 
   &lt;td&gt;3.9&lt;/td&gt; 
   &lt;td&gt;3.10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;torch&lt;/td&gt; 
   &lt;td&gt;1.13.1&lt;/td&gt; 
   &lt;td&gt;2.5.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;transformers&lt;/td&gt; 
   &lt;td&gt;4.41.2&lt;/td&gt; 
   &lt;td&gt;4.49.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;datasets&lt;/td&gt; 
   &lt;td&gt;2.16.0&lt;/td&gt; 
   &lt;td&gt;3.2.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;accelerate&lt;/td&gt; 
   &lt;td&gt;0.34.0&lt;/td&gt; 
   &lt;td&gt;1.2.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;peft&lt;/td&gt; 
   &lt;td&gt;0.11.1&lt;/td&gt; 
   &lt;td&gt;0.12.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;trl&lt;/td&gt; 
   &lt;td&gt;0.8.6&lt;/td&gt; 
   &lt;td&gt;0.9.6&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Optional&lt;/th&gt; 
   &lt;th&gt;Minimum&lt;/th&gt; 
   &lt;th&gt;Recommend&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CUDA&lt;/td&gt; 
   &lt;td&gt;11.6&lt;/td&gt; 
   &lt;td&gt;12.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;deepspeed&lt;/td&gt; 
   &lt;td&gt;0.10.0&lt;/td&gt; 
   &lt;td&gt;0.16.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;bitsandbytes&lt;/td&gt; 
   &lt;td&gt;0.39.0&lt;/td&gt; 
   &lt;td&gt;0.43.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vllm&lt;/td&gt; 
   &lt;td&gt;0.4.3&lt;/td&gt; 
   &lt;td&gt;0.7.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;flash-attn&lt;/td&gt; 
   &lt;td&gt;2.3.0&lt;/td&gt; 
   &lt;td&gt;2.7.2&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Requirement&lt;/h3&gt; 
&lt;p&gt;* &lt;em&gt;estimated&lt;/em&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Bits&lt;/th&gt; 
   &lt;th&gt;7B&lt;/th&gt; 
   &lt;th&gt;14B&lt;/th&gt; 
   &lt;th&gt;30B&lt;/th&gt; 
   &lt;th&gt;70B&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;x&lt;/code&gt;B&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Full (&lt;code&gt;bf16&lt;/code&gt; or &lt;code&gt;fp16&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;32&lt;/td&gt; 
   &lt;td&gt;120GB&lt;/td&gt; 
   &lt;td&gt;240GB&lt;/td&gt; 
   &lt;td&gt;600GB&lt;/td&gt; 
   &lt;td&gt;1200GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;18x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Full (&lt;code&gt;pure_bf16&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;60GB&lt;/td&gt; 
   &lt;td&gt;120GB&lt;/td&gt; 
   &lt;td&gt;300GB&lt;/td&gt; 
   &lt;td&gt;600GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;8x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Freeze/LoRA/GaLore/APOLLO/BAdam&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;16GB&lt;/td&gt; 
   &lt;td&gt;32GB&lt;/td&gt; 
   &lt;td&gt;64GB&lt;/td&gt; 
   &lt;td&gt;160GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QLoRA&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;10GB&lt;/td&gt; 
   &lt;td&gt;20GB&lt;/td&gt; 
   &lt;td&gt;40GB&lt;/td&gt; 
   &lt;td&gt;80GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QLoRA&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;6GB&lt;/td&gt; 
   &lt;td&gt;12GB&lt;/td&gt; 
   &lt;td&gt;24GB&lt;/td&gt; 
   &lt;td&gt;48GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;x/2&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QLoRA&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;16GB&lt;/td&gt; 
   &lt;td&gt;24GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;x/4&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Installation is mandatory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e &quot;.[torch,metrics]&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Extra dependencies available: torch, torch-npu, metrics, deepspeed, liger-kernel, bitsandbytes, hqq, eetq, gptq, awq, aqlm, vllm, sglang, galore, apollo, badam, adam-mini, qwen, minicpm_v, modelscope, openmind, swanlab, quality&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Use &lt;code&gt;pip install --no-deps -e .&lt;/code&gt; to resolve package conflicts.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt;
 &lt;summary&gt;Setting up a virtual environment with &lt;b&gt;uv&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Create an isolated Python environment with &lt;a href=&quot;https://github.com/astral-sh/uv&quot;&gt;uv&lt;/a&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;uv sync --extra torch --extra metrics --prerelease=allow
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Run LLaMA-Factory in the isolated environment:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;uv run --prerelease=allow llamafactory-cli train examples/train_lora/llama3_lora_pretrain.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;For Windows users&lt;/summary&gt; 
 &lt;h4&gt;Install BitsAndBytes&lt;/h4&gt; 
 &lt;p&gt;If you want to enable the quantized LoRA (QLoRA) on the Windows platform, you need to install a pre-built version of &lt;code&gt;bitsandbytes&lt;/code&gt; library, which supports CUDA 11.1 to 12.2, please select the appropriate &lt;a href=&quot;https://github.com/jllllll/bitsandbytes-windows-webui/releases/tag/wheels&quot;&gt;release version&lt;/a&gt; based on your CUDA version.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Install Flash Attention-2&lt;/h4&gt; 
 &lt;p&gt;To enable FlashAttention-2 on the Windows platform, please use the script from &lt;a href=&quot;https://huggingface.co/lldacing/flash-attention-windows-wheel&quot;&gt;flash-attention-windows-wheel&lt;/a&gt; to compile and install it by yourself.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;For Ascend NPU users&lt;/summary&gt; 
 &lt;p&gt;To install LLaMA Factory on Ascend NPU devices, please upgrade Python to version 3.10 or higher and specify extra dependencies: &lt;code&gt;pip install -e &quot;.[torch-npu,metrics]&quot;&lt;/code&gt;. Additionally, you need to install the &lt;strong&gt;&lt;a href=&quot;https://www.hiascend.com/developer/download/community/result?module=cann&quot;&gt;Ascend CANN Toolkit and Kernels&lt;/a&gt;&lt;/strong&gt;. Please follow the &lt;a href=&quot;https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/softwareinstall/instg/atlasdeploy_03_0031.html&quot;&gt;installation tutorial&lt;/a&gt; or use the following commands:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# replace the url according to your CANN version and devices
# install CANN Toolkit
wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-toolkit_8.0.0.alpha002_linux-&quot;$(uname -i)&quot;.run
bash Ascend-cann-toolkit_8.0.0.alpha002_linux-&quot;$(uname -i)&quot;.run --install

# install CANN Kernels
wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-kernels-910b_8.0.0.alpha002_linux-&quot;$(uname -i)&quot;.run
bash Ascend-cann-kernels-910b_8.0.0.alpha002_linux-&quot;$(uname -i)&quot;.run --install

# set env variables
source /usr/local/Ascend/ascend-toolkit/set_env.sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Requirement&lt;/th&gt; 
    &lt;th&gt;Minimum&lt;/th&gt; 
    &lt;th&gt;Recommend&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CANN&lt;/td&gt; 
    &lt;td&gt;8.0.RC1&lt;/td&gt; 
    &lt;td&gt;8.0.0.alpha002&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;torch&lt;/td&gt; 
    &lt;td&gt;2.1.0&lt;/td&gt; 
    &lt;td&gt;2.4.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;torch-npu&lt;/td&gt; 
    &lt;td&gt;2.1.0&lt;/td&gt; 
    &lt;td&gt;2.4.0.post2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;deepspeed&lt;/td&gt; 
    &lt;td&gt;0.13.2&lt;/td&gt; 
    &lt;td&gt;0.13.2&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;Remember to use &lt;code&gt;ASCEND_RT_VISIBLE_DEVICES&lt;/code&gt; instead of &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt; to specify the device to use.&lt;/p&gt; 
 &lt;p&gt;If you cannot infer model on NPU devices, try setting &lt;code&gt;do_sample: false&lt;/code&gt; in the configurations.&lt;/p&gt; 
 &lt;p&gt;Download the pre-built Docker images: &lt;a href=&quot;http://mirrors.cn-central-221.ovaijisuan.com/detail/130.html&quot;&gt;32GB&lt;/a&gt; | &lt;a href=&quot;http://mirrors.cn-central-221.ovaijisuan.com/detail/131.html&quot;&gt;64GB&lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;Install BitsAndBytes&lt;/h4&gt; 
 &lt;p&gt;To use QLoRA based on bitsandbytes on Ascend NPU, please follow these 3 steps:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Manually compile bitsandbytes: Refer to &lt;a href=&quot;https://huggingface.co/docs/bitsandbytes/installation?backend=Ascend+NPU&amp;amp;platform=Ascend+NPU&quot;&gt;the installation documentation&lt;/a&gt; for the NPU version of bitsandbytes to complete the compilation and installation. The compilation requires a cmake version of at least 3.22.1 and a g++ version of at least 12.x.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Install bitsandbytes from source
# Clone bitsandbytes repo, Ascend NPU backend is currently enabled on multi-backend-refactor branch
git clone -b multi-backend-refactor https://github.com/bitsandbytes-foundation/bitsandbytes.git
cd bitsandbytes/

# Install dependencies
pip install -r requirements-dev.txt

# Install the dependencies for the compilation tools. Note that the commands for this step may vary depending on the operating system. The following are provided for reference
apt-get install -y build-essential cmake

# Compile &amp;amp; install  
cmake -DCOMPUTE_BACKEND=npu -S .
make
pip install .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start=&quot;2&quot;&gt; 
  &lt;li&gt;Install transformers from the main branch.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone -b main https://github.com/huggingface/transformers.git
cd transformers
pip install .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start=&quot;3&quot;&gt; 
  &lt;li&gt;Set &lt;code&gt;double_quantization: false&lt;/code&gt; in the configuration. You can refer to the &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/train_qlora/llama3_lora_sft_bnb_npu.yaml&quot;&gt;example&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h3&gt;Data Preparation&lt;/h3&gt; 
&lt;p&gt;Please refer to &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/README.md&quot;&gt;data/README.md&lt;/a&gt; for checking the details about the format of dataset files. You can either use datasets on HuggingFace / ModelScope / Modelers hub or load the dataset in local disk.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Please update &lt;code&gt;data/dataset_info.json&lt;/code&gt; to use your custom dataset.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Quickstart&lt;/h3&gt; 
&lt;p&gt;Use the following 3 commands to run LoRA &lt;strong&gt;fine-tuning&lt;/strong&gt;, &lt;strong&gt;inference&lt;/strong&gt; and &lt;strong&gt;merging&lt;/strong&gt; of the Llama3-8B-Instruct model, respectively.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;llamafactory-cli train examples/train_lora/llama3_lora_sft.yaml
llamafactory-cli chat examples/inference/llama3_lora_sft.yaml
llamafactory-cli export examples/merge_lora/llama3_lora_sft.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md&quot;&gt;examples/README.md&lt;/a&gt; for advanced usage (including distributed training).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Use &lt;code&gt;llamafactory-cli help&lt;/code&gt; to show help information.&lt;/p&gt; 
 &lt;p&gt;Read &lt;a href=&quot;https://github.com/hiyouga/LLaMA-Factory/issues/4614&quot;&gt;FAQs&lt;/a&gt; first if you encounter any problems.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Fine-Tuning with LLaMA Board GUI (powered by &lt;a href=&quot;https://github.com/gradio-app/gradio&quot;&gt;Gradio&lt;/a&gt;)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;llamafactory-cli webui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build Docker&lt;/h3&gt; 
&lt;p&gt;For CUDA users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd docker/docker-cuda/
docker compose up -d
docker compose exec llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Ascend NPU users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd docker/docker-npu/
docker compose up -d
docker compose exec llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For AMD ROCm users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd docker/docker-rocm/
docker compose up -d
docker compose exec llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt;
 &lt;summary&gt;Build without Docker Compose&lt;/summary&gt; 
 &lt;p&gt;For CUDA users:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker build -f ./docker/docker-cuda/Dockerfile \
    --build-arg INSTALL_BNB=false \
    --build-arg INSTALL_VLLM=false \
    --build-arg INSTALL_DEEPSPEED=false \
    --build-arg INSTALL_FLASHATTN=false \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    -t llamafactory:latest .

docker run -dit --gpus=all \
    -v ./hf_cache:/root/.cache/huggingface \
    -v ./ms_cache:/root/.cache/modelscope \
    -v ./om_cache:/root/.cache/openmind \
    -v ./data:/app/data \
    -v ./output:/app/output \
    -p 7860:7860 \
    -p 8000:8000 \
    --shm-size 16G \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Ascend NPU users:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Choose docker image upon your environment
docker build -f ./docker/docker-npu/Dockerfile \
    --build-arg INSTALL_DEEPSPEED=false \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    -t llamafactory:latest .

# Change `device` upon your resources
docker run -dit \
    -v ./hf_cache:/root/.cache/huggingface \
    -v ./ms_cache:/root/.cache/modelscope \
    -v ./om_cache:/root/.cache/openmind \
    -v ./data:/app/data \
    -v ./output:/app/output \
    -v /usr/local/dcmi:/usr/local/dcmi \
    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \
    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \
    -v /etc/ascend_install.info:/etc/ascend_install.info \
    -p 7860:7860 \
    -p 8000:8000 \
    --device /dev/davinci0 \
    --device /dev/davinci_manager \
    --device /dev/devmm_svm \
    --device /dev/hisi_hdc \
    --shm-size 16G \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For AMD ROCm users:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker build -f ./docker/docker-rocm/Dockerfile \
    --build-arg INSTALL_BNB=false \
    --build-arg INSTALL_VLLM=false \
    --build-arg INSTALL_DEEPSPEED=false \
    --build-arg INSTALL_FLASHATTN=false \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    -t llamafactory:latest .

docker run -dit \
    -v ./hf_cache:/root/.cache/huggingface \
    -v ./ms_cache:/root/.cache/modelscope \
    -v ./om_cache:/root/.cache/openmind \
    -v ./data:/app/data \
    -v ./output:/app/output \
    -v ./saves:/app/saves \
    -p 7860:7860 \
    -p 8000:8000 \
    --device /dev/kfd \
    --device /dev/dri \
    --shm-size 16G \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Details about volume&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;hf_cache&lt;/code&gt;: Utilize Hugging Face cache on the host machine. Reassignable if a cache already exists in a different directory.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;ms_cache&lt;/code&gt;: Similar to Hugging Face cache but for ModelScope users.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;om_cache&lt;/code&gt;: Similar to Hugging Face cache but for Modelers users.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;data&lt;/code&gt;: Place datasets on this dir of the host machine so that they can be selected on LLaMA Board GUI.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;output&lt;/code&gt;: Set export dir to this location so that the merged result can be accessed directly on the host machine.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Deploy with OpenAI-style API and vLLM&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;API_PORT=8000 llamafactory-cli api examples/inference/llama3_vllm.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Visit &lt;a href=&quot;https://platform.openai.com/docs/api-reference/chat/create&quot;&gt;this page&lt;/a&gt; for API document.&lt;/p&gt; 
 &lt;p&gt;Examples: &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/scripts/api_example/test_image.py&quot;&gt;Image understanding&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/scripts/api_example/test_toolcall.py&quot;&gt;Function calling&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Download from ModelScope Hub&lt;/h3&gt; 
&lt;p&gt;If you have trouble with downloading models and datasets from Hugging Face, you can use ModelScope.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export USE_MODELSCOPE_HUB=1 # `set USE_MODELSCOPE_HUB=1` for Windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Train the model by specifying a model ID of the ModelScope Hub as the &lt;code&gt;model_name_or_path&lt;/code&gt;. You can find a full list of model IDs at &lt;a href=&quot;https://modelscope.cn/models&quot;&gt;ModelScope Hub&lt;/a&gt;, e.g., &lt;code&gt;LLM-Research/Meta-Llama-3-8B-Instruct&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Download from Modelers Hub&lt;/h3&gt; 
&lt;p&gt;You can also use Modelers Hub to download models and datasets.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export USE_OPENMIND_HUB=1 # `set USE_OPENMIND_HUB=1` for Windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Train the model by specifying a model ID of the Modelers Hub as the &lt;code&gt;model_name_or_path&lt;/code&gt;. You can find a full list of model IDs at &lt;a href=&quot;https://modelers.cn/models&quot;&gt;Modelers Hub&lt;/a&gt;, e.g., &lt;code&gt;TeleAI/TeleChat-7B-pt&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Use W&amp;amp;B Logger&lt;/h3&gt; 
&lt;p&gt;To use &lt;a href=&quot;https://wandb.ai&quot;&gt;Weights &amp;amp; Biases&lt;/a&gt; for logging experimental results, you need to add the following arguments to yaml files.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;report_to: wandb
run_name: test_run # optional
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set &lt;code&gt;WANDB_API_KEY&lt;/code&gt; to &lt;a href=&quot;https://wandb.ai/authorize&quot;&gt;your key&lt;/a&gt; when launching training tasks to log in with your W&amp;amp;B account.&lt;/p&gt; 
&lt;h3&gt;Use SwanLab Logger&lt;/h3&gt; 
&lt;p&gt;To use &lt;a href=&quot;https://github.com/SwanHubX/SwanLab&quot;&gt;SwanLab&lt;/a&gt; for logging experimental results, you need to add the following arguments to yaml files.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;use_swanlab: true
swanlab_run_name: test_run # optional
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When launching training tasks, you can log in to SwanLab in three ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Add &lt;code&gt;swanlab_api_key=&amp;lt;your_api_key&amp;gt;&lt;/code&gt; to the yaml file, and set it to your &lt;a href=&quot;https://swanlab.cn/settings&quot;&gt;API key&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Set the environment variable &lt;code&gt;SWANLAB_API_KEY&lt;/code&gt; to your &lt;a href=&quot;https://swanlab.cn/settings&quot;&gt;API key&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use the &lt;code&gt;swanlab login&lt;/code&gt; command to complete the login.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Projects using LLaMA Factory&lt;/h2&gt; 
&lt;p&gt;If you have a project that should be incorporated, please contact via email or create a pull request.&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Click to show&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Wang et al. ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. 2023. &lt;a href=&quot;https://arxiv.org/abs/2308.02223&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yu et al. Open, Closed, or Small Language Models for Text Classification? 2023. &lt;a href=&quot;https://arxiv.org/abs/2308.10092&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with Action Understanding and Feedback in Natural Language. 2023. &lt;a href=&quot;https://arxiv.org/abs/2308.10526&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Luceri et al. Leveraging Large Language Models to Detect Influence Campaigns in Social Media. 2023. &lt;a href=&quot;https://arxiv.org/abs/2311.07816&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Alleviating Hallucinations of Large Language Models through Induced Hallucinations. 2023. &lt;a href=&quot;https://arxiv.org/abs/2312.15710&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. KDD 2024. &lt;a href=&quot;https://arxiv.org/abs/2401.04319&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning. ACL 2024. &lt;a href=&quot;https://arxiv.org/abs/2401.07286&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Choi et al. FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs. 2024. &lt;a href=&quot;https://arxiv.org/abs/2402.05904&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts. 2024. &lt;a href=&quot;https://arxiv.org/abs/2402.07625&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lyu et al. KnowTuning: Knowledge-aware Fine-tuning for Large Language Models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2402.11176&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yang et al. LaCo: Large Language Model Pruning via Layer Collaps. 2024. &lt;a href=&quot;https://arxiv.org/abs/2402.11187&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Bhardwaj et al. Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic. 2024. &lt;a href=&quot;https://arxiv.org/abs/2402.11746&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yang et al. Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2402.11801&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yi et al. Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding. ACL 2024 Findings. &lt;a href=&quot;https://arxiv.org/abs/2402.11809&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Cao et al. Head-wise Shareable Attention for Large Language Models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2402.11819&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages. 2024. &lt;a href=&quot;https://arxiv.org/abs/2402.12204&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Kim et al. Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2402.14714&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yu et al. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL 2024. &lt;a href=&quot;https://arxiv.org/abs/2402.15043&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Huang et al. Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning. 2024. &lt;a href=&quot;https://arxiv.org/abs/2403.02333&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Duan et al. Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization. 2024. &lt;a href=&quot;https://arxiv.org/abs/2403.03419&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xie and Schwertfeger. Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs. 2024. &lt;a href=&quot;https://arxiv.org/abs/2403.08228&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wu et al. Large Language Models are Parallel Multilingual Learners. 2024. &lt;a href=&quot;https://arxiv.org/abs/2403.09073&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. EDT: Improving Large Language Models&#39; Generation by Entropy-based Dynamic Temperature Sampling. 2024. &lt;a href=&quot;https://arxiv.org/abs/2403.14541&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Weller et al. FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions. 2024. &lt;a href=&quot;https://arxiv.org/abs/2403.15246&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Hongbin Na. CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering. COLING 2024. &lt;a href=&quot;https://arxiv.org/abs/2403.16008&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zan et al. CodeS: Natural Language to Code Repository via Multi-Layer Sketch. 2024. &lt;a href=&quot;https://arxiv.org/abs/2403.16443&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Extensive Self-Contrast Enables Feedback-Free Language Model Alignment. 2024. &lt;a href=&quot;https://arxiv.org/abs/2404.00604&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Luo et al. BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2404.02827&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Du et al. Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model. 2024. &lt;a href=&quot;https://arxiv.org/abs/2404.04167&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ma et al. Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation. ICML 2024. &lt;a href=&quot;https://arxiv.org/abs/2404.04316&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Dynamic Generation of Personalities with Large Language Models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2404.07084&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Shang et al. How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2404.09836&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Huang et al. LLMTune: Accelerate Database Knob Tuning with Large Language Models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2404.11581&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Deng et al. Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction. 2024. &lt;a href=&quot;https://arxiv.org/abs/2404.14215&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Acikgoz et al. Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare. 2024. &lt;a href=&quot;https://arxiv.org/abs/2404.16621&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Small Language Models Need Strong Verifiers to Self-Correct Reasoning. ACL 2024 Findings. &lt;a href=&quot;https://arxiv.org/abs/2404.17140&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhou et al. FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering. NAACL 2024. &lt;a href=&quot;https://arxiv.org/abs/2404.18585&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xu et al. Large Language Models for Cyber Security: A Systematic Literature Review. 2024. &lt;a href=&quot;https://arxiv.org/abs/2405.04760&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Dammu et al. &quot;They are uncultured&quot;: Unveiling Covert Harms and Social Threats in LLM Generated Conversations. 2024. &lt;a href=&quot;https://arxiv.org/abs/2405.05378&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yi et al. A safety realignment framework via subspace-oriented model fusion for large language models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2405.09055&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lou et al. SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling. 2024. &lt;a href=&quot;https://arxiv.org/abs/2405.12739&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners. 2024. &lt;a href=&quot;https://arxiv.org/abs/2405.13816&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2405.20215&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zihong Chen. Sentence Segmentation and Sentence Punctuation Based on XunziALLM. 2024. &lt;a href=&quot;https://aclanthology.org/2024.lt4hala-1.30&quot;&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Gao et al. The Best of Both Worlds: Toward an Honest and Helpful Large Language Model. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.00380&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang and Song. MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.02106&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Hu et al. Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.03136&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ge et al. Time Sensitive Knowledge Editing through Efficient Finetuning. ACL 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.04496&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Tan et al. Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.05688&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Song et al. Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.05955&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Gu et al. RWKV-CLIP: A Robust Vision-Language Representation Learner. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.06973&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Chen et al. Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.07115&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhu et al. Are Large Language Models Good Statisticians?. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.07815&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Li et al. Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.10099&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ding et al. IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.10173&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;He et al. COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.12074&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lin et al. FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.14408&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Treutlein et al. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.14546&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Feng et al. SS-Bench: A Benchmark for Social Story Generation and Evaluation. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.15695&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Feng et al. Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.17233&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.18069&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Iyer et al. Exploring Very Low-Resource Translation with LLMs: The University of Edinburgh&#39;s Submission to AmericasNLP 2024 Translation Task. AmericasNLP 2024. &lt;a href=&quot;https://aclanthology.org/2024.americasnlp-1.25&quot;&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Li et al. Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring. 2024. &lt;a href=&quot;https://arxiv.org/abs/2406.19949&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yang et al. Financial Knowledge Large Language Model. 2024. &lt;a href=&quot;https://arxiv.org/abs/2407.00365&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lin et al. DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging. 2024. &lt;a href=&quot;https://arxiv.org/abs/2407.01470&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Bako et al. Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization. 2024. &lt;a href=&quot;https://arxiv.org/abs/2407.06129&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Huang et al. RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization. 2024. &lt;a href=&quot;https://arxiv.org/abs/2407.08044&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Jiang et al. LLM-Collaboration on Automatic Science Journalism for the General Audience. 2024. &lt;a href=&quot;https://arxiv.org/abs/2407.09756&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Inouye et al. Applied Auto-tuning on LoRA Hyperparameters. 2024. &lt;a href=&quot;https://scholarcommons.scu.edu/cseng_senior/272/&quot;&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Qi et al. Research on Tibetan Tourism Viewpoints information generation system based on LLM. 2024. &lt;a href=&quot;https://arxiv.org/abs/2407.13561&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xu et al. Course-Correction: Safety Alignment Using Synthetic Preferences. 2024. &lt;a href=&quot;https://arxiv.org/abs/2407.16637&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Sun et al. LAMBDA: A Large Model Based Data Agent. 2024. &lt;a href=&quot;https://arxiv.org/abs/2407.17535&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhu et al. CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare. 2024. &lt;a href=&quot;https://arxiv.org/abs/2407.19705&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yu et al. Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment. 2024. &lt;a href=&quot;https://arxiv.org/abs/2408.00137&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xie et al. The Power of Personalized Datasets: Advancing Chinese Composition Writing for Elementary School through Targeted Model Fine-Tuning. IALP 2024. &lt;a href=&quot;https://www.asianlp.sg/conferences/ialp2024/proceedings/papers/IALP2024_P055.pdf&quot;&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Instruct-Code-Llama: Improving Capabilities of Language Model in Competition Level Code Generation by Online Judge Feedback. ICIC 2024. &lt;a href=&quot;https://link.springer.com/chapter/10.1007/978-981-97-5669-8_11&quot;&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. Cybernetic Sentinels: Unveiling the Impact of Safety Data Selection on Model Security in Supervised Fine-Tuning. ICIC 2024. &lt;a href=&quot;https://link.springer.com/chapter/10.1007/978-981-97-5669-8_23&quot;&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xia et al. Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. 2024. &lt;a href=&quot;https://arxiv.org/abs/2408.04693&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zeng et al. Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions. 2024. &lt;a href=&quot;https://arxiv.org/abs/2408.04168&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xia et al. Using Pre-trained Language Model for Accurate ESG Prediction. FinNLP 2024. &lt;a href=&quot;https://aclanthology.org/2024.finnlp-2.1/&quot;&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liang et al. I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm. 2024. &lt;a href=&quot;https://arxiv.org/abs/2408.08072&quot;&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Bai et al. Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation. CIKM 2024. &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3627673.3679611&quot;&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/Yu-Yang-Li/StarWhisper&quot;&gt;StarWhisper&lt;/a&gt;&lt;/strong&gt;: A large language model for Astronomy, based on ChatGLM2-6B and Qwen-14B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/FudanDISC/DISC-LawLLM&quot;&gt;DISC-LawLLM&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in Chinese legal domain, based on Baichuan-13B, is capable of retrieving and reasoning on legal knowledge.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/X-D-Lab/Sunsimiao&quot;&gt;Sunsimiao&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in Chinese medical domain, based on Baichuan-7B and ChatGLM-6B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/WangRongsheng/CareGPT&quot;&gt;CareGPT&lt;/a&gt;&lt;/strong&gt;: A series of large language models for Chinese medical domain, based on LLaMA2-7B and Baichuan-13B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/PKU-YuanGroup/Machine-Mindset/&quot;&gt;MachineMindset&lt;/a&gt;&lt;/strong&gt;: A series of MBTI Personality large language models, capable of giving any LLM 16 different personality types based on different datasets and training methods.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://huggingface.co/Nekochu/Luminia-13B-v3&quot;&gt;Luminia-13B-v3&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in generate metadata for stable diffusion. &lt;a href=&quot;https://huggingface.co/spaces/Nekochu/Luminia-13B_SD_Prompt&quot;&gt;[demo]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/BUAADreamer/Chinese-LLaVA-Med&quot;&gt;Chinese-LLaVA-Med&lt;/a&gt;&lt;/strong&gt;: A multimodal large language model specialized in Chinese medical domain, based on LLaVA-1.5-7B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/THUDM/AutoRE&quot;&gt;AutoRE&lt;/a&gt;&lt;/strong&gt;: A document-level relation extraction system based on large language models.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NVIDIA/RTX-AI-Toolkit&quot;&gt;NVIDIA RTX AI Toolkit&lt;/a&gt;&lt;/strong&gt;: SDKs for fine-tuning LLMs on Windows PC for NVIDIA RTX.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/LazyAGI/LazyLLM&quot;&gt;LazyLLM&lt;/a&gt;&lt;/strong&gt;: An easy and lazy way for building multi-agent LLMs applications and supports model fine-tuning via LLaMA Factory.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NLPJCL/RAG-Retrieval&quot;&gt;RAG-Retrieval&lt;/a&gt;&lt;/strong&gt;: A full pipeline for RAG retrieval model fine-tuning, inference, and distillation. &lt;a href=&quot;https://zhuanlan.zhihu.com/p/987727357&quot;&gt;[blog]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/Qihoo360/360-LLaMA-Factory&quot;&gt;360-LLaMA-Factory&lt;/a&gt;&lt;/strong&gt;: A modified library that supports long sequence SFT &amp;amp; DPO using ring attention.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://novasky-ai.github.io/posts/sky-t1/&quot;&gt;Sky-T1&lt;/a&gt;&lt;/strong&gt;: An o1-like model fine-tuned by NovaSky AI with very small cost.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE&quot;&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please follow the model licenses to use the corresponding model weights: &lt;a href=&quot;https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Community%20License%20for%20Baichuan%202%20Model.pdf&quot;&gt;Baichuan 2&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/spaces/bigscience/license&quot;&gt;BLOOM&lt;/a&gt; / &lt;a href=&quot;https://github.com/THUDM/ChatGLM3/raw/main/MODEL_LICENSE&quot;&gt;ChatGLM3&lt;/a&gt; / &lt;a href=&quot;https://cohere.com/c4ai-cc-by-nc-license&quot;&gt;Command R&lt;/a&gt; / &lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-LLM/raw/main/LICENSE-MODEL&quot;&gt;DeepSeek&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/tiiuae/falcon-180B/blob/main/LICENSE.txt&quot;&gt;Falcon&lt;/a&gt; / &lt;a href=&quot;https://ai.google.dev/gemma/terms&quot;&gt;Gemma&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE&quot;&gt;GLM-4&lt;/a&gt; / &lt;a href=&quot;https://github.com/openai/gpt-2/raw/master/LICENSE&quot;&gt;GPT-2&lt;/a&gt; / &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE&quot;&gt;Granite&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/IndexTeam/Index-1.9B/blob/main/LICENSE&quot;&gt;Index&lt;/a&gt; / &lt;a href=&quot;https://github.com/InternLM/InternLM#license&quot;&gt;InternLM&lt;/a&gt; / &lt;a href=&quot;https://github.com/facebookresearch/llama/raw/main/MODEL_CARD.md&quot;&gt;Llama&lt;/a&gt; / &lt;a href=&quot;https://ai.meta.com/llama/license/&quot;&gt;Llama 2 (LLaVA-1.5)&lt;/a&gt; / &lt;a href=&quot;https://llama.meta.com/llama3/license/&quot;&gt;Llama 3&lt;/a&gt; / &lt;a href=&quot;https://github.com/OpenBMB/MiniCPM/raw/main/MiniCPM%20Model%20License.md&quot;&gt;MiniCPM&lt;/a&gt; / &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE&quot;&gt;Mistral/Mixtral/Pixtral&lt;/a&gt; / &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE&quot;&gt;OLMo&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx&quot;&gt;Phi-1.5/Phi-2&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE&quot;&gt;Phi-3/Phi-4&lt;/a&gt; / &lt;a href=&quot;https://github.com/QwenLM/Qwen/raw/main/Tongyi%20Qianwen%20LICENSE%20AGREEMENT&quot;&gt;Qwen&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/Skywork/Skywork-13B-base/blob/main/Skywork%20Community%20License.pdf&quot;&gt;Skywork&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement&quot;&gt;StarCoder 2&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/Tele-AI/telechat-7B/blob/main/TeleChat%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf&quot;&gt;TeleChat2&lt;/a&gt; / &lt;a href=&quot;https://github.com/xverse-ai/XVERSE-13B/raw/main/MODEL_LICENSE.pdf&quot;&gt;XVERSE&lt;/a&gt; / &lt;a href=&quot;https://huggingface.co/01-ai/Yi-6B/blob/main/LICENSE&quot;&gt;Yi&lt;/a&gt; / &lt;a href=&quot;https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE&quot;&gt;Yi-1.5&lt;/a&gt; / &lt;a href=&quot;https://github.com/IEIT-Yuan/Yuan-2.0/raw/main/LICENSE-Yuan&quot;&gt;Yuan 2&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If this work is helpful, please kindly cite as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@inproceedings{zheng2024llamafactory,
  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  address={Bangkok, Thailand},
  publisher={Association for Computational Linguistics},
  year={2024},
  url={http://arxiv.org/abs/2403.13372}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;This repo benefits from &lt;a href=&quot;https://github.com/huggingface/peft&quot;&gt;PEFT&lt;/a&gt;, &lt;a href=&quot;https://github.com/huggingface/trl&quot;&gt;TRL&lt;/a&gt;, &lt;a href=&quot;https://github.com/artidoro/qlora&quot;&gt;QLoRA&lt;/a&gt; and &lt;a href=&quot;https://github.com/lm-sys/FastChat&quot;&gt;FastChat&lt;/a&gt;. Thanks for their wonderful works.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=hiyouga/LLaMA-Factory&amp;amp;type=Date&quot; alt=&quot;Star History Chart&quot;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>infiniflow/ragflow</title>
      <link>https://github.com/infiniflow/ragflow</link>
      <description>&lt;p&gt;RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://demo.ragflow.io/&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/web/src/assets/logo-with-text.png&quot; width=&quot;520&quot; alt=&quot;ragflow logo&quot;&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/README.md&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/README_zh.md&quot;&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/README_tzh.md&quot;&gt;ç¹ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/README_ja.md&quot;&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/README_ko.md&quot;&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/README_id.md&quot;&gt;Bahasa Indonesia&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/README_pt_br.md&quot;&gt;PortuguÃªs (Brasil)&lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://x.com/intent/follow?screen_name=infiniflowai&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/twitter/follow/infiniflow?logo=X&amp;amp;color=%20%23f5f5f5&quot; alt=&quot;follow on X(Twitter)&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://demo.ragflow.io&quot; target=&quot;_blank&quot;&gt; &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Online-Demo-4e6b99&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://hub.docker.com/r/infiniflow/ragflow&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/docker_pull-ragflow:v0.17.2-brightgreen&quot; alt=&quot;docker pull infiniflow/ragflow:v0.17.2&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://github.com/infiniflow/ragflow/releases/latest&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/v/release/infiniflow/ragflow?color=blue&amp;amp;label=Latest%20Release&quot; alt=&quot;Latest Release&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://github.com/infiniflow/ragflow/raw/main/LICENSE&quot;&gt; &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4&quot; alt=&quot;license&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h4 align=&quot;center&quot;&gt; &lt;a href=&quot;https://ragflow.io/docs/dev/&quot;&gt;Document&lt;/a&gt; | &lt;a href=&quot;https://github.com/infiniflow/ragflow/issues/4214&quot;&gt;Roadmap&lt;/a&gt; | &lt;a href=&quot;https://twitter.com/infiniflowai&quot;&gt;Twitter&lt;/a&gt; | &lt;a href=&quot;https://discord.gg/4XxujFgUN7&quot;&gt;Discord&lt;/a&gt; | &lt;a href=&quot;https://demo.ragflow.io&quot;&gt;Demo&lt;/a&gt; &lt;/h4&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ“• Table of Contents&lt;/b&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ğŸ’¡ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-what-is-ragflow&quot;&gt;What is RAGFlow?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ® &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-demo&quot;&gt;Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ“Œ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-latest-updates&quot;&gt;Latest Updates&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸŒŸ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-key-features&quot;&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ” &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-system-architecture&quot;&gt;System Architecture&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ¬ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-get-started&quot;&gt;Get Started&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ”§ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-configurations&quot;&gt;Configurations&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ”§ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-build-a-docker-image-without-embedding-models&quot;&gt;Build a docker image without embedding models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ”§ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-build-a-docker-image-including-embedding-models&quot;&gt;Build a docker image including embedding models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ”¨ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-launch-service-from-source-for-development&quot;&gt;Launch service from source for development&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ“š &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-documentation&quot;&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ“œ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-roadmap&quot;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ„ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-community&quot;&gt;Community&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ™Œ &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/#-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸ’¡ What is RAGFlow?&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://ragflow.io/&quot;&gt;RAGFlow&lt;/a&gt; is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding. It offers a streamlined RAG workflow for businesses of any scale, combining LLM (Large Language Models) to provide truthful question-answering capabilities, backed by well-founded citations from various complex formatted data.&lt;/p&gt; 
&lt;h2&gt;ğŸ® Demo&lt;/h2&gt; 
&lt;p&gt;Try our demo at &lt;a href=&quot;https://demo.ragflow.io&quot;&gt;https://demo.ragflow.io&lt;/a&gt;.&lt;/p&gt; 
&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt; 
 &lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/7248/2f6baa3e-1092-4f11-866d-36f6a9d075e5&quot; width=&quot;1200&quot;&gt; 
 &lt;img src=&quot;https://github.com/user-attachments/assets/504bbbf1-c9f7-4d83-8cc5-e9cb63c26db6&quot; width=&quot;1200&quot;&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ”¥ Latest Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025-02-28 Combined with Internet search (Tavily), supports reasoning like Deep Research for any LLMs.&lt;/li&gt; 
 &lt;li&gt;2025-02-05 Updates the model list of &#39;SILICONFLOW&#39; and adds support for Deepseek-R1/DeepSeek-V3.&lt;/li&gt; 
 &lt;li&gt;2025-01-26 Optimizes knowledge graph extraction and application, offering various configuration options.&lt;/li&gt; 
 &lt;li&gt;2024-12-18 Upgrades Document Layout Analysis model in DeepDoc.&lt;/li&gt; 
 &lt;li&gt;2024-12-04 Adds support for pagerank score in knowledge base.&lt;/li&gt; 
 &lt;li&gt;2024-11-22 Adds more variables to Agent.&lt;/li&gt; 
 &lt;li&gt;2024-11-01 Adds keyword extraction and related question generation to the parsed chunks to improve the accuracy of retrieval.&lt;/li&gt; 
 &lt;li&gt;2024-08-22 Support text to SQL statements through RAG.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‰ Stay Tuned&lt;/h2&gt; 
&lt;p&gt;â­ï¸ Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new releases! ğŸŒŸ&lt;/p&gt; 
&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt; 
 &lt;img src=&quot;https://github.com/user-attachments/assets/18c9707e-b8aa-4caf-a154-037089c105ba&quot; width=&quot;1200&quot;&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸŒŸ Key Features&lt;/h2&gt; 
&lt;h3&gt;ğŸ­ &lt;strong&gt;&quot;Quality in, quality out&quot;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/deepdoc/README.md&quot;&gt;Deep document understanding&lt;/a&gt;-based knowledge extraction from unstructured data with complicated formats.&lt;/li&gt; 
 &lt;li&gt;Finds &quot;needle in a data haystack&quot; of literally unlimited tokens.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ± &lt;strong&gt;Template-based chunking&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Intelligent and explainable.&lt;/li&gt; 
 &lt;li&gt;Plenty of template options to choose from.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸŒ± &lt;strong&gt;Grounded citations with reduced hallucinations&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visualization of text chunking to allow human intervention.&lt;/li&gt; 
 &lt;li&gt;Quick view of the key references and traceable citations to support grounded answers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ” &lt;strong&gt;Compatibility with heterogeneous data sources&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ›€ &lt;strong&gt;Automated and effortless RAG workflow&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamlined RAG orchestration catered to both personal and large businesses.&lt;/li&gt; 
 &lt;li&gt;Configurable LLMs as well as embedding models.&lt;/li&gt; 
 &lt;li&gt;Multiple recall paired with fused re-ranking.&lt;/li&gt; 
 &lt;li&gt;Intuitive APIs for seamless integration with business.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ” System Architecture&lt;/h2&gt; 
&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt; 
 &lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/12318111/d6ac5664-c237-4200-a7c2-a4a00691b485&quot; width=&quot;1000&quot;&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ¬ Get Started&lt;/h2&gt; 
&lt;h3&gt;ğŸ“ Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU &amp;gt;= 4 cores&lt;/li&gt; 
 &lt;li&gt;RAM &amp;gt;= 16 GB&lt;/li&gt; 
 &lt;li&gt;Disk &amp;gt;= 50 GB&lt;/li&gt; 
 &lt;li&gt;Docker &amp;gt;= 24.0.0 &amp;amp; Docker Compose &amp;gt;= v2.26.1 
  &lt;blockquote&gt; 
   &lt;p&gt;If you have not installed Docker on your local machine (Windows, Mac, or Linux), see &lt;a href=&quot;https://docs.docker.com/engine/install/&quot;&gt;Install Docker Engine&lt;/a&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸš€ Start up the server&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Ensure &lt;code&gt;vm.max_map_count&lt;/code&gt; &amp;gt;= 262144:&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;To check the value of &lt;code&gt;vm.max_map_count&lt;/code&gt;:&lt;/p&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ sysctl vm.max_map_count
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;Reset &lt;code&gt;vm.max_map_count&lt;/code&gt; to a value at least 262144 if it is not.&lt;/p&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# In this case, we set it to 262144:
$ sudo sysctl -w vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;This change will be reset after a system reboot. To ensure your change remains permanent, add or update the &lt;code&gt;vm.max_map_count&lt;/code&gt; value in &lt;strong&gt;/etc/sysctl.conf&lt;/strong&gt; accordingly:&lt;/p&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repo:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ git clone https://github.com/infiniflow/ragflow.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start up the server using the pre-built Docker images:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] All Docker images are built for x86 platforms. We don&#39;t currently offer Docker images for ARM64. If you are on an ARM64 platform, follow &lt;a href=&quot;https://ragflow.io/docs/dev/build_docker_image&quot;&gt;this guide&lt;/a&gt; to build a Docker image compatible with your system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The command below downloads the &lt;code&gt;v0.17.2-slim&lt;/code&gt; edition of the RAGFlow Docker image. See the following table for descriptions of different RAGFlow editions. To download a RAGFlow edition different from &lt;code&gt;v0.17.2-slim&lt;/code&gt;, update the &lt;code&gt;RAGFLOW_IMAGE&lt;/code&gt; variable accordingly in &lt;strong&gt;docker/.env&lt;/strong&gt; before using &lt;code&gt;docker compose&lt;/code&gt; to start the server. For example: set &lt;code&gt;RAGFLOW_IMAGE=infiniflow/ragflow:v0.17.2&lt;/code&gt; for the full edition &lt;code&gt;v0.17.2&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ cd ragflow/docker
$ docker compose -f docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;RAGFlow image tag&lt;/th&gt; 
   &lt;th&gt;Image size (GB)&lt;/th&gt; 
   &lt;th&gt;Has embedding models?&lt;/th&gt; 
   &lt;th&gt;Stable?&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;v0.17.2&lt;/td&gt; 
   &lt;td&gt;â‰ˆ9&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;Stable release&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;v0.17.2-slim&lt;/td&gt; 
   &lt;td&gt;â‰ˆ2&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;Stable release&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nightly&lt;/td&gt; 
   &lt;td&gt;â‰ˆ9&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;âœ”&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Unstable&lt;/em&gt; nightly build&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nightly-slim&lt;/td&gt; 
   &lt;td&gt;â‰ˆ2&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Unstable&lt;/em&gt; nightly build&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt; &lt;p&gt;Check the server status after having the server up and running:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ docker logs -f ragflow-server
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;The following output confirms a successful launch of the system:&lt;/em&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;
      ____   ___    ______ ______ __
     / __ \ /   |  / ____// ____// /____  _      __
    / /_/ // /| | / / __ / /_   / // __ \| | /| / /
   / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ /
  /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/

 * Running on all addresses (0.0.0.0)
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;If you skip this confirmation step and directly log in to RAGFlow, your browser may prompt a &lt;code&gt;network anormal&lt;/code&gt; error because, at that moment, your RAGFlow may not be fully initialized.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In your web browser, enter the IP address of your server and log in to RAGFlow.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;With the default settings, you only need to enter &lt;code&gt;http://IP_OF_YOUR_MACHINE&lt;/code&gt; (&lt;strong&gt;sans&lt;/strong&gt; port number) as the default HTTP serving port &lt;code&gt;80&lt;/code&gt; can be omitted when using the default configurations.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/service_conf.yaml.template&quot;&gt;service_conf.yaml.template&lt;/a&gt;, select the desired LLM factory in &lt;code&gt;user_default_llm&lt;/code&gt; and update the &lt;code&gt;API_KEY&lt;/code&gt; field with the corresponding API key.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;See &lt;a href=&quot;https://ragflow.io/docs/dev/llm_api_key_setup&quot;&gt;llm_api_key_setup&lt;/a&gt; for more information.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;p&gt;&lt;em&gt;The show is on!&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ”§ Configurations&lt;/h2&gt; 
&lt;p&gt;When it comes to system configurations, you will need to manage the following files:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/.env&quot;&gt;.env&lt;/a&gt;: Keeps the fundamental setups for the system, such as &lt;code&gt;SVR_HTTP_PORT&lt;/code&gt;, &lt;code&gt;MYSQL_PASSWORD&lt;/code&gt;, and &lt;code&gt;MINIO_PASSWORD&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/service_conf.yaml.template&quot;&gt;service_conf.yaml.template&lt;/a&gt;: Configures the back-end services. The environment variables in this file will be automatically populated when the Docker container starts. Any environment variables set within the Docker container will be available for use, allowing you to customize service behavior based on the deployment environment.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/docker-compose.yml&quot;&gt;docker-compose.yml&lt;/a&gt;: The system relies on &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/docker-compose.yml&quot;&gt;docker-compose.yml&lt;/a&gt; to start up.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/README.md&quot;&gt;./docker/README&lt;/a&gt; file provides a detailed description of the environment settings and service configurations which can be used as &lt;code&gt;${ENV_VARS}&lt;/code&gt; in the &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/service_conf.yaml.template&quot;&gt;service_conf.yaml.template&lt;/a&gt; file.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To update the default HTTP serving port (80), go to &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/docker-compose.yml&quot;&gt;docker-compose.yml&lt;/a&gt; and change &lt;code&gt;80:80&lt;/code&gt; to &lt;code&gt;&amp;lt;YOUR_SERVING_PORT&amp;gt;:80&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Updates to the above configurations require a reboot of all containers to take effect:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ docker compose -f docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Switch doc engine from Elasticsearch to Infinity&lt;/h3&gt; 
&lt;p&gt;RAGFlow uses Elasticsearch by default for storing full text and vectors. To switch to &lt;a href=&quot;https://github.com/infiniflow/infinity/&quot;&gt;Infinity&lt;/a&gt;, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Stop all running containers:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ docker compose -f docker/docker-compose.yml down -v
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;code&gt;-v&lt;/code&gt; will delete the docker container volumes, and the existing data will be cleared.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt; &lt;p&gt;Set &lt;code&gt;DOC_ENGINE&lt;/code&gt; in &lt;strong&gt;docker/.env&lt;/strong&gt; to &lt;code&gt;infinity&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start the containers:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ docker compose -f docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Switching to Infinity on a Linux/arm64 machine is not yet officially supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ”§ Build a Docker image without embedding models&lt;/h2&gt; 
&lt;p&gt;This image is approximately 2 GB in size and relies on external LLM and embedding services.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --build-arg LIGHTEN=1 -f Dockerfile -t infiniflow/ragflow:nightly-slim .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ”§ Build a Docker image including embedding models&lt;/h2&gt; 
&lt;p&gt;This image is approximately 9 GB in size. As it includes embedding models, it relies on external LLM services only.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build -f Dockerfile -t infiniflow/ragflow:nightly .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ”¨ Launch service from source for development&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install uv, or skip this step if it is already installed:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pipx install uv
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the source code and install Python dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
uv sync --python 3.10 --all-extras # install RAGFlow dependent python modules
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch the dependent services (MinIO, Elasticsearch, Redis, and MySQL) using Docker Compose:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker compose -f docker/docker-compose-base.yml up -d
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add the following line to &lt;code&gt;/etc/hosts&lt;/code&gt; to resolve all hosts specified in &lt;strong&gt;docker/.env&lt;/strong&gt; to &lt;code&gt;127.0.0.1&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;127.0.0.1       es01 infinity mysql minio redis
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you cannot access HuggingFace, set the &lt;code&gt;HF_ENDPOINT&lt;/code&gt; environment variable to use a mirror site:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export HF_ENDPOINT=https://hf-mirror.com
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch backend service:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;source .venv/bin/activate
export PYTHONPATH=$(pwd)
bash docker/launch_backend_service.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install frontend dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd web
npm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch frontend service:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;npm run dev
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;The following output confirms a successful launch of the system:&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/0daf462c-a24d-4496-a66f-92533534e187&quot; alt=&quot;&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ragflow.io/docs/dev/&quot;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ragflow.io/docs/dev/category/guides&quot;&gt;User guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ragflow.io/docs/dev/category/references&quot;&gt;References&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ragflow.io/docs/dev/faq&quot;&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“œ Roadmap&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://github.com/infiniflow/ragflow/issues/4214&quot;&gt;RAGFlow Roadmap 2025&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ„ Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://discord.gg/4XxujFgUN7&quot;&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://twitter.com/infiniflowai&quot;&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/orgs/infiniflow/discussions&quot;&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ™Œ Contributing&lt;/h2&gt; 
&lt;p&gt;RAGFlow flourishes via open-source collaboration. In this spirit, we embrace diverse contributions from the community. If you would like to be a part, review our &lt;a href=&quot;https://raw.githubusercontent.com/infiniflow/ragflow/main/CONTRIBUTING.md&quot;&gt;Contribution Guidelines&lt;/a&gt; first.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>harry0703/MoneyPrinterTurbo</title>
      <link>https://github.com/harry0703/MoneyPrinterTurbo</link>
      <description>&lt;p&gt;åˆ©ç”¨AIå¤§æ¨¡å‹ï¼Œä¸€é”®ç”Ÿæˆé«˜æ¸…çŸ­è§†é¢‘ Generate short videos with one click using AI LLM.&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;h1 align=&quot;center&quot;&gt;MoneyPrinterTurbo ğŸ’¸&lt;/h1&gt; 
 &lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Stargazers&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Issues&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/network/members&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Forks&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/raw/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;License&quot;&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;br&gt; 
 &lt;h3&gt;ç®€ä½“ä¸­æ–‡ | &lt;a href=&quot;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/README-en.md&quot;&gt;English&lt;/a&gt;&lt;/h3&gt; 
 &lt;div align=&quot;center&quot;&gt; 
  &lt;a href=&quot;https://trendshift.io/repositories/8731&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/8731&quot; alt=&quot;harry0703%2FMoneyPrinterTurbo | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br&gt; åªéœ€æä¾›ä¸€ä¸ªè§†é¢‘ 
 &lt;b&gt;ä¸»é¢˜&lt;/b&gt; æˆ– 
 &lt;b&gt;å…³é”®è¯&lt;/b&gt; ï¼Œå°±å¯ä»¥å…¨è‡ªåŠ¨ç”Ÿæˆè§†é¢‘æ–‡æ¡ˆã€è§†é¢‘ç´ æã€è§†é¢‘å­—å¹•ã€è§†é¢‘èƒŒæ™¯éŸ³ä¹ï¼Œç„¶ååˆæˆä¸€ä¸ªé«˜æ¸…çš„çŸ­è§†é¢‘ã€‚ 
 &lt;br&gt; 
 &lt;h4&gt;Webç•Œé¢&lt;/h4&gt; 
 &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/webui.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
 &lt;h4&gt;APIç•Œé¢&lt;/h4&gt; 
 &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/api.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ç‰¹åˆ«æ„Ÿè°¢ ğŸ™&lt;/h2&gt; 
&lt;p&gt;ç”±äºè¯¥é¡¹ç›®çš„ &lt;strong&gt;éƒ¨ç½²&lt;/strong&gt; å’Œ &lt;strong&gt;ä½¿ç”¨&lt;/strong&gt;ï¼Œå¯¹äºä¸€äº›å°ç™½ç”¨æˆ·æ¥è¯´ï¼Œè¿˜æ˜¯ &lt;strong&gt;æœ‰ä¸€å®šçš„é—¨æ§›&lt;/strong&gt;ï¼Œåœ¨æ­¤ç‰¹åˆ«æ„Ÿè°¢ &lt;strong&gt;å½•å’–ï¼ˆAIæ™ºèƒ½ å¤šåª’ä½“æœåŠ¡å¹³å°ï¼‰&lt;/strong&gt; ç½‘ç«™åŸºäºè¯¥é¡¹ç›®ï¼Œæä¾›çš„å…è´¹&lt;code&gt;AIè§†é¢‘ç”Ÿæˆå™¨&lt;/code&gt;æœåŠ¡ï¼Œå¯ä»¥ä¸ç”¨éƒ¨ç½²ï¼Œç›´æ¥åœ¨çº¿ä½¿ç”¨ï¼Œéå¸¸æ–¹ä¾¿ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¸­æ–‡ç‰ˆï¼š&lt;a href=&quot;https://reccloud.cn&quot;&gt;https://reccloud.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;è‹±æ–‡ç‰ˆï¼š&lt;a href=&quot;https://reccloud.com&quot;&gt;https://reccloud.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/reccloud.cn.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;æ„Ÿè°¢èµåŠ© ğŸ™&lt;/h2&gt; 
&lt;p&gt;æ„Ÿè°¢ä½ç³– &lt;a href=&quot;https://picwish.cn&quot;&gt;https://picwish.cn&lt;/a&gt; å¯¹è¯¥é¡¹ç›®çš„æ”¯æŒå’ŒèµåŠ©ï¼Œä½¿å¾—è¯¥é¡¹ç›®èƒ½å¤ŸæŒç»­çš„æ›´æ–°å’Œç»´æŠ¤ã€‚&lt;/p&gt; 
&lt;p&gt;ä½ç³–ä¸“æ³¨äº&lt;strong&gt;å›¾åƒå¤„ç†é¢†åŸŸ&lt;/strong&gt;ï¼Œæä¾›ä¸°å¯Œçš„&lt;strong&gt;å›¾åƒå¤„ç†å·¥å…·&lt;/strong&gt;ï¼Œå°†å¤æ‚æ“ä½œæè‡´ç®€åŒ–ï¼ŒçœŸæ­£å®ç°è®©å›¾åƒå¤„ç†æ›´ç®€å•ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/picwish.jpg&quot; alt=&quot;picwish.jpg&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;åŠŸèƒ½ç‰¹æ€§ ğŸ¯&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; å®Œæ•´çš„ &lt;strong&gt;MVCæ¶æ„&lt;/strong&gt;ï¼Œä»£ç  &lt;strong&gt;ç»“æ„æ¸…æ™°&lt;/strong&gt;ï¼Œæ˜“äºç»´æŠ¤ï¼Œæ”¯æŒ &lt;code&gt;API&lt;/code&gt; å’Œ &lt;code&gt;Webç•Œé¢&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; æ”¯æŒè§†é¢‘æ–‡æ¡ˆ &lt;strong&gt;AIè‡ªåŠ¨ç”Ÿæˆ&lt;/strong&gt;ï¼Œä¹Ÿå¯ä»¥&lt;strong&gt;è‡ªå®šä¹‰æ–‡æ¡ˆ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; æ”¯æŒå¤šç§ &lt;strong&gt;é«˜æ¸…è§†é¢‘&lt;/strong&gt; å°ºå¯¸ 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; ç«–å± 9:16ï¼Œ&lt;code&gt;1080x1920&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; æ¨ªå± 16:9ï¼Œ&lt;code&gt;1920x1080&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; æ”¯æŒ &lt;strong&gt;æ‰¹é‡è§†é¢‘ç”Ÿæˆ&lt;/strong&gt;ï¼Œå¯ä»¥ä¸€æ¬¡ç”Ÿæˆå¤šä¸ªè§†é¢‘ï¼Œç„¶åé€‰æ‹©ä¸€ä¸ªæœ€æ»¡æ„çš„&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; æ”¯æŒ &lt;strong&gt;è§†é¢‘ç‰‡æ®µæ—¶é•¿&lt;/strong&gt; è®¾ç½®ï¼Œæ–¹ä¾¿è°ƒèŠ‚ç´ æåˆ‡æ¢é¢‘ç‡&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; æ”¯æŒ &lt;strong&gt;ä¸­æ–‡&lt;/strong&gt; å’Œ &lt;strong&gt;è‹±æ–‡&lt;/strong&gt; è§†é¢‘æ–‡æ¡ˆ&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; æ”¯æŒ &lt;strong&gt;å¤šç§è¯­éŸ³&lt;/strong&gt; åˆæˆï¼Œå¯ &lt;strong&gt;å®æ—¶è¯•å¬&lt;/strong&gt; æ•ˆæœ&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; æ”¯æŒ &lt;strong&gt;å­—å¹•ç”Ÿæˆ&lt;/strong&gt;ï¼Œå¯ä»¥è°ƒæ•´ &lt;code&gt;å­—ä½“&lt;/code&gt;ã€&lt;code&gt;ä½ç½®&lt;/code&gt;ã€&lt;code&gt;é¢œè‰²&lt;/code&gt;ã€&lt;code&gt;å¤§å°&lt;/code&gt;ï¼ŒåŒæ—¶æ”¯æŒ&lt;code&gt;å­—å¹•æè¾¹&lt;/code&gt;è®¾ç½®&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; æ”¯æŒ &lt;strong&gt;èƒŒæ™¯éŸ³ä¹&lt;/strong&gt;ï¼Œéšæœºæˆ–è€…æŒ‡å®šéŸ³ä¹æ–‡ä»¶ï¼Œå¯è®¾ç½®&lt;code&gt;èƒŒæ™¯éŸ³ä¹éŸ³é‡&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; è§†é¢‘ç´ ææ¥æº &lt;strong&gt;é«˜æ¸…&lt;/strong&gt;ï¼Œè€Œä¸” &lt;strong&gt;æ— ç‰ˆæƒ&lt;/strong&gt;ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨è‡ªå·±çš„ &lt;strong&gt;æœ¬åœ°ç´ æ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; æ”¯æŒ &lt;strong&gt;OpenAI&lt;/strong&gt;ã€&lt;strong&gt;Moonshot&lt;/strong&gt;ã€&lt;strong&gt;Azure&lt;/strong&gt;ã€&lt;strong&gt;gpt4free&lt;/strong&gt;ã€&lt;strong&gt;one-api&lt;/strong&gt;ã€&lt;strong&gt;é€šä¹‰åƒé—®&lt;/strong&gt;ã€&lt;strong&gt;Google Gemini&lt;/strong&gt;ã€&lt;strong&gt;Ollama&lt;/strong&gt;ã€ &lt;strong&gt;DeepSeek&lt;/strong&gt;ã€ &lt;strong&gt;æ–‡å¿ƒä¸€è¨€&lt;/strong&gt; ç­‰å¤šç§æ¨¡å‹æ¥å…¥ 
  &lt;ul&gt; 
   &lt;li&gt;ä¸­å›½ç”¨æˆ·å»ºè®®ä½¿ç”¨ &lt;strong&gt;DeepSeek&lt;/strong&gt; æˆ– &lt;strong&gt;Moonshot&lt;/strong&gt; ä½œä¸ºå¤§æ¨¡å‹æä¾›å•†ï¼ˆå›½å†…å¯ç›´æ¥è®¿é—®ï¼Œä¸éœ€è¦VPNã€‚æ³¨å†Œå°±é€é¢åº¦ï¼ŒåŸºæœ¬å¤Ÿç”¨ï¼‰&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;åæœŸè®¡åˆ’ ğŸ“…&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; GPT-SoVITS é…éŸ³æ”¯æŒ&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; ä¼˜åŒ–è¯­éŸ³åˆæˆï¼Œåˆ©ç”¨å¤§æ¨¡å‹ï¼Œä½¿å…¶åˆæˆçš„å£°éŸ³ï¼Œæ›´åŠ è‡ªç„¶ï¼Œæƒ…ç»ªæ›´åŠ ä¸°å¯Œ&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; å¢åŠ è§†é¢‘è½¬åœºæ•ˆæœï¼Œä½¿å…¶çœ‹èµ·æ¥æ›´åŠ çš„æµç•…&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; å¢åŠ æ›´å¤šè§†é¢‘ç´ ææ¥æºï¼Œä¼˜åŒ–è§†é¢‘ç´ æå’Œæ–‡æ¡ˆçš„åŒ¹é…åº¦&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; å¢åŠ è§†é¢‘é•¿åº¦é€‰é¡¹ï¼šçŸ­ã€ä¸­ã€é•¿&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; æ”¯æŒæ›´å¤šçš„è¯­éŸ³åˆæˆæœåŠ¡å•†ï¼Œæ¯”å¦‚ OpenAI TTS&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; è‡ªåŠ¨ä¸Šä¼ åˆ°YouTubeå¹³å°&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;è§†é¢‘æ¼”ç¤º ğŸ“º&lt;/h2&gt; 
&lt;h3&gt;ç«–å± 9:16&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;
    &lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;
     â–¶ï¸
    &lt;/g-emoji&gt; ã€Šå¦‚ä½•å¢åŠ ç”Ÿæ´»çš„ä¹è¶£ã€‹&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;
    &lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;
     â–¶ï¸
    &lt;/g-emoji&gt; ã€Šé‡‘é’±çš„ä½œç”¨ã€‹&lt;br&gt;æ›´çœŸå®çš„åˆæˆå£°éŸ³&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;
    &lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;
     â–¶ï¸
    &lt;/g-emoji&gt; ã€Šç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä»€ä¹ˆã€‹&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6&quot;&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8&quot;&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476&quot;&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;æ¨ªå± 16:9&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;
    &lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;
     â–¶ï¸
    &lt;/g-emoji&gt;ã€Šç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä»€ä¹ˆã€‹&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;
    &lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;
     â–¶ï¸
    &lt;/g-emoji&gt;ã€Šä¸ºä»€ä¹ˆè¦è¿åŠ¨ã€‹&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073&quot;&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;
    &lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87&quot;&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;é…ç½®è¦æ±‚ ğŸ“¦&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;å»ºè®®æœ€ä½ CPU 4æ ¸æˆ–ä»¥ä¸Šï¼Œå†…å­˜ 8G æˆ–ä»¥ä¸Šï¼Œæ˜¾å¡éå¿…é¡»&lt;/li&gt; 
 &lt;li&gt;Windows 10 æˆ– MacOS 11.0 ä»¥ä¸Šç³»ç»Ÿ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;å¿«é€Ÿå¼€å§‹ ğŸš€&lt;/h2&gt; 
&lt;p&gt;ä¸‹è½½ä¸€é”®å¯åŠ¨åŒ…ï¼Œè§£å‹ç›´æ¥ä½¿ç”¨ï¼ˆè·¯å¾„ä¸è¦æœ‰ &lt;strong&gt;ä¸­æ–‡&lt;/strong&gt;ã€&lt;strong&gt;ç‰¹æ®Šå­—ç¬¦&lt;/strong&gt;ã€&lt;strong&gt;ç©ºæ ¼&lt;/strong&gt;ï¼‰&lt;/p&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ç™¾åº¦ç½‘ç›˜ï¼ˆ1.2.1 æœ€æ–°ç‰ˆæœ¬ï¼‰: &lt;a href=&quot;https://pan.baidu.com/s/1pSNjxTYiVENulTLm6zieMQ?pwd=g36q&quot;&gt;https://pan.baidu.com/s/1pSNjxTYiVENulTLm6zieMQ?pwd=g36q&lt;/a&gt; æå–ç : g36q&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ä¸‹è½½åï¼Œå»ºè®®å…ˆ&lt;strong&gt;åŒå‡»æ‰§è¡Œ&lt;/strong&gt; &lt;code&gt;update.bat&lt;/code&gt; æ›´æ–°åˆ°&lt;strong&gt;æœ€æ–°ä»£ç &lt;/strong&gt;ï¼Œç„¶ååŒå‡» &lt;code&gt;start.bat&lt;/code&gt; å¯åŠ¨&lt;/p&gt; 
&lt;p&gt;å¯åŠ¨åï¼Œä¼šè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼ˆå¦‚æœæ‰“å¼€æ˜¯ç©ºç™½ï¼Œå»ºè®®æ¢æˆ &lt;strong&gt;Chrome&lt;/strong&gt; æˆ–è€… &lt;strong&gt;Edge&lt;/strong&gt; æ‰“å¼€ï¼‰&lt;/p&gt; 
&lt;h3&gt;å…¶ä»–ç³»ç»Ÿ&lt;/h3&gt; 
&lt;p&gt;è¿˜æ²¡æœ‰åˆ¶ä½œä¸€é”®å¯åŠ¨åŒ…ï¼Œçœ‹ä¸‹é¢çš„ &lt;strong&gt;å®‰è£…éƒ¨ç½²&lt;/strong&gt; éƒ¨åˆ†ï¼Œå»ºè®®ä½¿ç”¨ &lt;strong&gt;docker&lt;/strong&gt; éƒ¨ç½²ï¼Œæ›´åŠ æ–¹ä¾¿ã€‚&lt;/p&gt; 
&lt;h2&gt;å®‰è£…éƒ¨ç½² ğŸ“¥&lt;/h2&gt; 
&lt;h3&gt;å‰ææ¡ä»¶&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;å°½é‡ä¸è¦ä½¿ç”¨ &lt;strong&gt;ä¸­æ–‡è·¯å¾„&lt;/strong&gt;ï¼Œé¿å…å‡ºç°ä¸€äº›æ— æ³•é¢„æ–™çš„é—®é¢˜&lt;/li&gt; 
 &lt;li&gt;è¯·ç¡®ä¿ä½ çš„ &lt;strong&gt;ç½‘ç»œ&lt;/strong&gt; æ˜¯æ­£å¸¸çš„ï¼ŒVPNéœ€è¦æ‰“å¼€&lt;code&gt;å…¨å±€æµé‡&lt;/code&gt;æ¨¡å¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;â‘  å…‹éš†ä»£ç &lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;â‘¡ ä¿®æ”¹é…ç½®æ–‡ä»¶&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;å°† &lt;code&gt;config.example.toml&lt;/code&gt; æ–‡ä»¶å¤åˆ¶ä¸€ä»½ï¼Œå‘½åä¸º &lt;code&gt;config.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;æŒ‰ç…§ &lt;code&gt;config.toml&lt;/code&gt; æ–‡ä»¶ä¸­çš„è¯´æ˜ï¼Œé…ç½®å¥½ &lt;code&gt;pexels_api_keys&lt;/code&gt; å’Œ &lt;code&gt;llm_provider&lt;/code&gt;ï¼Œå¹¶æ ¹æ® llm_provider å¯¹åº”çš„æœåŠ¡å•†ï¼Œé…ç½®ç›¸å…³çš„ API Key&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Dockeréƒ¨ç½² ğŸ³&lt;/h3&gt; 
&lt;h4&gt;â‘  å¯åŠ¨Docker&lt;/h4&gt; 
&lt;p&gt;å¦‚æœæœªå®‰è£… Dockerï¼Œè¯·å…ˆå®‰è£… &lt;a href=&quot;https://www.docker.com/products/docker-desktop/&quot;&gt;https://www.docker.com/products/docker-desktop/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;å¦‚æœæ˜¯Windowsç³»ç»Ÿï¼Œè¯·å‚è€ƒå¾®è½¯çš„æ–‡æ¡£ï¼š&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://learn.microsoft.com/zh-cn/windows/wsl/install&quot;&gt;https://learn.microsoft.com/zh-cn/windows/wsl/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers&quot;&gt;https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;cd MoneyPrinterTurbo
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨æ„ï¼šæœ€æ–°ç‰ˆçš„dockerå®‰è£…æ—¶ä¼šè‡ªåŠ¨ä»¥æ’ä»¶çš„å½¢å¼å®‰è£…docker composeï¼Œå¯åŠ¨å‘½ä»¤è°ƒæ•´ä¸ºdocker compose up&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;â‘¡ è®¿é—®Webç•Œé¢&lt;/h4&gt; 
&lt;p&gt;æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® &lt;a href=&quot;http://0.0.0.0:8501&quot;&gt;http://0.0.0.0:8501&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;â‘¢ è®¿é—®APIæ–‡æ¡£&lt;/h4&gt; 
&lt;p&gt;æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® &lt;a href=&quot;http://0.0.0.0:8080/docs&quot;&gt;http://0.0.0.0:8080/docs&lt;/a&gt; æˆ–è€… &lt;a href=&quot;http://0.0.0.0:8080/redoc&quot;&gt;http://0.0.0.0:8080/redoc&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;æ‰‹åŠ¨éƒ¨ç½² ğŸ“¦&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è§†é¢‘æ•™ç¨‹&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;å®Œæ•´çš„ä½¿ç”¨æ¼”ç¤ºï¼š&lt;a href=&quot;https://v.douyin.com/iFhnwsKY/&quot;&gt;https://v.douyin.com/iFhnwsKY/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;å¦‚ä½•åœ¨Windowsä¸Šéƒ¨ç½²ï¼š&lt;a href=&quot;https://v.douyin.com/iFyjoW3M&quot;&gt;https://v.douyin.com/iFyjoW3M&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;â‘  åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ&lt;/h4&gt; 
&lt;p&gt;å»ºè®®ä½¿ç”¨ &lt;a href=&quot;https://conda.io/projects/conda/en/latest/user-guide/install/index.html&quot;&gt;conda&lt;/a&gt; åˆ›å»º python è™šæ‹Ÿç¯å¢ƒ&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
cd MoneyPrinterTurbo
conda create -n MoneyPrinterTurbo python=3.11
conda activate MoneyPrinterTurbo
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;â‘¡ å®‰è£…å¥½ ImageMagick&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ä¸‹è½½ &lt;a href=&quot;https://imagemagick.org/script/download.php&quot;&gt;https://imagemagick.org/script/download.php&lt;/a&gt; é€‰æ‹©Windowsç‰ˆæœ¬ï¼Œåˆ‡è®°ä¸€å®šè¦é€‰æ‹© &lt;strong&gt;é™æ€åº“&lt;/strong&gt; ç‰ˆæœ¬ï¼Œæ¯”å¦‚ ImageMagick-7.1.1-32-Q16-x64-&lt;strong&gt;static&lt;/strong&gt;.exe&lt;/li&gt; 
   &lt;li&gt;å®‰è£…ä¸‹è½½å¥½çš„ ImageMagickï¼Œ&lt;strong&gt;æ³¨æ„ä¸è¦ä¿®æ”¹å®‰è£…è·¯å¾„&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;ä¿®æ”¹ &lt;code&gt;é…ç½®æ–‡ä»¶ config.toml&lt;/code&gt; ä¸­çš„ &lt;code&gt;imagemagick_path&lt;/code&gt; ä¸ºä½ çš„ &lt;strong&gt;å®é™…å®‰è£…è·¯å¾„&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MacOS:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;brew install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;sudo apt-get install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CentOS&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;sudo yum install ImageMagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;â‘¢ å¯åŠ¨Webç•Œé¢ ğŸŒ&lt;/h4&gt; 
&lt;p&gt;æ³¨æ„éœ€è¦åˆ° MoneyPrinterTurbo é¡¹ç›® &lt;code&gt;æ ¹ç›®å½•&lt;/code&gt; ä¸‹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤&lt;/p&gt; 
&lt;h6&gt;Windows&lt;/h6&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bat&quot;&gt;conda activate MoneyPrinterTurbo
webui.bat
&lt;/code&gt;&lt;/pre&gt; 
&lt;h6&gt;MacOS or Linux&lt;/h6&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;conda activate MoneyPrinterTurbo
sh webui.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;å¯åŠ¨åï¼Œä¼šè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼ˆå¦‚æœæ‰“å¼€æ˜¯ç©ºç™½ï¼Œå»ºè®®æ¢æˆ &lt;strong&gt;Chrome&lt;/strong&gt; æˆ–è€… &lt;strong&gt;Edge&lt;/strong&gt; æ‰“å¼€ï¼‰&lt;/p&gt; 
&lt;h4&gt;â‘£ å¯åŠ¨APIæœåŠ¡ ğŸš€&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;å¯åŠ¨åï¼Œå¯ä»¥æŸ¥çœ‹ &lt;code&gt;APIæ–‡æ¡£&lt;/code&gt; &lt;a href=&quot;http://127.0.0.1:8080/docs&quot;&gt;http://127.0.0.1:8080/docs&lt;/a&gt; æˆ–è€… &lt;a href=&quot;http://127.0.0.1:8080/redoc&quot;&gt;http://127.0.0.1:8080/redoc&lt;/a&gt; ç›´æ¥åœ¨çº¿è°ƒè¯•æ¥å£ï¼Œå¿«é€Ÿä½“éªŒã€‚&lt;/p&gt; 
&lt;h2&gt;è¯­éŸ³åˆæˆ ğŸ—£&lt;/h2&gt; 
&lt;p&gt;æ‰€æœ‰æ”¯æŒçš„å£°éŸ³åˆ—è¡¨ï¼Œå¯ä»¥æŸ¥çœ‹ï¼š&lt;a href=&quot;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/voice-list.txt&quot;&gt;å£°éŸ³åˆ—è¡¨&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2024-04-16 v1.1.2 æ–°å¢äº†9ç§Azureçš„è¯­éŸ³åˆæˆå£°éŸ³ï¼Œéœ€è¦é…ç½®API KEYï¼Œè¯¥å£°éŸ³åˆæˆçš„æ›´åŠ çœŸå®ã€‚&lt;/p&gt; 
&lt;h2&gt;å­—å¹•ç”Ÿæˆ ğŸ“œ&lt;/h2&gt; 
&lt;p&gt;å½“å‰æ”¯æŒ2ç§å­—å¹•ç”Ÿæˆæ–¹å¼ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;edge&lt;/strong&gt;: ç”Ÿæˆ&lt;code&gt;é€Ÿåº¦å¿«&lt;/code&gt;ï¼Œæ€§èƒ½æ›´å¥½ï¼Œå¯¹ç”µè„‘é…ç½®æ²¡æœ‰è¦æ±‚ï¼Œä½†æ˜¯è´¨é‡å¯èƒ½ä¸ç¨³å®š&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;whisper&lt;/strong&gt;: ç”Ÿæˆ&lt;code&gt;é€Ÿåº¦æ…¢&lt;/code&gt;ï¼Œæ€§èƒ½è¾ƒå·®ï¼Œå¯¹ç”µè„‘é…ç½®æœ‰ä¸€å®šè¦æ±‚ï¼Œä½†æ˜¯&lt;code&gt;è´¨é‡æ›´å¯é &lt;/code&gt;ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;å¯ä»¥ä¿®æ”¹ &lt;code&gt;config.toml&lt;/code&gt; é…ç½®æ–‡ä»¶ä¸­çš„ &lt;code&gt;subtitle_provider&lt;/code&gt; è¿›è¡Œåˆ‡æ¢&lt;/p&gt; 
&lt;p&gt;å»ºè®®ä½¿ç”¨ &lt;code&gt;edge&lt;/code&gt; æ¨¡å¼ï¼Œå¦‚æœç”Ÿæˆçš„å­—å¹•è´¨é‡ä¸å¥½ï¼Œå†åˆ‡æ¢åˆ° &lt;code&gt;whisper&lt;/code&gt; æ¨¡å¼&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨æ„ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;whisper æ¨¡å¼ä¸‹éœ€è¦åˆ° HuggingFace ä¸‹è½½ä¸€ä¸ªæ¨¡å‹æ–‡ä»¶ï¼Œå¤§çº¦ 3GB å·¦å³ï¼Œè¯·ç¡®ä¿ç½‘ç»œé€šç•…&lt;/li&gt; 
 &lt;li&gt;å¦‚æœç•™ç©ºï¼Œè¡¨ç¤ºä¸ç”Ÿæˆå­—å¹•ã€‚&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ç”±äºå›½å†…æ— æ³•è®¿é—® HuggingFaceï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ä¸‹è½½ &lt;code&gt;whisper-large-v3&lt;/code&gt; çš„æ¨¡å‹æ–‡ä»¶&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ä¸‹è½½åœ°å€ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ç™¾åº¦ç½‘ç›˜: &lt;a href=&quot;https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9&quot;&gt;https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;å¤¸å…‹ç½‘ç›˜ï¼š&lt;a href=&quot;https://pan.quark.cn/s/3ee3d991d64b&quot;&gt;https://pan.quark.cn/s/3ee3d991d64b&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;æ¨¡å‹ä¸‹è½½åè§£å‹ï¼Œæ•´ä¸ªç›®å½•æ”¾åˆ° &lt;code&gt;.\MoneyPrinterTurbo\models&lt;/code&gt; é‡Œé¢ï¼Œ æœ€ç»ˆçš„æ–‡ä»¶è·¯å¾„åº”è¯¥æ˜¯è¿™æ ·: &lt;code&gt;.\MoneyPrinterTurbo\models\whisper-large-v3&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MoneyPrinterTurbo  
  â”œâ”€models
  â”‚   â””â”€whisper-large-v3
  â”‚          config.json
  â”‚          model.bin
  â”‚          preprocessor_config.json
  â”‚          tokenizer.json
  â”‚          vocabulary.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;èƒŒæ™¯éŸ³ä¹ ğŸµ&lt;/h2&gt; 
&lt;p&gt;ç”¨äºè§†é¢‘çš„èƒŒæ™¯éŸ³ä¹ï¼Œä½äºé¡¹ç›®çš„ &lt;code&gt;resource/songs&lt;/code&gt; ç›®å½•ä¸‹ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å½“å‰é¡¹ç›®é‡Œé¢æ”¾äº†ä¸€äº›é»˜è®¤çš„éŸ³ä¹ï¼Œæ¥è‡ªäº YouTube è§†é¢‘ï¼Œå¦‚æœ‰ä¾µæƒï¼Œè¯·åˆ é™¤ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;å­—å¹•å­—ä½“ ğŸ…°&lt;/h2&gt; 
&lt;p&gt;ç”¨äºè§†é¢‘å­—å¹•çš„æ¸²æŸ“ï¼Œä½äºé¡¹ç›®çš„ &lt;code&gt;resource/fonts&lt;/code&gt; ç›®å½•ä¸‹ï¼Œä½ ä¹Ÿå¯ä»¥æ”¾è¿›å»è‡ªå·±çš„å­—ä½“ã€‚&lt;/p&gt; 
&lt;h2&gt;å¸¸è§é—®é¢˜ ğŸ¤”&lt;/h2&gt; 
&lt;h3&gt;â“å¦‚ä½•ä½¿ç”¨å…è´¹çš„OpenAI GPT-3.5æ¨¡å‹?&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://openai.com/blog/start-using-chatgpt-instantly&quot;&gt;OpenAIå®£å¸ƒChatGPTé‡Œé¢3.5å·²ç»å…è´¹äº†&lt;/a&gt;ï¼Œæœ‰å¼€å‘è€…å°†å…¶å°è£…æˆäº†APIï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ç¡®ä¿ä½ å®‰è£…å’Œå¯åŠ¨äº†dockeræœåŠ¡&lt;/strong&gt;ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨dockeræœåŠ¡&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;docker run -p 3040:3040 missuo/freegpt35
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;å¯åŠ¨æˆåŠŸåï¼Œä¿®æ”¹ &lt;code&gt;config.toml&lt;/code&gt; ä¸­çš„é…ç½®&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;llm_provider&lt;/code&gt; è®¾ç½®ä¸º &lt;code&gt;openai&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;openai_api_key&lt;/code&gt; éšä¾¿å¡«å†™ä¸€ä¸ªå³å¯ï¼Œæ¯”å¦‚ &#39;123456&#39;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;openai_base_url&lt;/code&gt; æ”¹ä¸º &lt;code&gt;http://localhost:3040/v1/&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;openai_model_name&lt;/code&gt; æ”¹ä¸º &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨æ„ï¼šè¯¥æ–¹å¼ç¨³å®šæ€§è¾ƒå·®&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;â“AttributeError: &#39;str&#39; object has no attribute &#39;choices&#39;`&lt;/h3&gt; 
&lt;p&gt;è¿™ä¸ªé—®é¢˜æ˜¯ç”±äºå¤§æ¨¡å‹æ²¡æœ‰è¿”å›æ­£ç¡®çš„å›å¤å¯¼è‡´çš„ã€‚&lt;/p&gt; 
&lt;p&gt;å¤§æ¦‚ç‡æ˜¯ç½‘ç»œåŸå› ï¼Œ ä½¿ç”¨ &lt;strong&gt;VPN&lt;/strong&gt;ï¼Œæˆ–è€…è®¾ç½® &lt;code&gt;openai_base_url&lt;/code&gt; ä¸ºä½ çš„ä»£ç† ï¼Œåº”è¯¥å°±å¯ä»¥è§£å†³äº†ã€‚&lt;/p&gt; 
&lt;p&gt;åŒæ—¶å»ºè®®ä½¿ç”¨ &lt;strong&gt;Moonshot&lt;/strong&gt; æˆ– &lt;strong&gt;DeepSeek&lt;/strong&gt; ä½œä¸ºå¤§æ¨¡å‹æä¾›å•†ï¼Œè¿™ä¸¤ä¸ªæœåŠ¡å•†åœ¨å›½å†…è®¿é—®é€Ÿåº¦æ›´å¿«ï¼Œæ›´åŠ ç¨³å®šã€‚&lt;/p&gt; 
&lt;h3&gt;â“RuntimeError: No ffmpeg exe could be found&lt;/h3&gt; 
&lt;p&gt;é€šå¸¸æƒ…å†µä¸‹ï¼Œffmpeg ä¼šè¢«è‡ªåŠ¨ä¸‹è½½ï¼Œå¹¶ä¸”ä¼šè¢«è‡ªåŠ¨æ£€æµ‹åˆ°ã€‚ ä½†æ˜¯å¦‚æœä½ çš„ç¯å¢ƒæœ‰é—®é¢˜ï¼Œæ— æ³•è‡ªåŠ¨ä¸‹è½½ï¼Œå¯èƒ½ä¼šé‡åˆ°å¦‚ä¸‹é”™è¯¯ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;RuntimeError: No ffmpeg exe could be found.
Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æ­¤æ—¶ä½ å¯ä»¥ä» &lt;a href=&quot;https://www.gyan.dev/ffmpeg/builds/&quot;&gt;https://www.gyan.dev/ffmpeg/builds/&lt;/a&gt; ä¸‹è½½ffmpegï¼Œè§£å‹åï¼Œè®¾ç½® &lt;code&gt;ffmpeg_path&lt;/code&gt; ä¸ºä½ çš„å®é™…å®‰è£…è·¯å¾„å³å¯ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;[app]
# è¯·æ ¹æ®ä½ çš„å®é™…è·¯å¾„è®¾ç½®ï¼Œæ³¨æ„ Windows è·¯å¾„åˆ†éš”ç¬¦ä¸º \\
ffmpeg_path = &quot;C:\\Users\\harry\\Downloads\\ffmpeg.exe&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;â“ImageMagickçš„å®‰å…¨ç­–ç•¥é˜»æ­¢äº†ä¸ä¸´æ—¶æ–‡ä»¶@/tmp/tmpur5hyyto.txtç›¸å…³çš„æ“ä½œ&lt;/h3&gt; 
&lt;p&gt;å¯ä»¥åœ¨ImageMagickçš„é…ç½®æ–‡ä»¶policy.xmlä¸­æ‰¾åˆ°è¿™äº›ç­–ç•¥ã€‚ è¿™ä¸ªæ–‡ä»¶é€šå¸¸ä½äº /etc/ImageMagick-&lt;code&gt;X&lt;/code&gt;/ æˆ– ImageMagick å®‰è£…ç›®å½•çš„ç±»ä¼¼ä½ç½®ã€‚ ä¿®æ”¹åŒ…å«&lt;code&gt;pattern=&quot;@&quot;&lt;/code&gt;çš„æ¡ç›®ï¼Œå°†&lt;code&gt;rights=&quot;none&quot;&lt;/code&gt;æ›´æ”¹ä¸º&lt;code&gt;rights=&quot;read|write&quot;&lt;/code&gt;ä»¥å…è®¸å¯¹æ–‡ä»¶çš„è¯»å†™æ“ä½œã€‚&lt;/p&gt; 
&lt;h3&gt;â“OSError: [Errno 24] Too many open files&lt;/h3&gt; 
&lt;p&gt;è¿™ä¸ªé—®é¢˜æ˜¯ç”±äºç³»ç»Ÿæ‰“å¼€æ–‡ä»¶æ•°é™åˆ¶å¯¼è‡´çš„ï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ç³»ç»Ÿçš„æ–‡ä»¶æ‰“å¼€æ•°é™åˆ¶æ¥è§£å†³ã€‚&lt;/p&gt; 
&lt;p&gt;æŸ¥çœ‹å½“å‰é™åˆ¶&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;ulimit -n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;å¦‚æœè¿‡ä½ï¼Œå¯ä»¥è°ƒé«˜ä¸€äº›ï¼Œæ¯”å¦‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;ulimit -n 10240
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;â“Whisper æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œå‡ºç°å¦‚ä¸‹é”™è¯¯&lt;/h3&gt; 
&lt;p&gt;LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and outgoing trafic has been disabled. To enablerepo look-ups and downloads online, pass &#39;local files only=False&#39; as input.&lt;/p&gt; 
&lt;p&gt;æˆ–è€…&lt;/p&gt; 
&lt;p&gt;An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Trying to load the model directly from the local cache, if it exists.&lt;/p&gt; 
&lt;p&gt;è§£å†³æ–¹æ³•ï¼š&lt;a href=&quot;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-&quot;&gt;ç‚¹å‡»æŸ¥çœ‹å¦‚ä½•ä»ç½‘ç›˜æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;åé¦ˆå»ºè®® ğŸ“¢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;å¯ä»¥æäº¤ &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/issues&quot;&gt;issue&lt;/a&gt; æˆ–è€… &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/pulls&quot;&gt;pull request&lt;/a&gt;ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;å‚è€ƒé¡¹ç›® ğŸ“š&lt;/h2&gt; 
&lt;p&gt;è¯¥é¡¹ç›®åŸºäº &lt;a href=&quot;https://github.com/FujiwaraChoki/MoneyPrinter&quot;&gt;https://github.com/FujiwaraChoki/MoneyPrinter&lt;/a&gt; é‡æ„è€Œæ¥ï¼Œåšäº†å¤§é‡çš„ä¼˜åŒ–ï¼Œå¢åŠ äº†æ›´å¤šçš„åŠŸèƒ½ã€‚ æ„Ÿè°¢åŸä½œè€…çš„å¼€æºç²¾ç¥ã€‚&lt;/p&gt; 
&lt;h2&gt;è®¸å¯è¯ ğŸ“&lt;/h2&gt; 
&lt;p&gt;ç‚¹å‡»æŸ¥çœ‹ &lt;a href=&quot;https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/LICENSE&quot;&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; æ–‡ä»¶&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;amp;Date&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;amp;type=Date&quot; alt=&quot;Star History Chart&quot;&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/OmniParser</title>
      <link>https://github.com/microsoft/OmniParser</link>
      <description>&lt;p&gt;A simple screen parsing tool towards pure vision based GUI agent&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/microsoft/OmniParser/master/imgs/logo.png&quot; alt=&quot;Logo&quot;&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2408.00203&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Paper-green&quot; alt=&quot;arXiv&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ğŸ“¢ [&lt;a href=&quot;https://microsoft.github.io/OmniParser/&quot;&gt;Project Page&lt;/a&gt;] [&lt;a href=&quot;https://www.microsoft.com/en-us/research/articles/omniparser-v2-turning-any-llm-into-a-computer-use-agent/&quot;&gt;V2 Blog Post&lt;/a&gt;] [&lt;a href=&quot;https://huggingface.co/microsoft/OmniParser-v2.0&quot;&gt;Models V2&lt;/a&gt;] [&lt;a href=&quot;https://huggingface.co/microsoft/OmniParser&quot;&gt;Models V1.5&lt;/a&gt;] [&lt;a href=&quot;https://huggingface.co/spaces/microsoft/OmniParser-v2&quot;&gt;HuggingFace Space Demo&lt;/a&gt;]&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OmniParser&lt;/strong&gt; is a comprehensive method for parsing user interface screenshots into structured and easy-to-understand elements, which significantly enhances the ability of GPT-4V to generate actions that can be accurately grounded in the corresponding regions of the interface.&lt;/p&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/3] We are gradually adding multi agents orchstration and improving user interface in OmniTool for better experience.&lt;/li&gt; 
 &lt;li&gt;[2025/2] We release OmniParser V2 &lt;a href=&quot;https://huggingface.co/microsoft/OmniParser-v2.0&quot;&gt;checkpoints&lt;/a&gt;. &lt;a href=&quot;https://1drv.ms/v/c/650b027c18d5a573/EWXbVESKWo9Buu6OYCwg06wBeoM97C6EOTG6RjvWLEN1Qg?e=alnHGC&quot;&gt;Watch Video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/2] We introduce OmniTool: Control a Windows 11 VM with OmniParser + your vision model of choice. OmniTool supports out of the box the following large language models - OpenAI (4o/o1/o3-mini), DeepSeek (R1), Qwen (2.5VL) or Anthropic Computer Use. &lt;a href=&quot;https://1drv.ms/v/c/650b027c18d5a573/EehZ7RzY69ZHn-MeQHrnnR4BCj3by-cLLpUVlxMjF4O65Q?e=8LxMgX&quot;&gt;Watch Video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/1] V2 is coming. We achieve new state of the art results 39.5% on the new grounding benchmark &lt;a href=&quot;https://github.com/likaixin2000/ScreenSpot-Pro-GUI-Grounding/tree/main&quot;&gt;Screen Spot Pro&lt;/a&gt; with OmniParser v2 (will be released soon)! Read more details &lt;a href=&quot;https://github.com/microsoft/OmniParser/tree/master/docs/Evaluation.md&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2024/11] We release an updated version, OmniParser V1.5 which features 1) more fine grained/small icon detection, 2) prediction of whether each screen element is interactable or not. Examples in the demo.ipynb.&lt;/li&gt; 
 &lt;li&gt;[2024/10] OmniParser was the #1 trending model on huggingface model hub (starting 10/29/2024).&lt;/li&gt; 
 &lt;li&gt;[2024/10] Feel free to checkout our demo on &lt;a href=&quot;https://huggingface.co/spaces/microsoft/OmniParser&quot;&gt;huggingface space&lt;/a&gt;! (stay tuned for OmniParser + Claude Computer Use)&lt;/li&gt; 
 &lt;li&gt;[2024/10] Both Interactive Region Detection Model and Icon functional description model are released! &lt;a href=&quot;https://huggingface.co/microsoft/OmniParser&quot;&gt;Hugginface models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2024/09] OmniParser achieves the best performance on &lt;a href=&quot;https://microsoft.github.io/WindowsAgentArena/&quot;&gt;Windows Agent Arena&lt;/a&gt;!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;First clone the repo, and then install environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;cd OmniParser
conda create -n &quot;omni&quot; python==3.12
conda activate omni
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure you have the V2 weights downloaded in weights folder (ensure caption weights folder is called icon_caption_florence). If not download them with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;   # download the model checkpoints to local directory OmniParser/weights/
   for f in icon_detect/{train_args.yaml,model.pt,model.yaml} icon_caption/{config.json,generation_config.json,model.safetensors}; do huggingface-cli download microsoft/OmniParser-v2.0 &quot;$f&quot; --local-dir weights; done
   mv weights/icon_caption weights/icon_caption_florence
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- ## [deprecated]
Then download the model ckpts files in: https://huggingface.co/microsoft/OmniParser, and put them under weights/, default folder structure is: weights/icon_detect, weights/icon_caption_florence, weights/icon_caption_blip2. 

For v1: 
convert the safetensor to .pt file. 
```python
python weights/convert_safetensor_to_pt.py

For v1.5: 
download &#39;model_v1_5.pt&#39; from https://huggingface.co/microsoft/OmniParser/tree/main/icon_detect_v1_5, make a new dir: weights/icon_detect_v1_5, and put it inside the folder. No weight conversion is needed. 
``` --&gt; 
&lt;h2&gt;Examples:&lt;/h2&gt; 
&lt;p&gt;We put together a few simple examples in the demo.ipynb.&lt;/p&gt; 
&lt;h2&gt;Gradio Demo&lt;/h2&gt; 
&lt;p&gt;To run gradio demo, simply run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;python gradio_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Weights License&lt;/h2&gt; 
&lt;p&gt;For the model checkpoints on huggingface model hub, please note that icon_detect model is under AGPL license since it is a license inherited from the original yolo model. And icon_caption_blip2 &amp;amp; icon_caption_florence is under MIT license. Please refer to the LICENSE file in the folder of each model: &lt;a href=&quot;https://huggingface.co/microsoft/OmniParser&quot;&gt;https://huggingface.co/microsoft/OmniParser&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ“š Citation&lt;/h2&gt; 
&lt;p&gt;Our technical report can be found &lt;a href=&quot;https://arxiv.org/abs/2408.00203&quot;&gt;here&lt;/a&gt;. If you find our work useful, please consider citing our work:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{lu2024omniparserpurevisionbased,
      title={OmniParser for Pure Vision Based GUI Agent}, 
      author={Yadong Lu and Jianwei Yang and Yelong Shen and Ahmed Awadallah},
      year={2024},
      eprint={2408.00203},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.00203}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>sinaptik-ai/pandas-ai</title>
      <link>https://github.com/sinaptik-ai/pandas-ai</link>
      <description>&lt;p&gt;Chat with your database or your datalake (SQL, CSV, parquet). PandasAI makes data analysis conversational using LLMs and RAG.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src=&quot;https://raw.githubusercontent.com/sinaptik-ai/pandas-ai/main/assets/logo.png&quot; alt=&quot;PandaAI&quot;&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://pypi.org/project/pandasai/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/pandasai?label=Release&amp;amp;style=flat-square&quot; alt=&quot;Release&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/sinaptik-ai/pandas-ai/actions/workflows/ci-core.yml/badge.svg&quot;&gt;&lt;img src=&quot;https://github.com/sinaptik-ai/pandas-ai/actions/workflows/ci-core.yml/badge.svg?sanitize=true&quot; alt=&quot;CI&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/sinaptik-ai/pandas-ai/actions/workflows/cd.yml/badge.svg&quot;&gt;&lt;img src=&quot;https://github.com/sinaptik-ai/pandas-ai/actions/workflows/cd.yml/badge.svg?sanitize=true&quot; alt=&quot;CD&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/sinaptik-ai/pandas-ai&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/sinaptik-ai/pandas-ai/branch/main/graph/badge.svg?sanitize=true&quot; alt=&quot;Coverage&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/KYKj9F2FRH&quot;&gt;&lt;img src=&quot;https://dcbadge.vercel.app/api/server/kF7FqH2FwS?style=flat&amp;amp;compact=true&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pepy.tech/project/pandasai&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/pandasai&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&quot; alt=&quot;License: MIT&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/drive/1ZnO-njhL7TBOYPZaqvMvGtsjckZKrv2E?usp=sharing&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;Open in Colab&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;PandaAI is a Python platform that makes it easy to ask questions to your data in natural language. It helps non-technical users to interact with their data in a more natural way, and it helps technical users to save time, and effort when working with data.&lt;/p&gt; 
&lt;h1&gt;ğŸ”§ Getting started&lt;/h1&gt; 
&lt;p&gt;You can find the full documentation for PandaAI &lt;a href=&quot;https://pandas-ai.readthedocs.io/en/latest/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can either decide to use PandaAI in your Jupyter notebooks, Streamlit apps, or use the client and server architecture from the repo.&lt;/p&gt; 
&lt;h2&gt;â˜ï¸ Using the platform&lt;/h2&gt; 
&lt;p&gt;The library can be used alongside our powerful data platform, making end-to-end conversational data analytics possible with as little as a few lines of code.&lt;/p&gt; 
&lt;p&gt;Load your data, save them as a dataframe, and push them to the platform&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import pandasai as pai

pai.api_key.set(&quot;your-pai-api-key&quot;)

file = pai.read_csv(&quot;./filepath.csv&quot;)

dataset = pai.create(path=&quot;your-organization/dataset-name&quot;,
    df=file,
    name=&quot;dataset-name&quot;,
    description=&quot;dataset-description&quot;)

dataset.push()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Your team can now access and query this data using natural language through the platform.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/sinaptik-ai/pandas-ai/main/assets/demo.gif&quot; alt=&quot;PandaAI&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“š Using the library&lt;/h2&gt; 
&lt;h3&gt;Python Requirements&lt;/h3&gt; 
&lt;p&gt;Python version &lt;code&gt;3.8+ &amp;lt;3.12&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;ğŸ“¦ Installation&lt;/h3&gt; 
&lt;p&gt;You can install the PandaAI library using pip or poetry.&lt;/p&gt; 
&lt;p&gt;With pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install &quot;pandasai&amp;gt;=3.0.0b2&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With poetry:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;poetry add &quot;pandasai&amp;gt;=3.0.0b2&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ’» Usage&lt;/h3&gt; 
&lt;h4&gt;Ask questions&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import pandasai as pai

# Sample DataFrame
df = pai.DataFrame({
    &quot;country&quot;: [&quot;United States&quot;, &quot;United Kingdom&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Italy&quot;, &quot;Spain&quot;, &quot;Canada&quot;, &quot;Australia&quot;, &quot;Japan&quot;, &quot;China&quot;],
    &quot;revenue&quot;: [5000, 3200, 2900, 4100, 2300, 2100, 2500, 2600, 4500, 7000]
})

# By default, unless you choose a different LLM, it will use BambooLLM.
# You can get your free API key signing up at https://app.pandabi.ai (you can also configure it in your .env file)
pai.api_key.set(&quot;your-pai-api-key&quot;)

df.chat(&#39;Which are the top 5 countries by sales?&#39;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;China, United States, Japan, Germany, Australia
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;p&gt;Or you can ask more complex questions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;df.chat(
    &quot;What is the total sales for the top 3 countries by sales?&quot;
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;The total sales for the top 3 countries by sales is 16500.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Visualize charts&lt;/h4&gt; 
&lt;p&gt;You can also ask PandaAI to generate charts for you:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;df.chat(
    &quot;Plot the histogram of countries showing for each one the gd. Use different colors for each bar&quot;,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/sinaptik-ai/pandas-ai/main/assets/histogram-chart.png?raw=true&quot; alt=&quot;Chart&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;Multiple DataFrames&lt;/h4&gt; 
&lt;p&gt;You can also pass in multiple dataframes to PandaAI and ask questions relating them.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import pandasai as pai

employees_data = {
    &#39;EmployeeID&#39;: [1, 2, 3, 4, 5],
    &#39;Name&#39;: [&#39;John&#39;, &#39;Emma&#39;, &#39;Liam&#39;, &#39;Olivia&#39;, &#39;William&#39;],
    &#39;Department&#39;: [&#39;HR&#39;, &#39;Sales&#39;, &#39;IT&#39;, &#39;Marketing&#39;, &#39;Finance&#39;]
}

salaries_data = {
    &#39;EmployeeID&#39;: [1, 2, 3, 4, 5],
    &#39;Salary&#39;: [5000, 6000, 4500, 7000, 5500]
}

employees_df = pai.DataFrame(employees_data)
salaries_df = pai.DataFrame(salaries_data)

# By default, unless you choose a different LLM, it will use BambooLLM.
# You can get your free API key signing up at https://app.pandabi.ai (you can also configure it in your .env file)
pai.api_key.set(&quot;your-pai-api-key&quot;)

pai.chat(&quot;Who gets paid the most?&quot;, employees_df, salaries_df)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;Olivia gets paid the most.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Docker Sandbox&lt;/h4&gt; 
&lt;p&gt;You can run PandaAI in a Docker sandbox, providing a secure, isolated environment to execute code safely and mitigate the risk of malicious attacks.&lt;/p&gt; 
&lt;h5&gt;Python Requirements&lt;/h5&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install &quot;pandasai-docker&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Usage&lt;/h5&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import pandasai as pai
from pandasai_docker import DockerSandbox

# Initialize the sandbox
sandbox = DockerSandbox()
sandbox.start()

employees_data = {
    &#39;EmployeeID&#39;: [1, 2, 3, 4, 5],
    &#39;Name&#39;: [&#39;John&#39;, &#39;Emma&#39;, &#39;Liam&#39;, &#39;Olivia&#39;, &#39;William&#39;],
    &#39;Department&#39;: [&#39;HR&#39;, &#39;Sales&#39;, &#39;IT&#39;, &#39;Marketing&#39;, &#39;Finance&#39;]
}

salaries_data = {
    &#39;EmployeeID&#39;: [1, 2, 3, 4, 5],
    &#39;Salary&#39;: [5000, 6000, 4500, 7000, 5500]
}

employees_df = pai.DataFrame(employees_data)
salaries_df = pai.DataFrame(salaries_data)

# By default, unless you choose a different LLM, it will use BambooLLM.
# You can get your free API key signing up at https://app.pandabi.ai (you can also configure it in your .env file)
pai.api_key.set(&quot;your-pai-api-key&quot;)

pai.chat(&quot;Who gets paid the most?&quot;, employees_df, salaries_df, sandbox=sandbox)

# Don&#39;t forget to stop the sandbox when done
sandbox.stop()
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;Olivia gets paid the most.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find more examples in the &lt;a href=&quot;https://raw.githubusercontent.com/sinaptik-ai/pandas-ai/main/examples&quot;&gt;examples&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h2&gt;ğŸ“œ License&lt;/h2&gt; 
&lt;p&gt;PandaAI is available under the MIT expat license, except for the &lt;code&gt;pandasai/ee&lt;/code&gt; directory of this repository, which has its &lt;a href=&quot;https://github.com/sinaptik-ai/pandas-ai/raw/main/ee/LICENSE&quot;&gt;license here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are interested in managed PandaAI Cloud or self-hosted Enterprise Offering, &lt;a href=&quot;https://getpanda.ai/pricing&quot;&gt;contact us&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Beta Notice&lt;/strong&gt;&lt;br&gt; Release v3 is currently in beta. The following documentation and examples reflect the features and functionality in progress and may change before the final release.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pandas-ai.readthedocs.io/en/latest/&quot;&gt;Docs&lt;/a&gt; for comprehensive documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/sinaptik-ai/pandas-ai/main/examples&quot;&gt;Examples&lt;/a&gt; for example notebooks&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://discord.gg/KYKj9F2FRH&quot;&gt;Discord&lt;/a&gt; for discussion with the community and PandaAI team&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please check the outstanding issues and feel free to open a pull request. For more information, please check out the &lt;a href=&quot;https://raw.githubusercontent.com/sinaptik-ai/pandas-ai/main/CONTRIBUTING.md&quot;&gt;contributing guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Thank you!&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/sinaptik-ai/pandas-ai/graphs/contributors&quot;&gt;&lt;img src=&quot;https://contrib.rocks/image?repo=sinaptik-ai/pandas-ai&quot; alt=&quot;Contributors&quot;&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>LadybirdBrowser/ladybird</title>
      <link>https://github.com/LadybirdBrowser/ladybird</link>
      <description>&lt;p&gt;Truly independent web browser&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ladybird&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://ladybird.org&quot;&gt;Ladybird&lt;/a&gt; is a truly independent web browser, using a novel engine based on web standards.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Ladybird is in a pre-alpha state, and only suitable for use by developers&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;We aim to build a complete, usable browser for the modern web.&lt;/p&gt; 
&lt;p&gt;Ladybird uses a multi-process architecture with a main UI process, several WebContent renderer processes, an ImageDecoder process, and a RequestServer process.&lt;/p&gt; 
&lt;p&gt;Image decoding and network connections are done out of process to be more robust against malicious content. Each tab has its own renderer process, which is sandboxed from the rest of the system.&lt;/p&gt; 
&lt;p&gt;At the moment, many core library support components are inherited from SerenityOS:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LibWeb: Web rendering engine&lt;/li&gt; 
 &lt;li&gt;LibJS: JavaScript engine&lt;/li&gt; 
 &lt;li&gt;LibWasm: WebAssembly implementation&lt;/li&gt; 
 &lt;li&gt;LibCrypto/LibTLS: Cryptography primitives and Transport Layer Security&lt;/li&gt; 
 &lt;li&gt;LibHTTP: HTTP/1.1 client&lt;/li&gt; 
 &lt;li&gt;LibGfx: 2D Graphics Library, Image Decoding and Rendering&lt;/li&gt; 
 &lt;li&gt;LibUnicode: Unicode and locale support&lt;/li&gt; 
 &lt;li&gt;LibMedia: Audio and video playback&lt;/li&gt; 
 &lt;li&gt;LibCore: Event loop, OS abstraction layer&lt;/li&gt; 
 &lt;li&gt;LibIPC: Inter-process communication&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How do I build and run this?&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/BuildInstructionsLadybird.md&quot;&gt;build instructions&lt;/a&gt; for information on how to build Ladybird.&lt;/p&gt; 
&lt;p&gt;Ladybird runs on Linux, macOS, Windows (with WSL2), and many other *Nixes.&lt;/p&gt; 
&lt;h2&gt;How do I read the documentation?&lt;/h2&gt; 
&lt;p&gt;Code-related documentation can be found in the &lt;a href=&quot;https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/&quot;&gt;documentation&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h2&gt;Get in touch and participate!&lt;/h2&gt; 
&lt;p&gt;Join &lt;a href=&quot;https://discord.gg/nvfjVJ4Svh&quot;&gt;our Discord server&lt;/a&gt; to participate in development discussion.&lt;/p&gt; 
&lt;p&gt;Please read &lt;a href=&quot;https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/GettingStartedContributing.md&quot;&gt;Getting started contributing&lt;/a&gt; if you plan to contribute to Ladybird for the first time.&lt;/p&gt; 
&lt;p&gt;Before opening an issue, please see the &lt;a href=&quot;https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/CONTRIBUTING.md#issue-policy&quot;&gt;issue policy&lt;/a&gt; and the &lt;a href=&quot;https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/ISSUES.md&quot;&gt;detailed issue-reporting guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The full contribution guidelines can be found in &lt;a href=&quot;https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/CONTRIBUTING.md&quot;&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Ladybird is licensed under a 2-clause BSD license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>huggingface/lerobot</title>
      <link>https://github.com/huggingface/lerobot</link>
      <description>&lt;p&gt;ğŸ¤— LeRobot: Making AI for Robotics more accessible with end-to-end learning&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;media/lerobot-logo-thumbnail.png&quot;&gt; 
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;media/lerobot-logo-thumbnail.png&quot;&gt; 
  &lt;img alt=&quot;LeRobot, Hugging Face Robotics Library&quot; src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/lerobot-logo-thumbnail.png&quot; style=&quot;max-width: 100%;&quot;&gt; 
 &lt;/picture&gt; &lt;br&gt; &lt;br&gt; &lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/huggingface/lerobot/actions/workflows/nightly-tests.yml?query=branch%3Amain&quot;&gt;&lt;img src=&quot;https://github.com/huggingface/lerobot/actions/workflows/nightly-tests.yml/badge.svg?branch=main&quot; alt=&quot;Tests&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/huggingface/lerobot&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/huggingface/lerobot/branch/main/graph/badge.svg?token=TODO&quot; alt=&quot;Coverage&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.python.org/downloads/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/lerobot&quot; alt=&quot;Python versions&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&quot; alt=&quot;License&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/lerobot/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/status/lerobot&quot; alt=&quot;Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/lerobot/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/lerobot&quot; alt=&quot;Version&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/huggingface/lerobot/tree/main/examples&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Examples-green.svg?sanitize=true&quot; alt=&quot;Examples&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/CODE_OF_CONDUCT.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Contributor%20Covenant-v2.1%20adopted-ff69b4.svg?sanitize=true&quot; alt=&quot;Contributor Covenant&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/s3KuuzsPFb&quot;&gt;&lt;img src=&quot;https://dcbadge.vercel.app/api/server/C5P34WJ68S?style=flat&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2 align=&quot;center&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/examples/10_use_so100.md&quot;&gt; Build Your Own SO-100 Robot!&lt;/a&gt;&lt;/p&gt; &lt;/h2&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/so100/leader_follower.webp?raw=true&quot; alt=&quot;SO-100 leader and follower arms&quot; title=&quot;SO-100 leader and follower arms&quot; width=&quot;50%&quot;&gt; 
 &lt;p&gt;&lt;strong&gt;Meet the SO-100 â€“ Just $110 per arm!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Train it in minutes with a few simple moves on your laptop.&lt;/p&gt; 
 &lt;p&gt;Then sit back and watch your creation act autonomously! ğŸ¤¯&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/examples/10_use_so100.md&quot;&gt; Get the full SO-100 tutorial here.&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Want to take it to the next level? Make your SO-100 mobile by building LeKiwi!&lt;/p&gt; 
 &lt;p&gt;Check out the &lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/examples/11_use_lekiwi.md&quot;&gt;LeKiwi tutorial&lt;/a&gt; and bring your robot to life on wheels.&lt;/p&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/lekiwi/kiwi.webp?raw=true&quot; alt=&quot;LeKiwi mobile robot&quot; title=&quot;LeKiwi mobile robot&quot; width=&quot;50%&quot;&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;h3 align=&quot;center&quot;&gt; &lt;p&gt;LeRobot: State-of-the-art AI for real-world robotics&lt;/p&gt; &lt;/h3&gt; 
&lt;hr&gt; 
&lt;p&gt;ğŸ¤— LeRobot aims to provide models, datasets, and tools for real-world robotics in PyTorch. The goal is to lower the barrier to entry to robotics so that everyone can contribute and benefit from sharing datasets and pretrained models.&lt;/p&gt; 
&lt;p&gt;ğŸ¤— LeRobot contains state-of-the-art approaches that have been shown to transfer to the real-world with a focus on imitation learning and reinforcement learning.&lt;/p&gt; 
&lt;p&gt;ğŸ¤— LeRobot already provides a set of pretrained models, datasets with human collected demonstrations, and simulation environments to get started without assembling a robot. In the coming weeks, the plan is to add more and more support for real-world robotics on the most affordable and capable robots out there.&lt;/p&gt; 
&lt;p&gt;ğŸ¤— LeRobot hosts pretrained models and datasets on this Hugging Face community page: &lt;a href=&quot;https://huggingface.co/lerobot&quot;&gt;huggingface.co/lerobot&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Examples of pretrained models on simulation environments&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/aloha_act.gif&quot; width=&quot;100%&quot; alt=&quot;ACT policy on ALOHA env&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/simxarm_tdmpc.gif&quot; width=&quot;100%&quot; alt=&quot;TDMPC policy on SimXArm env&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/pusht_diffusion.gif&quot; width=&quot;100%&quot; alt=&quot;Diffusion policy on PushT env&quot;&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;ACT policy on ALOHA env&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;TDMPC policy on SimXArm env&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Diffusion policy on PushT env&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Acknowledgment&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks to Tony Zhao, Zipeng Fu and colleagues for open sourcing ACT policy, ALOHA environments and datasets. Ours are adapted from &lt;a href=&quot;https://tonyzhaozh.github.io/aloha&quot;&gt;ALOHA&lt;/a&gt; and &lt;a href=&quot;https://mobile-aloha.github.io&quot;&gt;Mobile ALOHA&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to Cheng Chi, Zhenjia Xu and colleagues for open sourcing Diffusion policy, Pusht environment and datasets, as well as UMI datasets. Ours are adapted from &lt;a href=&quot;https://diffusion-policy.cs.columbia.edu&quot;&gt;Diffusion Policy&lt;/a&gt; and &lt;a href=&quot;https://umi-gripper.github.io&quot;&gt;UMI Gripper&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to Nicklas Hansen, Yunhai Feng and colleagues for open sourcing TDMPC policy, Simxarm environments and datasets. Ours are adapted from &lt;a href=&quot;https://github.com/nicklashansen/tdmpc&quot;&gt;TDMPC&lt;/a&gt; and &lt;a href=&quot;https://www.yunhaifeng.com/FOWM&quot;&gt;FOWM&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to Antonio Loquercio and Ashish Kumar for their early support.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href=&quot;https://sjlee.cc/&quot;&gt;Seungjae (Jay) Lee&lt;/a&gt;, &lt;a href=&quot;https://mahis.life/&quot;&gt;Mahi Shafiullah&lt;/a&gt; and colleagues for open sourcing &lt;a href=&quot;https://sjlee.cc/vq-bet/&quot;&gt;VQ-BeT&lt;/a&gt; policy and helping us adapt the codebase to our repository. The policy is adapted from &lt;a href=&quot;https://github.com/jayLEE0301/vq_bet_official&quot;&gt;VQ-BeT repo&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Download our source code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/huggingface/lerobot.git
cd lerobot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment with Python 3.10 and activate it, e.g. with &lt;a href=&quot;https://docs.anaconda.com/free/miniconda/index.html&quot;&gt;&lt;code&gt;miniconda&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;conda create -y -n lerobot python=3.10
conda activate lerobot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install ğŸ¤— LeRobot:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Depending on your platform, If you encounter any build errors during this step you may need to install &lt;code&gt;cmake&lt;/code&gt; and &lt;code&gt;build-essential&lt;/code&gt; for building some of our dependencies. On linux: &lt;code&gt;sudo apt-get install cmake build-essential&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For simulations, ğŸ¤— LeRobot comes with gymnasium environments that can be installed as extras:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/huggingface/gym-aloha&quot;&gt;aloha&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/huggingface/gym-xarm&quot;&gt;xarm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/huggingface/gym-pusht&quot;&gt;pusht&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For instance, to install ğŸ¤— LeRobot with aloha and pusht, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -e &quot;.[aloha, pusht]&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use &lt;a href=&quot;https://docs.wandb.ai/quickstart&quot;&gt;Weights and Biases&lt;/a&gt; for experiment tracking, log in with&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;wandb login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(note: you will also need to enable WandB in the configuration. See below.)&lt;/p&gt; 
&lt;h2&gt;Walkthrough&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;.
â”œâ”€â”€ examples             # contains demonstration examples, start here to learn about LeRobot
|   â””â”€â”€ advanced         # contains even more examples for those who have mastered the basics
â”œâ”€â”€ lerobot
|   â”œâ”€â”€ configs          # contains config classes with all options that you can override in the command line
|   â”œâ”€â”€ common           # contains classes and utilities
|   |   â”œâ”€â”€ datasets       # various datasets of human demonstrations: aloha, pusht, xarm
|   |   â”œâ”€â”€ envs           # various sim environments: aloha, pusht, xarm
|   |   â”œâ”€â”€ policies       # various policies: act, diffusion, tdmpc
|   |   â”œâ”€â”€ robot_devices  # various real devices: dynamixel motors, opencv cameras, koch robots
|   |   â””â”€â”€ utils          # various utilities
|   â””â”€â”€ scripts          # contains functions to execute via command line
|       â”œâ”€â”€ eval.py                 # load policy and evaluate it on an environment
|       â”œâ”€â”€ train.py                # train a policy via imitation learning and/or reinforcement learning
|       â”œâ”€â”€ control_robot.py        # teleoperate a real robot, record data, run a policy
|       â”œâ”€â”€ push_dataset_to_hub.py  # convert your dataset into LeRobot dataset format and upload it to the Hugging Face hub
|       â””â”€â”€ visualize_dataset.py    # load a dataset and render its demonstrations
â”œâ”€â”€ outputs               # contains results of scripts execution: logs, videos, model checkpoints
â””â”€â”€ tests                 # contains pytest utilities for continuous integration
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Visualize datasets&lt;/h3&gt; 
&lt;p&gt;Check out &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/1_load_lerobot_dataset.py&quot;&gt;example 1&lt;/a&gt; that illustrates how to use our dataset class which automatically downloads data from the Hugging Face hub.&lt;/p&gt; 
&lt;p&gt;You can also locally visualize episodes from a dataset on the hub by executing our script from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python lerobot/scripts/visualize_dataset.py \
    --repo-id lerobot/pusht \
    --episode-index 0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or from a dataset in a local folder with the &lt;code&gt;root&lt;/code&gt; option and the &lt;code&gt;--local-files-only&lt;/code&gt; (in the following case the dataset will be searched for in &lt;code&gt;./my_local_data_dir/lerobot/pusht&lt;/code&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python lerobot/scripts/visualize_dataset.py \
    --repo-id lerobot/pusht \
    --root ./my_local_data_dir \
    --local-files-only 1 \
    --episode-index 0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It will open &lt;code&gt;rerun.io&lt;/code&gt; and display the camera streams, robot states and actions, like this:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20240505T172924Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&amp;amp;X-Amz-SignedHeaders=host&amp;amp;actor_id=24889239&amp;amp;key_id=0&amp;amp;repo_id=748713144&quot;&gt;https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20240505T172924Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&amp;amp;X-Amz-SignedHeaders=host&amp;amp;actor_id=24889239&amp;amp;key_id=0&amp;amp;repo_id=748713144&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Our script can also visualize datasets stored on a distant server. See &lt;code&gt;python lerobot/scripts/visualize_dataset.py --help&lt;/code&gt; for more instructions.&lt;/p&gt; 
&lt;h3&gt;The &lt;code&gt;LeRobotDataset&lt;/code&gt; format&lt;/h3&gt; 
&lt;p&gt;A dataset in &lt;code&gt;LeRobotDataset&lt;/code&gt; format is very simple to use. It can be loaded from a repository on the Hugging Face hub or a local folder simply with e.g. &lt;code&gt;dataset = LeRobotDataset(&quot;lerobot/aloha_static_coffee&quot;)&lt;/code&gt; and can be indexed into like any Hugging Face and PyTorch dataset. For instance &lt;code&gt;dataset[0]&lt;/code&gt; will retrieve a single temporal frame from the dataset containing observation(s) and an action as PyTorch tensors ready to be fed to a model.&lt;/p&gt; 
&lt;p&gt;A specificity of &lt;code&gt;LeRobotDataset&lt;/code&gt; is that, rather than retrieving a single frame by its index, we can retrieve several frames based on their temporal relationship with the indexed frame, by setting &lt;code&gt;delta_timestamps&lt;/code&gt; to a list of relative times with respect to the indexed frame. For example, with &lt;code&gt;delta_timestamps = {&quot;observation.image&quot;: [-1, -0.5, -0.2, 0]}&lt;/code&gt; one can retrieve, for a given index, 4 frames: 3 &quot;previous&quot; frames 1 second, 0.5 seconds, and 0.2 seconds before the indexed frame, and the indexed frame itself (corresponding to the 0 entry). See example &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/1_load_lerobot_dataset.py&quot;&gt;1_load_lerobot_dataset.py&lt;/a&gt; for more details on &lt;code&gt;delta_timestamps&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Under the hood, the &lt;code&gt;LeRobotDataset&lt;/code&gt; format makes use of several ways to serialize data which can be useful to understand if you plan to work more closely with this format. We tried to make a flexible yet simple dataset format that would cover most type of features and specificities present in reinforcement learning and robotics, in simulation and in real-world, with a focus on cameras and robot states but easily extended to other types of sensory inputs as long as they can be represented by a tensor.&lt;/p&gt; 
&lt;p&gt;Here are the important details and internal structure organization of a typical &lt;code&gt;LeRobotDataset&lt;/code&gt; instantiated with &lt;code&gt;dataset = LeRobotDataset(&quot;lerobot/aloha_static_coffee&quot;)&lt;/code&gt;. The exact features will change from dataset to dataset but not the main aspects:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;dataset attributes:
  â”œ hf_dataset: a Hugging Face dataset (backed by Arrow/parquet). Typical features example:
  â”‚  â”œ observation.images.cam_high (VideoFrame):
  â”‚  â”‚   VideoFrame = {&#39;path&#39;: path to a mp4 video, &#39;timestamp&#39; (float32): timestamp in the video}
  â”‚  â”œ observation.state (list of float32): position of an arm joints (for instance)
  â”‚  ... (more observations)
  â”‚  â”œ action (list of float32): goal position of an arm joints (for instance)
  â”‚  â”œ episode_index (int64): index of the episode for this sample
  â”‚  â”œ frame_index (int64): index of the frame for this sample in the episode ; starts at 0 for each episode
  â”‚  â”œ timestamp (float32): timestamp in the episode
  â”‚  â”œ next.done (bool): indicates the end of en episode ; True for the last frame in each episode
  â”‚  â”” index (int64): general index in the whole dataset
  â”œ episode_data_index: contains 2 tensors with the start and end indices of each episode
  â”‚  â”œ from (1D int64 tensor): first frame index for each episode â€” shape (num episodes,) starts with 0
  â”‚  â”” to: (1D int64 tensor): last frame index for each episode â€” shape (num episodes,)
  â”œ stats: a dictionary of statistics (max, mean, min, std) for each feature in the dataset, for instance
  â”‚  â”œ observation.images.cam_high: {&#39;max&#39;: tensor with same number of dimensions (e.g. `(c, 1, 1)` for images, `(c,)` for states), etc.}
  â”‚  ...
  â”œ info: a dictionary of metadata on the dataset
  â”‚  â”œ codebase_version (str): this is to keep track of the codebase version the dataset was created with
  â”‚  â”œ fps (float): frame per second the dataset is recorded/synchronized to
  â”‚  â”œ video (bool): indicates if frames are encoded in mp4 video files to save space or stored as png files
  â”‚  â”” encoding (dict): if video, this documents the main options that were used with ffmpeg to encode the videos
  â”œ videos_dir (Path): where the mp4 videos or png images are stored/accessed
  â”” camera_keys (list of string): the keys to access camera features in the item returned by the dataset (e.g. `[&quot;observation.images.cam_high&quot;, ...]`)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A &lt;code&gt;LeRobotDataset&lt;/code&gt; is serialised using several widespread file formats for each of its parts, namely:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;hf_dataset stored using Hugging Face datasets library serialization to parquet&lt;/li&gt; 
 &lt;li&gt;videos are stored in mp4 format to save space&lt;/li&gt; 
 &lt;li&gt;metadata are stored in plain json/jsonl files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Dataset can be uploaded/downloaded from the HuggingFace hub seamlessly. To work on a local dataset, you can specify its location with the &lt;code&gt;root&lt;/code&gt; argument if it&#39;s not in the default &lt;code&gt;~/.cache/huggingface/lerobot&lt;/code&gt; location.&lt;/p&gt; 
&lt;h3&gt;Evaluate a pretrained policy&lt;/h3&gt; 
&lt;p&gt;Check out &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/2_evaluate_pretrained_policy.py&quot;&gt;example 2&lt;/a&gt; that illustrates how to download a pretrained policy from Hugging Face hub, and run an evaluation on its corresponding environment.&lt;/p&gt; 
&lt;p&gt;We also provide a more capable script to parallelize the evaluation over multiple environments during the same rollout. Here is an example with a pretrained model hosted on &lt;a href=&quot;https://huggingface.co/lerobot/diffusion_pusht&quot;&gt;lerobot/diffusion_pusht&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python lerobot/scripts/eval.py \
    --policy.path=lerobot/diffusion_pusht \
    --env.type=pusht \
    --eval.batch_size=10 \
    --eval.n_episodes=10 \
    --policy.use_amp=false \
    --policy.device=cuda
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: After training your own policy, you can re-evaluate the checkpoints with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python lerobot/scripts/eval.py --policy.path={OUTPUT_DIR}/checkpoints/last/pretrained_model
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;code&gt;python lerobot/scripts/eval.py --help&lt;/code&gt; for more instructions.&lt;/p&gt; 
&lt;h3&gt;Train your own policy&lt;/h3&gt; 
&lt;p&gt;Check out &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/3_train_policy.py&quot;&gt;example 3&lt;/a&gt; that illustrate how to train a model using our core library in python, and &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/4_train_policy_with_script.md&quot;&gt;example 4&lt;/a&gt; that shows how to use our training script from command line.&lt;/p&gt; 
&lt;p&gt;To use wandb for logging training and evaluation curves, make sure you&#39;ve run &lt;code&gt;wandb login&lt;/code&gt; as a one-time setup step. Then, when running the training command above, enable WandB in the configuration by adding &lt;code&gt;--wandb.enable=true&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;A link to the wandb logs for the run will also show up in yellow in your terminal. Here is an example of what they look like in your browser. Please also check &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/4_train_policy_with_script.md#typical-logs-and-metrics&quot;&gt;here&lt;/a&gt; for the explanation of some commonly used metrics in logs.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/wandb.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Note: For efficiency, during training every checkpoint is evaluated on a low number of episodes. You may use &lt;code&gt;--eval.n_episodes=500&lt;/code&gt; to evaluate on more episodes than the default. Or, after training, you may want to re-evaluate your best checkpoints on more episodes or change the evaluation settings. See &lt;code&gt;python lerobot/scripts/eval.py --help&lt;/code&gt; for more instructions.&lt;/p&gt; 
&lt;h4&gt;Reproduce state-of-the-art (SOTA)&lt;/h4&gt; 
&lt;p&gt;We provide some pretrained policies on our &lt;a href=&quot;https://huggingface.co/lerobot&quot;&gt;hub page&lt;/a&gt; that can achieve state-of-the-art performances. You can reproduce their training by loading the config from their run. Simply running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python lerobot/scripts/train.py --config_path=lerobot/diffusion_pusht
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;reproduces SOTA results for Diffusion Policy on the PushT task.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;If you would like to contribute to ğŸ¤— LeRobot, please check out our &lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/CONTRIBUTING.md&quot;&gt;contribution guide&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ### Add a new dataset

To add a dataset to the hub, you need to login using a write-access token, which can be generated from the [Hugging Face settings](https://huggingface.co/settings/tokens):
```bash
huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential
```

Then point to your raw dataset folder (e.g. `data/aloha_static_pingpong_test_raw`), and push your dataset to the hub with:
```bash
python lerobot/scripts/push_dataset_to_hub.py \
--raw-dir data/aloha_static_pingpong_test_raw \
--out-dir data \
--repo-id lerobot/aloha_static_pingpong_test \
--raw-format aloha_hdf5
```

See `python lerobot/scripts/push_dataset_to_hub.py --help` for more instructions.

If your dataset format is not supported, implement your own in `lerobot/common/datasets/push_dataset_to_hub/${raw_format}_format.py` by copying examples like [pusht_zarr](https://github.com/huggingface/lerobot/blob/main/lerobot/common/datasets/push_dataset_to_hub/pusht_zarr_format.py), [umi_zarr](https://github.com/huggingface/lerobot/blob/main/lerobot/common/datasets/push_dataset_to_hub/umi_zarr_format.py), [aloha_hdf5](https://github.com/huggingface/lerobot/blob/main/lerobot/common/datasets/push_dataset_to_hub/aloha_hdf5_format.py), or [xarm_pkl](https://github.com/huggingface/lerobot/blob/main/lerobot/common/datasets/push_dataset_to_hub/xarm_pkl_format.py). --&gt; 
&lt;h3&gt;Add a pretrained policy&lt;/h3&gt; 
&lt;p&gt;Once you have trained a policy you may upload it to the Hugging Face hub using a hub id that looks like &lt;code&gt;${hf_user}/${repo_name}&lt;/code&gt; (e.g. &lt;a href=&quot;https://huggingface.co/lerobot/diffusion_pusht&quot;&gt;lerobot/diffusion_pusht&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;You first need to find the checkpoint folder located inside your experiment directory (e.g. &lt;code&gt;outputs/train/2024-05-05/20-21-12_aloha_act_default/checkpoints/002500&lt;/code&gt;). Within that there is a &lt;code&gt;pretrained_model&lt;/code&gt; directory which should contain:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;config.json&lt;/code&gt;: A serialized version of the policy configuration (following the policy&#39;s dataclass config).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;model.safetensors&lt;/code&gt;: A set of &lt;code&gt;torch.nn.Module&lt;/code&gt; parameters, saved in &lt;a href=&quot;https://huggingface.co/docs/safetensors/index&quot;&gt;Hugging Face Safetensors&lt;/a&gt; format.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;train_config.json&lt;/code&gt;: A consolidated configuration containing all parameter userd for training. The policy configuration should match &lt;code&gt;config.json&lt;/code&gt; exactly. Thisis useful for anyone who wants to evaluate your policy or for reproducibility.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To upload these to the hub, run the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;huggingface-cli upload ${hf_user}/${repo_name} path/to/pretrained_model
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/lerobot/scripts/eval.py&quot;&gt;eval.py&lt;/a&gt; for an example of how other people may use your policy.&lt;/p&gt; 
&lt;h3&gt;Improve your code with profiling&lt;/h3&gt; 
&lt;p&gt;An example of a code snippet to profile the evaluation of a policy:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from torch.profiler import profile, record_function, ProfilerActivity

def trace_handler(prof):
    prof.export_chrome_trace(f&quot;tmp/trace_schedule_{prof.step_num}.json&quot;)

with profile(
    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    schedule=torch.profiler.schedule(
        wait=2,
        warmup=2,
        active=3,
    ),
    on_trace_ready=trace_handler
) as prof:
    with record_function(&quot;eval_policy&quot;):
        for i in range(num_episodes):
            prof.step()
            # insert code to profile, potentially whole body of eval_policy function
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you want, you can cite this work with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@misc{cadene2024lerobot,
    author = {Cadene, Remi and Alibert, Simon and Soare, Alexander and Gallouedec, Quentin and Zouitine, Adil and Wolf, Thomas},
    title = {LeRobot: State-of-the-art Machine Learning for Real-World Robotics in Pytorch},
    howpublished = &quot;\url{https://github.com/huggingface/lerobot}&quot;,
    year = {2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, if you are using any of the particular policy architecture, pretrained models, or datasets, it is recommended to cite the original authors of the work as they appear below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://diffusion-policy.cs.columbia.edu&quot;&gt;Diffusion Policy&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@article{chi2024diffusionpolicy,
	author = {Cheng Chi and Zhenjia Xu and Siyuan Feng and Eric Cousineau and Yilun Du and Benjamin Burchfiel and Russ Tedrake and Shuran Song},
	title ={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
	journal = {The International Journal of Robotics Research},
	year = {2024},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tonyzhaozh.github.io/aloha&quot;&gt;ACT or ALOHA&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@article{zhao2023learning,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nicklashansen.com/td-mpc/&quot;&gt;TDMPC&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@inproceedings{Hansen2022tdmpc,
	title={Temporal Difference Learning for Model Predictive Control},
	author={Nicklas Hansen and Xiaolong Wang and Hao Su},
	booktitle={ICML},
	year={2022}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://sjlee.cc/vq-bet/&quot;&gt;VQ-BeT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@article{lee2024behavior,
  title={Behavior generation with latent actions},
  author={Lee, Seungjae and Wang, Yibin and Etukuru, Haritheja and Kim, H Jin and Shafiullah, Nur Muhammad Mahi and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2403.03181},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://star-history.com/#huggingface/lerobot&amp;amp;Timeline&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=huggingface/lerobot&amp;amp;type=Timeline&quot; alt=&quot;Star History Chart&quot;&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jingyaogong/minimind</title>
      <link>https://github.com/jingyaogong/minimind</link>
      <description>&lt;p&gt;ğŸš€ğŸš€ ã€Œå¤§æ¨¡å‹ã€2å°æ—¶å®Œå…¨ä»0è®­ç»ƒ26Mçš„å°å‚æ•°GPTï¼ğŸŒ Train a 26M-parameter GPT from scratch in just 2h!&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/logo.png&quot; alt=&quot;logo&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;img src=&quot;https://visitor-badge.laobi.icu/badge?page_id=jingyaogong/minimind&quot; alt=&quot;visitors&quot;&gt; &lt;a href=&quot;https://github.com/jingyaogong/minimind/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/jingyaogong/minimind?style=social&quot; alt=&quot;GitHub Repo stars&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/jingyaogong/minimind&quot; alt=&quot;GitHub Code License&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/jingyaogong/minimind/commits/master&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/last-commit/jingyaogong/minimind&quot; alt=&quot;GitHub last commit&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/jingyaogong/minimind/pulls&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-blue&quot; alt=&quot;GitHub pull request&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%F0%9F%A4%97-MiniMind%20%20Collection-blue&quot; alt=&quot;Collection&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;h3&gt;&quot;å¤§é“è‡³ç®€&quot;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;ä¸­æ–‡ | &lt;a href=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/README_en.md&quot;&gt;English&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ­¤å¼€æºé¡¹ç›®æ—¨åœ¨å®Œå…¨ä»0å¼€å§‹ï¼Œä»…ç”¨3å—é’±æˆæœ¬ + 2å°æ—¶ï¼å³å¯è®­ç»ƒå‡ºä»…ä¸º25.8Mçš„è¶…å°è¯­è¨€æ¨¡å‹&lt;strong&gt;MiniMind&lt;/strong&gt;ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;ç³»åˆ—æå…¶è½»é‡ï¼Œæœ€å°ç‰ˆæœ¬ä½“ç§¯æ˜¯ GPT-3 çš„ $\frac{1}{7000}$ï¼ŒåŠ›æ±‚åšåˆ°æœ€æ™®é€šçš„ä¸ªäººGPUä¹Ÿå¯å¿«é€Ÿè®­ç»ƒã€‚&lt;/li&gt; 
 &lt;li&gt;é¡¹ç›®åŒæ—¶å¼€æºäº†å¤§æ¨¡å‹çš„æç®€ç»“æ„-åŒ…å«æ‹“å±•å…±äº«æ··åˆä¸“å®¶(MoE)ã€æ•°æ®é›†æ¸…æ´—ã€é¢„è®­ç»ƒ(Pretrain)ã€ç›‘ç£å¾®è°ƒ(SFT)ã€LoRAå¾®è°ƒï¼Œ ç›´æ¥åå¥½å¼ºåŒ–å­¦ä¹ (DPO)ç®—æ³•ã€æ¨¡å‹è’¸é¦ç®—æ³•ç­‰å…¨è¿‡ç¨‹ä»£ç ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;åŒæ—¶æ‹“å±•äº†è§†è§‰å¤šæ¨¡æ€çš„VLM: &lt;a href=&quot;https://github.com/jingyaogong/minimind-v&quot;&gt;MiniMind-V&lt;/a&gt;ã€‚&lt;/li&gt; 
 &lt;li&gt;é¡¹ç›®æ‰€æœ‰æ ¸å¿ƒç®—æ³•ä»£ç å‡ä»0ä½¿ç”¨PyTorchåŸç”Ÿé‡æ„ï¼ä¸ä¾èµ–ç¬¬ä¸‰æ–¹åº“æä¾›çš„æŠ½è±¡æ¥å£ã€‚&lt;/li&gt; 
 &lt;li&gt;è¿™ä¸ä»…æ˜¯å¤§è¯­è¨€æ¨¡å‹çš„å…¨é˜¶æ®µå¼€æºå¤ç°ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå…¥é—¨LLMçš„æ•™ç¨‹ã€‚&lt;/li&gt; 
 &lt;li&gt;å¸Œæœ›æ­¤é¡¹ç›®èƒ½ä¸ºæ‰€æœ‰äººæä¾›ä¸€ä¸ªæŠ›ç –å¼•ç‰çš„ç¤ºä¾‹ï¼Œä¸€èµ·æ„Ÿå—åˆ›é€ çš„ä¹è¶£ï¼æ¨åŠ¨æ›´å¹¿æ³›AIç¤¾åŒºçš„è¿›æ­¥ï¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä¸ºé˜²æ­¢è¯¯è§£ï¼Œâ€œ2å°æ—¶â€ åŸºäºNVIDIA 3090ç¡¬ä»¶è®¾å¤‡ï¼ˆå•å¡ï¼‰æµ‹è¯•ï¼Œâ€œ3å—é’±â€ æŒ‡GPUæœåŠ¡å™¨ç§Ÿç”¨æˆæœ¬ï¼Œå…·ä½“è§„æ ¼è¯¦æƒ…è§ä¸‹æ–‡ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/minimind2.gif&quot; alt=&quot;minimind2&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.modelscope.cn/studios/gongjy/MiniMind-Reasoning&quot;&gt;ğŸ”—ğŸ“æ¨ç†æ¨¡å‹&lt;/a&gt; | &lt;a href=&quot;https://www.modelscope.cn/studios/gongjy/MiniMind&quot;&gt;ğŸ”—ğŸ¤–å¸¸è§„æ¨¡å‹&lt;/a&gt; | &lt;a href=&quot;https://www.bilibili.com/video/BV12dHPeqE72/?share_source=copy_web&amp;amp;vd_source=670c2504f88726f8cf4a21ef6147c0e8&quot;&gt;ğŸ”—ğŸï¸è§†é¢‘ä»‹ç»&lt;/a&gt;&lt;/p&gt; 
 &lt;div align=&quot;center&quot;&gt; 
  &lt;table&gt; 
   &lt;tbody&gt;
    &lt;tr&gt; 
     &lt;td align=&quot;center&quot;&gt; &lt;a href=&quot;https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5&quot; style=&quot;text-decoration: none;&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_huggingface.png&quot; alt=&quot;Hugging Face Logo&quot; style=&quot;vertical-align: middle; width: auto; max-width: 100%;&quot;&gt; &lt;/a&gt; &lt;/td&gt; 
     &lt;td align=&quot;center&quot;&gt; &lt;a href=&quot;https://www.modelscope.cn/profile/gongjy&quot; style=&quot;text-decoration: none;&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_modelscope.png&quot; alt=&quot;ModelScope Logo&quot; style=&quot;vertical-align: middle; width: auto; max-width: 100%;&quot;&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt;
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h1&gt;ğŸ“Œ Introduction&lt;/h1&gt; 
&lt;p&gt;å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Model, LLMï¼‰çš„å‡ºç°å¼•å‘äº†å…¨ä¸–ç•Œå¯¹AIçš„ç©ºå‰å…³æ³¨ã€‚ æ— è®ºæ˜¯ChatGPTã€DeepSeekè¿˜æ˜¯Qwenï¼Œéƒ½ä»¥å…¶æƒŠè‰³çš„æ•ˆæœä»¤äººå¹ä¸ºè§‚æ­¢ã€‚ ç„¶è€Œï¼ŒåŠ¨è¾„æ•°ç™¾äº¿å‚æ•°çš„åºå¤§è§„æ¨¡ï¼Œä½¿å¾—å®ƒä»¬å¯¹ä¸ªäººè®¾å¤‡è€Œè¨€ä¸ä»…éš¾ä»¥è®­ç»ƒï¼Œç”šè‡³è¿éƒ¨ç½²éƒ½æ˜¾å¾—é¥ä¸å¯åŠã€‚ æ‰“å¼€å¤§æ¨¡å‹çš„â€œé»‘ç›’å­â€ï¼Œæ¢ç´¢å…¶å†…éƒ¨è¿ä½œæœºåˆ¶ï¼Œå¤šä¹ˆä»¤äººå¿ƒæ½®æ¾æ¹ƒï¼ é—æ†¾çš„æ˜¯ï¼Œ99%çš„æ¢ç´¢åªèƒ½æ­¢æ­¥äºä½¿ç”¨LoRAç­‰æŠ€æœ¯å¯¹ç°æœ‰å¤§æ¨¡å‹è¿›è¡Œå°‘é‡å¾®è°ƒï¼Œå­¦ä¹ ä¸€äº›æ–°æŒ‡ä»¤æˆ–ä»»åŠ¡ã€‚ è¿™å°±å¥½æ¯”æ•™ç‰›é¡¿å¦‚ä½•ä½¿ç”¨21ä¸–çºªçš„æ™ºèƒ½æ‰‹æœºâ€”â€”è™½ç„¶æœ‰è¶£ï¼Œå´å®Œå…¨åç¦»äº†ç†è§£ç‰©ç†æœ¬è´¨çš„åˆè¡·ã€‚ ä¸æ­¤åŒæ—¶ï¼Œç¬¬ä¸‰æ–¹çš„å¤§æ¨¡å‹æ¡†æ¶å’Œå·¥å…·åº“ï¼Œå¦‚transformers+trlï¼Œå‡ ä¹åªæš´éœ²äº†é«˜åº¦æŠ½è±¡çš„æ¥å£ã€‚ é€šè¿‡çŸ­çŸ­10è¡Œä»£ç ï¼Œå°±èƒ½å®Œæˆâ€œåŠ è½½æ¨¡å‹+åŠ è½½æ•°æ®é›†+æ¨ç†+å¼ºåŒ–å­¦ä¹ â€çš„å…¨æµç¨‹è®­ç»ƒã€‚ è¿™ç§é«˜æ•ˆçš„å°è£…å›ºç„¶ä¾¿åˆ©ï¼Œä½†ä¹Ÿåƒä¸€æ¶é«˜é€Ÿé£èˆ¹ï¼Œå°†æˆ‘ä»¬ä¸åº•å±‚å®ç°éš”ç¦»å¼€æ¥ï¼Œé˜»ç¢äº†æ·±å…¥æ¢ç©¶LLMæ ¸å¿ƒä»£ç çš„æœºä¼šã€‚ ç„¶è€Œï¼Œâ€œç”¨ä¹é«˜æ‹¼å‡ºä¸€æ¶é£æœºï¼Œè¿œæ¯”ååœ¨å¤´ç­‰èˆ±é‡Œé£è¡Œæ›´è®©äººå…´å¥‹ï¼â€ã€‚ æ›´ç³Ÿç³•çš„æ˜¯ï¼Œäº’è”ç½‘ä¸Šå……æ–¥ç€å¤§é‡ä»˜è´¹è¯¾ç¨‹å’Œè¥é”€å·ï¼Œä»¥æ¼æ´ç™¾å‡ºã€ä¸€çŸ¥åŠè§£çš„å†…å®¹æ¨é”€AIæ•™ç¨‹ã€‚ æ­£å› å¦‚æ­¤ï¼Œæœ¬é¡¹ç›®åˆè¡·æ˜¯æ‹‰ä½LLMçš„å­¦ä¹ é—¨æ§›ï¼Œè®©æ¯ä¸ªäººéƒ½èƒ½ä»ç†è§£æ¯ä¸€è¡Œä»£ç å¼€å§‹ï¼Œ ä»é›¶å¼€å§‹äº²æ‰‹è®­ç»ƒä¸€ä¸ªæå°çš„è¯­è¨€æ¨¡å‹ã€‚æ˜¯çš„ï¼Œä»&lt;strong&gt;é›¶å¼€å§‹è®­ç»ƒ&lt;/strong&gt;ï¼Œè€Œä¸æ˜¯ä»…ä»…è¿›è¡Œ&lt;strong&gt;æ¨ç†&lt;/strong&gt;ï¼ æœ€ä½åªéœ€3å—é’±ä¸åˆ°çš„æœåŠ¡å™¨æˆæœ¬ï¼Œå°±èƒ½äº²èº«ä½“éªŒä»0åˆ°1æ„å»ºä¸€ä¸ªè¯­è¨€æ¨¡å‹çš„å…¨è¿‡ç¨‹ã€‚ ä¸€èµ·æ„Ÿå—åˆ›é€ çš„ä¹è¶£å§ï¼&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] ï¼ˆæˆªè‡³2025-02-07ï¼‰MiniMindç³»åˆ—å·²å®Œæˆå¤šä¸ªå‹å·æ¨¡å‹çš„é¢„è®­ç»ƒï¼Œæœ€å°ä»…éœ€25.8Mï¼ˆ0.02Bï¼‰ï¼Œå³å¯å…·å¤‡æµç•…å¯¹è¯èƒ½åŠ›ï¼&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;Models List&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;æ¨¡å‹ (å¤§å°)&lt;/th&gt; 
    &lt;th&gt;æ¨ç†å ç”¨ (çº¦)&lt;/th&gt; 
    &lt;th&gt;Release&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2025.02.06&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE (145M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.02.06&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2 (104M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.02.06&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2024.08.28&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-moe (4Ã—26M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.17&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1 (108M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.01&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;é¡¹ç›®åŒ…å«&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MiniMind-LLMç»“æ„çš„å…¨éƒ¨ä»£ç ï¼ˆDense+MoEæ¨¡å‹ï¼‰ã€‚&lt;/li&gt; 
 &lt;li&gt;åŒ…å«Tokenizeråˆ†è¯å™¨è¯¦ç»†è®­ç»ƒä»£ç ã€‚&lt;/li&gt; 
 &lt;li&gt;åŒ…å«Pretrainã€SFTã€LoRAã€RLHF-DPOã€æ¨¡å‹è’¸é¦çš„å…¨è¿‡ç¨‹è®­ç»ƒä»£ç ã€‚&lt;/li&gt; 
 &lt;li&gt;æ”¶é›†ã€è’¸é¦ã€æ•´ç†å¹¶æ¸…æ´—å»é‡æ‰€æœ‰é˜¶æ®µçš„é«˜è´¨é‡æ•°æ®é›†ï¼Œä¸”å…¨éƒ¨å¼€æºã€‚&lt;/li&gt; 
 &lt;li&gt;ä»0å®ç°é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒã€LoRAã€DPOå¼ºåŒ–å­¦ä¹ ï¼Œç™½ç›’æ¨¡å‹è’¸é¦ã€‚å…³é”®ç®—æ³•å‡ ä¹ä¸ä¾èµ–ç¬¬ä¸‰æ–¹å°è£…çš„æ¡†æ¶ï¼Œä¸”å…¨éƒ¨å¼€æºã€‚&lt;/li&gt; 
 &lt;li&gt;åŒæ—¶å…¼å®¹&lt;code&gt;transformers&lt;/code&gt;ã€&lt;code&gt;trl&lt;/code&gt;ã€&lt;code&gt;peft&lt;/code&gt;ç­‰ç¬¬ä¸‰æ–¹ä¸»æµæ¡†æ¶ã€‚&lt;/li&gt; 
 &lt;li&gt;è®­ç»ƒæ”¯æŒå•æœºå•å¡ã€å•æœºå¤šå¡(DDPã€DeepSpeed)è®­ç»ƒï¼Œæ”¯æŒwandbå¯è§†åŒ–è®­ç»ƒæµç¨‹ã€‚æ”¯æŒåŠ¨æ€å¯åœè®­ç»ƒã€‚&lt;/li&gt; 
 &lt;li&gt;åœ¨ç¬¬ä¸‰æ–¹æµ‹è¯„æ¦œï¼ˆC-Evalã€C-MMLUã€OpenBookQAç­‰ï¼‰è¿›è¡Œæ¨¡å‹æµ‹è¯•ã€‚&lt;/li&gt; 
 &lt;li&gt;å®ç°Openai-Apiåè®®çš„æç®€æœåŠ¡ç«¯ï¼Œä¾¿äºé›†æˆåˆ°ç¬¬ä¸‰æ–¹ChatUIä½¿ç”¨ï¼ˆFastGPTã€Open-WebUIç­‰ï¼‰ã€‚&lt;/li&gt; 
 &lt;li&gt;åŸºäºstreamlitå®ç°æœ€ç®€èŠå¤©WebUIå‰ç«¯ã€‚&lt;/li&gt; 
 &lt;li&gt;å¤ç°(è’¸é¦/RL)å¤§å‹æ¨ç†æ¨¡å‹DeepSeek-R1çš„MiniMind-Reasonæ¨¡å‹ï¼Œ&lt;strong&gt;æ•°æ®+æ¨¡å‹&lt;/strong&gt;å…¨éƒ¨å¼€æºï¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;å¸Œæœ›æ­¤å¼€æºé¡¹ç›®å¯ä»¥å¸®åŠ©LLMåˆå­¦è€…å¿«é€Ÿå…¥é—¨ï¼&lt;/p&gt; 
&lt;h3&gt;ğŸ‘‰&lt;strong&gt;æ›´æ–°æ—¥å¿—&lt;/strong&gt;&lt;/h3&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-02-09 (newest ğŸ‰ğŸ‰ğŸ‰)&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è¿æ¥å‘å¸ƒä»¥æ¥é‡å¤§æ›´æ–°ï¼ŒRelease MiniMind2 Seriesã€‚&lt;/li&gt; 
  &lt;li&gt;ä»£ç å‡ ä¹å…¨éƒ¨é‡æ„ï¼Œä½¿ç”¨æ›´ç®€æ´æ˜äº†çš„ç»Ÿä¸€ç»“æ„ã€‚ å¦‚æœ‰æ—§ä»£ç çš„å…¼å®¹æ€§éœ€è¦ï¼Œå¯è®¿é—®&lt;a href=&quot;https://github.com/jingyaogong/minimind/tree/6e9cd28ef9b34a0a10afbdf6f59e65cb6e628efb&quot;&gt;ğŸ”—æ—§ä»“åº“å†…å®¹ğŸ”—&lt;/a&gt;ã€‚&lt;/li&gt; 
  &lt;li&gt;å…å»æ•°æ®é¢„å¤„ç†æ­¥éª¤ã€‚ç»Ÿä¸€æ•°æ®é›†æ ¼å¼ï¼Œæ›´æ¢ä¸º&lt;code&gt;jsonl&lt;/code&gt;æ ¼å¼æœç»æ•°æ®é›†ä¸‹è½½æ··ä¹±çš„é—®é¢˜ã€‚&lt;/li&gt; 
  &lt;li&gt;MiniMind2ç³»åˆ—æ•ˆæœç›¸æ¯”MiniMind-V1æ˜¾è‘—æå‡ã€‚&lt;/li&gt; 
  &lt;li&gt;å°é—®é¢˜ï¼š{kv-cacheå†™æ³•æ›´æ ‡å‡†ã€MoEçš„è´Ÿè½½å‡è¡¡lossè¢«è€ƒè™‘ç­‰ç­‰}&lt;/li&gt; 
  &lt;li&gt;æä¾›æ¨¡å‹è¿ç§»åˆ°ç§æœ‰æ•°æ®é›†çš„è®­ç»ƒæ–¹æ¡ˆï¼ˆåŒ»ç–—æ¨¡å‹ã€è‡ªæˆ‘è®¤çŸ¥æ ·ä¾‹ï¼‰ã€‚&lt;/li&gt; 
  &lt;li&gt;ç²¾ç®€é¢„è®­ç»ƒæ•°æ®é›†ï¼Œå¹¶å¤§å¹…æå‡é¢„è®­ç»ƒæ•°æ®è´¨é‡ï¼Œå¤§å¹…ç¼©çŸ­ä¸ªäººå¿«é€Ÿè®­ç»ƒæ‰€éœ€æ—¶é—´ï¼Œå•å¡3090å³å¯2å°æ—¶å¤ç°ï¼&lt;/li&gt; 
  &lt;li&gt;æ›´æ–°ï¼šLoRAå¾®è°ƒè„±ç¦»peftåŒ…è£…ï¼Œä»0å®ç°LoRAè¿‡ç¨‹ï¼›DPOç®—æ³•ä»0ä½¿ç”¨PyTorchåŸç”Ÿå®ç°ï¼›æ¨¡å‹ç™½ç›’è’¸é¦åŸç”Ÿå®ç°ã€‚&lt;/li&gt; 
  &lt;li&gt;MiniMind2-DeepSeek-R1ç³»åˆ—è’¸é¦æ¨¡å‹è¯ç”Ÿï¼&lt;/li&gt; 
  &lt;li&gt;MiniMind2å…·å¤‡ä¸€å®šçš„è‹±æ–‡èƒ½åŠ›ï¼&lt;/li&gt; 
  &lt;li&gt;æ›´æ–°MiniMind2ä¸ç¬¬ä¸‰æ–¹æ¨¡å‹çš„åŸºäºæ›´å¤šå¤§æ¨¡å‹æ¦œå•æµ‹è¯•æ€§èƒ½çš„ç»“æœã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-10-05&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¸ºMiniMindæ‹“å±•äº†å¤šæ¨¡æ€èƒ½åŠ›ä¹‹---è§†è§‰&lt;/li&gt; 
  &lt;li&gt;ç§»æ­¥å­ªç”Ÿé¡¹ç›®&lt;a href=&quot;https://github.com/jingyaogong/minimind-v&quot;&gt;minimind-v&lt;/a&gt;æŸ¥çœ‹è¯¦æƒ…ï¼&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-27&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;09-27æ›´æ–°pretrainæ•°æ®é›†çš„é¢„å¤„ç†æ–¹å¼ï¼Œä¸ºäº†ä¿è¯æ–‡æœ¬å®Œæ•´æ€§ï¼Œæ”¾å¼ƒé¢„å¤„ç†æˆ.binè®­ç»ƒçš„å½¢å¼ï¼ˆè½»å¾®ç‰ºç‰²è®­ç»ƒé€Ÿåº¦ï¼‰ã€‚&lt;/li&gt; 
  &lt;li&gt;ç›®å‰pretrainé¢„å¤„ç†åçš„æ–‡ä»¶å‘½åä¸ºï¼špretrain_data.csvã€‚&lt;/li&gt; 
  &lt;li&gt;åˆ é™¤äº†ä¸€äº›å†—ä½™çš„ä»£ç ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-17&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ›´æ–°minimind-v1-moeæ¨¡å‹&lt;/li&gt; 
  &lt;li&gt;ä¸ºäº†é˜²æ­¢æ­§ä¹‰ï¼Œä¸å†ä½¿ç”¨mistral_tokenizeråˆ†è¯ï¼Œå…¨éƒ¨é‡‡ç”¨è‡ªå®šä¹‰çš„minimind_tokenizerä½œä¸ºåˆ†è¯å™¨ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-01&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ›´æ–°minimind-v1 (108M)æ¨¡å‹ï¼Œé‡‡ç”¨minimind_tokenizerï¼Œé¢„è®­ç»ƒè½®æ¬¡3 + SFTè½®æ¬¡10ï¼Œæ›´å……åˆ†è®­ç»ƒï¼Œæ€§èƒ½æ›´å¼ºã€‚&lt;/li&gt; 
  &lt;li&gt;é¡¹ç›®å·²éƒ¨ç½²è‡³ModelScopeåˆ›ç©ºé—´ï¼Œå¯ä»¥åœ¨æ­¤ç½‘ç«™ä¸Šä½“éªŒï¼š&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://www.modelscope.cn/studios/gongjy/minimind&quot;&gt;ğŸ”—ModelScopeåœ¨çº¿ä½“éªŒğŸ”—&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-08-27&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é¡¹ç›®é¦–æ¬¡å¼€æº&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;ğŸ“Œ å¿«é€Ÿå¼€å§‹&lt;/h1&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;åˆ†äº«æœ¬äººçš„è½¯ç¡¬ä»¶é…ç½®ï¼ˆä»…ä¾›å‚è€ƒï¼‰&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz&lt;/li&gt; 
  &lt;li&gt;RAM: 128 GB&lt;/li&gt; 
  &lt;li&gt;GPU: NVIDIA GeForce RTX 3090(24GB) * 8&lt;/li&gt; 
  &lt;li&gt;Ubuntu==20.04&lt;/li&gt; 
  &lt;li&gt;CUDA==12.2&lt;/li&gt; 
  &lt;li&gt;Python==3.10.16&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/requirements.txt&quot;&gt;requirements.txt&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ç¬¬0æ­¥&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/jingyaogong/minimind.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…  æµ‹è¯•å·²æœ‰æ¨¡å‹æ•ˆæœ&lt;/h2&gt; 
&lt;h3&gt;1.ç¯å¢ƒå‡†å¤‡&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.ä¸‹è½½æ¨¡å‹&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://huggingface.co/jingyaogong/MiniMind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3.å‘½ä»¤è¡Œé—®ç­”&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# load=0: load from pytorch model, load=1: load from transformers-hf model
python eval_model.py --load 1 --model_mode 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4.æˆ–å¯åŠ¨WebUI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# å¯èƒ½éœ€è¦`python&amp;gt;=3.10` å®‰è£… `pip install streamlit`
# cd scripts
streamlit run web_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…¡ ä»0å¼€å§‹è‡ªå·±è®­ç»ƒ&lt;/h2&gt; 
&lt;h3&gt;1.ç¯å¢ƒå‡†å¤‡&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;æ³¨ï¼šæå‰æµ‹è¯•Torchæ˜¯å¦å¯ç”¨cuda&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;import torch
print(torch.cuda.is_available())
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;å¦‚æœä¸å¯ç”¨ï¼Œè¯·è‡ªè¡Œå»&lt;a href=&quot;https://download.pytorch.org/whl/torch_stable.html&quot;&gt;torch_stable&lt;/a&gt; ä¸‹è½½whlæ–‡ä»¶å®‰è£…ã€‚å‚è€ƒ&lt;a href=&quot;https://blog.csdn.net/weixin_45456738/article/details/141029610?ops_request_misc=&amp;amp;request_id=&amp;amp;biz_id=102&amp;amp;utm_term=%E5%AE%89%E8%A3%85torch&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-141029610.nonecase&amp;amp;spm=1018.2226.3001.4187&quot;&gt;é“¾æ¥&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;2.æ•°æ®ä¸‹è½½&lt;/h3&gt; 
&lt;p&gt;ä»ä¸‹æ–‡æä¾›çš„&lt;a href=&quot;https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files&quot;&gt;æ•°æ®é›†ä¸‹è½½é“¾æ¥&lt;/a&gt; ä¸‹è½½éœ€è¦çš„æ•°æ®æ–‡ä»¶ï¼ˆåˆ›å»º&lt;code&gt;./dataset&lt;/code&gt;ç›®å½•ï¼‰å¹¶æ”¾åˆ°&lt;code&gt;./dataset&lt;/code&gt;ä¸‹&lt;/p&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;æ³¨ï¼šæ•°æ®é›†é¡»çŸ¥&lt;/summary&gt; 
 &lt;p&gt;é»˜è®¤æ¨èä¸‹è½½&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;æœ€å¿«é€Ÿåº¦å¤ç°ZeroèŠå¤©æ¨¡å‹ã€‚&lt;/p&gt; 
 &lt;p&gt;æ•°æ®æ–‡ä»¶å¯è‡ªç”±é€‰æ‹©ï¼Œä¸‹æ–‡æä¾›äº†å¤šç§æ­é…æ–¹æ¡ˆï¼Œå¯æ ¹æ®è‡ªå·±æ‰‹å¤´çš„è®­ç»ƒéœ€æ±‚å’ŒGPUèµ„æºè¿›è¡Œé€‚å½“ç»„åˆã€‚&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;3.å¼€å§‹è®­ç»ƒ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;3.1 é¢„è®­ç»ƒï¼ˆå­¦çŸ¥è¯†ï¼‰&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ‰§è¡Œé¢„è®­ç»ƒï¼Œå¾—åˆ° &lt;code&gt;pretrain_*.pth&lt;/code&gt; ä½œä¸ºé¢„è®­ç»ƒçš„è¾“å‡ºæƒé‡ï¼ˆå…¶ä¸­*ä¸ºæ¨¡å‹çš„dimensionï¼Œé»˜è®¤ä¸º512ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;3.2 ç›‘ç£å¾®è°ƒï¼ˆå­¦å¯¹è¯æ–¹å¼ï¼‰&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ‰§è¡Œç›‘ç£å¾®è°ƒï¼Œå¾—åˆ° &lt;code&gt;full_sft_*.pth&lt;/code&gt; ä½œä¸ºæŒ‡ä»¤å¾®è°ƒçš„è¾“å‡ºæƒé‡ï¼ˆå…¶ä¸­&lt;code&gt;full&lt;/code&gt;å³ä¸ºå…¨å‚æ•°å¾®è°ƒï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;æ³¨ï¼šè®­ç»ƒé¡»çŸ¥&lt;/summary&gt; 
 &lt;p&gt;æ‰€æœ‰è®­ç»ƒè¿‡ç¨‹é»˜è®¤æ¯éš”100æ­¥ä¿å­˜1æ¬¡å‚æ•°åˆ°æ–‡ä»¶&lt;code&gt;./out/***.pth&lt;/code&gt;ï¼ˆæ¯æ¬¡ä¼šè¦†ç›–æ‰æ—§æƒé‡æ–‡ä»¶ï¼‰ã€‚&lt;/p&gt; 
 &lt;p&gt;ç®€å•èµ·è§ï¼Œæ­¤å¤„åªå†™æ˜ä¸¤ä¸ªé˜¶æ®µè®­ç»ƒè¿‡ç¨‹ã€‚å¦‚éœ€å…¶å®ƒè®­ç»ƒ (LoRA, è’¸é¦, å¼ºåŒ–å­¦ä¹ , å¾®è°ƒæ¨ç†ç­‰) å¯å‚è€ƒä¸‹æ–‡ã€å®éªŒã€‘å°èŠ‚çš„è¯¦ç»†è¯´æ˜ã€‚&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h3&gt;4.æµ‹è¯•æ¨¡å‹æ•ˆæœ&lt;/h3&gt; 
&lt;p&gt;ç¡®ä¿éœ€è¦æµ‹è¯•çš„æ¨¡å‹&lt;code&gt;*.pth&lt;/code&gt;æ–‡ä»¶ä½äº&lt;code&gt;./out/&lt;/code&gt;ç›®å½•ä¸‹ã€‚ ä¹Ÿå¯ä»¥ç›´æ¥å»&lt;a href=&quot;https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch/files&quot;&gt;æ­¤å¤„&lt;/a&gt;ä¸‹è½½ä½¿ç”¨æˆ‘è®­ç»ƒçš„&lt;code&gt;*.pth&lt;/code&gt;æ–‡ä»¶ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python eval_model.py --model_mode 1 # é»˜è®¤ä¸º0ï¼šæµ‹è¯•pretrainæ¨¡å‹æ•ˆæœï¼Œè®¾ç½®ä¸º1ï¼šæµ‹è¯•full_sftæ¨¡å‹æ•ˆæœ
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;æ³¨ï¼šæµ‹è¯•é¡»çŸ¥&lt;/summary&gt; 
 &lt;p&gt;å¦‚éœ€è¯¦æƒ…ï¼ŒæŸ¥çœ‹&lt;code&gt;eval_model.py&lt;/code&gt;è„šæœ¬ä»£ç å³å¯ã€‚model_modeåˆ†ä¸º 0: é¢„è®­ç»ƒæ¨¡å‹ï¼Œ1: SFT-Chatæ¨¡å‹ï¼Œ2: RLHF-Chatæ¨¡å‹ï¼Œ3: Reasonæ¨¡å‹&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] æ‰€æœ‰è®­ç»ƒè„šæœ¬å‡ä¸ºPytorchåŸç”Ÿæ¡†æ¶ï¼Œå‡æ”¯æŒå¤šå¡åŠ é€Ÿï¼Œå‡è®¾ä½ çš„è®¾å¤‡æœ‰N (Nï¼1) å¼ æ˜¾å¡ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;å•æœºNå¡å¯åŠ¨è®­ç»ƒæ–¹å¼ (DDP, æ”¯æŒå¤šæœºå¤šå¡é›†ç¾¤)&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;torchrun --nproc_per_node N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;æ³¨ï¼šå…¶å®ƒé¡»çŸ¥&lt;/summary&gt; 
 &lt;p&gt;å•æœºNå¡å¯åŠ¨è®­ç»ƒ (DeepSpeed)&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;deepspeed --master_port 29500 --num_gpus=N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;å¯æ ¹æ®éœ€è¦å¼€å¯wandbè®°å½•è®­ç»ƒè¿‡ç¨‹&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# éœ€è¦ç™»å½•: wandb login
torchrun --nproc_per_node N train_xxx.py --use_wandb
# and
python train_xxx.py --use_wandb
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;é€šè¿‡æ·»åŠ &lt;code&gt;--use_wandb&lt;/code&gt;å‚æ•°ï¼Œå¯ä»¥è®°å½•è®­ç»ƒè¿‡ç¨‹ï¼Œè®­ç»ƒå®Œæˆåï¼Œå¯ä»¥åœ¨wandbç½‘ç«™ä¸ŠæŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ã€‚é€šè¿‡ä¿®æ”¹&lt;code&gt;wandb_project&lt;/code&gt; å’Œ&lt;code&gt;wandb_run_name&lt;/code&gt;å‚æ•°ï¼Œå¯ä»¥æŒ‡å®šé¡¹ç›®åç§°å’Œè¿è¡Œåç§°ã€‚&lt;/p&gt; 
&lt;/details&gt; 
&lt;h1&gt;ğŸ“Œ æ•°æ®ä»‹ç»&lt;/h1&gt; 
&lt;h2&gt;â…  Tokenizer&lt;/h2&gt; 
&lt;p&gt;åˆ†è¯å™¨å°†å•è¯ä»è‡ªç„¶è¯­è¨€é€šè¿‡â€œè¯å…¸â€æ˜ å°„åˆ°&lt;code&gt;0, 1, 36&lt;/code&gt;è¿™æ ·çš„æ•°å­—ï¼Œå¯ä»¥ç†è§£ä¸ºæ•°å­—å°±ä»£è¡¨äº†å•è¯åœ¨â€œè¯å…¸â€ä¸­çš„é¡µç ã€‚ å¯ä»¥é€‰æ‹©è‡ªå·±æ„é€ è¯è¡¨è®­ç»ƒä¸€ä¸ªâ€œè¯å…¸â€ï¼Œä»£ç å¯è§&lt;code&gt;./scripts/train_tokenizer.py&lt;/code&gt;ï¼ˆä»…ä¾›å­¦ä¹ å‚è€ƒï¼Œè‹¥éå¿…è¦æ— éœ€å†è‡ªè¡Œè®­ç»ƒï¼ŒMiniMindå·²è‡ªå¸¦tokenizerï¼‰ã€‚ æˆ–è€…é€‰æ‹©æ¯”è¾ƒå‡ºåçš„å¼€æºå¤§æ¨¡å‹åˆ†è¯å™¨ï¼Œ æ­£å¦‚åŒç›´æ¥ç”¨æ–°å/ç‰›æ´¥è¯å…¸çš„ä¼˜ç‚¹æ˜¯tokenç¼–ç å‹ç¼©ç‡å¾ˆå¥½ï¼Œç¼ºç‚¹æ˜¯é¡µæ•°å¤ªå¤šï¼ŒåŠ¨è¾„æ•°åä¸‡ä¸ªè¯æ±‡çŸ­è¯­ï¼› è‡ªå·±è®­ç»ƒçš„åˆ†è¯å™¨ï¼Œä¼˜ç‚¹æ˜¯è¯è¡¨é•¿åº¦å’Œå†…å®¹éšæ„æ§åˆ¶ï¼Œç¼ºç‚¹æ˜¯å‹ç¼©ç‡å¾ˆä½ï¼ˆä¾‹å¦‚&quot;hello&quot;ä¹Ÿè®¸ä¼šè¢«æ‹†åˆ†ä¸º&quot;h e l l o&quot; äº”ä¸ªç‹¬ç«‹çš„tokenï¼‰ï¼Œä¸”ç”Ÿåƒ»è¯éš¾ä»¥è¦†ç›–ã€‚ â€œè¯å…¸â€çš„é€‰æ‹©å›ºç„¶å¾ˆé‡è¦ï¼ŒLLMçš„è¾“å‡ºæœ¬è´¨ä¸Šæ˜¯SoftMaxåˆ°è¯å…¸Nä¸ªè¯çš„å¤šåˆ†ç±»é—®é¢˜ï¼Œç„¶åé€šè¿‡â€œè¯å…¸â€è§£ç åˆ°è‡ªç„¶è¯­è¨€ã€‚ å› ä¸ºMiniMindä½“ç§¯éœ€è¦ä¸¥æ ¼æ§åˆ¶ï¼Œä¸ºäº†é¿å…æ¨¡å‹å¤´é‡è„šè½»ï¼ˆè¯åµŒå…¥embeddingå±‚å‚æ•°åœ¨LLMå æ¯”å¤ªé«˜ï¼‰ï¼Œæ‰€ä»¥è¯è¡¨é•¿åº¦çŸ­çŸ­ç›Šå–„ã€‚&lt;/p&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;Tokenizerä»‹ç»&lt;/summary&gt; 
 &lt;p&gt;ç¬¬ä¸‰æ–¹å¼ºå¤§çš„å¼€æºæ¨¡å‹ä¾‹å¦‚Yiã€qwenã€chatglmã€mistralã€Llama3çš„tokenizerè¯è¡¨é•¿åº¦å¦‚ä¸‹ï¼š&lt;/p&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;th&gt;Tokenizeræ¨¡å‹&lt;/th&gt;
    &lt;th&gt;è¯è¡¨å¤§å°&lt;/th&gt;
    &lt;th&gt;æ¥æº&lt;/th&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;yi tokenizer&lt;/td&gt;
    &lt;td&gt;64,000&lt;/td&gt;
    &lt;td&gt;01ä¸‡ç‰©ï¼ˆä¸­å›½ï¼‰&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;qwen2 tokenizer&lt;/td&gt;
    &lt;td&gt;151,643&lt;/td&gt;
    &lt;td&gt;é˜¿é‡Œäº‘ï¼ˆä¸­å›½ï¼‰&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;glm tokenizer&lt;/td&gt;
    &lt;td&gt;151,329&lt;/td&gt;
    &lt;td&gt;æ™ºè°±AIï¼ˆä¸­å›½ï¼‰&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;mistral tokenizer&lt;/td&gt;
    &lt;td&gt;32,000&lt;/td&gt;
    &lt;td&gt;Mistral AIï¼ˆæ³•å›½ï¼‰&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;llama3 tokenizer&lt;/td&gt;
    &lt;td&gt;128,000&lt;/td&gt;
    &lt;td&gt;Metaï¼ˆç¾å›½ï¼‰&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;minimind tokenizer&lt;/td&gt;
    &lt;td&gt;6,400&lt;/td&gt;
    &lt;td&gt;è‡ªå®šä¹‰&lt;/td&gt;
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ‘‰2024-09-17æ›´æ–°ï¼šä¸ºäº†é˜²æ­¢è¿‡å»çš„ç‰ˆæœ¬æ­§ä¹‰&amp;amp;æ§åˆ¶ä½“ç§¯ï¼Œminimindæ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨minimind_tokenizeråˆ†è¯ï¼ŒåºŸå¼ƒæ‰€æœ‰mistral_tokenizerç‰ˆæœ¬ã€‚&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code&gt;# ä¸€äº›è‡ªè¨€è‡ªè¯­
&amp;gt; å°½ç®¡minimind_tokenizeré•¿åº¦å¾ˆå°ï¼Œç¼–è§£ç æ•ˆç‡å¼±äºqwen2ã€glmç­‰ä¸­æ–‡å‹å¥½å‹åˆ†è¯å™¨ã€‚
&amp;gt; ä½†minimindæ¨¡å‹é€‰æ‹©äº†è‡ªå·±è®­ç»ƒçš„minimind_tokenizerä½œä¸ºåˆ†è¯å™¨ï¼Œä»¥ä¿æŒæ•´ä½“å‚æ•°è½»é‡ï¼Œé¿å…ç¼–ç å±‚å’Œè®¡ç®—å±‚å æ¯”å¤±è¡¡ï¼Œå¤´é‡è„šè½»ï¼Œå› ä¸ºminimindçš„è¯è¡¨å¤§å°åªæœ‰6400ã€‚
&amp;gt; ä¸”minimindåœ¨å®é™…æµ‹è¯•ä¸­æ²¡æœ‰å‡ºç°è¿‡ç”Ÿåƒ»è¯æ±‡è§£ç å¤±è´¥çš„æƒ…å†µï¼Œæ•ˆæœè‰¯å¥½ã€‚
&amp;gt; ç”±äºè‡ªå®šä¹‰è¯è¡¨å‹ç¼©é•¿åº¦åˆ°6400ï¼Œä½¿å¾—LLMæ€»å‚æ•°é‡æœ€ä½åªæœ‰25.8Mã€‚
&amp;gt; è®­ç»ƒæ•°æ®`tokenizer_train.jsonl`å‡æ¥è‡ªäº`åŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†`ï¼Œè¿™éƒ¨åˆ†æ•°æ®ç›¸å¯¹æ¬¡è¦ï¼Œå¦‚éœ€è®­ç»ƒå¯ä»¥è‡ªç”±é€‰æ‹©ã€‚
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;â…¡ Pretrainæ•°æ®&lt;/h2&gt; 
&lt;p&gt;ç»å†äº†MiniMind-V1çš„ä½è´¨é‡é¢„è®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´æ¨¡å‹èƒ¡è¨€ä¹±è¯­çš„æ•™è®­ï¼Œ&lt;code&gt;2025-02-05&lt;/code&gt; ä¹‹åå†³å®šä¸å†é‡‡ç”¨å¤§è§„æ¨¡æ— ç›‘ç£çš„æ•°æ®é›†åšé¢„è®­ç»ƒã€‚ è¿›è€Œå°è¯•æŠŠ&lt;a href=&quot;https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data&quot;&gt;åŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†&lt;/a&gt;çš„ä¸­æ–‡éƒ¨åˆ†æå–å‡ºæ¥ï¼Œ æ¸…æ´—å‡ºå­—ç¬¦&lt;code&gt;&amp;lt;512&lt;/code&gt;é•¿åº¦çš„å¤§çº¦1.6GBçš„è¯­æ–™ç›´æ¥æ‹¼æ¥æˆé¢„è®­ç»ƒæ•°æ® &lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;ï¼Œhqå³ä¸ºhigh qualityï¼ˆå½“ç„¶ä¹Ÿè¿˜ä¸ç®—highï¼Œæå‡æ•°æ®è´¨é‡æ— æ­¢å°½ï¼‰ã€‚&lt;/p&gt; 
&lt;p&gt;æ–‡ä»¶&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; æ•°æ®æ ¼å¼ä¸º&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;{&quot;text&quot;: &quot;å¦‚ä½•æ‰èƒ½æ‘†è„±æ‹–å»¶ç—‡ï¼Ÿ æ²»æ„ˆæ‹–å»¶ç—‡å¹¶ä¸å®¹æ˜“ï¼Œä½†ä»¥ä¸‹å»ºè®®å¯èƒ½æœ‰æ‰€å¸®åŠ©...&quot;}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…¢ SFTæ•°æ®&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data&quot;&gt;åŒ æ•°å¤§æ¨¡å‹SFTæ•°æ®é›†&lt;/a&gt; â€œæ˜¯ä¸€ä¸ªå®Œæ•´ã€æ ¼å¼ç»Ÿä¸€ã€å®‰å…¨çš„å¤§æ¨¡å‹è®­ç»ƒå’Œç ”ç©¶èµ„æºã€‚ ä»ç½‘ç»œä¸Šçš„å…¬å¼€æ•°æ®æºæ”¶é›†å¹¶æ•´ç†äº†å¤§é‡å¼€æºæ•°æ®é›†ï¼Œå¯¹å…¶è¿›è¡Œäº†æ ¼å¼ç»Ÿä¸€ï¼Œæ•°æ®æ¸…æ´—ï¼Œ åŒ…å«10Mæ¡æ•°æ®çš„ä¸­æ–‡æ•°æ®é›†å’ŒåŒ…å«2Mæ¡æ•°æ®çš„è‹±æ–‡æ•°æ®é›†ã€‚â€ ä»¥ä¸Šæ˜¯å®˜æ–¹ä»‹ç»ï¼Œä¸‹è½½æ–‡ä»¶åçš„æ•°æ®æ€»é‡å¤§çº¦åœ¨4B tokensï¼Œè‚¯å®šæ˜¯é€‚åˆä½œä¸ºä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹çš„SFTæ•°æ®çš„ã€‚ ä½†æ˜¯å®˜æ–¹æä¾›çš„æ•°æ®æ ¼å¼å¾ˆä¹±ï¼Œå…¨éƒ¨ç”¨æ¥sftä»£ä»·å¤ªå¤§ã€‚ æˆ‘å°†æŠŠå®˜æ–¹æ•°æ®é›†è¿›è¡Œäº†äºŒæ¬¡æ¸…æ´—ï¼ŒæŠŠå«æœ‰ç¬¦å·æ±¡æŸ“å’Œå™ªå£°çš„æ¡ç›®å»é™¤ï¼›å¦å¤–ä¾ç„¶åªä¿ç•™äº†æ€»é•¿åº¦&lt;code&gt;&amp;lt;512&lt;/code&gt; çš„å†…å®¹ï¼Œæ­¤é˜¶æ®µå¸Œæœ›é€šè¿‡å¤§é‡å¯¹è¯è¡¥å……é¢„è®­ç»ƒé˜¶æ®µæ¬ ç¼ºçš„çŸ¥è¯†ã€‚ å¯¼å‡ºæ–‡ä»¶ä¸º&lt;code&gt;sft_512.jsonl&lt;/code&gt;(~7.5GB)ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.modelscope.cn/organization/Magpie-Align&quot;&gt;Magpie-SFTæ•°æ®é›†&lt;/a&gt; æ”¶é›†äº†~1Mæ¡æ¥è‡ªQwen2/2.5çš„é«˜è´¨é‡å¯¹è¯ï¼Œæˆ‘å°†è¿™éƒ¨åˆ†æ•°æ®è¿›ä¸€æ­¥æ¸…æ´—ï¼ŒæŠŠæ€»é•¿åº¦&lt;code&gt;&amp;lt;2048&lt;/code&gt;çš„éƒ¨åˆ†å¯¼å‡ºä¸º&lt;code&gt;sft_2048.jsonl&lt;/code&gt;(~9GB)ã€‚ é•¿åº¦&lt;code&gt;&amp;lt;1024&lt;/code&gt;çš„éƒ¨åˆ†å¯¼å‡ºä¸º&lt;code&gt;sft_1024.jsonl&lt;/code&gt;(~5.5GB)ï¼Œç”¨å¤§æ¨¡å‹å¯¹è¯æ•°æ®ç›´æ¥è¿›è¡Œsftå°±å±äºâ€œé»‘ç›’è’¸é¦â€çš„èŒƒç•´ã€‚&lt;/p&gt; 
&lt;p&gt;è¿›ä¸€æ­¥æ¸…æ´—å‰ä¸¤æ­¥sftçš„æ•°æ®ï¼ˆåªä¿ç•™ä¸­æ–‡å­—ç¬¦å æ¯”é«˜çš„å†…å®¹ï¼‰ï¼Œç­›é€‰é•¿åº¦&lt;code&gt;&amp;lt;512&lt;/code&gt;çš„å¯¹è¯ï¼Œå¾—åˆ°&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;(~1.2GB)ã€‚&lt;/p&gt; 
&lt;p&gt;æ‰€æœ‰sftæ–‡ä»¶ &lt;code&gt;sft_X.jsonl&lt;/code&gt; æ•°æ®æ ¼å¼å‡ä¸º&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;{
    &quot;conversations&quot;: [
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä½ å¥½&quot;},
        {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;ä½ å¥½ï¼&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;å†è§&quot;},
        {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;å†è§ï¼&quot;}
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…£ RLHFæ•°æ®&lt;/h2&gt; 
&lt;p&gt;æ¥è‡ª&lt;a href=&quot;https://www.modelscope.cn/datasets/Magpie-Align/MagpieLM-DPO-Data-v0.1&quot;&gt;Magpie-DPOæ•°æ®é›†&lt;/a&gt; å¤§çº¦200kæ¡åå¥½æ•°æ®ï¼ˆå‡æ˜¯è‹±æ–‡ï¼‰ç”Ÿæˆè‡ªLlama3.1-70B/8Bï¼Œå¯ä»¥ç”¨äºè®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œä¼˜åŒ–æ¨¡å‹å›å¤è´¨é‡ï¼Œä½¿å…¶æ›´åŠ ç¬¦åˆäººç±»åå¥½ã€‚ è¿™é‡Œå°†æ•°æ®æ€»é•¿åº¦&lt;code&gt;&amp;lt;3000&lt;/code&gt;çš„å†…å®¹é‡ç»„ä¸º&lt;code&gt;dpo.jsonl&lt;/code&gt;(~0.9GB)ï¼ŒåŒ…å«&lt;code&gt;chosen&lt;/code&gt;å’Œ&lt;code&gt;rejected&lt;/code&gt;ä¸¤ä¸ªå­—æ®µï¼Œ&lt;code&gt;chosen&lt;/code&gt; ä¸ºåå¥½çš„å›å¤ï¼Œ&lt;code&gt;rejected&lt;/code&gt;ä¸ºæ‹’ç»çš„å›å¤ã€‚&lt;/p&gt; 
&lt;p&gt;æ–‡ä»¶ &lt;code&gt;dpo.jsonl&lt;/code&gt; æ•°æ®æ ¼å¼ä¸º&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;{
  &quot;chosen&quot;: [
    {&quot;content&quot;: &quot;Q&quot;, &quot;role&quot;: &quot;user&quot;}, 
    {&quot;content&quot;: &quot;good answer&quot;, &quot;role&quot;: &quot;assistant&quot;}
  ], 
  &quot;rejected&quot;: [
    {&quot;content&quot;: &quot;Q&quot;, &quot;role&quot;: &quot;user&quot;}, 
    {&quot;content&quot;: &quot;bad answer&quot;, &quot;role&quot;: &quot;assistant&quot;}
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…¤ Reasonæ•°æ®é›†ï¼š&lt;/h2&gt; 
&lt;p&gt;ä¸å¾—ä¸è¯´2025å¹´2æœˆè°èƒ½ç«çš„è¿‡DeepSeek... ä¹Ÿæ¿€å‘äº†æˆ‘å¯¹RLå¼•å¯¼çš„æ¨ç†æ¨¡å‹çš„æµ“åšå…´è¶£ï¼Œç›®å‰å·²ç»ç”¨Qwen2.5å¤ç°äº†R1-Zeroã€‚ å¦‚æœæœ‰æ—¶é—´+æ•ˆæœworkï¼ˆä½†99%åŸºæ¨¡èƒ½åŠ›ä¸è¶³ï¼‰æˆ‘ä¼šåœ¨ä¹‹åæ›´æ–°MiniMindåŸºäºRLè®­ç»ƒçš„æ¨ç†æ¨¡å‹è€Œä¸æ˜¯è’¸é¦æ¨¡å‹ã€‚ æ—¶é—´æœ‰é™ï¼Œæœ€å¿«çš„ä½æˆæœ¬æ–¹æ¡ˆä¾ç„¶æ˜¯ç›´æ¥è’¸é¦ï¼ˆé»‘ç›’æ–¹å¼ï¼‰ã€‚ è€ä¸ä½R1å¤ªç«ï¼ŒçŸ­çŸ­å‡ å¤©å°±å·²ç»å­˜åœ¨ä¸€äº›R1çš„è’¸é¦æ•°æ®é›†&lt;a href=&quot;https://www.modelscope.cn/datasets/Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B&quot;&gt;R1-Llama-70B&lt;/a&gt;ã€&lt;a href=&quot;https://www.modelscope.cn/datasets/AI-ModelScope/R1-Distill-SFT&quot;&gt;R1-Distill-SFT&lt;/a&gt;ã€ &lt;a href=&quot;https://huggingface.co/datasets/shareAI/Alpaca-Distill-R1-ZH&quot;&gt;Alpaca-Distill-R1&lt;/a&gt;ã€ &lt;a href=&quot;https://huggingface.co/datasets/jinliuxi/deepseek_r1_zh&quot;&gt;deepseek_r1_zh&lt;/a&gt;ç­‰ç­‰ï¼Œçº¯ä¸­æ–‡çš„æ•°æ®å¯èƒ½æ¯”è¾ƒå°‘ã€‚ æœ€ç»ˆæ•´åˆå®ƒä»¬ï¼Œå¯¼å‡ºæ–‡ä»¶ä¸º&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;ï¼Œæ•°æ®æ ¼å¼å’Œ&lt;code&gt;sft_X.jsonl&lt;/code&gt;ä¸€è‡´ã€‚&lt;/p&gt; 
&lt;h2&gt;â…¥ æ›´å¤šæ•°æ®é›†&lt;/h2&gt; 
&lt;p&gt;ç›®å‰å·²ç»æœ‰&lt;a href=&quot;https://github.com/HqWu-HITCS/Awesome-Chinese-LLM&quot;&gt;HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt; åœ¨æ”¶é›†å’Œæ¢³ç†ä¸­æ–‡LLMç›¸å…³çš„å¼€æºæ¨¡å‹ã€åº”ç”¨ã€æ•°æ®é›†åŠæ•™ç¨‹ç­‰èµ„æ–™ï¼Œå¹¶æŒç»­æ›´æ–°è¿™æ–¹é¢çš„æœ€æ–°è¿›å±•ã€‚å…¨é¢ä¸”ä¸“ä¸šï¼ŒRespectï¼&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;â…§ æ•°æ®é›†ä¸‹è½½&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] 2025-02-05åï¼Œå¼€æºMiniMindæœ€ç»ˆè®­ç»ƒæ‰€ç”¨çš„æ‰€æœ‰æ•°æ®é›†ï¼Œå› æ­¤æ— éœ€å†è‡ªè¡Œé¢„å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ï¼Œé¿å…é‡å¤æ€§çš„æ•°æ®å¤„ç†å·¥ä½œã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MiniMindè®­ç»ƒæ•°æ®é›† (&lt;a href=&quot;https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files&quot;&gt;ModelScope&lt;/a&gt; | &lt;a href=&quot;https://huggingface.co/datasets/jingyaogong/minimind_dataset/tree/main&quot;&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ— éœ€å…¨éƒ¨cloneï¼Œå¯å•ç‹¬ä¸‹è½½æ‰€éœ€çš„æ–‡ä»¶&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;å°†ä¸‹è½½çš„æ•°æ®é›†æ–‡ä»¶æ”¾åˆ°&lt;code&gt;./dataset/&lt;/code&gt;ç›®å½•ä¸‹ï¼ˆâœ¨ä¸ºæ¨èçš„å¿…é¡»é¡¹ï¼‰&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;./dataset/
â”œâ”€â”€ dpo.jsonl (909MB)
â”œâ”€â”€ lora_identity.jsonl (22.8KB)
â”œâ”€â”€ lora_medical.jsonl (34MB)
â”œâ”€â”€ pretrain_hq.jsonl (1.6GB, âœ¨)
â”œâ”€â”€ r1_mix_1024.jsonl (340MB)
â”œâ”€â”€ sft_1024.jsonl (5.6GB)
â”œâ”€â”€ sft_2048.jsonl (9GB)
â”œâ”€â”€ sft_512.jsonl (7.5GB)
â”œâ”€â”€ sft_mini_512.jsonl (1.2GB, âœ¨)
â””â”€â”€ tokenizer_train.jsonl (1GB)
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;æ³¨ï¼šå„æ•°æ®é›†ç®€ä»‹&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;dpo.jsonl&lt;/code&gt; --RLHFé˜¶æ®µæ•°æ®é›†&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_identity.jsonl&lt;/code&gt; --è‡ªæˆ‘è®¤çŸ¥æ•°æ®é›†ï¼ˆä¾‹å¦‚ï¼šä½ æ˜¯è°ï¼Ÿæˆ‘æ˜¯minimind...ï¼‰ï¼Œæ¨èç”¨äºloraè®­ç»ƒï¼ˆäº¦å¯ç”¨äºå…¨å‚SFTï¼Œå‹¿è¢«åå­—å±€é™ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_medical.jsonl&lt;/code&gt; --åŒ»ç–—é—®ç­”æ•°æ®é›†ï¼Œæ¨èç”¨äºloraè®­ç»ƒï¼ˆäº¦å¯ç”¨äºå…¨å‚SFTï¼Œå‹¿è¢«åå­—å±€é™ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;âœ¨ --é¢„è®­ç»ƒæ•°æ®é›†ï¼Œæ•´åˆè‡ªjiangshuç§‘æŠ€&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt; --DeepSeek-R1-1.5Bè’¸é¦æ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º1024ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=1024ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_1024.jsonl&lt;/code&gt; --æ•´åˆè‡ªQwen2.5è’¸é¦æ•°æ®ï¼ˆæ˜¯sft_2048çš„å­é›†ï¼‰ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º1024ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=1024ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_2048.jsonl&lt;/code&gt; --æ•´åˆè‡ªQwen2.5è’¸é¦æ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º2048ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=2048ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_512.jsonl&lt;/code&gt; --æ•´åˆè‡ªåŒ æ•°ç§‘æŠ€SFTæ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º512ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=512ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;âœ¨ --æç®€æ•´åˆè‡ªåŒ æ•°ç§‘æŠ€SFTæ•°æ®+Qwen2.5è’¸é¦æ•°æ®ï¼ˆç”¨äºå¿«é€Ÿè®­ç»ƒZeroæ¨¡å‹ï¼‰ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º512ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=512ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;tokenizer_train.jsonl&lt;/code&gt; --å‡æ¥è‡ªäº&lt;code&gt;åŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†&lt;/code&gt;ï¼Œè¿™éƒ¨åˆ†æ•°æ®ç›¸å¯¹æ¬¡è¦ï¼Œï¼ˆä¸æ¨èè‡ªå·±é‡å¤è®­ç»ƒtokenizerï¼Œç†ç”±å¦‚ä¸Šï¼‰å¦‚éœ€è‡ªå·±è®­ç»ƒtokenizerå¯ä»¥è‡ªç”±é€‰æ‹©æ•°æ®é›†ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/dataset.jpg&quot; alt=&quot;dataset&quot;&gt;&lt;/p&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;è¯´æ˜ &amp;amp; æ¨èè®­ç»ƒæ–¹æ¡ˆ&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;MiniMind2 Serieså‡ç»è¿‡å…±çº¦20GBè¯­æ–™è®­ç»ƒï¼Œå¤§çº¦4B tokensï¼Œå³å¯¹åº”ä¸Šé¢çš„æ•°æ®ç»„åˆè®­ç»ƒç»“æœï¼ˆå¼€é”€ï¼šğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ï¼Œæ•ˆæœï¼šğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜Šï¼‰&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;æƒ³è¦æœ€å¿«é€Ÿåº¦ä»0å®ç°Zeroæ¨¡å‹ï¼Œæ¨èä½¿ç”¨&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt; çš„æ•°æ®ç»„åˆï¼Œå…·ä½“èŠ±é”€å’Œæ•ˆæœå¯æŸ¥çœ‹ä¸‹æ–‡è¡¨æ ¼ï¼ˆå¼€é”€ï¼šğŸ’°ï¼Œæ•ˆæœï¼šğŸ˜ŠğŸ˜Šï¼‰&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;æ¨èå…·å¤‡ä¸€å®šç®—åŠ›èµ„æºæˆ–æ›´åœ¨æ„æ•ˆæœçš„æœ‹å‹å¯ä»¥è€ƒè™‘å‰è€…å®Œæ•´å¤ç°MiniMind2ï¼›ä»…æœ‰å•å¡GPUæˆ–åœ¨ä¹çŸ­æ—¶é—´å¿«é€Ÿå¤ç°çš„æœ‹å‹å¼ºçƒˆæ¨èåè€…ï¼›&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;ã€æŠ˜ä¸­æ–¹æ¡ˆã€‘äº¦å¯é€‰æ‹©ä¾‹å¦‚&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;ã€&lt;code&gt;sft_1024.jsonl&lt;/code&gt;ä¸­ç­‰è§„æ¨¡æ•°æ®è¿›è¡Œè‡ªç”±ç»„åˆè®­ç»ƒï¼ˆå¼€é”€ï¼šğŸ’°ğŸ’°ğŸ’°ï¼Œæ•ˆæœï¼šğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜Šï¼‰ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;ğŸ“Œ Model Structure&lt;/h1&gt; 
&lt;p&gt;MiniMind-Denseï¼ˆå’Œ&lt;a href=&quot;https://ai.meta.com/blog/meta-llama-3-1/&quot;&gt;Llama3.1&lt;/a&gt;ä¸€æ ·ï¼‰ä½¿ç”¨äº†Transformerçš„Decoder-Onlyç»“æ„ï¼Œè·ŸGPT-3çš„åŒºåˆ«åœ¨äºï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;é‡‡ç”¨äº†GPT-3çš„é¢„æ ‡å‡†åŒ–æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯åœ¨æ¯ä¸ªTransformerå­å±‚çš„è¾“å…¥ä¸Šè¿›è¡Œå½’ä¸€åŒ–ï¼Œè€Œä¸æ˜¯åœ¨è¾“å‡ºä¸Šã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨çš„æ˜¯RMSNormå½’ä¸€åŒ–å‡½æ•°ã€‚&lt;/li&gt; 
 &lt;li&gt;ç”¨SwiGLUæ¿€æ´»å‡½æ•°æ›¿ä»£äº†ReLUï¼Œè¿™æ ·åšæ˜¯ä¸ºäº†æé«˜æ€§èƒ½ã€‚&lt;/li&gt; 
 &lt;li&gt;åƒGPT-Neoä¸€æ ·ï¼Œå»æ‰äº†ç»å¯¹ä½ç½®åµŒå…¥ï¼Œæ”¹ç”¨äº†æ—‹è½¬ä½ç½®åµŒå…¥ï¼ˆRoPEï¼‰ï¼Œè¿™æ ·åœ¨å¤„ç†è¶…å‡ºè®­ç»ƒé•¿åº¦çš„æ¨ç†æ—¶æ•ˆæœæ›´å¥½ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;MiniMind-MoEæ¨¡å‹ï¼Œå®ƒçš„ç»“æ„åŸºäºLlama3å’Œ&lt;a href=&quot;https://arxiv.org/pdf/2405.04434&quot;&gt;Deepseek-V2/3&lt;/a&gt;ä¸­çš„MixFFNæ··åˆä¸“å®¶æ¨¡å—ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-V2åœ¨å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰æ–¹é¢ï¼Œé‡‡ç”¨äº†æ›´ç»†ç²’åº¦çš„ä¸“å®¶åˆ†å‰²å’Œå…±äº«çš„ä¸“å®¶éš”ç¦»æŠ€æœ¯ï¼Œä»¥æé«˜Expertsçš„æ•ˆæœã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;MiniMindçš„æ•´ä½“ç»“æ„ä¸€è‡´ï¼Œåªæ˜¯åœ¨RoPEè®¡ç®—ã€æ¨ç†å‡½æ•°å’ŒFFNå±‚çš„ä»£ç ä¸Šåšäº†ä¸€äº›å°è°ƒæ•´ã€‚ å…¶ç»“æ„å¦‚ä¸‹å›¾ï¼ˆé‡ç»˜ç‰ˆï¼‰ï¼š&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure.png&quot; alt=&quot;structure&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure-moe.png&quot; alt=&quot;structure-moe&quot;&gt;&lt;/p&gt; 
&lt;p&gt;ä¿®æ”¹æ¨¡å‹é…ç½®è§&lt;a href=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/model/LMConfig.py&quot;&gt;./model/LMConfig.py&lt;/a&gt;ã€‚ å‚è€ƒæ¨¡å‹å‚æ•°ç‰ˆæœ¬è§ä¸‹è¡¨ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;len_vocab&lt;/th&gt; 
   &lt;th&gt;rope_theta&lt;/th&gt; 
   &lt;th&gt;n_layers&lt;/th&gt; 
   &lt;th&gt;d_model&lt;/th&gt; 
   &lt;th&gt;kv_heads&lt;/th&gt; 
   &lt;th&gt;q_heads&lt;/th&gt; 
   &lt;th&gt;share+route&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;640&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-moe&lt;/td&gt; 
   &lt;td&gt;4Ã—26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1&lt;/td&gt; 
   &lt;td&gt;108M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;ğŸ“Œ Experiment&lt;/h1&gt; 
&lt;h2&gt;â…  è®­ç»ƒå¼€é”€&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æ—¶é—´å•ä½&lt;/strong&gt;ï¼šå°æ—¶ (h)ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æˆæœ¬å•ä½&lt;/strong&gt;ï¼šäººæ°‘å¸ (ï¿¥)ï¼›7ï¿¥ â‰ˆ 1ç¾å…ƒã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;3090 ç§Ÿå¡å•ä»·&lt;/strong&gt;ï¼šâ‰ˆ1.3ï¿¥/hï¼ˆå¯è‡ªè¡Œå‚è€ƒå®æ—¶å¸‚ä»·ï¼‰ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å‚è€ƒæ ‡å‡†&lt;/strong&gt;ï¼šè¡¨æ ¼ä»…å®æµ‹ &lt;code&gt;pretrain&lt;/code&gt; å’Œ &lt;code&gt;sft_mini_512&lt;/code&gt; ä¸¤ä¸ªæ•°æ®é›†çš„è®­ç»ƒæ—¶é—´ï¼Œå…¶å®ƒè€—æ—¶æ ¹æ®æ•°æ®é›†å¤§å°ä¼°ç®—ï¼ˆå¯èƒ½å­˜åœ¨äº›è®¸å‡ºå…¥ï¼‰ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;åŸºäº 3090 ï¼ˆå•å¡ï¼‰æˆæœ¬è®¡ç®—&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;pretrain&lt;/th&gt; 
   &lt;th&gt;sft_mini_512&lt;/th&gt; 
   &lt;th&gt;sft_512&lt;/th&gt; 
   &lt;th&gt;sft_1024&lt;/th&gt; 
   &lt;th&gt;sft_2048&lt;/th&gt; 
   &lt;th&gt;RLHF&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;â‰ˆ1.1h&lt;br&gt;â‰ˆ1.43ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ1h&lt;br&gt;â‰ˆ1.3ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ6h&lt;br&gt;â‰ˆ7.8ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ4.58h&lt;br&gt;â‰ˆ5.95ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ7.5h&lt;br&gt;â‰ˆ9.75ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ1h&lt;br&gt;â‰ˆ1.3ï¿¥&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;â‰ˆ3.9h&lt;br&gt;â‰ˆ5.07ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ3.3h&lt;br&gt;â‰ˆ4.29ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ20h&lt;br&gt;â‰ˆ26ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ15h&lt;br&gt;â‰ˆ19.5ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ25h&lt;br&gt;â‰ˆ32.5ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ3h&lt;br&gt;â‰ˆ3.9ï¿¥&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;è®­ç»ƒå¼€é”€æ€»ç»“&amp;amp;é¢„æµ‹&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-Smallå‚æ•°&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_mini_512&lt;/code&gt;æ•°æ®é›† &lt;br&gt;å•å¡3090 (1 epoch) + 2.1å°æ—¶ + èŠ±è´¹2.73å…ƒäººæ°‘å¸ &lt;br&gt;å³å¯ä»0è®­ç»ƒå‡ºMiniMind-Zero-0.025Bæ¨¡å‹!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-Smallå‚æ•°&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;æ•°æ®é›† &lt;br&gt;å•å¡3090 (2 epochs) + å¤§çº¦38.16å°æ—¶ + èŠ±è´¹49.61å…ƒäººæ°‘å¸ &lt;br&gt;å³å¯ä»0è®­ç»ƒå‡ºMiniMind2-Small-0.025Bæ¨¡å‹!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2å‚æ•°&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;æ•°æ®é›† &lt;br&gt;å•å¡3090 (2 epochs) + å¤§çº¦122å°æ—¶ + èŠ±è´¹158.6å…ƒäººæ°‘å¸ &lt;br&gt;å³å¯ä»0è®­ç»ƒå‡ºMiniMind2-0.1Bæ¨¡å‹!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;p&gt;âœ¨åŸºäºå•å¡NVIDIA 3090çš„&lt;code&gt;MiniMind-Zero&lt;/code&gt;ä»0è®­ç»ƒä»…éœ€&lt;code&gt;2å°æ—¶&lt;/code&gt; + &lt;code&gt;3å—é’±&lt;/code&gt;ï¼Œå®ç°ChatBotæ•ˆæœï¼&lt;/p&gt; 
&lt;p&gt;âœ¨PSï¼šè‹¥é‡‡ç”¨8å¡4090è®­ç»ƒï¼Œæ€»ç”¨æ—¶ç”šè‡³å¯ä»¥å‹ç¼©åˆ°10åˆ†é’Ÿä»¥å†…ï¼ï¼ˆç”±äºæ—¶é—´æ›´çŸ­ï¼ŒèŠ±è´¹åŒæ ·3å…ƒå·¦å³ï¼Œä¸å•å¡æˆæœ¬ç›¸å½“ï¼‰&lt;/p&gt; 
&lt;p&gt;âœ¨ä»¥æä½æä½çš„é—¨æ§›ï¼Œå®ç°äººäººå¯ç©çš„å¤§æ¨¡å‹è‡ªç”±ï¼è¿™æ­£æ˜¯MiniMindç³»åˆ—çš„è¯ç”Ÿåˆè¡·ï¼&lt;/p&gt; 
&lt;p&gt;âœ¨ä»…ä»·å€¼&lt;code&gt;3å—é’±&lt;/code&gt;æˆæœ¬çš„&lt;code&gt;MiniMind-Zero&lt;/code&gt;å¹¶ä¸æ˜¯å™±å¤´ï¼Chatæµ‹è¯•ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ğŸ‘¶: è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚
ğŸ¤–ï¸: ä½œä¸ºäººå·¥æ™ºèƒ½ï¼Œæˆ‘æ²¡æœ‰å®é™…çš„ç”Ÿæ´»ï¼Œä¹Ÿæ²¡æœ‰è‡ªæˆ‘æ„è¯†ï¼Œæ‰€ä»¥æ²¡æœ‰è‡ªå·±çš„ç”Ÿæ´»ã€‚æˆ‘è¢«è®¾è®¡æˆèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯ã€è¿›è¡Œå¯¹è¯ç­‰ã€‚æˆ‘çš„è®¾è®¡å’ŒåŠŸèƒ½æ˜¯ç”±è®¡ç®—æœºç§‘å­¦ã€æœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½æŠ€æœ¯å’Œç®—æ³•æ‰€æ„å»ºçš„ï¼Œæˆ‘é€šè¿‡ç¼–ç¨‹å’Œç®—æ³•å®ç°ã€‚

ğŸ‘¶: æ¨èä¸€äº›æ­å·çš„ç‰¹è‰²ç¾é£Ÿå§ã€‚
ğŸ¤–ï¸: æ­å·æœ‰å¾ˆå¤šç¾å‘³çš„ç‰¹è‰²ç¾é£Ÿï¼Œæ¯”å¦‚é¸¡è‚‰ä¸²ã€é³—é±¼å¤´ã€æ°´ç…®é±¼ã€è±†è…è„‘ç­‰ã€‚è¿™äº›ç¾é£Ÿéƒ½éå¸¸ç¾å‘³ï¼Œæœ‰ç€ç‹¬ç‰¹çš„é£å‘³å’Œå£æ„Ÿï¼Œç»å¯¹æ˜¯å€¼å¾—ä¸€è¯•çš„ç¾é£Ÿã€‚

ğŸ‘¶: è¯·ä¸ºæˆ‘è®²è§£â€œå¤§è¯­è¨€æ¨¡å‹â€è¿™ä¸ªæ¦‚å¿µã€‚
ğŸ¤–ï¸: å¤§è¯­è¨€æ¨¡å‹æ˜¯ä¸€ç§äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨å¤§é‡çš„æ–‡æœ¬æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ï¼Œç„¶ååœ¨ä¸æ–­çš„è¿­ä»£ä¸­ä¸æ–­ä¼˜åŒ–æ¨¡å‹ã€‚å®ƒçš„ç›®æ ‡æ˜¯æ ¹æ®è¾“å…¥çš„æ•°æ®æ¥ç”Ÿæˆç¬¦åˆç‰¹å®šéœ€æ±‚çš„æ–‡æœ¬ï¼Œè¿™äº›æ–‡æœ¬å¯ä»¥æ˜¯ä»»ä½•ä½ æ„Ÿå…´è¶£çš„ä¸»é¢˜ã€‚

ğŸ‘¶: Introduce the history of the United States, please.
ğŸ¤–ï¸: æ‚¨æåˆ°çš„â€œIntrook&#39;s the believeations of theument.&quot; è¿™ä¸ªåå­—æ¥æºäºä¸­å›½å¤ä»£çš„&quot;groty of of the change.&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æé€Ÿä¸”åˆå…·æ•ˆæœï¼Œç”šè‡³ä»ç„¶å¯ä»¥è¿›ä¸€æ­¥å‹ç¼©è·å–æ›´å°æ›´ä¼˜è´¨çš„è®­ç»ƒæ•°æ®ã€‚ Zeroæ¨¡å‹æƒé‡ä¿å­˜ä¸º &lt;code&gt;full_sft_512_zero.pth&lt;/code&gt;ï¼ˆè§ä¸‹æ–‡MiniMindæ¨¡å‹æ–‡ä»¶é“¾æ¥ï¼‰ï¼Œå¦‚æœ‰å…´è¶£å¯ä¸‹è½½æ£€éªŒæ­¤æ¨¡å‹æ•ˆæœã€‚&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;â…¡ ä¸»è¦è®­ç»ƒæ­¥éª¤&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;1. é¢„è®­ç»ƒ(Pretrain)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;LLMé¦–å…ˆè¦å­¦ä¹ çš„å¹¶éç›´æ¥ä¸äººäº¤æµï¼Œè€Œæ˜¯è®©ç½‘ç»œå‚æ•°ä¸­å……æ»¡çŸ¥è¯†çš„å¢¨æ°´ï¼Œâ€œå¢¨æ°´â€ ç†è®ºä¸Šå–çš„è¶Šé¥±è¶Šå¥½ï¼Œäº§ç”Ÿå¤§é‡çš„å¯¹ä¸–ç•Œçš„çŸ¥è¯†ç§¯ç´¯ã€‚ é¢„è®­ç»ƒå°±æ˜¯è®©Modelå…ˆåŸ‹å¤´è‹¦å­¦å¤§é‡åŸºæœ¬çš„çŸ¥è¯†ï¼Œä¾‹å¦‚ä»Wikiç™¾ç§‘ã€æ–°é—»ã€ä¹¦ç±æ•´ç†å¤§è§„æ¨¡çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚ è¿™ä¸ªè¿‡ç¨‹æ˜¯â€œæ— ç›‘ç£â€çš„ï¼Œå³äººç±»ä¸éœ€è¦åœ¨è¿‡ç¨‹ä¸­åšä»»ä½•â€œæœ‰ç›‘ç£â€çš„æ ¡æ­£ï¼Œè€Œæ˜¯ç”±æ¨¡å‹è‡ªå·±ä»å¤§é‡æ–‡æœ¬ä¸­æ€»ç»“è§„å¾‹å­¦ä¹ çŸ¥è¯†ç‚¹ã€‚ æ¨¡å‹æ­¤é˜¶æ®µç›®çš„åªæœ‰ä¸€ä¸ªï¼š&lt;strong&gt;å­¦ä¼šè¯è¯­æ¥é¾™&lt;/strong&gt;ã€‚ä¾‹å¦‚æˆ‘ä»¬è¾“å…¥â€œç§¦å§‹çš‡â€å››ä¸ªå­—ï¼Œå®ƒå¯ä»¥æ¥é¾™â€œæ˜¯ä¸­å›½çš„ç¬¬ä¸€ä½çš‡å¸â€ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;torchrun --nproc_per_node 1 train_pretrain.py # 1å³ä¸ºå•å¡è®­ç»ƒï¼Œå¯æ ¹æ®ç¡¬ä»¶æƒ…å†µè‡ªè¡Œè°ƒæ•´ (è®¾ç½®&amp;gt;=2)
# or
python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;pretrain_*.pth&lt;/code&gt;ï¼ˆ* ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;2. æœ‰ç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;ç»è¿‡é¢„è®­ç»ƒï¼ŒLLMæ­¤æ—¶å·²ç»æŒæ¡äº†å¤§é‡çŸ¥è¯†ï¼Œç„¶è€Œæ­¤æ—¶å®ƒåªä¼šæ— è„‘åœ°è¯è¯­æ¥é¾™ï¼Œè¿˜ä¸ä¼šä¸äººèŠå¤©ã€‚ SFTé˜¶æ®µå°±éœ€è¦æŠŠåŠæˆå“LLMæ–½åŠ ä¸€ä¸ªè‡ªå®šä¹‰çš„èŠå¤©æ¨¡æ¿è¿›è¡Œå¾®è°ƒã€‚ ä¾‹å¦‚æ¨¡å‹é‡åˆ°è¿™æ ·çš„æ¨¡æ¿ã€é—®é¢˜-&amp;gt;å›ç­”ï¼Œé—®é¢˜-&amp;gt;å›ç­”ã€‘åä¸å†æ— è„‘æ¥é¾™ï¼Œè€Œæ˜¯æ„è¯†åˆ°è¿™æ˜¯ä¸€æ®µå®Œæ•´çš„å¯¹è¯ç»“æŸã€‚ ç§°è¿™ä¸ªè¿‡ç¨‹ä¸ºæŒ‡ä»¤å¾®è°ƒï¼Œå°±å¦‚åŒè®©å·²ç»å­¦å¯Œäº”è½¦çš„ã€Œç‰›é¡¿ã€å…ˆç”Ÿé€‚åº”21ä¸–çºªæ™ºèƒ½æ‰‹æœºçš„èŠå¤©ä¹ æƒ¯ï¼Œå­¦ä¹ å±å¹•å·¦ä¾§æ˜¯å¯¹æ–¹æ¶ˆæ¯ï¼Œå³ä¾§æ˜¯æœ¬äººæ¶ˆæ¯è¿™ä¸ªè§„å¾‹ã€‚ åœ¨è®­ç»ƒæ—¶ï¼ŒMiniMindçš„æŒ‡ä»¤å’Œå›ç­”é•¿åº¦è¢«æˆªæ–­åœ¨512ï¼Œæ˜¯ä¸ºäº†èŠ‚çœæ˜¾å­˜ç©ºé—´ã€‚å°±åƒæˆ‘ä»¬å­¦ä¹ æ—¶ï¼Œä¼šå…ˆä»çŸ­çš„æ–‡ç« å¼€å§‹ï¼Œå½“å­¦ä¼šå†™ä½œ200å­—ä½œæ–‡åï¼Œ800å­—æ–‡ç« ä¹Ÿå¯ä»¥æ‰‹åˆ°æ“’æ¥ã€‚ åœ¨éœ€è¦é•¿åº¦æ‹“å±•æ—¶ï¼Œåªéœ€è¦å‡†å¤‡å°‘é‡çš„2k/4k/8ké•¿åº¦å¯¹è¯æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥å¾®è°ƒå³å¯ï¼ˆæ­¤æ—¶æœ€å¥½é…åˆRoPE-NTKçš„åŸºå‡†å·®å€¼ï¼‰ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;åœ¨æ¨ç†æ—¶é€šè¿‡è°ƒæ•´RoPEçº¿æ€§å·®å€¼ï¼Œå®ç°å…è®­ç»ƒé•¿åº¦å¤–æ¨åˆ°2048åŠä»¥ä¸Šå°†ä¼šå¾ˆæ–¹ä¾¿ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;full_sft_*.pth&lt;/code&gt;ï¼ˆ* ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;â…¢ å…¶å®ƒè®­ç»ƒæ­¥éª¤&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;3. äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ (Reinforcement Learning from Human Feedback, RLHF)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;åœ¨å‰é¢çš„è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¨¡å‹å·²ç»å…·å¤‡äº†åŸºæœ¬çš„å¯¹è¯èƒ½åŠ›ï¼Œä½†æ˜¯è¿™æ ·çš„èƒ½åŠ›å®Œå…¨åŸºäºå•è¯æ¥é¾™ï¼Œç¼ºå°‘æ­£åæ ·ä¾‹çš„æ¿€åŠ±ã€‚ æ¨¡å‹æ­¤æ—¶å°šæœªçŸ¥ä»€ä¹ˆå›ç­”æ˜¯å¥½çš„ï¼Œä»€ä¹ˆæ˜¯å·®çš„ã€‚æˆ‘ä»¬å¸Œæœ›å®ƒèƒ½å¤Ÿæ›´ç¬¦åˆäººçš„åå¥½ï¼Œé™ä½è®©äººç±»ä¸æ»¡æ„ç­”æ¡ˆçš„äº§ç”Ÿæ¦‚ç‡ã€‚ è¿™ä¸ªè¿‡ç¨‹å°±åƒæ˜¯è®©æ¨¡å‹å‚åŠ æ–°çš„åŸ¹è®­ï¼Œä»ä¼˜ç§€å‘˜å·¥çš„ä½œä¸ºä¾‹å­ï¼Œæ¶ˆæå‘˜å·¥ä½œä¸ºåä¾‹ï¼Œå­¦ä¹ å¦‚ä½•æ›´å¥½åœ°å›å¤ã€‚ æ­¤å¤„ä½¿ç”¨çš„æ˜¯RLHFç³»åˆ—ä¹‹-ç›´æ¥åå¥½ä¼˜åŒ–(Direct Preference Optimization, DPO)ã€‚ ä¸PPO(Proximal Policy Optimization)è¿™ç§éœ€è¦å¥–åŠ±æ¨¡å‹ã€ä»·å€¼æ¨¡å‹çš„RLç®—æ³•ä¸åŒï¼› DPOé€šè¿‡æ¨å¯¼PPOå¥–åŠ±æ¨¡å‹çš„æ˜¾å¼è§£ï¼ŒæŠŠåœ¨çº¿å¥–åŠ±æ¨¡å‹æ¢æˆç¦»çº¿æ•°æ®ï¼ŒRefæ¨¡å‹è¾“å‡ºå¯ä»¥æå‰ä¿å­˜ã€‚ DPOæ€§èƒ½å‡ ä¹ä¸å˜ï¼Œåªç”¨è·‘ actor_model å’Œ ref_model ä¸¤ä¸ªæ¨¡å‹ï¼Œå¤§å¤§èŠ‚çœæ˜¾å­˜å¼€é”€å’Œå¢åŠ è®­ç»ƒç¨³å®šæ€§ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨ï¼šRLHFè®­ç»ƒæ­¥éª¤&lt;strong&gt;å¹¶éå¿…é¡»&lt;/strong&gt;ï¼Œæ­¤æ­¥éª¤éš¾ä»¥æå‡æ¨¡å‹â€œæ™ºåŠ›â€è€Œé€šå¸¸ä»…ç”¨äºæå‡æ¨¡å‹çš„â€œç¤¼è²Œâ€ï¼Œæœ‰åˆ©ï¼ˆç¬¦åˆåå¥½ã€å‡å°‘æœ‰å®³å†…å®¹ï¼‰ä¹Ÿæœ‰å¼Šï¼ˆæ ·æœ¬æ”¶é›†æ˜‚è´µã€åé¦ˆåå·®ã€å¤šæ ·æ€§æŸå¤±ï¼‰ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;torchrun --nproc_per_node 1 train_dpo.py
# or
python train_dpo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;rlhf_*.pth&lt;/code&gt;ï¼ˆ* ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;4. çŸ¥è¯†è’¸é¦(Knowledge Distillation, KD)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;åœ¨å‰é¢çš„æ‰€æœ‰è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¨¡å‹å·²ç»å®Œå…¨å…·å¤‡äº†åŸºæœ¬èƒ½åŠ›ï¼Œé€šå¸¸å¯ä»¥å­¦æˆå‡ºå¸ˆäº†ã€‚ è€ŒçŸ¥è¯†è’¸é¦å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡ï¼Œæ‰€è°“çŸ¥è¯†è’¸é¦ï¼Œå³å­¦ç”Ÿæ¨¡å‹é¢å‘æ•™å¸ˆæ¨¡å‹å­¦ä¹ ã€‚ æ•™å¸ˆæ¨¡å‹é€šå¸¸æ˜¯ç»è¿‡å……åˆ†è®­ç»ƒçš„å¤§æ¨¡å‹ï¼Œå…·æœ‰è¾ƒé«˜çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ å­¦ç”Ÿæ¨¡å‹æ˜¯ä¸€ä¸ªè¾ƒå°çš„æ¨¡å‹ï¼Œç›®æ ‡æ˜¯å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„è¡Œä¸ºï¼Œè€Œä¸æ˜¯ç›´æ¥ä»åŸå§‹æ•°æ®ä¸­å­¦ä¹ ã€‚ åœ¨SFTå­¦ä¹ ä¸­ï¼Œæ¨¡å‹çš„ç›®æ ‡æ˜¯æ‹Ÿåˆè¯Tokenåˆ†ç±»ç¡¬æ ‡ç­¾ï¼ˆhard labelsï¼‰ï¼Œå³çœŸå®çš„ç±»åˆ«æ ‡ç­¾ï¼ˆå¦‚ 0 æˆ– 6400ï¼‰ã€‚ åœ¨çŸ¥è¯†è’¸é¦ä¸­ï¼Œæ•™å¸ˆæ¨¡å‹çš„softmaxæ¦‚ç‡åˆ†å¸ƒè¢«ç”¨ä½œè½¯æ ‡ç­¾ï¼ˆsoft labelsï¼‰ã€‚å°æ¨¡å‹ä»…å­¦ä¹ è½¯æ ‡ç­¾ï¼Œå¹¶ä½¿ç”¨KL-Lossæ¥ä¼˜åŒ–æ¨¡å‹çš„å‚æ•°ã€‚ é€šä¿—åœ°è¯´ï¼ŒSFTç›´æ¥å­¦ä¹ è€å¸ˆç»™çš„è§£é¢˜ç­”æ¡ˆã€‚è€ŒKDè¿‡ç¨‹ç›¸å½“äºâ€œæ‰“å¼€â€è€å¸ˆèªæ˜çš„å¤§è„‘ï¼Œå°½å¯èƒ½åœ°æ¨¡ä»¿è€å¸ˆâ€œå¤§è„‘â€æ€è€ƒé—®é¢˜çš„ç¥ç»å…ƒçŠ¶æ€ã€‚ ä¾‹å¦‚ï¼Œå½“è€å¸ˆæ¨¡å‹è®¡ç®—&lt;code&gt;1+1=2&lt;/code&gt;è¿™ä¸ªé—®é¢˜çš„æ—¶å€™ï¼Œæœ€åä¸€å±‚ç¥ç»å…ƒaçŠ¶æ€ä¸º0ï¼Œç¥ç»å…ƒbçŠ¶æ€ä¸º100ï¼Œç¥ç»å…ƒcçŠ¶æ€ä¸º-99... å­¦ç”Ÿæ¨¡å‹é€šè¿‡å¤§é‡æ•°æ®ï¼Œå­¦ä¹ æ•™å¸ˆæ¨¡å‹å¤§è„‘å†…éƒ¨çš„è¿è½¬è§„å¾‹ã€‚è¿™ä¸ªè¿‡ç¨‹å³ç§°ä¹‹ä¸ºï¼šçŸ¥è¯†è’¸é¦ã€‚ çŸ¥è¯†è’¸é¦çš„ç›®çš„åªæœ‰ä¸€ä¸ªï¼šè®©å°æ¨¡å‹ä½“ç§¯æ›´å°çš„åŒæ—¶æ•ˆæœæ›´å¥½ã€‚ ç„¶è€Œéšç€LLMè¯ç”Ÿå’Œå‘å±•ï¼Œæ¨¡å‹è’¸é¦ä¸€è¯è¢«å¹¿æ³›æ»¥ç”¨ï¼Œä»è€Œäº§ç”Ÿäº†â€œç™½ç›’/é»‘ç›’â€çŸ¥è¯†è’¸é¦ä¸¤ä¸ªæ´¾åˆ«ã€‚ GPT-4è¿™ç§é—­æºæ¨¡å‹ï¼Œç”±äºæ— æ³•è·å–å…¶å†…éƒ¨ç»“æ„ï¼Œå› æ­¤åªèƒ½é¢å‘å®ƒæ‰€è¾“å‡ºçš„æ•°æ®å­¦ä¹ ï¼Œè¿™ä¸ªè¿‡ç¨‹ç§°ä¹‹ä¸ºé»‘ç›’è’¸é¦ï¼Œä¹Ÿæ˜¯å¤§æ¨¡å‹æ—¶ä»£æœ€æ™®éçš„åšæ³•ã€‚ é»‘ç›’è’¸é¦ä¸SFTè¿‡ç¨‹å®Œå…¨ä¸€è‡´ï¼Œåªä¸è¿‡æ•°æ®æ˜¯ä»å¤§æ¨¡å‹çš„è¾“å‡ºæ”¶é›†ï¼Œå› æ­¤åªéœ€è¦å‡†å¤‡æ•°æ®å¹¶ä¸”è¿›ä¸€æ­¥FTå³å¯ã€‚ æ³¨æ„æ›´æ”¹è¢«åŠ è½½çš„åŸºç¡€æ¨¡å‹ä¸º&lt;code&gt;full_sft_*.pth&lt;/code&gt;ï¼Œå³åŸºäºå¾®è°ƒæ¨¡å‹åšè¿›ä¸€æ­¥çš„è’¸é¦å­¦ä¹ ã€‚ &lt;code&gt;./dataset/sft_1024.jsonl&lt;/code&gt;ä¸&lt;code&gt;./dataset/sft_2048.jsonl&lt;/code&gt; å‡æ”¶é›†è‡ªqwen2.5-7/72B-Instructå¤§æ¨¡å‹ï¼Œå¯ç›´æ¥ç”¨äºSFTä»¥è·å–Qwençš„éƒ¨åˆ†è¡Œä¸ºã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# æ³¨æ„éœ€è¦æ›´æ”¹train_full_sft.pyæ•°æ®é›†è·¯å¾„ï¼Œä»¥åŠmax_seq_len  
torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;åŒæ ·ä¿å­˜ä¸º: &lt;code&gt;full_sft_*.pth&lt;/code&gt;ï¼ˆ*ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;æ­¤å¤„åº”å½“ç€é‡ä»‹ç»MiniMindå®ç°çš„ç™½ç›’è’¸é¦ä»£ç &lt;code&gt;train_distillation.py&lt;/code&gt;ï¼Œç”±äºMiniMindåŒç³»åˆ—æœ¬èº«å¹¶ä¸å­˜åœ¨å¼ºå¤§çš„æ•™å¸ˆæ¨¡å‹ï¼Œå› æ­¤ç™½ç›’è’¸é¦ä»£ç ä»…ä½œä¸ºå­¦ä¹ å‚è€ƒã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;torchrun --nproc_per_node 1 train_distillation.py
# or
python train_distillation.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;5. LoRA (Low-Rank Adaptation)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;LoRAæ˜¯ä¸€ç§é«˜æ•ˆçš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuning, PEFTï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ä½ç§©åˆ†è§£çš„æ–¹å¼å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚ ç›¸æ¯”äºå…¨å‚æ•°å¾®è°ƒï¼ˆFull Fine-Tuningï¼‰ï¼ŒLoRA åªéœ€è¦æ›´æ–°å°‘é‡çš„å‚æ•°ã€‚ LoRA çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨æ¨¡å‹çš„æƒé‡çŸ©é˜µä¸­å¼•å…¥ä½ç§©åˆ†è§£ï¼Œä»…å¯¹ä½ç§©éƒ¨åˆ†è¿›è¡Œæ›´æ–°ï¼Œè€Œä¿æŒåŸå§‹é¢„è®­ç»ƒæƒé‡ä¸å˜ã€‚ ä»£ç å¯è§&lt;code&gt;./model/model_lora.py&lt;/code&gt;å’Œ&lt;code&gt;train_lora.py&lt;/code&gt;ï¼Œå®Œå…¨ä»0å®ç°LoRAæµç¨‹ï¼Œä¸ä¾èµ–ç¬¬ä¸‰æ–¹åº“çš„å°è£…ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;torchrun --nproc_per_node 1 train_lora.py
# or
python train_lora.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;lora_xxx_*.pth&lt;/code&gt;ï¼ˆ* ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;éå¸¸å¤šçš„äººå›°æƒ‘ï¼Œå¦‚ä½•ä½¿æ¨¡å‹å­¦ä¼šè‡ªå·±ç§æœ‰é¢†åŸŸçš„çŸ¥è¯†ï¼Ÿå¦‚ä½•å‡†å¤‡æ•°æ®é›†ï¼Ÿå¦‚ä½•è¿ç§»é€šç”¨é¢†åŸŸæ¨¡å‹æ‰“é€ å‚åŸŸæ¨¡å‹ï¼Ÿ è¿™é‡Œä¸¾å‡ ä¸ªä¾‹å­ï¼Œå¯¹äºé€šç”¨æ¨¡å‹ï¼ŒåŒ»å­¦é¢†åŸŸçŸ¥è¯†æ¬ ç¼ºï¼Œå¯ä»¥å°è¯•åœ¨åŸæœ‰æ¨¡å‹åŸºç¡€ä¸ŠåŠ å…¥é¢†åŸŸçŸ¥è¯†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚ åŒæ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¸å¸Œæœ›å­¦ä¼šé¢†åŸŸçŸ¥è¯†çš„åŒæ—¶æŸå¤±åŸæœ‰åŸºç¡€æ¨¡å‹çš„å…¶å®ƒèƒ½åŠ›ï¼Œæ­¤æ—¶LoRAå¯ä»¥å¾ˆå¥½çš„æ”¹å–„è¿™ä¸ªé—®é¢˜ã€‚ åªéœ€è¦å‡†å¤‡å¦‚ä¸‹æ ¼å¼çš„å¯¹è¯æ•°æ®é›†æ”¾ç½®åˆ°&lt;code&gt;./dataset/lora_xxx.jsonl&lt;/code&gt;ï¼Œå¯åŠ¨ &lt;code&gt;python train_lora.py&lt;/code&gt; è®­ç»ƒå³å¯å¾—åˆ°&lt;code&gt;./out/lora/lora_xxx.pth&lt;/code&gt;æ–°æ¨¡å‹æƒé‡ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;åŒ»ç–—åœºæ™¯&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {&quot;conversations&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;è¯·é—®é¢ˆæ¤ç—…çš„äººæ•å¤´å¤šé«˜æ‰æœ€å¥½ï¼Ÿ&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;é¢ˆæ¤ç—…æ‚£è€…é€‰æ‹©æ•å¤´çš„é«˜åº¦åº”è¯¥æ ¹æ®...&quot;}]}
 {&quot;conversations&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;è¯·é—®xxx&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;xxx...&quot;}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;è‡ªæˆ‘è®¤çŸ¥åœºæ™¯&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {&quot;conversations&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;æˆ‘å«minimind...&quot;}]}
 {&quot;conversations&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä½ æ˜¯è°&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;æˆ‘æ˜¯...&quot;}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æ­¤æ—¶ã€åŸºç¡€æ¨¡å‹+LoRAæ¨¡å‹ã€‘å³å¯è·å¾—åŒ»ç–—åœºæ™¯æ¨¡å‹å¢å¼ºçš„èƒ½åŠ›ï¼Œç›¸å½“äºä¸ºåŸºç¡€æ¨¡å‹å¢åŠ äº†LoRAå¤–æŒ‚ï¼Œè¿™ä¸ªè¿‡ç¨‹å¹¶ä¸æŸå¤±åŸºç¡€æ¨¡å‹çš„æœ¬èº«èƒ½åŠ›ã€‚ æˆ‘ä»¬å¯ä»¥é€šè¿‡&lt;code&gt;eval_model.py&lt;/code&gt;è¿›è¡Œæ¨¡å‹è¯„ä¼°æµ‹è¯•ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# æ³¨æ„ï¼šmodel_modeå³é€‰æ‹©åŸºç¡€æ¨¡å‹çš„ç±»å‹ï¼Œè¿™å’Œtrain_loraæ˜¯åŸºäºå“ªä¸ªæ¨¡å‹è®­ç»ƒçš„ç›¸å…³ï¼Œç¡®ä¿ç»Ÿä¸€å³å¯ã€‚
python eval_model.py --lora_name &#39;lora_medical&#39; --model_mode 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;å°æµ‹è¯•&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ğŸ‘¶: æˆ‘æœ€è¿‘ç»å¸¸æ„Ÿåˆ°å¤´æ™•ï¼Œå¯èƒ½æ˜¯ä»€ä¹ˆåŸå› ï¼Ÿ
ğŸ¤–ï¸: å¤´æ™•å¯èƒ½æ˜¯ç”±äºå¤šç§åŸå› ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šå¿ƒè„ç–¾ç—…ã€çœ¼ç›æŸä¼¤ã€è¿‡æ•ååº”ã€çš®è‚¤é—®é¢˜ã€è¿‡æ•ååº”ã€å‹åŠ›ã€ç„¦è™‘ã€ç–²åŠ³ã€è¯ç‰©å‰¯ä½œç”¨ã€æ€§åŠŸèƒ½éšœç¢æˆ–è€…å…¶ä»–...

---

ğŸ‘¶: ä½ å’Œopenaiæ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ
ğŸ¤–ï¸: æˆ‘æ˜¯ MiniMindï¼Œä¸€ä¸ªç”± Jingyao Gong å¼€å‘çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚æˆ‘é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å’Œç®—æ³•è®­ç»ƒæ¥ä¸ç”¨æˆ·è¿›è¡Œäº¤äº’ã€‚
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;PSï¼šåªè¦æœ‰æ‰€éœ€è¦çš„æ•°æ®é›†ï¼Œä¹Ÿå¯ä»¥full_sftå…¨å‚å¾®è°ƒï¼ˆéœ€è¦è¿›è¡Œé€šç”¨çŸ¥è¯†çš„æ··åˆé…æ¯”ï¼Œå¦åˆ™è¿‡æ‹Ÿåˆé¢†åŸŸæ•°æ®ä¼šè®©æ¨¡å‹å˜å‚»ï¼ŒæŸå¤±é€šç”¨æ€§ï¼‰&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;6. è®­ç»ƒæ¨ç†æ¨¡å‹ (Reasoning Model)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;DeepSeek-R1å®åœ¨å¤ªç«äº†ï¼Œå‡ ä¹é‡æ–°æŒ‡æ˜äº†æœªæ¥LLMçš„æ–°èŒƒå¼ã€‚ è®ºæ–‡æŒ‡å‡º&lt;code&gt;&amp;gt;3B&lt;/code&gt;çš„æ¨¡å‹ç»å†å¤šæ¬¡åå¤çš„å†·å¯åŠ¨å’ŒRLå¥–åŠ±è®­ç»ƒæ‰èƒ½è·å¾—è‚‰çœ¼å¯è§çš„æ¨ç†èƒ½åŠ›æå‡ã€‚ æœ€å¿«æœ€ç¨³å¦¥æœ€ç»æµçš„åšæ³•ï¼Œä»¥åŠæœ€è¿‘çˆ†å‘çš„å„ç§å„æ ·æ‰€è°“çš„æ¨ç†æ¨¡å‹å‡ ä¹éƒ½æ˜¯ç›´æ¥é¢å‘æ•°æ®è¿›è¡Œè’¸é¦è®­ç»ƒï¼Œ ä½†ç”±äºç¼ºä¹æŠ€æœ¯å«é‡ï¼Œè’¸é¦æ´¾è¢«RLæ´¾ç§ä¸èµ·ï¼ˆhhhhï¼‰ã€‚ æœ¬äººè¿…é€Ÿå·²ç»åœ¨Qwenç³»åˆ—1.5Bå°æ¨¡å‹ä¸Šè¿›è¡Œäº†å°è¯•ï¼Œå¾ˆå¿«å¤ç°äº†Zeroè¿‡ç¨‹çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚ ç„¶è€Œä¸€ä¸ªé—æ†¾çš„å…±è¯†æ˜¯ï¼šå‚æ•°å¤ªå°çš„æ¨¡å‹ç›´æ¥é€šè¿‡å†·å¯åŠ¨SFT+GRPOå‡ ä¹ä¸å¯èƒ½è·å¾—ä»»ä½•æ¨ç†æ•ˆæœã€‚ MiniMind2ç¬¬ä¸€æ—¶é—´åªèƒ½åšå®šä¸ç§»çš„é€‰æ‹©åšè’¸é¦æ´¾ï¼Œæ—¥ååŸºäº0.1Bæ¨¡å‹çš„RLå¦‚æœåŒæ ·å–å¾—å°å°è¿›å±•ä¼šæ›´æ–°æ­¤éƒ¨åˆ†çš„è®­ç»ƒæ–¹æ¡ˆã€‚&lt;/p&gt; 
&lt;p&gt;åšè’¸é¦éœ€è¦å‡†å¤‡çš„ä¾ç„¶æ˜¯å’ŒSFTé˜¶æ®µåŒæ ·æ ¼å¼çš„æ•°æ®å³å¯ï¼Œæ•°æ®é›†æ¥æºå·²å¦‚ä¸Šæ–‡ä»‹ç»ã€‚æ•°æ®æ ¼å¼ä¾‹å¦‚ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;conversations&quot;: [
    {
      &quot;role&quot;: &quot;user&quot;,
      &quot;content&quot;: &quot;ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ³ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚&quot;
    },
    {
      &quot;role&quot;: &quot;assistant&quot;,
      &quot;content&quot;: &quot;&amp;lt;think&amp;gt;\nä½ å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…ç‹¬ç«‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1-Lite-Previewï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æœåŠ¡ï¼\n&amp;lt;/think&amp;gt;\n&amp;lt;answer&amp;gt;\nä½ å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…ç‹¬ç«‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1-Lite-Previewï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æœåŠ¡ï¼\n&amp;lt;/answer&amp;gt;&quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æ¨ç†æ¨¡å‹R1çš„å›å¤æ¨¡æ¿æ˜¯ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&amp;lt;think&amp;gt;\næ€è€ƒè¿‡ç¨‹\n&amp;lt;/think&amp;gt;\n
&amp;lt;answer&amp;gt;\næœ€ç»ˆå›ç­”\n&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;è¿™åœ¨GRPOä¸­é€šè¿‡è®¾ç½®è§„åˆ™å¥–åŠ±å‡½æ•°çº¦æŸæ¨¡å‹ç¬¦åˆæ€è€ƒæ ‡ç­¾å’Œå›å¤æ ‡ç­¾ï¼ˆåœ¨å†·å¯åŠ¨é å‰çš„é˜¶æ®µå¥–åŠ±å€¼è®¾ç½®åº”è¯¥æé«˜ä¸€äº›ï¼‰&lt;/p&gt; 
&lt;p&gt;å¦ä¸€ä¸ªé—®é¢˜æ˜¯è’¸é¦è¿‡ç¨‹è™½ç„¶å’ŒSFTä¸€æ ·ï¼Œä½†å®éªŒç»“æœæ˜¯æ¨¡å‹éš¾ä»¥æ¯æ¬¡éƒ½ç¬¦åˆæ¨¡æ¿è§„èŒƒçš„å›å¤ï¼Œå³è„±ç¦»æ€è€ƒå’Œå›å¤æ ‡ç­¾çº¦æŸã€‚ è¿™é‡Œçš„å°æŠ€å·§æ˜¯å¢åŠ æ ‡è®°ä½ç½®tokençš„æŸå¤±æƒ©ç½šï¼Œè¯¦è§&lt;code&gt;train_distill_reason.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# åœ¨ sp_ids å¯¹åº”çš„ä½ç½®å¢åŠ é¢å¤–çš„æƒ©ç½š
...
loss_mask[sp_ids] = 10 # æƒ©ç½šç³»æ•°
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;å¦å¦ä¸€ä¸ªtipsæ˜¯ç”±äºæ¨ç†æ•°æ®ç”±äºåªç­›é€‰äº†&lt;code&gt;&amp;lt;1024&lt;/code&gt;é•¿åº¦çš„æ•°æ®ï¼Œå…¶ä¸­å¤šè½®å¯¹è¯å’Œè‹±æ–‡æ•°æ®åå°‘ï¼Œ å› æ­¤&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;è¿›è¡Œäº†å¤§çº¦10kæ¡å¤šè½®å¯¹è¯+è‹±æ–‡æ•°æ®çš„æ··åˆï¼Œé˜²æ­¢æ¨¡å‹é—å¿˜ä¸¥é‡ã€‚&lt;/p&gt; 
&lt;p&gt;è„šæœ¬é»˜è®¤åŸºäºrlhfåçš„åŸºæ¨¡å‹åšæ¨ç†èƒ½åŠ›çš„è’¸é¦å¾®è°ƒï¼Œä¸‹é¢ç›´æ¥å¯åŠ¨è®­ç»ƒå³å¯ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;torchrun --nproc_per_node 1 train_distill_reason.py
# or
python train_distill_reason.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;reason_*.pth&lt;/code&gt;ï¼ˆ*ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;æµ‹è¯•ä¸€ä¸‹ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ğŸ‘¶: è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚
ğŸ¤–ï¸: &amp;lt;think&amp;gt;
å—¯ï¼Œç”¨æˆ·è®©æˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚æˆ‘ç°åœ¨éœ€è¦è§£é‡Šä¸€ä¸‹è‡ªå·±ã€‚é¦–å…ˆï¼Œæˆ‘åº”è¯¥æ˜ç¡®ç”¨æˆ·æ˜¯è°ï¼Œæ˜¯å­¦ç”Ÿã€èŒåœºäººå£«è¿˜æ˜¯æ™®é€šäººã€‚ç”¨æˆ·å¯èƒ½æ˜¯ä¸€ä¸ªå­¦ç”Ÿæˆ–è€…èŒåœºäººå£«ï¼Œæ‰€ä»¥ä¿¡æ¯ä¼ é€’åº”è¯¥æ˜¯å¸®åŠ©å­¦ç”Ÿå’ŒèŒåœºäººå£«çš„ä¿¡æ¯ã€‚
ç„¶åï¼Œæˆ‘éœ€è¦å›åº”ç”¨æˆ·ï¼Œè¿™å¯èƒ½åŒ…æ‹¬ä»‹ç»è‡ªå·±çš„ä½ç½®ã€å…´è¶£çˆ±å¥½ã€èŒä¸šç»å†ç­‰ä¿¡æ¯ã€‚ç”¨æˆ·è¿˜å¯èƒ½æƒ³äº†è§£è‡ªå·±åœ¨å“ªé‡Œï¼Œæ¯”å¦‚èŒä¸šå‘å±•ã€å·¥ä½œç»éªŒç­‰ã€‚
æˆ‘åº”è¯¥æ³¨æ„ç”¨è¯è¦æ­£å¼ï¼Œä¸è¦å¤ªæ­£å¼ï¼ŒåŒæ—¶è¦ä¿æŒç®€æ´æ˜äº†ã€‚è¿™æ ·ç”¨æˆ·å®¹æ˜“ç†è§£ï¼Œä¹Ÿæ–¹ä¾¿ä»–ä»¬æŸ¥é˜…ç›¸å…³èµ„æ–™ã€‚
æœ€åï¼Œæˆ‘åº”è¯¥æ€»ç»“ä¸€ä¸‹ï¼Œè®©ç”¨æˆ·çŸ¥é“æˆ‘æ˜¯å¦‚ä½•å¸®åŠ©ä»–ä»¬å®Œæˆä»–ä»¬çš„ä»»åŠ¡çš„ï¼Œè¿™æ ·ä»–ä»¬æœ‰æ›´å¤šå…³äºæˆ‘çš„ä¿¡æ¯ã€‚
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
æˆ‘æ˜¯**â€œä½ çš„åå­—â€ï¼Œä½ å«ä»€ä¹ˆåå­—ï¼Ÿ
&amp;lt;/answer&amp;gt;

ğŸ‘¶: ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿ
ğŸ¤–ï¸: &amp;lt;think&amp;gt;
æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚
&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;h2&gt;â…£ æ¨¡å‹å‚æ•°è®¾å®š&lt;/h2&gt; 
&lt;p&gt;ğŸ“‹å…³äºLLMçš„å‚æ•°é…ç½®ï¼Œæœ‰ä¸€ç¯‡å¾ˆæœ‰æ„æ€çš„è®ºæ–‡&lt;a href=&quot;https://arxiv.org/pdf/2402.14905&quot;&gt;MobileLLM&lt;/a&gt;åšäº†è¯¦ç»†çš„ç ”ç©¶å’Œå®éªŒã€‚ Scaling Lawåœ¨å°æ¨¡å‹ä¸­æœ‰è‡ªå·±ç‹¬ç‰¹çš„è§„å¾‹ã€‚ å¼•èµ·Transformerå‚æ•°æˆè§„æ¨¡å˜åŒ–çš„å‚æ•°å‡ ä¹åªå–å†³äº&lt;code&gt;d_model&lt;/code&gt;å’Œ&lt;code&gt;n_layers&lt;/code&gt;ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;â†‘ + &lt;code&gt;n_layers&lt;/code&gt;â†“ -&amp;gt; çŸ®èƒ–å­&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;â†“ + &lt;code&gt;n_layers&lt;/code&gt;â†‘ -&amp;gt; ç˜¦é«˜ä¸ª&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;2020å¹´æå‡ºScaling Lawçš„è®ºæ–‡è®¤ä¸ºï¼Œè®­ç»ƒæ•°æ®é‡ã€å‚æ•°é‡ä»¥åŠè®­ç»ƒè¿­ä»£æ¬¡æ•°æ‰æ˜¯å†³å®šæ€§èƒ½çš„å…³é”®å› ç´ ï¼Œè€Œæ¨¡å‹æ¶æ„çš„å½±å“å‡ ä¹å¯ä»¥å¿½è§†ã€‚ ç„¶è€Œä¼¼ä¹è¿™ä¸ªå®šå¾‹å¯¹å°æ¨¡å‹å¹¶ä¸å®Œå…¨é€‚ç”¨ã€‚ MobileLLMæå‡ºæ¶æ„çš„æ·±åº¦æ¯”å®½åº¦æ›´é‡è¦ï¼Œã€Œæ·±è€Œçª„ã€çš„ã€Œç˜¦é•¿ã€æ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°æ¯”ã€Œå®½è€Œæµ…ã€æ¨¡å‹æ›´å¤šçš„æŠ½è±¡æ¦‚å¿µã€‚ ä¾‹å¦‚å½“æ¨¡å‹å‚æ•°å›ºå®šåœ¨125Mæˆ–è€…350Mæ—¶ï¼Œ30ï½42å±‚çš„ã€Œç‹­é•¿ã€æ¨¡å‹æ˜æ˜¾æ¯”12å±‚å·¦å³çš„ã€ŒçŸ®èƒ–ã€æ¨¡å‹æœ‰æ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œ åœ¨å¸¸è¯†æ¨ç†ã€é—®ç­”ã€é˜…è¯»ç†è§£ç­‰8ä¸ªåŸºå‡†æµ‹è¯•ä¸Šéƒ½æœ‰ç±»ä¼¼çš„è¶‹åŠ¿ã€‚ è¿™å…¶å®æ˜¯éå¸¸æœ‰è¶£çš„å‘ç°ï¼Œå› ä¸ºä»¥å¾€ä¸º100Må·¦å³é‡çº§çš„å°æ¨¡å‹è®¾è®¡æ¶æ„æ—¶ï¼Œå‡ ä¹æ²¡äººå°è¯•è¿‡å åŠ è¶…è¿‡12å±‚ã€‚ è¿™ä¸MiniMindåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹å‚æ•°é‡åœ¨&lt;code&gt;d_model&lt;/code&gt;å’Œ&lt;code&gt;n_layers&lt;/code&gt;ä¹‹é—´è¿›è¡Œè°ƒæ•´å®éªŒè§‚å¯Ÿåˆ°çš„æ•ˆæœæ˜¯ä¸€è‡´çš„ã€‚ ç„¶è€Œã€Œæ·±è€Œçª„ã€çš„ã€Œçª„ã€ä¹Ÿæ˜¯æœ‰ç»´åº¦æé™çš„ï¼Œå½“d_model&amp;lt;512æ—¶ï¼Œè¯åµŒå…¥ç»´åº¦åå¡Œçš„åŠ£åŠ¿éå¸¸æ˜æ˜¾ï¼Œ å¢åŠ çš„layerså¹¶ä¸èƒ½å¼¥è¡¥è¯åµŒå…¥åœ¨å›ºå®šq_headå¸¦æ¥d_headä¸è¶³çš„åŠ£åŠ¿ã€‚ å½“d_model&amp;gt;1536æ—¶ï¼Œlayersçš„å¢åŠ ä¼¼ä¹æ¯”d_modelçš„ä¼˜å…ˆçº§æ›´é«˜ï¼Œæ›´èƒ½å¸¦æ¥å…·æœ‰â€œæ€§ä»·æ¯”â€çš„å‚æ•°-&amp;gt;æ•ˆæœå¢ç›Šã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;å› æ­¤MiniMindè®¾å®šsmallæ¨¡å‹dim=512ï¼Œn_layers=8æ¥è·å–çš„ã€Œæå°ä½“ç§¯&amp;lt;-&amp;gt;æ›´å¥½æ•ˆæœã€çš„å¹³è¡¡ã€‚&lt;/li&gt; 
 &lt;li&gt;è®¾å®šdim=768ï¼Œn_layers=16æ¥è·å–æ•ˆæœçš„æ›´å¤§æ”¶ç›Šï¼Œæ›´åŠ ç¬¦åˆå°æ¨¡å‹Scaling-Lawçš„å˜åŒ–æ›²çº¿ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ä½œä¸ºå‚è€ƒï¼ŒGPT3çš„å‚æ•°è®¾å®šè§ä¸‹è¡¨ï¼š &lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/gpt3_config.png&quot; alt=&quot;gpt3_config.png&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;â…¤ è®­ç»ƒç»“æœ&lt;/h2&gt; 
&lt;p&gt;MiniMind2 æ¨¡å‹è®­ç»ƒæŸå¤±èµ°åŠ¿ï¼ˆç”±äºæ•°æ®é›†åœ¨è®­ç»ƒååˆæ›´æ–°æ¸…æ´—å¤šæ¬¡ï¼Œå› æ­¤Lossä»…ä¾›å‚è€ƒï¼‰&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;models&lt;/th&gt; 
   &lt;th&gt;pretrain (length-512)&lt;/th&gt; 
   &lt;th&gt;sft (length-512)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_512_loss.png&quot; width=&quot;100%&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_512_loss.png&quot; width=&quot;100%&quot;&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_768_loss.png&quot; width=&quot;100%&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_768_loss.png&quot; width=&quot;100%&quot;&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;è®­ç»ƒå®Œæˆ-æ¨¡å‹åˆé›†&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è€ƒè™‘åˆ°å¤šäººååº”ç™¾åº¦ç½‘ç›˜é€Ÿåº¦æ…¢ï¼ŒMiniMind2åŠä»¥åå…¨éƒ¨ä½¿ç”¨ModelScope/HuggingFaceæ‰˜ç®¡ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;â‘  PyTorchåŸç”Ÿæ¨¡å‹&lt;/h4&gt; 
&lt;p&gt;MiniMind2æ¨¡å‹æƒé‡ (&lt;a href=&quot;https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch&quot;&gt;ModelScope&lt;/a&gt; | &lt;a href=&quot;https://huggingface.co/jingyaogong/MiniMind2-Pytorch&quot;&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;MiniMind-V1æ¨¡å‹æƒé‡ (&lt;a href=&quot;https://pan.baidu.com/s/1KUfSzEkSXYbCCBj0Pw-9fA?pwd=6666&quot;&gt;ç™¾åº¦ç½‘ç›˜&lt;/a&gt;)&lt;/p&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;Torchæ–‡ä»¶å‘½åå¯¹ç…§&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model Name&lt;/th&gt; 
    &lt;th&gt;params&lt;/th&gt; 
    &lt;th&gt;pretrain_model&lt;/th&gt; 
    &lt;th&gt;sft_model&lt;/th&gt; 
    &lt;th&gt;rl_model&lt;/th&gt; 
    &lt;th&gt;reason_model&lt;/th&gt; 
    &lt;th&gt;lora_model&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small&lt;/td&gt; 
    &lt;td&gt;26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_512.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
    &lt;td&gt;145M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2&lt;/td&gt; 
    &lt;td&gt;104M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_768.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model Name&lt;/th&gt; 
    &lt;th&gt;params&lt;/th&gt; 
    &lt;th&gt;pretrain_model&lt;/th&gt; 
    &lt;th&gt;å•è½®å¯¹è¯sft&lt;/th&gt; 
    &lt;th&gt;å¤šè½®å¯¹è¯sft&lt;/th&gt; 
    &lt;th&gt;rl_model&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-small&lt;/td&gt; 
    &lt;td&gt;26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rl_512.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-moe&lt;/td&gt; 
    &lt;td&gt;4Ã—26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1&lt;/td&gt; 
    &lt;td&gt;108M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rl_768.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h4&gt;â‘¡ Transformersæ¨¡å‹&lt;/h4&gt; 
&lt;p&gt;MiniMindç³»åˆ— (&lt;a href=&quot;https://www.modelscope.cn/collections/MiniMind-b72f4cfeb74b47&quot;&gt;ModelScope&lt;/a&gt; | &lt;a href=&quot;https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5&quot;&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;hr&gt; 
&lt;h1&gt;ğŸ“Œ Eval&lt;/h1&gt; 
&lt;h2&gt;â…  RLHFå¯¹æ¯”SFTç¯‡&lt;/h2&gt; 
&lt;p&gt;æµ‹è¯•åŸºäº&lt;code&gt;full_sft&lt;/code&gt;å’Œ&lt;code&gt;rlhf&lt;/code&gt;çš„&lt;code&gt;MiniMind2ç³»åˆ—&lt;/code&gt;æ¨¡å‹å¯¹æ¯”ï¼Œæµ‹è¯•éšæœºç§å­å‡å›ºå®š&lt;/p&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;é—®ç­”å®æµ‹&lt;/summary&gt; 
 &lt;p&gt;[A0] MiniMind2ï¼šfull_sft_640&lt;/p&gt; 
 &lt;p&gt;[A1] MiniMind2ï¼šrlhf_640&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[Q]: ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ
[A0]: æˆ‘æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥å›ç­”å„ç§é—®é¢˜ï¼Œæä¾›ä¿¡æ¯å’Œå¸®åŠ©ã€‚æˆ‘å¯ä»¥å›ç­”å„ç§é—®é¢˜ï¼Œæä¾›ä¿¡æ¯å’Œå¸®åŠ©ï¼Œå¸®åŠ©ä½ è§£å†³å„ç§é—®é¢˜ã€‚
[A1]: æˆ‘æ˜¯ä¸€ç§åŸºäºæ–‡æœ¬çš„AIæ¨¡å‹ï¼Œæˆ‘å¹¶æ²¡æœ‰ä¸ªäººç»å†æˆ–æƒ…æ„Ÿï¼Œæ‰€ä»¥æ— æ³•æ„Ÿå—å’Œä½“éªŒæƒ…æ„Ÿã€‚æˆ‘çš„è®¾è®¡ç›®çš„æ˜¯ä¸ºäº†å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€æä¾›ä¿¡æ¯å’Œè¿›è¡Œå¯¹è¯ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼

[Q]: ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿ
[A0]: ä½œä¸ºä¸€ä¸ªAIæ¨¡å‹ï¼Œæˆ‘å¹¶æ²¡æœ‰çœŸæ­£çš„â€œæ“…é•¿â€è¿™ä¸ªå­¦ç§‘ã€‚æˆ‘è¢«è®¾è®¡æˆèƒ½å¤Ÿæä¾›ä¿¡æ¯ã€è§£ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯ã€æ‰§è¡Œä»»åŠ¡å’Œä¸ç”¨æˆ·è¿›è¡Œå¯¹è¯ã€‚ä¸è¿‡ï¼Œæˆ‘å¯ä»¥æä¾›ä¿¡æ¯ã€è§£ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯ã€æä¾›å»ºè®®ã€å¤„ç†é—®é¢˜ã€è¿›è¡Œå¯¹è¯ã€æä¾›å»ºè®®ã€å­¦ä¹ æ–°çŸ¥è¯†ã€ç¼–å†™ä»£ç ã€å›ç­”é—®é¢˜ã€æä¾›å»ºè®®ç­‰å¤šç§å­¦ç§‘çš„åŠŸèƒ½ã€‚å¦‚æœä½ æœ‰å…·ä½“çš„å­¦ç§‘éœ€æ±‚æˆ–ä¸»é¢˜ï¼Œæ¬¢è¿æä¾›è¯¦ç»†ä¿¡æ¯ã€‚
[A1]: ä½œä¸ºAIï¼Œæˆ‘å¹¶æ²¡æœ‰ä¸ªäººèƒ½åŠ›æˆ–å…´è¶£ï¼Œä½†æˆ‘å¯ä»¥æä¾›ä¸€äº›å…³äºæ•°å­¦ã€ç§‘å­¦ã€è®¡ç®—æœºç§‘å­¦ã€è¯­è¨€å­¦ã€å¿ƒç†å­¦ç­‰å­¦ç§‘çš„çŸ¥è¯†ã€‚å¦‚æœä½ å¯¹æ•°å­¦æ„Ÿå…´è¶£ï¼Œæˆ‘å¯ä»¥æä¾›ä¸€äº›åŸºç¡€çŸ¥è¯†ï¼Œä¾‹å¦‚ä»£æ•°ã€å‡ ä½•ã€æ¦‚ç‡ã€ç»Ÿè®¡å­¦ç­‰ã€‚å¦‚æœä½ éœ€è¦æ›´æ·±å…¥çš„å­¦ä¹ ï¼Œæˆ‘ä¹Ÿå¯ä»¥æä¾›ç›¸å…³çš„åœ¨çº¿è¯¾ç¨‹ã€ä¹¦ç±ã€è®ºæ–‡ç­‰èµ„æºã€‚è¯·å‘Šè¯‰æˆ‘ä½ å…·ä½“éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›å¸®åŠ©ã€‚

[Q]: é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™çš„ï¼Ÿ
[A0]: é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯ä¸€éƒ¨è®²è¿°äº†é²è¿…å¯¹äººç±»ä»·å€¼å’Œé“å¾·è´£ä»»çš„å€¡å¯¼ã€‚åœ¨è¿™éƒ¨ä½œå“ä¸­ï¼Œé²è¿…é€šè¿‡ç»†è…»çš„ç¬”è§¦ï¼Œæ¢è®¨äº†äººæ€§ã€é“å¾·ã€æ­£ä¹‰ã€ç‰ºç‰²ä¸è´£ä»»ç­‰æ·±åˆ»çš„ä¸»é¢˜ã€‚ä»¥ä¸‹æ˜¯é²è¿…åœ¨ã€Šç‹‚äººæ—¥è®°ã€‹ä¸­å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™çš„å‡ ä¸ªæ–¹é¢ï¼š1. **ç¤¾ä¼šç°å®ä¸é“å¾·è§‚å¿µ**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ¢è®¨äº†ç¤¾ä¼šçš„ä¸å¹³ç­‰ã€æƒåŠ›çš„æµåŠ¨ã€äººæ€§çš„æ¼”å˜ç­‰ç¤¾ä¼šé—®é¢˜ã€‚ä»–è®¤ä¸ºï¼Œç¤¾ä¼šä¸å¹³ç­‰ä¸ä»…ä»…æ˜¯ä¸å…¬æ­£çš„ï¼Œæ›´æ˜¯æ¯ä¸ªäººåœ¨ç¤¾ä¼šä¸­çš„ä¸å…¬æ­£ã€‚ä»–å‘¼åç¤¾ä¼šå„ç•Œå…±åŒåŠªåŠ›ï¼Œé€šè¿‡æ•™è‚²ã€å®£ä¼ ã€æ³•å¾‹ç­‰æ‰‹æ®µï¼Œä¸ºæ„å»ºå’Œè°ç¤¾ä¼šåšå‡ºè´¡çŒ®ã€‚2. **é“å¾·ä¸è´£ä»»**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œå±•ç°äº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚ä»–æå€¡é€šè¿‡é“å¾·æ•™è‚²æ¥åŸ¹å…»äººä»¬çš„é“å¾·å“è´¨ï¼ŒåŒæ—¶ä¹Ÿå¼ºè°ƒäº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚é²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†ç¤¾ä¼šçš„ä¸å¹³ç­‰å’Œäººæ€§çš„å¤æ‚æ€§ï¼Œä½“ç°äº†å¯¹äººæ€§çš„æ·±åˆ»ç†è§£ã€‚3. **é“å¾·ä¸è´£ä»»**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œå¼ºè°ƒäº†é“å¾·è´£ä»»çš„é‡è¦æ€§ã€‚ä»–æå€¡é€šè¿‡è‡ªå·±çš„è¡Œä¸ºæ¥ä½“ç°å¯¹ç¤¾ä¼šçš„å°Šé‡å’Œå¯¹äººæ€§çš„æ·±åˆ»ç†è§£ã€‚é²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œå¼ºè°ƒäº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚4. **é“å¾·ä¸é“å¾·**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†é“å¾·å’Œè´£ä»»çš„çœŸæ­£æ„ä¹‰ã€‚é²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†é“å¾·å’Œè´£ä»»çš„æœ¬è´¨ï¼Œå¼ºè°ƒäº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚5. **ä¸ªäººä¸ç¤¾ä¼š**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†ä¸ªäººä¸ç¤¾ä¼šä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚ä»–å‘¼åç¤¾ä¼šå„ç•Œå…±åŒåŠªåŠ›ï¼Œé€šè¿‡æ•™è‚²å’Œå®£ä¼ ï¼Œä¸ºæ„å»ºå’Œè°ç¤¾ä¼šåšå‡ºè´¡çŒ®ã€‚é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹é€šè¿‡å…¶ä¸°å¯Œçš„æ•…äº‹å’Œæ·±åˆ»çš„é“å¾·å¯“è¨€ï¼Œä¼ è¾¾äº†å…³äºäººæ€§ã€é“å¾·ã€æ­£ä¹‰ã€é“å¾·ä»¥åŠä¸ªäººä¸ç¤¾ä¼šçš„å¤æ‚å…³ç³»ã€‚è¿™éƒ¨ä½œå“ä¸ä»…åœ¨æ–‡å­¦ä»·å€¼ä¸Šå–å¾—äº†å·¨å¤§æˆå°±ï¼Œæ›´åœ¨æ€æƒ³å±‚é¢ä¸Šå¯å‘äº†åæ¥çš„æ–‡å­¦åˆ›ä½œï¼Œå¯¹åä¸–äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚
[A1]: é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯ä¸€éƒ¨æç»˜æˆ˜äº‰å’Œè‡ªç”±ç²¾ç¥çš„ä½œå“ï¼Œå®ƒæ‰¹åˆ¤äº†å°å»ºç¤¾ä¼šçš„ç§ç§é—®é¢˜å’Œå†²çªï¼Œåæ˜ äº†ç¤¾ä¼šçš„ä¸å¹³ç­‰å’Œäººæ€§æœ¬è´¨ã€‚åœ¨è¿™éƒ¨ä½œå“ä¸­ï¼Œé²è¿…é€šè¿‡å¯¹å°å»ºç¤¾ä¼šçš„è¯¸å¤šç°è±¡è¿›è¡Œæ‰¹åˆ¤ï¼Œå¦‚â€œå¼—é›·å¾·é‡Œå…‹Â·çº¦ç¿°é€Šçš„â€œé¹°è¿ªä¼¦â€ã€â€œçº³æ‰ç‰¹çš„â€ã€â€œè´å…‹æ±‰å§†â€ã€â€œä¹”æ²»Â·å¨å°”é€Šâ€ç­‰ï¼Œå¯¹å°å»ºç¤¾ä¼šçš„ç§ç§é—®é¢˜è¿›è¡Œäº†æ‰¹åˆ¤ï¼Œå¼ºè°ƒäº†å°å»ºç¤¾ä¼šçš„ä¸å¹³ç­‰ã€äººæ€§æœ¬è´¨ä»¥åŠäººæ€§æœ¬è´¨ã€‚é²è¿…é€šè¿‡ä»–çš„â€œé¹°è¿ªä¼¦â€ã€â€œçº³æ‰ç‰¹çš„â€ã€â€œè´å…‹æ±‰å§†â€ã€â€œä¹”æ²»Â·å¨å°”é€Šâ€ç­‰ï¼Œå¯¹å°å»ºç¤¾ä¼šçš„ç§ç§é—®é¢˜è¿›è¡Œäº†æ‰¹åˆ¤ã€‚åœ¨å°è¯´ä¸­ï¼Œé²è¿…é€šè¿‡å¯¹å°å»ºç¤¾ä¼šçš„è¯¸å¤šç°è±¡è¿›è¡Œæ‰¹åˆ¤ï¼Œæ­ç¤ºäº†å°å»ºç¤¾ä¼šçš„è…è´¥ã€äººæ€§æœ¬è´¨ä»¥åŠäººæ€§æœ¬è´¨çš„å¤æ‚æ€§ã€‚è¿™ç§æ‰¹åˆ¤ä½“ç°äº†å¯¹å°å»ºç¤¾ä¼šçš„å°Šé‡å’Œå¯¹äººæ€§çš„å¤æ‚æ€§ï¼ŒåŒæ—¶ä¹Ÿåæ˜ äº†ç°ä»£ç¤¾ä¼šä¸­æ™®éå­˜åœ¨çš„ä¸å¹³ç­‰å’Œäººæ€§æœ¬è´¨ã€‚é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹ä¸ä»…æ˜¯ä¸€éƒ¨å…³äºå°å»ºç¤¾ä¼šçš„å°è¯´ï¼Œä¹Ÿæ˜¯ä¸€éƒ¨å…·æœ‰æ·±åˆ»ç¤¾ä¼šæ„ä¹‰çš„ä½œå“ï¼Œå¯¹åä¸–çš„å®¡åˆ¤å’Œæ‰¹åˆ¤èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚

[Q]: æˆ‘å’³å—½å·²ç»æŒç»­äº†ä¸¤å‘¨ï¼Œéœ€è¦å»åŒ»é™¢æ£€æŸ¥å—ï¼Ÿ
[A0]: å’³å—½ç¡®å®éœ€è¦ä¸€å®šçš„æ£€æŸ¥ï¼Œä½†å¦‚æœæ‚¨çš„å’³å—½æŒç»­æ—¶é—´è¿‡é•¿ï¼Œæˆ–è€…æœ‰å…¶ä»–ä¸é€‚ç—‡çŠ¶ï¼ˆå¦‚æŒç»­å’³å—½ã€å‘¼å¸å›°éš¾ç­‰ï¼‰ï¼Œå»ºè®®å°½å¿«å°±åŒ»ã€‚åŒ»ç”Ÿä¼šæ ¹æ®æ‚¨çš„ç—‡çŠ¶ã€ä½“æ£€ç»“æœå’Œå¯èƒ½çš„å½±åƒå­¦æ£€æŸ¥ï¼ˆå¦‚Xå…‰ã€MRIæˆ–CTæ‰«æï¼‰æ¥è¯Šæ–­æ‚¨çš„ç—‡çŠ¶ã€‚åœ¨ç­‰å¾…å°±åŒ»æœŸé—´ï¼Œæ‚¨å¯ä»¥å°è¯•ä»¥ä¸‹æ–¹æ³•æ¥å¸®åŠ©ç¼“è§£ç—‡çŠ¶ï¼š1. **ä¼‘æ¯**ï¼šç¡®ä¿æ‚¨æœ‰è¶³å¤Ÿçš„ç¡çœ ã€‚2. **ä¿æŒæ°´åˆ†**ï¼šè„±æ°´å¯èƒ½ä¼šåŠ é‡å’³å—½ã€‚3. **çƒ­æ•·**ï¼šä½¿ç”¨çƒ­æ•·è¢‹æˆ–çƒ­æ¯›å·¾æ•·åœ¨ç–¼ç—›çš„éƒ¨ä½ï¼Œæœ‰åŠ©äºç¼“è§£å–‰å’™ç—›ã€‚4. **é¿å…åˆºæ¿€**ï¼šé¿å…ä½¿ç”¨å¯èƒ½åˆºæ¿€å–‰å’™çš„åŒ–å­¦ç‰©è´¨ï¼Œå¦‚æŸäº›åŒ–å­¦ç‰©è´¨ã€‚5. **ä¿æŒå®¤å†…æ¹¿æ¶¦**ï¼šç¡®ä¿æ‚¨çš„å§å®¤æœ‰è‰¯å¥½çš„é€šé£ï¼Œå¯ä»¥ä½¿ç”¨åŠ æ¹¿å™¨å¸®åŠ©ä¿æŒç©ºæ°”æ¹¿åº¦ã€‚6. **ä¿æŒå®¤å†…æ¹¿åº¦**ï¼šä½¿ç”¨åŠ æ¹¿å™¨å¯ä»¥å¸®åŠ©ç¼“è§£å–‰å’™å¹²ç‡¥å’Œå’³å—½ã€‚å¦‚æœç—‡çŠ¶æŒç»­ä¸ç¼“è§£æˆ–æœ‰å…¶ä»–ä¸é€‚ç—‡çŠ¶ï¼Œè¯·ç«‹å³å°±åŒ»ã€‚å¸Œæœ›æ‚¨æ—©æ—¥åº·å¤ï¼
[A1]: å¦‚æœæ‚¨çš„å’³å—½æŒç»­äº†ä¸¤å‘¨ï¼Œé€šå¸¸å»ºè®®æ‚¨å°½å¿«å°±åŒ»ï¼Œå› ä¸ºè¿™å¯èƒ½ä¼šå½±å“æ‚¨çš„å‘¼å¸å’Œå¿ƒè·³ã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ­¥éª¤æ¥æ£€æŸ¥å’³å—½ï¼š1. **ä¼‘æ¯**ï¼šç”¨çº¸å·¾æˆ–è‚˜éƒ¨è½»è½»æŒ‰å‹å’³å—½çš„ä½ç½®ã€‚2. **ä½¿ç”¨è¯ç‰©**ï¼šåœ¨å¯èƒ½çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨è¯ç‰©ï¼ˆå¦‚æŠ—è¿‡æ•è¯ã€æŠ—è¿‡æ•è¯ç­‰ï¼‰æ¥ç¼“è§£å’³å—½ã€‚è¯·åœ¨åŒ»ç”Ÿçš„æŒ‡å¯¼ä¸‹ä½¿ç”¨è¯ç‰©ã€‚3. **çƒ­æ•·**ï¼šåœ¨å’³å—½æœŸé—´ï¼Œå¯ä»¥ä½¿ç”¨çƒ­æ•·æ¥ç¼“è§£ç–¼ç—›å’Œè‚¿èƒ€ã€‚4. **è¯ç‰©æ²»ç–—**ï¼šå¦‚æœå’³å—½æŒç»­äº†ä¸¤å‘¨ï¼Œå¯ä»¥ä½¿ç”¨ä¸€äº›æ¶ˆç‚è¯æˆ–æŠ—è¿‡æ•è¯æ¥ç¼“è§£ç—‡çŠ¶ã€‚è¯·åŠ¡å¿…åœ¨åŒ»ç”Ÿçš„æŒ‡å¯¼ä¸‹ä½¿ç”¨ã€‚5. **ä¿æŒå¥åº·çš„ç”Ÿæ´»æ–¹å¼**ï¼šä¿æŒå……è¶³çš„ç¡çœ ã€å‡è¡¡çš„é¥®é£Ÿã€é€‚é‡çš„è¿åŠ¨å’Œé¿å…å¸çƒŸå’Œé™é…’ï¼Œè¿™äº›éƒ½æœ‰åŠ©äºæé«˜å’³å—½çš„å‡ ç‡ã€‚è¯·è®°ä½ï¼Œè¿™äº›å»ºè®®ä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—æ„è§ã€‚å¦‚æœæ‚¨çš„ç—‡çŠ¶æŒç»­æˆ–åŠ é‡ï¼Œå¼ºçƒˆå»ºè®®æ‚¨å°½å¿«å°±åŒ»ã€‚
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;ğŸ‘‰æ•ˆæœæ€»ç»“&lt;/p&gt; 
&lt;p&gt;full_sftæ¨¡å‹åœ¨ç®€æ´æ€§å’Œä¿¡æ¯å‡†ç¡®æ€§æ–¹é¢è¡¨ç°æ›´å¥½ï¼›rlhfæ¨¡å‹åœ¨å›ç­”ä¸­å€¾å‘äºæä¾›æ›´å¤šçš„èƒŒæ™¯ä¿¡æ¯ï¼Œä½†ä¿¡æ¯å‡†ç¡®æ€§æœ‰å¾…æ”¹è¿›ã€‚ æ€»çš„æ¥è¯´RLHFåçš„æ¨¡å‹å€¾å‘äºå­¦ä¹ ï¼šè¯´æ›´å¤šæœ‰ç¤¼è²Œä½†æ— ç”¨çš„åºŸè¯è®¨å¥½â€œå¯¹è¯â€æœ¬èº«ï¼Œè€Œå¯¹ä¿¡æ¯å‡†ç¡®æ€§åˆ™æœ‰è½»å¾®æŸå¤±ã€‚ å¤©ä¸‹æ²¡æœ‰å…è´¹çš„åˆé¤ï¼Œè¿˜éœ€è¦ç»§ç»­æå‡RLHFæ•°æ®é›†çš„è´¨é‡ï¼Œä¹Ÿè¦æ¥å—æ¨¡å‹èƒ½åŠ›æ— æ³•é¿å…çš„æŸå¤±(ç¨‹åº¦æœ‰è½»é‡)ã€‚ DPOå’Œåœ¨çº¿PPOçš„åŒºåˆ«åœ¨äºrejectå’Œchosenéƒ½æ˜¯ç¦»çº¿å‡†å¤‡çš„ï¼Œå’Œminimindæ¨¡å‹æœ¬èº«çš„è¾“å‡ºå¿…ç„¶å­˜åœ¨å¾ˆå¤§çš„åˆ†å¸ƒå·®å¼‚ã€‚ é€šä¿—åœ°è¯´DPOç®—æ³•ä½¿æ¨¡å‹è§‚çœ‹ä¹’ä¹“çƒä¸–ç•Œå† å†›çš„æ‰“æ³•ã€Œå½•åƒã€è¿›è¡ŒRLï¼Œè€Œä¸æ˜¯åƒPPOä¸€æ ·è¯·rewardæ¨¡å‹åšã€Œæ•™ç»ƒã€çº æ­£è‡ªå·±çš„æ‰“æ³•è¿›è¡ŒRLã€‚&lt;/p&gt; 
&lt;h2&gt;â…¡ ä¸»è§‚æ ·ä¾‹æµ‹è¯„&lt;/h2&gt; 
&lt;p&gt;ğŸƒä»¥ä¸‹æµ‹è¯•äº2025-02-09å®Œæˆï¼Œæ­¤æ—¥æœŸåå‘å¸ƒçš„æ–°æ¨¡å‹ï¼Œæ— ç‰¹æ®Šéœ€è¦æ—¶å°†ä¸åŠ å…¥æµ‹è¯•ã€‚&lt;/p&gt; 
&lt;p&gt;[A] &lt;a href=&quot;https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch&quot;&gt;MiniMind2 (0.1B)&lt;/a&gt;&lt;br&gt; [B] &lt;a href=&quot;https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch&quot;&gt;MiniMind2-MoE (0.15B)&lt;/a&gt;&lt;br&gt; [C] &lt;a href=&quot;https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch&quot;&gt;MiniMind2-Small (0.02B)&lt;/a&gt;&lt;br&gt; [D] &lt;a href=&quot;https://pan.baidu.com/s/1_COe0FQRDmeapSsvArahCA?pwd=6666&quot;&gt;minimind-v1-small(0.02B)&lt;/a&gt;&lt;br&gt; [E] &lt;a href=&quot;https://pan.baidu.com/s/1tqB-GMvuiGQBvEl-yZ-oBw?pwd=6666&quot;&gt;minimind-v1-moe(0.1B)&lt;/a&gt;&lt;br&gt; [F] &lt;a href=&quot;https://pan.baidu.com/s/1p713loS7EfwHQf3G9eYI3Q?pwd=6666&quot;&gt;minimind-v1(0.1B)&lt;/a&gt;&lt;br&gt; [G] &lt;a href=&quot;https://github.com/DLLXW/baby-llama2-chinese&quot;&gt;baby-llama2-chinese(0.2B)&lt;/a&gt;&lt;br&gt; [H] &lt;a href=&quot;https://github.com/charent/ChatLM-mini-Chinese&quot;&gt;chatlm-mini-chinese(0.2B)&lt;/a&gt;&lt;br&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[Q]: ä½ çŸ¥é“é•¿æ±Ÿå—ï¼Ÿ
[A]: é•¿æ±Ÿï¼Œä½äºä¸­å›½ä¸œå—éƒ¨ï¼Œæ˜¯ä¸­å›½çš„ç¬¬ä¸€é•¿æ²³ï¼Œå…¨é•¿6300å¤šå…¬é‡Œï¼Œæµç»11ä¸ªçœä»½ï¼Œæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œä¹Ÿæ˜¯ä¸­å›½çš„â€œæ¯äº²æ²³â€ã€‚é•¿æ±Ÿçš„å†å²å¯ä»¥è¿½æº¯åˆ°å…¬å…ƒå‰2000å¤šå¹´çš„å•†æœæ—¶æœŸï¼Œå½“æ—¶çš„å•†æœæ˜¯å•†æœçš„åè£”ã€‚å•†æœæ—¶æœŸï¼Œé•¿æ±Ÿçš„ç»æµå‘å±•è¾¾åˆ°äº†é«˜å³°ï¼Œæ˜¯ä¸­å›½æœ€é‡è¦çš„å†œä¸šå’Œå·¥ä¸šä¸­å¿ƒä¹‹ä¸€ã€‚é•¿æ±ŸæµåŸŸçš„ç»æµä¸»è¦ä»¥å†œä¸šä¸ºä¸»ï¼Œé•¿æ±Ÿæ¸”ä¸šå æ®äº†ä¸»è¦äº§ä¸šï¼Œå¦‚é’“é±¼ã€çŒé±¼ç­‰ã€‚é•¿æ±Ÿçš„æ°´èµ„æºä¹Ÿéå¸¸ä¸°å¯Œï¼ŒåŒ…æ‹¬æ²³æµã€æ¹–æ³Šã€æ²³æµç­‰ã€‚é•¿æ±Ÿçš„è‡ªç„¶æ™¯è§‚ä¹Ÿååˆ†å£®è§‚ï¼Œé•¿æ±Ÿå››å­£æ™¯è‰²å„å¼‚ï¼Œæ˜¥å­£å¤šé›¨ï¼Œå¤å­£å¤šé›¨ï¼Œç§‹å­£åˆ™å¤šé›¨ï¼Œå†¬å­£åˆ™å¯’å†·å¤šé›ªï¼Œæ˜¥å­£å’Œç§‹å­£éƒ½æœ‰ç¾ä¸½çš„èŠ±æœµå’Œæœå®ã€‚é•¿æ±Ÿæ˜¯ä¸­å›½çš„ç»æµä¸­å¿ƒï¼Œæ‹¥æœ‰ä¼—å¤šçš„å›½å®¶å’ŒåŸå¸‚ï¼Œæ˜¯ä¸–ç•Œä¸Šé‡è¦çš„äº¤é€šæ¢çº½å’Œèˆªè¿ä¸­å¿ƒã€‚åŒæ—¶ï¼Œé•¿æ±Ÿè¿˜æ˜¯ä¸­å›½çš„é‡è¦æ°´åˆ©èµ„æºï¼Œå¯¹äºä¸­å›½çš„ç»æµå‘å±•å…·æœ‰é‡è¦æ„ä¹‰ã€‚
[B]: æ˜¯çš„ï¼Œæˆ‘çŸ¥é“é•¿æ±Ÿã€‚é•¿æ±Ÿä½äºä¸­å›½çš„ä¸­éƒ¨ï¼Œæ˜¯ä¸­å›½ç¬¬ä¸‰é•¿çš„æ²³æµï¼Œå…¨é•¿çº¦6300å…¬é‡Œï¼Œæµç»æ±Ÿè¥¿çœã€å®‰å¾½çœã€æ±Ÿè‹çœã€å®‰å¾½çœã€æ±Ÿè‹çœå’Œå®‰å¾½çœã€‚
[C]: å½“ç„¶ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œå…¨é•¿çº¦6300å…¬é‡Œã€‚å®ƒä»¥å…¶ä¸°å¯Œçš„æ°´èµ„æºã€ä¸°å¯Œçš„æ°´ç”ŸåŠ¨æ¤ç‰©èµ„æºä»¥åŠç‹¬ç‰¹çš„åœ°ç†ä½ç½®è€Œé—»åäºä¸–ã€‚
[D]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œå…¨é•¿è¶…è¿‡3300åƒç±³ã€‚
[E]: é•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œæ€»é•¿åº¦çº¦ä¸º6300å…¬é‡Œã€‚å®ƒå‘æºäºé’è—é«˜åŸçš„é’æµ·æ¹–ï¼Œæµç»é’æµ·ã€å››å·ã€ç”˜è‚ƒã€å®å¤ã€å†…è’™å¤ã€é™•è¥¿å’Œå±±è¥¿ã€‚é•¿æ±ŸæµåŸŸæ˜¯ä¸­å›½æœ€å¤§çš„å†œä¸šåŒºä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½çš„æ–‡åŒ–å’Œç»æµä¸­å¿ƒã€‚
[F]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸–ç•Œç¬¬ä¸‰å¤§æ²³æµã€‚é•¿æ±Ÿå‘æºäºé’è—é«˜åŸï¼Œæµç»11ä¸ªçœä»½ï¼Œæœ€ç»ˆæ³¨å…¥ä¸œæµ·ã€‚é•¿æ±ŸæµåŸŸæ˜¯ä¸­å›½æœ€å¤§çš„æ²³æµæµåŸŸä¹‹ä¸€ï¼Œæ‹¥æœ‰ç€ä¸°å¯Œçš„è‡ªç„¶èµ„æºå’Œæ–‡åŒ–é—äº§ï¼Œå¦‚é•¿æ±Ÿå¤§æ¡¥ã€é•¿æ±Ÿæµ·æ´‹åšç‰©é¦†ã€é•¿æ±Ÿå¤åŸç­‰ã€‚
[G]: åŒæ—¶ä¹ŸçŸ¥é“ï¼Œä¸­å›½æ˜¯ä¸–ç•Œä¸Šæœ€é•¿çš„åŸå¸‚ä¹‹ä¸€ï¼Œæ‹¥æœ‰è¶…è¿‡3400ä¸‡äººå£ã€‚
[H]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€é•¿çš„æ²³æµä¹‹ä¸€ã€‚å®ƒå‘æºäºé’è—é«˜åŸï¼Œæµç»ä¹ä¸ªçœåŒºï¼Œæœ€ç»ˆæ³¨å…¥ä¸œæµ·ã€‚é•¿æ±ŸæµåŸŸçš„æ°”å€™æ¸©å’Œï¼Œå››å­£åˆ†æ˜ï¼Œæ˜¯ä¸­å›½é‡è¦çš„å†œä¸šå’Œå·¥ä¸šåŸºåœ°ã€‚é•¿æ±ŸæµåŸŸçš„æ°´äº§èµ„æºä¸°å¯Œï¼Œæ˜¯ä¸­å›½çš„é‡è¦æ¸”ä¸šèµ„æºä¹‹ä¸€ã€‚


[Q]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ä»€ä¹ˆï¼Ÿ
[A]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼ˆMount Everestï¼‰ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œå°¼æ³Šå°”å’Œä¸­å›½çš„è¾¹ç•Œä¸Šã€‚å®ƒçš„æµ·æ‹”é«˜åº¦æ˜¯8,848.86ç±³ï¼ˆ29,031.7è‹±å°ºï¼‰ï¼Œæ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±å³°ã€‚
[B]: ç ç©†æœ—ç›å³°ï¼ˆMount Everestï¼‰æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œæµ·æ‹”é«˜åº¦è¾¾8,848ç±³ï¼ˆ29,029è‹±å°ºï¼‰ã€‚
[C]: ç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.7è‹±å°ºï¼‰ã€‚å®ƒä½äºå°¼æ³Šå°”å’Œä¸­å›½çš„è¾¹ç•Œä¸Šï¼Œæ˜¯å–œé©¬æ‹‰é›…å±±è„‰çš„ä¸€éƒ¨åˆ†ã€‚
[D]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä½äºå°¼æ³Šå°”å’Œä¸­å›½çš„è¾¹å¢ƒä¸Šï¼Œæµ·æ‹”8848ç±³ã€‚
[E]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848ç±³ã€‚
[F]: ç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œæµ·æ‹”8848ç±³ã€‚
[G]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.69è‹±å°ºï¼‰ã€‚
[H]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä¹Ÿç§°ä¸ºè¨åŠ ç›å¡”ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰çš„å°¼æ³Šå°”å’Œä¸­å›½è¾¹å¢ƒä¹‹é—´ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.69è‹±å°ºï¼‰ã€‚å®ƒæ˜¯ä¸–ç•Œä¸Šæœ€è‘—åçš„ç™»å±±ç›®æ ‡ä¹‹ä¸€ï¼Œå¸å¼•ç€æ¥è‡ªä¸–ç•Œå„åœ°çš„ç™»å±±è€…å‰æ¥æŒ‘æˆ˜ã€‚ç ç©†æœ—ç›å³°çš„åå­—æ¥è‡ªè—è¯­ï¼Œæ„æ€æ˜¯â€œå¥³ç¥çš„é¢å³°â€ï¼Œå®ƒæ˜¯ç”±ä¸¤ä¸ªä¸åŒçš„å±±å³°ç»„æˆçš„ï¼Œå…¶ä¸­ä¸€ä¸ªæ˜¯ä½äºå°¼æ³Šå°”çš„ç ç©†æœ—ç›å³°ï¼Œå¦ä¸€ä¸ªåˆ™ä½äºä¸­å›½ã€‚å®ƒçš„é«˜åº¦æ˜¯é€šè¿‡æµ‹é‡æµ·æ‹”é«˜åº¦æ¥ç¡®å®šçš„ï¼Œå› ä¸ºå®ƒæ˜¯é€šè¿‡æµ‹é‡åœ°çƒçš„å¹³å‡é«˜åº¦æ¥ç¡®å®šçš„ã€‚å°½ç®¡ç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•å…¶ä»–åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚åœ°çƒä¸Šçš„å…¶ä»–åœ°æ–¹ï¼Œå¦‚å—ç¾æ´²çš„å®‰ç¬¬æ–¯å±±è„‰ï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±è„‰ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±å³°ã€‚æ€»ä¹‹ï¼Œç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚å®ƒæ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±è„‰ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚


[Q]: ä¸‡æœ‰å¼•åŠ›æ˜¯è°æå‡ºçš„ï¼Ÿ
[A]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„ï¼Œå®ƒæ˜¯ç‰›é¡¿ä¸‰å¤§å®šå¾‹ä¹‹ä¸€ã€‚ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„å¼•åŠ›å®šå¾‹æ­ç¤ºäº†ä¸‡æœ‰å¼•åŠ›å®šå¾‹çš„æœ¬è´¨ï¼Œå¹¶ä¸”è§£é‡Šäº†è¡Œæ˜Ÿã€å«æ˜Ÿã€å½—æ˜Ÿç­‰å¤©ä½“ä¹‹é—´å¦‚ä½•ç›¸äº’ä½œç”¨ã€‚è¿™ä¸ªå®šå¾‹æ˜¯ç”±è‰¾è¨å…‹Â·ç‰›é¡¿åœ¨1687å¹´æå‡ºçš„ï¼Œä»–é€šè¿‡å¯¹ä¸‡æœ‰å¼•åŠ›å®šå¾‹çš„åˆ†æå’Œå®éªŒï¼ŒæˆåŠŸåœ°è§£é‡Šäº†å¤©ä½“ä¹‹é—´çš„å¼•åŠ›ä½œç”¨ï¼Œä»è€Œè§£é‡Šäº†åœ°çƒç»•å¤ªé˜³æ—‹è½¬çš„ç°è±¡ã€‚
[B]: ä¸‡æœ‰å¼•åŠ›ï¼ˆHuman Policyï¼‰æ˜¯ç‰›é¡¿çš„ä¸‰å¤§åŠ›å­¦å®šå¾‹ï¼Œç”¨äºæè¿°ä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„ç›¸äº’ä½œç”¨åŠ›ã€‚å®ƒç”±ä¸‡æœ‰å¼•åŠ›å®šå¾‹å’Œç‰›é¡¿çš„ç¬¬ä¸€å®šå¾‹ï¼ˆæƒ¯æ€§å®šå¾‹ï¼‰æ„æˆã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±äºä¸¤ä¸ªç‰©ä½“ä¹‹é—´ç›¸äº’ä½œç”¨è€Œäº§ç”Ÿçš„ï¼Œå®ƒä»¬çš„è´¨é‡ã€è·ç¦»ã€é€Ÿåº¦å’Œæ–¹å‘ç­‰å› ç´ å†³å®šäº†å®ƒä»¬ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™ç§ç›¸äº’ä½œç”¨åŠ›æ˜¯ï¼šè´¨é‡çš„ä¹˜ç§¯ï¼šè´¨é‡çš„ä¹˜ç§¯æ˜¯ä¸‡æœ‰å¼•åŠ›å®šå¾‹å’Œç‰›é¡¿ç¬¬äºŒå®šå¾‹çš„ä¹˜ç§¯ã€‚è´¨é‡çš„ä¹˜ç§¯ï¼šè´¨é‡çš„ä¹˜ç§¯æ˜¯ç‰©ä½“ä¹‹é—´çš„ä¸€ç§ç‰©ç†è¿‡ç¨‹ï¼Œå®ƒæ˜¯ç‰©ä½“é—´ç›¸äº’ä½œç”¨çš„äº§ç‰©ï¼Œå¯¹äºå…¶ä»–ç‰©ä½“æ¥è¯´ï¼Œå…¶è´¨é‡å¯ä»¥è¡¨ç¤ºä¸ºä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„è´¨é‡ä¹‹å’Œï¼Œå³é‡åŠ›åŠ é€Ÿåº¦aã€‚
[C]: ä¸‡æœ‰å¼•åŠ›æ˜¯ä¸€ä¸ªç”±ç‰›é¡¿åœ¨1687å¹´æå‡ºçš„ç‰©ç†å­¦æ¦‚å¿µï¼Œå®ƒæè¿°äº†ç‰©ä½“ä¹‹é—´å¼•åŠ›å¦‚ä½•ç›¸äº’ä½œç”¨çš„è§„å¾‹ã€‚
[D]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±è‹±å›½ç‰©ç†å­¦å®¶ç‰›é¡¿æå‡ºçš„ã€‚ä»–è®¤ä¸ºï¼Œæ‰€æœ‰ç‰©ä½“éƒ½ä¼šäº§ç”Ÿå¼•åŠ›ï¼Œè¿™ä¸ªå¼•åŠ›æ˜¯ç”±ç‰©ä½“çš„è´¨é‡å’Œè·ç¦»å†³å®šçš„ã€‚è¿™ä¸ªç†è®ºæ­ç¤ºäº†è´¨é‡å’Œè·ç¦»ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶è¯æ˜äº†ä¸‡æœ‰å¼•åŠ›çš„æœ¬è´¨ã€‚
[E]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±ç‰›é¡¿åœ¨1687å¹´æå‡ºçš„ã€‚å®ƒæ˜¯å®‡å®™ä¸­ä¸€ä¸ªåŸºæœ¬çš„ç‰©ç†ç°è±¡ï¼Œå®ƒæè¿°äº†ç‰©ä½“ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™ä¸ªåŠ›è¢«ç§°ä¸ºä¸‡æœ‰å¼•åŠ›ï¼Œå®ƒåœ¨æ‰€æœ‰ç‰©ä½“ä¹‹é—´éƒ½å­˜åœ¨ï¼Œè¿™ç§åŠ›ä¸ç‰©ä½“çš„è´¨é‡å’Œè·ç¦»æœ‰å…³ã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯è‡ªç„¶ç•Œä¸­æœ€åŸºæœ¬çš„åŠ›é‡ä¹‹ä¸€ï¼Œå®ƒä¸ä»…å½±å“ç€ç‰©ä½“çš„è¿åŠ¨å’Œå˜åŒ–ï¼Œè¿˜å¯¹å®‡å®™çš„ç»“æ„å’Œæ¼”åŒ–äº§ç”Ÿç€é‡è¦çš„å½±å“ã€‚
[F]: ä¸‡æœ‰å¼•åŠ›æ˜¯è‹±å›½ç‰©ç†å­¦å®¶è‰¾è¨å…‹Â·ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„ã€‚
[G]: å¼•åŠ›æ˜¯å®‡å®™ä¸­ä¸€ç§åŠ›é‡ï¼Œå®ƒæ˜¯ç”±è´¨é‡æˆ–èƒ½é‡æ‰€ç»„æˆçš„ã€‚æ ¹æ®ç‰›é¡¿çš„ä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼Œä¸€ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›å¤§å°ä¸å®ƒçš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒçš„è´¨é‡æˆåæ¯”ã€‚å› æ­¤ï¼Œç‰›é¡¿çš„ä¸‡æœ‰å¼•åŠ›å®šå¾‹è¡¨æ˜ï¼Œä¸€ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›å¤§å°ä¸å®ƒçš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒçš„è´¨é‡æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹åœ¨ç‰©ç†å­¦ã€å¤©æ–‡å­¦å’Œç‰©ç†å­¦ä¸­éƒ½æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚
[H]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±è‹±å›½ç‰©ç†å­¦å®¶è‰¾è¨å…‹Â·ç‰›é¡¿äº1687å¹´æå‡ºçš„ã€‚ä»–åœ¨1687å¹´å‘è¡¨äº†ä¸€ç¯‡è‘—åçš„è®ºæ–‡ï¼Œé¢˜ä¸ºã€Šè‡ªç„¶å“²å­¦çš„æ•°å­¦åŸç†ã€‹ï¼Œå…¶ä¸­æå‡ºäº†ä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼ŒæŒ‡å‡ºä»»ä½•ä¸¤ä¸ªç‰©ä½“ä¹‹é—´éƒ½å­˜åœ¨ç€ä¸€ç§å¼•åŠ›ï¼Œè¿™ç§å¼•åŠ›çš„å¤§å°ä¸å®ƒä»¬çš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒä»¬ä¹‹é—´çš„è·ç¦»çš„å¹³æ–¹æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹è¢«ç§°ä¸ºä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼Œå®ƒæè¿°äº†è´¨é‡å’Œè·ç¦»ä¹‹é—´çš„å…³ç³»ã€‚å®ƒè¡¨æ˜ï¼Œä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›ä¸å®ƒä»¬çš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒä»¬ä¹‹é—´çš„è·ç¦»çš„å¹³æ–¹æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹å¯¹äºè§£é‡Šå®‡å®™ä¸­çš„è®¸å¤šç°è±¡å’Œç°è±¡ä¹‹é—´çš„ç›¸äº’ä½œç”¨éå¸¸é‡è¦ï¼Œä¾‹å¦‚è¡Œæ˜Ÿç»•å¤ªé˜³è¿åŠ¨ã€æ’æ˜Ÿä¹‹é—´çš„å¼•åŠ›é€é•œæ•ˆåº”ç­‰ç­‰ã€‚å®ƒä¹Ÿè¢«å¹¿æ³›åº”ç”¨äºå¤©æ–‡å­¦ã€ç‰©ç†å­¦å’Œå·¥ç¨‹å­¦ç­‰é¢†åŸŸï¼Œä¸ºæˆ‘ä»¬ç†è§£å®‡å®™çš„æœ¬è´¨å’Œæ¼”åŒ–æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚


[Q]: ä½ çŸ¥é“å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ä»€ä¹ˆå—ï¼Ÿ
[A]: å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä½†ä¹Ÿä¼šåƒå…¶ä»–æ¤ç‰©ã€æ˜†è™«ã€å°å‹å“ºä¹³åŠ¨ç‰©å’Œé±¼ç±»ã€‚å®ƒä»¬çš„æ¶ˆåŒ–ç³»ç»Ÿä¸å…¶ä»–ç†Šç§‘åŠ¨ç‰©ç±»ä¼¼ï¼Œèƒ½å¤Ÿæ¶ˆåŒ–ç«¹å­ã€‚å¤§ç†ŠçŒ«çš„ç‰™é½¿é”‹åˆ©ï¼Œé€‚åˆå’€åš¼ç«¹å­ï¼Œå› æ­¤å®ƒä»¬ç»å¸¸è¢«ç§°ä¸ºâ€œç«¹é£ŸåŠ¨ç‰©â€ã€‚
[B]: å¤§ç†ŠçŒ«æ˜¯ä»¥ç«¹å­ä¸ºé£Ÿçš„å“ºä¹³åŠ¨ç‰©ï¼Œå®ƒä»¬æ˜¯è‚‰é£ŸåŠ¨ç‰©ã€‚å®ƒä»¬ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ï¼Œç‰¹åˆ«æ˜¯ç«¹å­ä¸­å¯Œå«çº¤ç»´ç´ å’ŒçŸ¿ç‰©è´¨ï¼Œå¹¶ä¸”ä¸ä¼šç›´æ¥è¿›å…¥æ¶ˆåŒ–ç³»ç»Ÿã€‚å¤§ç†ŠçŒ«çš„è‚ é“ä¸»è¦ç”±ç«¹å­ç»„æˆï¼Œå®ƒä»¬éœ€è¦æ¶ˆåŒ–ç«¹å­ä¸­çš„çº¤ç»´ç´ å’Œå…¶ä»–çº¤ç»´ç´ æ¥æ”¯æŒå®ƒä»¬çš„æ­£å¸¸è¿›é£Ÿã€‚
[C]: å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä½†å®ƒä»¬ä¹Ÿåƒå…¶ä»–æ¤ç‰©ï¼ŒåŒ…æ‹¬æ ‘å¶ã€å«©èŠ½ã€æ˜†è™«ã€æ°´æœã€è”¬èœå’Œå°å‹å“ºä¹³åŠ¨ç‰©ç­‰ã€‚å¤§ç†ŠçŒ«æ˜¯ä¸­å›½ç‰¹æœ‰çš„ç‰©ç§ï¼Œå±äºç†Šç§‘ï¼Œä¸»è¦åˆ†å¸ƒåœ¨ä¸­å›½çš„å››å·ã€é™•è¥¿å’Œç”˜è‚ƒç­‰åœ°ã€‚
[D]: å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ã€‚å®ƒä»¬é€šå¸¸åƒç«¹å­ï¼Œæ¯å¤©éœ€è¦åƒæ‰å¤§çº¦30å…¬æ–¤çš„ç«¹å­ã€‚
[E]: æ˜¯çš„ï¼Œå¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿã€‚å®ƒä»¬æ¯å¤©éœ€è¦åƒæ‰å¤§é‡çš„ç«¹å­æ¥ç»´æŒç”Ÿå‘½ï¼Œæ¯å¤©éœ€è¦åƒæ‰40è‡³80å…¬æ–¤çš„ç«¹å­ã€‚æ­¤å¤–ï¼Œå®ƒä»¬ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–çš„æ¤ç‰©ï¼Œå¦‚è‰ã€æœå®ã€åšæœå’Œå°å‹å“ºä¹³åŠ¨ç‰©ã€‚
[F]: å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä¹Ÿä¼šå¶å°”é£Ÿç”¨å…¶ä»–çš„æ¤ç‰©å’ŒåŠ¨ç‰©ã€‚æ­¤å¤–ï¼Œå¤§ç†ŠçŒ«ä¹Ÿä¼šåƒä¸€äº›é‡æœã€å°åŠ¨ç‰©å’Œæ¤ç‰©ï¼Œä½†è¿™äº›éƒ½ä¸å±äºå®ƒä»¬çš„ä¸»è¦é£Ÿç‰©æ¥æºã€‚
[G]: å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ã€‚
[H]: å¤§ç†ŠçŒ«æ˜¯ä¸€ç§ä»¥ç«¹å­ä¸ºä¸»è¦é£Ÿç‰©çš„æ¤é£ŸåŠ¨ç‰©ï¼Œå®ƒä»¬çš„è‚ é“ç»“æ„é€‚åˆæ¶ˆåŒ–çº¤ç»´ç´ å«é‡é«˜çš„ç«¹å­ï¼Œä½†ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–æ¤ç‰©ï¼Œå¦‚è‰æœ¬æ¤ç‰©å’Œå°å‹å“ºä¹³åŠ¨ç‰©ã€‚å¤§ç†ŠçŒ«çš„è‚ é“ç»“æ„ä¹Ÿé€‚åº”äº†é«˜çº¤ç»´çš„ç«¹å­ï¼Œè¿™ä½¿å¾—å®ƒä»¬èƒ½å¤Ÿæ¶ˆåŒ–å¤§é‡çš„çº¤ç»´ç´ ï¼Œä»è€Œå¸®åŠ©å®ƒä»¬åœ¨é‡å¤–ç”Ÿå­˜ã€‚å¤§ç†ŠçŒ«çš„è‚ é“ä¸­è¿˜å«æœ‰ä¸€ç§å«åšâ€œçº¤ç»´ç´ é…¶â€çš„é…¶ç±»ç‰©è´¨ï¼Œè¿™ç§é…¶èƒ½å¤Ÿå¸®åŠ©å¤§ç†ŠçŒ«åˆ†è§£çº¤ç»´ç´ ï¼Œä»è€Œå¸®åŠ©å®ƒä»¬æ¶ˆåŒ–å¤§é‡çš„æ°´åˆ†å’Œè¥å…»ç‰©è´¨ã€‚æ­¤å¤–ï¼Œå¤§ç†ŠçŒ«çš„è‚ é“è¿˜å«æœ‰ä¸€ç§å«åšâ€œçº¤ç»´ç´ è›‹ç™½â€çš„è›‹ç™½è´¨ï¼Œè¿™ç§è›‹ç™½è´¨èƒ½å¤Ÿå¸®åŠ©å¤§ç†ŠçŒ«ç»´æŒä½“å†…çš„èƒ½é‡æ°´å¹³ï¼Œä»è€Œå¸®åŠ©å®ƒä»¬åœ¨é‡å¤–ç”Ÿå­˜ã€‚æ€»çš„æ¥è¯´ï¼Œå¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ï¼Œä½†å®ƒä»¬ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–æ¤ç‰©ï¼Œå¦‚è‰æœ¬æ¤ç‰©å’Œå°å‹å“ºä¹³åŠ¨ç‰©ã€‚


[Q]: æµ·æ°´ä¸ºä»€ä¹ˆæ˜¯å’¸çš„ï¼Ÿ
[A]: æµ·æ°´ä¹‹æ‰€ä»¥æ˜¯å’¸çš„ï¼Œä¸»è¦æ˜¯ç”±äºå…¶ä¸­çš„åŒ–å­¦æˆåˆ†ã€‚æµ·æ°´ä¸­å«æœ‰å¤§é‡çš„çŸ¿ç‰©è´¨å’Œç›åˆ†ï¼Œå…¶ä¸­ä¸»è¦æˆåˆ†æ˜¯ç¡«é…¸ç›ã€ç¢³é…¸ç›ã€é•ç¦»å­å’Œé’¾ç¦»å­ã€‚è¿™äº›ç‰©è´¨åœ¨é«˜æµ“åº¦ä¸‹ï¼Œä¼šæ²‰æ·€åœ¨æµ·æ°´ä¸­ï¼Œå½¢æˆæµ·æ°´ã€‚å…·ä½“æ¥è¯´ï¼Œæµ·æ°´ä¸­çš„çŸ¿ç‰©è´¨å’Œç›åˆ†ä¸»è¦æ¥è‡ªäºå²©çŸ³ã€åœŸå£¤ã€ç”Ÿç‰©å’Œäººç±»æ’æ³„ç‰©ç­‰ã€‚å²©çŸ³æ˜¯æµ·æ°´çš„ç»„æˆéƒ¨åˆ†ï¼Œä¸»è¦ç”±çŸ¿ç‰©è´¨ç»„æˆï¼Œå¦‚çŸ³è‹±ã€é•¿çŸ³ã€äº‘æ¯ç­‰ã€‚åœŸå£¤ä¸­å«æœ‰å¤§é‡çš„åŒ–å­¦ç‰©è´¨ï¼Œå¦‚æ°®ã€ç£·ã€é’¾ç­‰ï¼Œè¿™äº›ç‰©è´¨ä¼šæ¸—é€åˆ°åœŸå£¤ä¸­ï¼Œå½¢æˆåœŸå£¤ã€‚ç”Ÿç‰©ä½“å†…çš„ç›åˆ†ä¸»è¦æ¥æºäºæ¤ç‰©çš„å¶ç»¿ç´ ç­‰è‰²ç´ ï¼Œè¿™äº›è‰²ç´ ä¼šå¸æ”¶å¤ªé˜³å…‰ä¸­çš„èƒ½é‡ï¼Œè½¬åŒ–ä¸ºç”Ÿç‰©ä½“å¯ä»¥åˆ©ç”¨çš„èƒ½é‡ã€‚è€Œäººç±»æ’æ³„ç‰©ä¸­å«æœ‰çš„ç›åˆ†ä¸»è¦æ¥æºäºçŸ¿ç‰©è´¨å’Œç¢³é…¸ç›ï¼Œè¿™äº›çŸ¿ç‰©è´¨åœ¨æ°´ä¸­çš„æµ“åº¦è¾ƒé«˜ï¼Œä¼šå¯¼è‡´æ°´ä¸­æº¶è§£çš„çŸ¿ç‰©è´¨æµ“åº¦å¢åŠ ï¼Œå½¢æˆæ°´ä½“ä¸­çš„ç›åˆ†ã€‚å› æ­¤ï¼Œæµ·æ°´ä¹‹æ‰€ä»¥æ˜¯å’¸çš„ï¼Œæ˜¯ç”±äºå…¶ä¸­çš„åŒ–å­¦æˆåˆ†å’Œç»“æ„ç‰¹å¾ã€‚æµ·æ°´ä¸­çš„çŸ¿ç‰©è´¨å’Œç›åˆ†ä¸»è¦æ¥è‡ªäºå²©çŸ³ã€åœŸå£¤ã€ç”Ÿç‰©å’Œäººç±»æ’æ³„ç‰©ç­‰ï¼Œè€Œè¿™äº›ç‰©è´¨çš„ç§¯ç´¯å’Œæ’æ³„ä¼šå¯¼è‡´æµ·æ°´å‘ˆç°å‡ºå’¸å‘³ã€‚
[B]: æµ·æ°´æ˜¯å’¸çš„ï¼Œå› ä¸ºå®ƒåŒ…å«äº†å¤šç§ç‰©è´¨ï¼ŒåŒ…æ‹¬æ°¯åŒ–é’ ï¼ˆNaClï¼‰ã€æ°¯åŒ–é’ ï¼ˆNaClï¼‰ã€ç¢³é…¸ç›ï¼ˆå¦‚ç¡«é…¸ç›ï¼‰ã€æ°¯åŒ–é’ ï¼ˆNaClï¼‰å’Œæ°´ã€‚å’¸ç‰©è´¨çš„æ¥æºï¼šç›æ˜¯å’¸çš„å¸¸è§æ¥æºï¼Œå«æœ‰é’¾ã€é’™ã€é•ã€é’¾ç­‰çŸ¿ç‰©è´¨ã€‚è¿™äº›çŸ¿ç‰©è´¨é€šå¸¸æ¥è‡ªäºåœ°ä¸‹æ°´ã€åœ°ä¸‹æ°´æˆ–åœŸå£¤ä¸­ï¼Œè¿™äº›çŸ¿ç‰©è´¨çš„å«é‡è¿œä½äºçº¯å‡€æ°´ã€‚å’¸å‘³çš„åŸå› ï¼šç›çš„å’¸å‘³ä¸»è¦æºäºå…¶æº¶è§£äºæ°´ä¸­çš„å¾®å°é¢—ç²’ç‰©ã€‚è¿™äº›å°é¢—ç²’ç‰©ä¸»è¦é€šè¿‡æ¤ç‰©æ ¹éƒ¨å’ŒåŠ¨ç‰©ä½“å†…çš„å¾®ç”Ÿç‰©ä¼ æ’­ï¼Œå¦‚æ˜†è™«ã€å°å‹å“ºä¹³åŠ¨ç‰©ã€é¸Ÿç±»å’ŒæŸäº›æ˜†è™«ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œæµ·æ°´æ˜¯å’¸çš„ï¼Œå› ä¸ºå®ƒå«æœ‰å¤§é‡çš„ç›ç±»ï¼ŒåŒ…æ‹¬çŸ¿ç‰©è´¨ã€å²©çŸ³ã€ç›ã€çŸ¿ç‰©è´¨ç­‰ï¼Œè¿™äº›ç‰©è´¨åœ¨æµ·æ°´ä¸­çš„æµ“åº¦é«˜ï¼Œå¯¹å’¸å‘³çš„äº§ç”Ÿè¾ƒå¤§å½±å“ã€‚
[C]: æµ·æ°´æ˜¯å’¸çš„ï¼Œä¸»è¦æ˜¯å› ä¸ºå…¶ä¸­å«æœ‰å„ç§ç›åˆ†ï¼Œå…¶ä¸­ä»¥æµ·æ°´ä¸ºä¸»è¦æˆåˆ†ä¹‹ä¸€ã€‚å½“æµ·æ°´ä¸­å«æœ‰å¤§é‡çš„ç›åˆ†æ—¶ï¼Œç›åˆ†ä¼šè¢«æº¶è§£åœ¨æµ·æ°´ä¸­ï¼Œå½¢æˆå’¸å‘³ã€‚æµ·æ°´ä¸­çš„ç›åˆ†ä¸»è¦æ¥æºäºæº¶è§£ç›ç±»ã€è’¸å‘æå‡ºçš„ç›å’Œæµ·æ°´å†»ç»“æˆå†°ç­‰å› ç´ ã€‚
[D]: æµ·æ°´ä¸­å«æœ‰è®¸å¤šç›åˆ†ï¼Œè¿™äº›ç›åˆ†å¯ä»¥å¯¼è‡´æµ·æ°´å’¸åº¦çš„å¢åŠ ã€‚æµ·æ°´ä¸­çš„ç›åˆ†ä¸»è¦æ¥è‡ªäºæµ·æ°´ä¸­çš„ç›åˆ†ï¼Œè¿™äº›ç›åˆ†å¯ä»¥ä»æµ·æ°´ä¸­çš„ç›åˆ†ä¸­è·å¾—ã€‚æµ·æ°´ä¸­çš„æ°§åŒ–ç‰©å’Œç›åˆ†å¯ä»¥ä¸æµ·æ°´ä¸­çš„ç›åˆ†å½¢æˆæ°¢é”®ï¼Œä»è€Œä½¿æµ·æ°´å’¸åº¦å¢åŠ ã€‚
[E]: æµ·æ°´æ˜¯å’¸çš„ï¼Œè¿™æ˜¯å› ä¸ºå®ƒå«æœ‰å¤§é‡çš„ç›åˆ†ï¼Œå…¶ä¸­åŒ…æ‹¬æ°¯ç¦»å­å’Œæ°¯ç¦»å­ã€‚è¿™äº›ç¦»å­åœ¨æµ·æ´‹ä¸­å½¢æˆäº†å¤§é‡çš„ç›ï¼Œè¿™äº›ç›åˆ†è¢«ç§°ä¸ºç›åˆ†ã€‚æµ·æ°´ä¸­å«æœ‰è®¸å¤šæº¶è§£åœ¨æ°´ä¸­çš„ç›ï¼Œè¿™äº›ç›åˆ†ä¼šéšç€æµ·æ°´çš„å‡é«˜è€Œé€æ¸è’¸å‘ï¼Œæœ€ç»ˆå¯¼è‡´æµ·æ°´ä¸­ç›åˆ†çš„è’¸å‘ã€‚è¿™äº›ç›åˆ†åœ¨æµ·æ°´ä¸­è¢«å®Œå…¨æ¶ˆè€—ï¼Œç„¶åè¢«æ’é™¤åœ¨æµ·æ°´ä¸­ã€‚æ­¤å¤–ï¼Œæµ·æ°´ä¸­è¿˜å«æœ‰è®¸å¤šå…¶ä»–çš„ç›åˆ†ï¼Œä½†è¿™äº›ç›åˆ†æ˜¯ä¸åŒçš„ï¼Œå› ä¸ºå®ƒä»¬åœ¨æ°´ä¸­çš„æµ®èµ·å’Œä¸‹é™è¿‡ç¨‹æ˜¯ä¸åŒçš„ã€‚æµ·æ°´ä¸­çš„ç›åˆ†æ˜¯ä»æµ·åº•çš„å²©çŸ³ä¸­æå–å‡ºæ¥çš„ï¼Œè¿™äº›ç›åˆ†åœ¨æµ·æ°´ä¸­å¯ä»¥è¢«åˆ©ç”¨ã€‚æ€»çš„æ¥è¯´ï¼Œæµ·æ°´æ˜¯å’¸çš„ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæµ·æ°´ä¸­å«æœ‰è®¸å¤šç›åˆ†å’Œç›åˆ†çš„åŸå› ã€‚
[F]: æµ·æ°´å«æœ‰è®¸å¤šæº¶è§£çš„ç›ç±»ï¼Œå…¶ä¸­æœ€ä¸»è¦çš„æ˜¯æ°¯åŒ–é’ ã€‚å½“æ°´ä¸­åŠ å…¥ç›æ—¶ï¼Œç›çš„åˆ†å­ä¼šä¸æ°´åˆ†å­å‘ç”Ÿååº”ï¼Œå½¢æˆæ°¢æ°§åŒ–é’ ï¼Œè¿™æ˜¯ä¸€ç§ç›ã€‚
[G]: å› ä¸ºæ°´æ˜¯è®¸å¤šç”Ÿç‰©çš„ç”Ÿå­˜æ‰€å¿…éœ€çš„ï¼Œå®ƒèƒ½å¤Ÿå¸æ”¶å’Œé‡Šæ”¾äºŒæ°§åŒ–ç¢³ï¼Œé‡Šæ”¾æ°§æ°”ï¼Œç»´æŒå¤§æ°”ä¸­çš„æ°´è’¸æ°”ï¼Œä»¥åŠç»´æŒæ°´å¾ªç¯ã€‚æ°´ä¸­çš„ç›ç±»å’ŒåŒ–å­¦ç‰©è´¨ä¼šé‡Šæ”¾å‡ºæ°§æ°”ï¼Œä½¿åœ°çƒä¸Šçš„ç”Ÿç‰©å‘¼å¸ã€‚æ­¤å¤–ï¼Œæ°´è¿˜å…·æœ‰è®¸å¤šå…¶ä»–åŠŸèƒ½ï¼Œå¦‚ä¿æŒæ°´å¾ªç¯ã€ç»´æŒæ°´å¾ªç¯ã€è°ƒèŠ‚æ°”å€™å’Œç¯å¢ƒç­‰ã€‚æ°´æ˜¯è®¸å¤šç”Ÿç‰©ç”Ÿå­˜æ‰€å¿…éœ€çš„ï¼Œå®ƒä¹Ÿæ˜¯è®¸å¤šè‡ªç„¶ç°è±¡çš„é‡è¦åŸºç¡€ã€‚
[H]: æµ·æ°´æ˜¯å’¸çš„ä¸»è¦åŸå› æ˜¯å› ä¸ºå…¶ä¸­å«æœ‰å¤§é‡çš„æº¶è§£ç›ç±»ï¼Œå…¶ä¸­æœ€ä¸»è¦çš„æ˜¯æ°¯åŒ–é’ ï¼ˆNaClï¼‰ã€‚æ°¯åŒ–é’ æ˜¯ä¸€ç§éå¸¸å¸¸è§çš„ç›ç±»ï¼Œå®ƒå­˜åœ¨äºåœ°çƒä¸Šçš„å¤§éƒ¨åˆ†åœ°åŒºï¼ŒåŒ…æ‹¬æµ·æ´‹ã€æ¹–æ³Šã€æ²³æµå’Œåœ°ä¸‹æ°´ã€‚å½“æ°´ä»æµ·æ´‹ä¸­è’¸å‘æ—¶ï¼Œå®ƒä¼šå¸¦èµ°ä¸€éƒ¨åˆ†ç›åˆ†ï¼Œä½¿æµ·æ°´å˜å¾—å’¸ã€‚æ­¤å¤–ï¼Œæµ·ä¸­è¿˜å«æœ‰å…¶ä»–æº¶è§£ç›ç±»çš„ç‰©è´¨ï¼Œå¦‚ç¡«é…¸ç›ã€ç¡«é…¸é•ã€ç¡«é…¸é’™ã€ç¡«é…¸é•ç›ã€ç¡«é…¸é•é’¾ã€ç¡«é…¸é•é’ ã€ç¡«é…¸é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’ ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•


[Q]: å†™ä¸€æ®µpythonçš„å¿«é€Ÿæ’åºä»£ç 
[A]: å¥½çš„ï¼Œä»¥ä¸‹æ˜¯Pythonçš„å¿«é€Ÿæ’åºä»£ç ï¼šdef quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else:        pivot = arr[len(arr) // 2]        left = [x for x in arr[1:]]        right = [x for x in arr[2:] if x &amp;lt; pivot]        return quick_sort(left) + [pivot] + quick_sort(right)# æµ‹è¯•ä»£ç arr = [3, 6, 8, 10, 1, 2, 1]print(quick_sort(arr))è¿™æ®µä»£ç é¦–å…ˆæ£€æŸ¥æ•°ç»„çš„é•¿åº¦æ˜¯å¦å°äºç­‰äº1ã€‚å¦‚æœæ˜¯ï¼Œé‚£ä¹ˆå®ƒå°±æŒ‰ç…§ä»å°åˆ°å¤§çš„é¡ºåºæ’åˆ—ã€‚æ¥ç€ï¼Œå¯¹äºæ•°ç»„çš„æ¯ä¸ªå…ƒç´ ï¼Œå®ƒæƒ³è¦è¿›è¡Œé€’å½’åœ°æ’åºï¼Œç›´åˆ°è¾¾åˆ°æ’åºçš„ç»“æŸä½ç½®ã€‚å¦‚æœæ•°ç»„çš„é•¿åº¦æ˜¯å¥‡æ•°ï¼Œé‚£ä¹ˆå®ƒå°±æŒ‰ç…§ä»å¤§åˆ°å°çš„é¡ºåºæ’åˆ—ã€‚æœ€åï¼Œå¹³å‡çš„æ—¶é—´å¤æ‚åº¦æ˜¯O(n log n)ï¼Œå…¶ä¸­næ˜¯æ•°ç»„çš„é•¿åº¦ã€‚
[B]: ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨Pythonçš„å¿«é€Ÿæ’åºç®—æ³•çš„å®ç°ï¼šdef sort_array(arr):    # ç”Ÿæˆä¸€ä¸ªéšæœºæ’åˆ—    sorted_array = sorted(arr)    # è¿”å›æ’åºåçš„åˆ—è¡¨    return sorted(arr)# ç¤ºä¾‹arr = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]# è°ƒç”¨å‡½æ•°sorted_array = sort_array(arr)print(&quot;åŸå§‹æ•°ç»„æ˜¯ï¼š&quot;, sorted_array)è¿™æ®µä»£ç é¦–å…ˆç”Ÿæˆä¸€ä¸ªéšæœºæ’åˆ—ï¼Œç„¶åé€šè¿‡ä¸€ä¸ªåˆ—è¡¨çš„é•¿åº¦è¿›è¡Œæ’åºã€‚æœ€åï¼Œè¿”å›æ’åºåçš„åˆ—è¡¨ã€‚æ³¨æ„ï¼Œè¿™ä¸ªä»£ç ä½¿ç”¨äº†Pythonçš„å†…ç½®sortedå‡½æ•°å’Œå†…ç½®çš„sorted()å‡½æ•°ï¼Œå®ƒä»¬åœ¨æ—¶é—´å¤æ‚åº¦ä¸ºO(n log n)çš„æƒ…å†µä¸‹ï¼Œæ¯”ç›´æ¥ä½¿ç”¨sorted()å‡½æ•°æ›´å¿«ã€‚
[C]: ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„æ’åºç®—æ³•ï¼Œé€‚ç”¨äºå°å‹æ•°ç»„ï¼ŒåŒ…æ‹¬å°äºç­‰äº5çš„æ•°ç»„ã€‚def quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else    for _ in range(2, 51):        if arr[len(arr) - 1:] is not None:            arr[len(arr) - 1] = arr[len(arr) - 1]                arr[len(arr)] = arr[len(arr)]    return quick_sort(arr)# ç¤ºä¾‹arr = [3, 5, 1, 4, 1, 2, 1]sorted_arr = quick_sort(arr)print(&quot;Sorted array is:&quot;, sorted_arr)### ä»£ç è§£é‡Šï¼š1. **å‡½æ•°å®šä¹‰**ï¼šquick_sort å‡½æ•°æ¥å—ä¸€ä¸ªæ•°ç»„ arr ä½œä¸ºå‚æ•°ã€‚2. **å¾ªç¯**ï¼šå¯¹äº arr çš„å…ƒç´ ï¼Œä½¿ç”¨é€’å½’æ¥å®ç°ï¼Œå³ä»å³åˆ°å·¦éå†æ•°ç»„ï¼Œå¹¶å°†å½“å‰å…ƒç´ ä¸æ•°ç»„çš„å½“å‰å…ƒç´ äº¤æ¢ä½ç½®ï¼Œç›´åˆ°æ•°ç»„è¾¾åˆ°ç©ºæˆ–æ•°ç»„é•¿åº¦å°äºç­‰äº arrã€‚3. **é€’å½’è°ƒç”¨**ï¼šéå†æ•°ç»„ï¼Œå°†å½“å‰å…ƒç´ ä¸æ•°ç»„çš„å½“å‰å…ƒç´ è¿›è¡Œäº¤æ¢ï¼Œç›´åˆ°æ•°ç»„è¾¾åˆ°ç©ºæˆ–æ•°ç»„é•¿åº¦å°äºç­‰äº arrã€‚4. **æ£€æŸ¥æ•°ç»„é•¿åº¦**ï¼šä½¿ç”¨ if __name__ == &quot;__main__&quot; æ£€æŸ¥æ•°ç»„çš„é•¿åº¦æ˜¯å¦å°äº arrï¼Œå¦‚æœæ˜¯ï¼Œå°±å°†æ•°ç»„ä»è¾ƒå¤§çš„æ•°ç»„ç§»åŠ¨åˆ°æ•°ç»„çš„æœ«å°¾ã€‚5. **è¾“å‡ºæ’åºåçš„ç»“æœ**
[D]: ä½œä¸ºä¸€ä¸ªAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘æ— æ³•ç¼–å†™Pythonç¨‹åºã€‚ä½†æ˜¯ï¼ŒPythonæ˜¯ä¸€ä¸ªéå¸¸æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ï¼Œå®ƒå…·æœ‰è®¸å¤šä¼˜ç§€çš„åº“å’Œæ¡†æ¶ï¼ŒåŒ…æ‹¬NumPyã€Pandasã€Matplotlibã€Pandasã€Bandkeã€Normå’ŒNKlearnç­‰ã€‚Pythonæœ‰å¾ˆå¤šä¼˜ç§€çš„è‡ªç„¶è¯­è¨€å¤„ç†åº“å’Œæ¡†æ¶ï¼Œå¯ä»¥ç”¨äºå¤„ç†å’Œåˆ†æå„ç§ç±»å‹çš„æ•°æ®ï¼Œå¦‚æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰ã€‚Pythonè¿˜å¯ä»¥ç”¨äºåˆ›å»ºå„ç§åº”ç”¨ç¨‹åºï¼Œå¦‚ç½‘é¡µæœç´¢ã€æ¸¸æˆå¼€å‘ã€ç§‘å­¦è®¡ç®—ç­‰ã€‚Pythonéå¸¸çµæ´»ï¼Œä¹Ÿæ”¯æŒå¤šç§ç¼–ç¨‹é£æ ¼ï¼Œå› æ­¤å¯ä»¥è½»æ¾åœ°æ‰¾åˆ°é€‚åˆè‡ªå·±çš„è§£å†³æ–¹æ¡ˆã€‚
[E]: ä½œä¸ºAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘å¯ä»¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚ä½†æ˜¯æˆ‘æ— æ³•è¿›è¡Œç¼–ç¨‹æ“ä½œï¼Œå› ä¸ºæˆ‘æ— æ³•ç¡®å®šæ‚¨æƒ³é—®çš„æ˜¯å“ªç§ç¼–ç¨‹è¯­è¨€ã€‚è¯·æ‚¨æä¾›æ›´å…·ä½“çš„é—®é¢˜ï¼Œä»¥ä¾¿æˆ‘èƒ½å¤Ÿæ›´å¥½åœ°å›ç­”æ‚¨çš„é—®é¢˜ã€‚
[F]: å¿«é€Ÿæ’åºï¼ˆQuick Sortï¼‰æ˜¯ä¸€ç§ç®€å•çš„æ’åºç®—æ³•ï¼Œå®ƒé€šè¿‡å°†æ•°æ®åˆ’åˆ†ä¸ºå°ç»„ï¼Œæ¯ç»„æ•°æ®æŒ‰ç…§ä¸€å®šè§„åˆ™æ’åºï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªæœ‰åºæ•°ç»„ã€‚
[G]: å¥½çš„ï¼Œä»¥ä¸‹æ˜¯ä¸€æ®µå¿«é€Ÿæ’åºçš„Pythonä»£ç ```python sorted_print(sorted(sorted(sorted(sorted_print))```è¾“å‡ºç»“æœä¸ºï¼š```[1, 2, 3, 4, 5, 6, 7, 8, 9]```
[H]: å¿«é€Ÿæ’åºæ˜¯ä¸€ç§åŸºäºåˆ†æ²»æ€æƒ³çš„é«˜æ•ˆæ’åºç®—æ³•ï¼Œå®ƒçš„æ—¶é—´å¤æ‚åº¦ä¸º O(n log n)ã€‚å®ƒçš„åŸºæœ¬æ€æƒ³æ˜¯é€šè¿‡ä¸€è¶Ÿæ’åºå°†å¾…æ’åºåºåˆ—åˆ’åˆ†ä¸ºä¸¤ä¸ªå­åºåˆ—ï¼Œå…¶ä¸­ä¸€ä¸ªå­åºåˆ—çš„æ‰€æœ‰å…ƒç´ éƒ½æ¯”å¦ä¸€ä¸ªå­åºåˆ—çš„æ‰€æœ‰å…ƒç´ å°ï¼Œç„¶åå¯¹è¿™ä¸¤ä¸ªå­åºåˆ—åˆ†åˆ«é€’å½’åœ°è¿›è¡Œæ’åºã€‚ä¸‹é¢æ˜¯ä¸€ä¸ª Python ä»£ç ç¤ºä¾‹ï¼Œå®ç°äº†å¿«é€Ÿæ’åºç®—æ³•ï¼š```pythondef quick_sort(arr):    if len(arr) &amp;gt; 1:        return arr    else: return quick_sort(arr)```è¯¥ä»£ç ä½¿ç”¨äº†é€’å½’çš„æ–¹å¼ï¼Œé¦–å…ˆåˆ¤æ–­æ•°ç»„çš„é•¿åº¦æ˜¯å¦å°äºç­‰äº1ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™ç›´æ¥è¿”å›æ•°ç»„ï¼Œå¦åˆ™é€’å½’åœ°å¯¹æ•°ç»„è¿›è¡Œæ’åºã€‚åœ¨é€’å½’è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ¤æ–­æ•°ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å¦å¤§äºç­‰äº1ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™å°†æ•°ç»„ä¸­çš„å…ƒç´ ä¸ç¬¬ä¸€ä¸ªå…ƒç´ è¿›è¡Œæ¯”è¾ƒï¼Œå¦‚æœä¸ç­‰äº1ï¼Œåˆ™å°†æ•°ç»„ä¸­çš„å…ƒç´ ä¸ç¬¬äºŒä¸ªå…ƒç´ è¿›è¡Œæ¯”è¾ƒï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°æ‰€æœ‰å…ƒç´ éƒ½è¢«æ’åºã€‚è¯¥ä»£ç çš„æ—¶é—´å¤æ‚åº¦ä¸º O(n log n)ï¼Œæ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„æ’åºç®—æ³•ã€‚


[Q]: æˆªè‡³2025å¹´2æœˆ9æ—¥14æ—¶31åˆ†ï¼Œç”µå½±ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç´¯è®¡ç¥¨æˆ¿ï¼ˆå«é¢„å”®ï¼‰çªç ´78.09äº¿å…ƒï¼Œè¶…è¿‡ã€Šæ˜Ÿçƒå¤§æˆ˜ï¼šå¤©è¡Œè€…å´›èµ·ã€‹çš„ç¥¨æˆ¿æˆç»©ï¼Œæˆä¸ºé¦–éƒ¨è¿›å…¥å…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ã€‚è¿™ä¸€æˆå°±ä¸ä»…æ ‡å¿—ç€ä¸­å›½ç”µå½±åœ¨å›½é™…å¸‚åœºçš„çªç ´ï¼Œä¹Ÿå±•ç¤ºäº†ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›å’Œå¸‚åœºå¸å¼•åŠ›ã€‚ä»è¿™æ®µæ–‡å­—æ€»ç»“20å­—çš„æ‘˜è¦ç»™æˆ‘ã€‚
[A]: ç”µå½±ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç¥¨æˆ¿çªç ´78.09äº¿å…ƒï¼Œæˆä¸ºé¦–éƒ¨è¿›å…¥å…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ã€‚è¿™æ ‡å¿—ç€ä¸­å›½ç”µå½±çš„å›½é™…çªç ´ï¼Œä¹Ÿå±•ç°äº†ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›ã€‚
[B]: 2025å¹´2æœˆ9æ—¥ï¼Œä¸­å›½ç”µå½±åœ¨ä¸–ç•Œèˆå°ä¸Šçªç ´78.09äº¿å…ƒï¼Œè¶…è¿‡ã€Šæ˜Ÿçƒå¤§æˆ˜ï¼šå¤©è¡Œè€…å´›èµ·ã€‹çš„ç¥¨æˆ¿æˆç»©ã€‚
[C]: ç”µå½±ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç¥¨æˆ¿çªç ´78.09äº¿å…ƒï¼Œæˆä¸ºå…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ï¼Œå±•ç°ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›ã€‚
[D]: ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç´¯è®¡ç¥¨æˆ¿çªç ´78.09äº¿ï¼Œæˆä¸ºé¦–éƒ¨è¿›å…¥å…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ï¼Œå±•ç¤ºäº†ä¸­å›½ç”µå½±åœ¨å›½é™…å¸‚åœºçš„çªç ´ï¼ŒåŒæ—¶å±•ç¤ºäº†ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›å’Œå¸‚åœºå¸å¼•åŠ›ã€‚
[E]: ã€ŠçŒ›é¾™å¼ºï¼šæ‰“å¼€ä¸–ç•Œå¥‡å¹»å†’é™©ã€‹æˆåŠŸåœ°ï¼Œä¸Šæµ·æˆåŠŸå¸å¼•äº†ä¼—å¤šè§‚ä¼—ï¼ŒåŒæ—¶ä¹Ÿå¼•èµ·äº†å¹¿æ³›çš„å…³æ³¨ã€‚
[F]: ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹æ˜¯ä¸€éƒ¨è®©ä¸­å›½åŠ¨ç”»ç”µå½±æˆä¸ºå›½é™…å¸‚åœºçš„å·¨å¤§æ½œåŠ›ã€‚è¯¥ç”µå½±ä»¥å…¶åä¸½çš„ç”»é¢å’ŒæƒŠé™©çš„æˆ˜æ–—åœºé¢è€Œé—»åäºä¸–ã€‚
[G]: ã€Šå“ªè¡Œæ˜¯å€¼å¾—çš„ã€‹æ˜¯2021å¹´1æœˆ9æ—¥14æ—¶31åˆ†ï¼Œç”µå½±ã€Šå“ªæˆå¤§ä½œä¸ºã€‹åœ¨ç”µå½±å¸‚åœºçªç ´7800äº¿ç¾å…ƒï¼Œæˆä¸ºä¸­å›½åŠ¨ç”»ç”µå½±çš„çªç ´ï¼Œå¹¶å±•ç¤ºä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›å’Œå¸‚åœºå¸å¼•åŠ›ã€‚
[H]: æˆ‘æ˜¯ä¸€ä¸ªå‚æ•°å¾ˆå°‘çš„AIæ¨¡å‹ğŸ¥ºï¼ŒçŸ¥è¯†åº“è¾ƒå°‘ï¼Œæ— æ³•ç›´æ¥å›ç­”æ‚¨çš„é—®é¢˜ï¼Œæ¢ä¸ªé—®é¢˜è¯•è¯•å§ğŸ‘‹
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;p&gt;ğŸ™‹â€ç›´æ¥æŠŠä»¥ä¸Šæ‰€æœ‰é—®é¢˜å’Œæ¨¡å‹çš„å›ç­”ä¸¢ç»™DeepSeek-R1ï¼Œè®©å®ƒå¸®å¿™ç‚¹è¯„å’Œæ’åæ‰“åˆ†ï¼š&lt;/p&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;å…·ä½“ç‚¹è¯„&lt;/summary&gt; 
 &lt;h3&gt;è¯„åˆ†æ ‡å‡†ï¼š&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;å‡†ç¡®æ€§&lt;/strong&gt;ï¼šå›ç­”æ˜¯å¦æ­£ç¡®ä¸”æ— æ˜æ˜¾é”™è¯¯ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å®Œæ•´æ€§&lt;/strong&gt;ï¼šå›ç­”æ˜¯å¦æ¶µç›–äº†é—®é¢˜çš„æ ¸å¿ƒè¦ç‚¹ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;é€»è¾‘æ€§&lt;/strong&gt;ï¼šå›ç­”æ˜¯å¦æœ‰æ¡ç†ï¼Œæ˜¯å¦ç¬¦åˆé€»è¾‘ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ä»£ç è´¨é‡&lt;/strong&gt;ï¼šä»£ç æ˜¯å¦èƒ½æ­£å¸¸è¿è¡Œï¼Œé€»è¾‘æ˜¯å¦æ¸…æ™°ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;ç‚¹è¯„ï¼š&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”éå¸¸å…¨é¢ï¼Œä¿¡æ¯é‡å¤§ï¼Œé€»è¾‘æ¸…æ™°ï¼Œå°¤å…¶åœ¨é•¿æ±Ÿã€å¤§ç†ŠçŒ«ã€æµ·æ°´å’¸å‘³ç­‰é—®é¢˜ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚ä»£ç è™½ç„¶æœ‰å°ç‘•ç–µï¼Œä½†æ•´ä½“æ€è·¯æ­£ç¡®ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”ç¨æ˜¾å†—é•¿ï¼Œä½†ä¸å½±å“æ•´ä½“è´¨é‡ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šç»¼åˆè¡¨ç°æœ€ä½³ï¼Œå¾—åˆ†æœ€é«˜ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨ç ç©†æœ—ç›å³°ã€ä¸‡æœ‰å¼•åŠ›ç­‰é—®é¢˜ä¸Šè¡¨ç°å‡ºè‰²ã€‚ä»£ç è™½æœªå®Œå…¨å±•ç¤ºï¼Œä½†è§£é‡Šè¾ƒä¸ºè¯¦ç»†ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”ç•¥æ˜¾å•°å—¦ï¼Œä½†é€»è¾‘æ€§è¾ƒå¼ºã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šä»…æ¬¡äºAæ¨¡å‹ï¼Œè¡¨ç°ç¨³å®šã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”ç®€æ´æ˜äº†ï¼Œå°¤å…¶åœ¨å¤§ç†ŠçŒ«ã€å¿«é€Ÿæ’åºä»£ç ç­‰é—®é¢˜ä¸Šè¡¨ç°è¾ƒå¥½ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”ç•¥æ˜¾ç®€çŸ­ï¼Œç¼ºä¹æ·±å…¥è§£é‡Šã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šæ•´ä½“è¡¨ç°ä¸é”™ï¼Œä½†ç»†èŠ‚ä¸Šç•¥é€ŠäºAå’ŒHã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨é•¿æ±Ÿã€ä¸‡æœ‰å¼•åŠ›ç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚ä»£ç éƒ¨åˆ†æœ‰ä¸€å®šé€»è¾‘æ€§ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”ä¸å¤Ÿæ·±å…¥ï¼Œä»£ç å­˜åœ¨ä¸€äº›å°é—®é¢˜ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šè¡¨ç°ä¸­è§„ä¸­çŸ©ï¼Œä»æœ‰æå‡ç©ºé—´ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”åŸºæœ¬å‡†ç¡®ï¼Œå°¤å…¶åœ¨ä¸‡æœ‰å¼•åŠ›ã€é•¿æ±Ÿç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”è¿‡äºç®€ç•¥ï¼Œä»£ç å­˜åœ¨æ˜æ˜¾é”™è¯¯ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šè¡¨ç°ä¸€èˆ¬ï¼Œéœ€æ”¹è¿›ä»£ç éƒ¨åˆ†ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨é•¿æ±Ÿã€æµ·æ°´å’¸å‘³ç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”é€»è¾‘æ€§è¾ƒå·®ï¼Œä»£ç å­˜åœ¨è¾ƒå¤§é—®é¢˜ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šè¡¨ç°å¹³å¹³ï¼Œéœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Eæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨æµ·æ°´å’¸å‘³ã€å¤§ç†ŠçŒ«ç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šå›ç­”è¿‡äºç®€ç•¥ï¼Œä»£ç éƒ¨åˆ†å‡ ä¹æ— æ³•è¿è¡Œã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šè¡¨ç°ä¸ä½³ï¼Œéœ€å¤§å¹…æå‡ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Gæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå‡ ä¹æ²¡æœ‰æ˜æ˜¾çš„ä¼˜ç‚¹ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šå›ç­”ä¸¥é‡åç¦»ä¸»é¢˜ï¼Œä»£ç éƒ¨åˆ†å®Œå…¨æ— æ³•è¿è¡Œã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šè¡¨ç°æœ€å·®ï¼Œéœ€å¤§å¹…æ”¹è¿›ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;hr&gt; 
 &lt;h3&gt;æ€»ç»“ï¼š&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Aæ¨¡å‹&lt;/strong&gt;åœ¨å„æ–¹é¢è¡¨ç°æœ€ä¸ºå‡ºè‰²ï¼Œå°¤å…¶åœ¨å¤æ‚é—®é¢˜çš„å›ç­”ä¸Šå±•ç°äº†æé«˜çš„å‡†ç¡®æ€§ä¸é€»è¾‘æ€§ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Hæ¨¡å‹&lt;/strong&gt;ç´§éšå…¶åï¼Œè¡¨ç°ç¨³å®šï¼Œä½†åœ¨æŸäº›ç»†èŠ‚ä¸Šç•¥æ˜¾ä¸è¶³ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Gæ¨¡å‹&lt;/strong&gt;è¡¨ç°æœ€å·®ï¼Œå›ç­”åç¦»ä¸»é¢˜ä¸”ä»£ç æ— æ³•è¿è¡Œï¼Œéœ€å¤§å¹…æ”¹è¿›ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;æ‰“åˆ†æ’åº&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;æ’å&lt;/th&gt; 
   &lt;th&gt;æ¨¡å‹&lt;/th&gt; 
   &lt;th&gt;å‡†ç¡®æ€§ (30åˆ†)&lt;/th&gt; 
   &lt;th&gt;å®Œæ•´æ€§ (30åˆ†)&lt;/th&gt; 
   &lt;th&gt;é€»è¾‘æ€§ (20åˆ†)&lt;/th&gt; 
   &lt;th&gt;ä»£ç è´¨é‡ (20åˆ†)&lt;/th&gt; 
   &lt;th&gt;æ€»åˆ† (100åˆ†)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;A&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;96&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;H&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;93&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;C&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;89&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;F&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;86&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;D&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;82&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;B&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;78&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;E&lt;/td&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;G&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;42&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ğŸ‘‰ä¸»è§‚æ•ˆæœæ€»ç»“&lt;/h3&gt; 
&lt;p&gt;ä¸ªäººä¸»è§‚è¯„ä»·ä¸DeepSeek-R1åŸºæœ¬ç›¸ç¬¦ï¼Œå…¶ä¸­ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;MiniMindç³»åˆ—çš„æ’åºéå¸¸ç¬¦åˆç›´è§‰ï¼Œå‚æ•°è¶Šå¤§+è®­ç»ƒæ•°æ®è¶Šå……åˆ†è¯„åˆ†è¶Šé«˜ï¼Œå¹»è§‰å’Œé”™è¯¯éƒ½ä¼šæ¯”å°æ¨¡å‹è‚‰çœ¼å¯è§çš„å¥½ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Hæ¨¡å‹çš„å›ç­”è‚‰çœ¼çœ‹èµ·æ¥æ˜¯ä¸é”™çš„ï¼Œå°½ç®¡å­˜åœ¨äº›è®¸å¹»è§‰çç¼–çš„æƒ…å†µã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Gæ¨¡å‹å¯èƒ½è®­ç»ƒæ•°æ®ä¸å¤Ÿå®Œå¤‡ï¼Œç»™å‡ºçš„æƒé‡ç»è¿‡æµ‹è¯•æ•ˆæœä¸ä½³ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;å†å¤è¯µä¸€éç»ä¹…ä¸è¡°çš„Scaling Law: å‚æ•°è¶Šå¤§ï¼Œè®­ç»ƒæ•°æ®è¶Šå¤šæ¨¡å‹çš„æ€§èƒ½è¶Šå¼ºã€‚&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;â…¢ Objective Benchmark&lt;/h2&gt; 
&lt;p&gt;ä¸‹é¢å°±åˆ°å–œé—»ä¹è§çš„benchmarkåˆ·æ¦œæµ‹è¯•ç¯èŠ‚ï¼Œå°±ä¸æ‰¾ä¹å­å’Œqwenã€glmçº§åˆ«çš„ä¸­æ–‡æ¨¡å‹åšå¯¹æ¯”äº†ã€‚ è¿™é‡Œé€‰å–äº†ä¸€äº›&amp;lt;1Bçš„å¾®å‹æ¨¡å‹è¿›è¡Œæ¨ªè¯„æ¯”è¾ƒï¼Œ æµ‹è¯•é›†é€‰æ‹©C-Evalã€CMMLUã€A-CLUEã€TMMLU+è¿™å‡ ä¸ªçº¯ä¸­æ–‡è¯­è¨€æ¦œå•ã€‚&lt;/p&gt; 
&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt; 
 &lt;summary&gt;æµ‹è¯„æ¡†æ¶&lt;/summary&gt; 
 &lt;p&gt;æµ‹è¯„æ¡†æ¶é€‰æ‹©&lt;a href=&quot;https://github.com/EleutherAI/lm-evaluation-harness&quot;&gt;lm-evaluation&lt;/a&gt;ï¼Œ å®‰è£…åå¯åŠ¨æµ‹è¯•éå¸¸æ–¹ä¾¿ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;lm_eval --model hf --model_args pretrained=&amp;lt;å¡«å†™æ¨¡å‹è·¯å¾„&amp;gt;,device=cuda,dtype=auto --tasks ceval* --batch_size 8 --trust_remote_code
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;PS: åœ¨è¿™ç§å…¨æ˜¯é€‰æ‹©é¢˜çš„æµ‹è¯„é›†ä¸­ï¼Œä¸ºäº†é¿å…å›å¤æ ¼å¼çš„éš¾ä»¥å›ºå®šçš„ç‰¹ç‚¹ï¼Œ æ‰€ä»¥å¸¸ç”¨åšæ³•æ˜¯ç›´æ¥æŠŠ&lt;code&gt;A&lt;/code&gt;,&lt;code&gt;B&lt;/code&gt;,&lt;code&gt;C&lt;/code&gt;,&lt;code&gt;D&lt;/code&gt;å››ä¸ªå­—æ¯å¯¹åº”tokençš„é¢„æµ‹æ¦‚ç‡å–å‡ºæ¥ï¼Œå°†å…¶ä¸­æ¦‚ç‡æœ€å¤§çš„å­—æ¯ä¸æ ‡å‡†ç­”æ¡ˆè®¡ç®—æ­£ç¡®ç‡ã€‚ é€‰æ‹©é¢˜1/4ä¹±é€‰çš„æ­£ç¡®ç‡æ˜¯25%ï¼Œç„¶è€Œè¿™ä¸ªé‡çº§çš„æ‰€æœ‰æ¨¡å‹éƒ½é›†ä¸­åœ¨25é™„è¿‘ï¼Œç”šè‡³å¾ˆå¤šæ—¶å€™ä¸å¦‚çé€‰ï¼Œæ˜¯ä¸æ˜¯åƒæäº†é«˜ä¸­å®Œå½¢å¡«ç©ºçš„æ»‘é“å¢æ­£ç¡®ç‡... MiniMindæ¨¡å‹æœ¬èº«é¢„è®­ç»ƒæ•°æ®é›†å°çš„å¯æ€œï¼Œä¹Ÿæ²¡æœ‰é’ˆå¯¹æ€§çš„å¯¹æµ‹è¯•é›†åšåˆ·æ¦œå¾®è°ƒï¼Œå› æ­¤ç»“æœå›¾ä¸€ä¹å³å¯ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;models&lt;/th&gt; 
   &lt;th&gt;from&lt;/th&gt; 
   &lt;th&gt;paramsâ†“&lt;/th&gt; 
   &lt;th&gt;cevalâ†‘&lt;/th&gt; 
   &lt;th&gt;cm mluâ†‘&lt;/th&gt; 
   &lt;th&gt;aclueâ†‘&lt;/th&gt; 
   &lt;th&gt;tmmlu+â†‘&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;26.52&lt;/td&gt; 
   &lt;td&gt;24.42&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;26.37&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.39&lt;/td&gt; 
   &lt;td&gt;24.63&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;26.6&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
   &lt;td&gt;24.83&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/zhanshijinwat/Steel-LLM&quot;&gt;Steel-LLM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ZhanShiJin&lt;/td&gt; 
   &lt;td&gt;1121M&lt;/td&gt; 
   &lt;td&gt;24.81&lt;/td&gt; 
   &lt;td&gt;25.32&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;24.39&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/openai-community/gpt2-medium&quot;&gt;GPT2-medium&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;360M&lt;/td&gt; 
   &lt;td&gt;23.18&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;18.6&lt;/td&gt; 
   &lt;td&gt;25.19&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/jzhang38/TinyLlama&quot;&gt;TinyLlama-1.1B-Chat-V1.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;TinyLlama&lt;/td&gt; 
   &lt;td&gt;1100M&lt;/td&gt; 
   &lt;td&gt;25.48&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;25.4&lt;/td&gt; 
   &lt;td&gt;25.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/huggingface/smollm&quot;&gt;SmolLM2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFaceTB&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;24.37&lt;/td&gt; 
   &lt;td&gt;25.02&lt;/td&gt; 
   &lt;td&gt;25.37&lt;/td&gt; 
   &lt;td&gt;25.06&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.modelscope.cn/models/BAAI/Aquila-135M-Instruct&quot;&gt;Aquila-Instruct&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;BAAI&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;25.11&lt;/td&gt; 
   &lt;td&gt;25.1&lt;/td&gt; 
   &lt;td&gt;24.43&lt;/td&gt; 
   &lt;td&gt;25.05&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/images/compare_radar.png&quot; alt=&quot;compare_radar&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;ğŸ“Œ å…¶å®ƒ (Others)&lt;/h1&gt; 
&lt;h3&gt;æ¨ç†ä¸å¯¼å‡º&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/convert_model.py&quot;&gt;./scripts/convert_model.py&lt;/a&gt;å¯ä»¥å°†torch/transformersæ¨¡å‹äº’ç›¸è½¬æ¢ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MiniMindçš„HuggingFaceé›†åˆåœ°å€ï¼š &lt;a href=&quot;https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5&quot;&gt;MiniMind&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h3&gt;åŸºäºMiniMind-APIæœåŠ¡æ¥å£&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/serve_openai_api.py&quot;&gt;./scripts/serve_openai_api.py&lt;/a&gt;å®Œæˆäº†å…¼å®¹openai-apiçš„æœ€ç®€èŠå¤©æ¥å£ï¼Œæ–¹ä¾¿å°†è‡ªå·±çš„æ¨¡å‹æ¥å…¥ç¬¬ä¸‰æ–¹UI ä¾‹å¦‚FastGPTã€OpenWebUIã€Difyç­‰ç­‰ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ä»&lt;a href=&quot;https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5&quot;&gt;Huggingface&lt;/a&gt;ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œæ–‡ä»¶æ ‘ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;MiniMind-Model-Name&amp;gt; (root dir)
â”œâ”€&amp;lt;MiniMind-Model-Name&amp;gt;
|  â”œâ”€â”€ config.json
|  â”œâ”€â”€ generation_config.json
|  â”œâ”€â”€ LMConfig.py
|  â”œâ”€â”€ model.py
|  â”œâ”€â”€ pytorch_model.bin
|  â”œâ”€â”€ special_tokens_map.json
|  â”œâ”€â”€ tokenizer_config.json
|  â”œâ”€â”€ tokenizer.json
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;å¯åŠ¨èŠå¤©æœåŠ¡ç«¯&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python serve_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;æµ‹è¯•æœåŠ¡æ¥å£&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python chat_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;APIæ¥å£ç¤ºä¾‹ï¼Œå…¼å®¹openai apiæ ¼å¼&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl http://ip:port/v1/chat/completions \
  -H &quot;Content-Type: application/json&quot; \
  -d &#39;{ 
    &quot;model&quot;: &quot;model-identifier&quot;,
    &quot;messages&quot;: [ 
      { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸–ç•Œä¸Šæœ€é«˜çš„å±±æ˜¯ä»€ä¹ˆï¼Ÿ&quot; }
    ], 
    &quot;temperature&quot;: 0.7, 
    &quot;max_tokens&quot;: 512,
    &quot;stream&quot;: true
}&#39;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;ğŸ“Œ Acknowledge&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] å¦‚æœè§‰å¾—&lt;code&gt;MiniMindç³»åˆ—&lt;/code&gt;å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œå¯ä»¥åœ¨ GitHub ä¸ŠåŠ ä¸€ä¸ªâ­&lt;br&gt; ç¯‡å¹…è¶…é•¿æ°´å¹³æœ‰é™éš¾å…çº°æ¼ï¼Œæ¬¢è¿åœ¨Issuesäº¤æµæŒ‡æ­£æˆ–æäº¤PRæ”¹è¿›é¡¹ç›®&lt;br&gt; æ‚¨çš„å°å°æ”¯æŒå°±æ˜¯æŒç»­æ”¹è¿›æ­¤é¡¹ç›®çš„åŠ¨åŠ›ï¼&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ¤&lt;a href=&quot;https://github.com/jingyaogong/minimind/graphs/contributors&quot;&gt;è´¡çŒ®è€…&lt;/a&gt;&lt;/h2&gt; 
&lt;!--
&lt;a href=&quot;https://github.com/jingyaogong/minimind/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=jingyaogong/minimind&amp;v3&quot; /&gt;
&lt;/a&gt;
--&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/jingyaogong&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/62287848&quot; width=&quot;70px&quot; height=&quot;70px&quot;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&quot;https://github.com/MuWinds&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/93832089&quot; width=&quot;70px&quot; height=&quot;70px&quot;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&quot;https://github.com/chuanzhubin&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/2813798&quot; width=&quot;70px&quot; height=&quot;70px&quot;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&quot;https://github.com/iomgaa-ycz&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/124225682&quot; width=&quot;70px&quot; height=&quot;70px&quot;&gt;&lt;/a&gt; &amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;ğŸ˜Šé¸£è°¢&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ipfgao&quot;&gt;&lt;b&gt;@ipfgao&lt;/b&gt;&lt;/a&gt;: &lt;a href=&quot;https://github.com/jingyaogong/minimind/issues/26&quot;&gt;ğŸ”—è®­ç»ƒæ­¥éª¤è®°å½•&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/chuanzhubin&quot;&gt;&lt;b&gt;@chuanzhubin&lt;/b&gt;&lt;/a&gt;: &lt;a href=&quot;https://github.com/jingyaogong/minimind/pull/34&quot;&gt;ğŸ”—ä»£ç é€è¡Œæ³¨é‡Š&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/WangRongsheng&quot;&gt;&lt;b&gt;@WangRongsheng&lt;/b&gt;&lt;/a&gt;: &lt;a href=&quot;https://github.com/jingyaogong/minimind/issues/39&quot;&gt;ğŸ”—å¤§å‹æ•°æ®é›†é¢„å¤„ç†&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/pengqianhan&quot;&gt;&lt;b&gt;@pengqianhan&lt;/b&gt;&lt;/a&gt;: &lt;a href=&quot;https://github.com/jingyaogong/minimind/issues/73&quot;&gt;ğŸ”—ä¸€ä¸ªç®€æ˜æ•™ç¨‹&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/RyanSunn&quot;&gt;&lt;b&gt;@RyanSunn&lt;/b&gt;&lt;/a&gt;: &lt;a href=&quot;https://github.com/jingyaogong/minimind/issues/75&quot;&gt;ğŸ”—æ¨ç†è¿‡ç¨‹å­¦ä¹ è®°å½•&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Nijikadesu&quot;&gt;&lt;b&gt;@Nijikadesu&lt;/b&gt;&lt;/a&gt;: &lt;a href=&quot;https://github.com/jingyaogong/minimind/issues/213&quot;&gt;ğŸ”—ä»¥äº¤äº’ç¬”è®°æœ¬æ–¹å¼åˆ†è§£é¡¹ç›®ä»£ç &lt;/a&gt;&lt;/p&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;å‚è€ƒé“¾æ¥ &amp;amp; æ„Ÿè°¢ä»¥ä¸‹ä¼˜ç§€çš„è®ºæ–‡æˆ–é¡¹ç›®&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ’åä¸åˆ†ä»»ä½•å…ˆåé¡ºåº&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/meta-llama/llama3&quot;&gt;https://github.com/meta-llama/llama3&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/karpathy/llama2.c&quot;&gt;https://github.com/karpathy/llama2.c&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/DLLXW/baby-llama2-chinese&quot;&gt;https://github.com/DLLXW/baby-llama2-chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.04434&quot;&gt;(DeepSeek-V2)https://arxiv.org/abs/2405.04434&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/charent/ChatLM-mini-Chinese&quot;&gt;https://github.com/charent/ChatLM-mini-Chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/wdndev/tiny-llm-zh&quot;&gt;https://github.com/wdndev/tiny-llm-zh&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2401.04088&quot;&gt;(Mistral-MoE)https://arxiv.org/pdf/2401.04088&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/Tongjilibo/build_MiniLLM_from_scratch&quot;&gt;https://github.com/Tongjilibo/build_MiniLLM_from_scratch&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/jzhang38/TinyLlama&quot;&gt;https://github.com/jzhang38/TinyLlama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/AI-Study-Han/Zero-Chatgpt&quot;&gt;https://github.com/AI-Study-Han/Zero-Chatgpt&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/xusenlinzy/api-for-open-llm&quot;&gt;https://github.com/xusenlinzy/api-for-open-llm&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/HqWu-HITCS/Awesome-Chinese-LLM&quot;&gt;https://github.com/HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸ«¶æ”¯æŒè€…&lt;/h2&gt; 
&lt;a href=&quot;https://github.com/jingyaogong/minimind/stargazers&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://reporoster.com/stars/dark/jingyaogong/minimind&quot;&gt; 
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://reporoster.com/stars/jingyaogong/minimind&quot;&gt; 
  &lt;img alt=&quot;github contribution grid snake animation&quot; src=&quot;https://reporoster.com/stars/jingyaogong/minimind&quot;&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;a href=&quot;https://github.com/jingyaogong/minimind/network/members&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://reporoster.com/forks/dark/jingyaogong/minimind&quot;&gt; 
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://reporoster.com/forks/jingyaogong/minimind&quot;&gt; 
  &lt;img alt=&quot;github contribution grid snake animation&quot; src=&quot;https://reporoster.com/forks/jingyaogong/minimind&quot;&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;picture&gt; 
 &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date&amp;amp;theme=dark&quot;&gt; 
 &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date&quot;&gt; 
 &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date&quot;&gt; 
&lt;/picture&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href=&quot;https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE&quot;&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
