<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>GitHub Jupyter Notebook Monthly Trending</title>
    <description>Monthly Trending of Jupyter Notebook in GitHub</description>
    <pubDate>Sun, 16 Mar 2025 02:02:54 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>datawhalechina/self-llm</title>
      <link>https://github.com/datawhalechina/self-llm</link>
      <description>&lt;p&gt;《开源大模型食用指南》针对中国宝宝量身打造的基于Linux环境快速微调（全参数/Lora）、部署国内外开源大模型（LLM）/多模态大模型（MLLM）教程&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/images/head-img.png&quot;&gt; 
 &lt;h1&gt;开源大模型食用指南&lt;/h1&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;中文 | &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/README_en.md&quot;&gt;English&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;  本项目是一个围绕开源大模型、针对国内初学者、基于 Linux 平台的中国宝宝专属大模型教程，针对各类开源大模型提供包括环境配置、本地部署、高效微调等技能在内的全流程指导，简化开源大模型的部署、使用和应用流程，让更多的普通学生、研究者更好地使用开源大模型，帮助开源、自由的大模型更快融入到普通学习者的生活中。&lt;/p&gt; 
&lt;p&gt;  本项目的主要内容包括：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;基于 Linux 平台的开源 LLM 环境配置指南，针对不同模型要求提供不同的详细环境配置步骤；&lt;/li&gt; 
 &lt;li&gt;针对国内外主流开源 LLM 的部署使用教程，包括 LLaMA、ChatGLM、InternLM 等；&lt;/li&gt; 
 &lt;li&gt;开源 LLM 的部署应用指导，包括命令行调用、在线 Demo 部署、LangChain 框架集成等；&lt;/li&gt; 
 &lt;li&gt;开源 LLM 的全量微调、高效微调方法，包括分布式全量微调、LoRA、ptuning 等。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;  &lt;strong&gt;项目的主要内容就是教程，让更多的学生和未来的从业者了解和熟悉开源大模型的食用方法！任何人都可以提出issue或是提交PR，共同构建维护这个项目。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;  想要深度参与的同学可以联系我们，我们会将你加入到项目的维护者中。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;  &lt;em&gt;&lt;strong&gt;学习建议：本项目的学习建议是，先学习环境配置，然后再学习模型的部署使用，最后再学习微调。因为环境配置是基础，模型的部署使用是基础，微调是进阶。初学者可以选择Qwen1.5，InternLM2，MiniCPM等模型优先学习。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：如果有同学希望了解大模型的模型构成，以及从零手写RAG、Agent和Eval等任务，可以学习Datawhale的另一个项目&lt;a href=&quot;https://github.com/datawhalechina/tiny-universe&quot;&gt;Tiny-Universe&lt;/a&gt;，大模型是当下深度学习领域的热点，但现有的大部分大模型教程只在于教给大家如何调用api完成大模型的应用，而很少有人能够从原理层面讲清楚模型结构、RAG、Agent 以及 Eval。所以该仓库会提供全部手写，不采用调用api的形式，完成大模型的 RAG 、 Agent 、Eval 任务。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：考虑到有同学希望在学习本项目之前，希望学习大模型的理论部分，如果想要进一步深入学习 LLM 的理论基础，并在理论的基础上进一步认识、应用 LLM，可以参考 Datawhale 的 &lt;a href=&quot;https://github.com/datawhalechina/so-large-lm.git&quot;&gt;so-large-llm&lt;/a&gt;课程。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：如果有同学在学习本课程之后，想要自己动手开发大模型应用。同学们可以参考 Datawhale 的 &lt;a href=&quot;https://github.com/datawhalechina/llm-universe&quot;&gt;动手学大模型应用开发&lt;/a&gt; 课程，该项目是一个面向小白开发者的大模型应用开发教程，旨在基于阿里云服务器，结合个人知识库助手项目，向同学们完整的呈现大模型应用开发流程。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;项目意义&lt;/h2&gt; 
&lt;p&gt;  什么是大模型？&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;大模型（LLM）狭义上指基于深度学习算法进行训练的自然语言处理（NLP）模型，主要应用于自然语言理解和生成等领域，广义上还包括机器视觉（CV）大模型、多模态大模型和科学计算大模型等。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;  百模大战正值火热，开源 LLM 层出不穷。如今国内外已经涌现了众多优秀开源 LLM，国外如 LLaMA、Alpaca，国内如 ChatGLM、BaiChuan、InternLM（书生·浦语）等。开源 LLM 支持用户本地部署、私域微调，每一个人都可以在开源 LLM 的基础上打造专属于自己的独特大模型。&lt;/p&gt; 
&lt;p&gt;  然而，当前普通学生和用户想要使用这些大模型，需要具备一定的技术能力，才能完成模型的部署和使用。对于层出不穷又各有特色的开源 LLM，想要快速掌握一个开源 LLM 的应用方法，是一项比较有挑战的任务。&lt;/p&gt; 
&lt;p&gt;  本项目旨在首先基于核心贡献者的经验，实现国内外主流开源 LLM 的部署、使用与微调教程；在实现主流 LLM 的相关部分之后，我们希望充分聚集共创者，一起丰富这个开源 LLM 的世界，打造更多、更全面特色 LLM 的教程。星火点点，汇聚成海。&lt;/p&gt; 
&lt;p&gt;  &lt;em&gt;&lt;strong&gt;我们希望成为 LLM 与普罗大众的阶梯，以自由、平等的开源精神，拥抱更恢弘而辽阔的 LLM 世界。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;项目受众&lt;/h2&gt; 
&lt;p&gt;  本项目适合以下学习者：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;想要使用或体验 LLM，但无条件获得或使用相关 API；&lt;/li&gt; 
 &lt;li&gt;希望长期、低成本、大量应用 LLM；&lt;/li&gt; 
 &lt;li&gt;对开源 LLM 感兴趣，想要亲自上手开源 LLM；&lt;/li&gt; 
 &lt;li&gt;NLP 在学，希望进一步学习 LLM；&lt;/li&gt; 
 &lt;li&gt;希望结合开源 LLM，打造领域特色的私域 LLM；&lt;/li&gt; 
 &lt;li&gt;以及最广大、最普通的学生群体。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;项目规划及进展&lt;/h2&gt; 
&lt;p&gt;   本项目拟围绕开源 LLM 应用全流程组织，包括环境配置及使用、部署应用、微调等，每个部分覆盖主流及特点开源 LLM：&lt;/p&gt; 
&lt;h3&gt;Example 系列&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/examples/Chat-%E5%AC%9B%E5%AC%9B/readme.md&quot;&gt;Chat-嬛嬛&lt;/a&gt;： Chat-甄嬛是利用《甄嬛传》剧本中所有关于甄嬛的台词和语句，基于LLM进行LoRA微调得到的模仿甄嬛语气的聊天语言模型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/examples/Tianji-%E5%A4%A9%E6%9C%BA/readme.md&quot;&gt;Tianji-天机&lt;/a&gt;：天机是一款基于人情世故社交场景，涵盖提示词工程 、智能体制作、 数据获取与模型微调、RAG 数据清洗与使用等全流程的大语言模型系统应用教程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/examples/AMchat-%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/readme.md&quot;&gt;AMChat&lt;/a&gt;: AM (Advanced Mathematics) chat 是一个集成了数学知识和高等数学习题及其解答的大语言模型。该模型使用 Math 和高等数学习题及其解析融合的数据集，基于 InternLM2-Math-7B 模型，通过 xtuner 微调，专门设计用于解答高等数学问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/examples/%E6%95%B0%E5%AD%97%E7%94%9F%E5%91%BD/readme.md&quot;&gt;数字生命&lt;/a&gt;: 本项目将以我为原型，利用特制的数据集对大语言模型进行微调，致力于创造一个能够真正反映我的个性特征的AI数字人——包括但不限于我的语气、表达方式和思维模式等等，因此无论是日常聊天还是分享心情，它都以一种既熟悉又舒适的方式交流，仿佛我在他们身边一样。整个流程是可迁移复制的，亮点是数据集的制作。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;已支持模型&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://huggingface.co/google/gemma-3-4b-it&quot;&gt;Gemma3&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; gemma-3-4b-it FastApi 部署调用&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; gemma-3-4b-it vLLM 部署&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; gemma-3-4b-it ollama + open-webui部署&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; gemma-3-4b-it evalscope 智商情商评测&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; gemma-3-4b-it Lora 微调&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; gemma-3-4b-it Docker 镜像&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.modelscope.cn/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B&quot;&gt;DeepSeek-R1-Distill&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-R1-Distill-Qwen/01-DeepSeek-R1-Distill-Qwen-7B%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;DeepSeek-R1-Distill-Qwen-7B FastApi 部署调用&lt;/a&gt; @骆秀韬&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-R1-Distill-Qwen/02-DeepSeek-R1-Distill-Qwen-7B%20Langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;DeepSeek-R1-Distill-Qwen-7B Langchain 接入&lt;/a&gt; @骆秀韬&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-R1-Distill-Qwen/03-DeepSeek-R1-Distill-Qwen-7B%20WebDemo%20%E9%83%A8%E7%BD%B2.md&quot;&gt;DeepSeek-R1-Distill-Qwen-7B WebDemo 部署&lt;/a&gt; @骆秀韬&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-R1-Distill-Qwen/04-DeepSeek-R1-Distill-Qwen-7B%20vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;DeepSeek-R1-Distill-Qwen-7B vLLM 部署调用&lt;/a&gt; @骆秀韬&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/OpenBMB/MiniCPM-o&quot;&gt;MiniCPM-o-2_6&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM-o/01MiniCPM-o%202%206%20FastApi%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8%20.md&quot;&gt;minicpm-o-2.6 FastApi 部署调用&lt;/a&gt; @林恒宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM-o/02minicpm-o-2.6WebDemo_streamlit.py&quot;&gt;minicpm-o-2.6 WebDemo 部署&lt;/a&gt; @程宏&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM-o/03-MiniCPM-o-2.6%20%E5%A4%9A%E6%A8%A1%E6%80%81%E8%AF%AD%E9%9F%B3%E8%83%BD%E5%8A%9B.md&quot;&gt;minicpm-o-2.6 多模态语音能力&lt;/a&gt; @邓恺俊&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM-o/04-MiniCPM-0-2.6%20Lora%E5%BE%AE%E8%B0%83.md&quot;&gt;minicpm-o-2.6 可视化 LaTeX_OCR Lora 微调&lt;/a&gt; @林泽毅&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/InternLM/InternLM&quot;&gt;InternLM3&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM3/01-InternLM3-8B-Instruct%20FastAPI.md&quot;&gt;internlm3-8b-instruct FastApi 部署调用&lt;/a&gt; @苏向标&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM3/02-internlm3-8b-Instruct%20Langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;internlm3-8b-instruct Langchian接入&lt;/a&gt; @赵文恺&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM3/03-InternLM3-8B-Instruct%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;internlm3-8b-instruct WebDemo 部署&lt;/a&gt; @王泽宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM3/04-InternLM3-8B-Instruct%20LoRA.md&quot;&gt;internlm3-8b-instruct Lora 微调&lt;/a&gt; @程宏&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM3/05-internlm3-8b-instruct%20%E4%B8%8Eo1%20.md&quot;&gt;internlm3-8b-instruct o1-like推理链实现&lt;/a&gt; @陈睿&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://huggingface.co/microsoft/phi-4&quot;&gt;phi4&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/01-Phi-4%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;phi4 FastApi 部署调用&lt;/a&gt; @杜森&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/02-Phi-4-Langchain%E6%8E%A5%E5%85%A5.md&quot;&gt;phi4 langchain 接入&lt;/a&gt; @小罗&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/03-Phi-4%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;phi4 WebDemo 部署&lt;/a&gt; @杜森&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/04-Phi-4-Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;phi4 Lora 微调&lt;/a&gt; @郑远婧&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/05-Phi-4-Lora%20%E5%BE%AE%E8%B0%83%20%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB.md&quot;&gt;phi4 Lora 微调 NER任务 SwanLab 可视化记录版&lt;/a&gt; @林泽毅&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/QwenLM/Qwen2.5-Coder&quot;&gt;Qwen2.5-Coder&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/01-Qwen2.5-Coder-7B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen2.5-Coder-7B-Instruct FastApi部署调用&lt;/a&gt; @赵文恺&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/02-Qwen2.5-7B-Instruct%20Langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;Qwen2.5-Coder-7B-Instruct Langchian接入&lt;/a&gt; @杨晨旭&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/03-Qwen2.5-Coder-7B-Instruct%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;Qwen2.5-Coder-7B-Instruct WebDemo 部署&lt;/a&gt; @王泽宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/04-Qwen2.5-Coder-7B-Instruct%20vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen2.5-Coder-7B-Instruct vLLM 部署&lt;/a&gt; @王泽宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/Qwen2.5-Coder-7B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Qwen2.5-Coder-7B-Instruct Lora 微调&lt;/a&gt; @荞麦&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/05-Qwen2.5-Coder-7B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83%20SwanLab%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95%E7%89%88.md&quot;&gt;Qwen2.5-Coder-7B-Instruct Lora 微调 SwanLab 可视化记录版&lt;/a&gt; @杨卓&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/QwenLM/Qwen2-VL&quot;&gt;Qwen2-vl&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/01-Qwen2-VL-2B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen2-vl-2B FastApi 部署调用&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/02-Qwen2-VL-2B-Instruct%20Web%20Demo%E9%83%A8%E7%BD%B2.md&quot;&gt;Qwen2-vl-2B WebDemo 部署&lt;/a&gt; @赵伟&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/03-Qwen2-VL-2B-Instruct%20vLLM%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen2-vl-2B vLLM 部署&lt;/a&gt; @荞麦&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/04-Qwen2-VL-2B%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Qwen2-vl-2B Lora 微调&lt;/a&gt; @李柯辰&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/05-Qwen2-VL-2B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83%20SwanLab%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95%E7%89%88.md&quot;&gt;Qwen2-vl-2B Lora 微调 SwanLab 可视化记录版&lt;/a&gt; @林泽毅&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/06-Qwen2-VL-2B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83%E6%A1%88%E4%BE%8B%20-%20LaTexOCR.md&quot;&gt;Qwen2-vl-2B Lora 微调案例 - LaTexOCR&lt;/a&gt; @林泽毅&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/QwenLM/Qwen2.5&quot;&gt;Qwen2.5&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/01-Qwen2.5-7B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen2.5-7B-Instruct FastApi 部署调用&lt;/a&gt; @娄天奥&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/02-Qwen2.5-7B-Instruct%20Langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;Qwen2.5-7B-Instruct langchain 接入&lt;/a&gt; @娄天奥&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/03-Qwen2.5-7B-Instruct%20vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen2.5-7B-Instruct vLLM 部署调用&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/04-Qwen2_5-7B-Instruct%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;Qwen2.5-7B-Instruct WebDemo 部署&lt;/a&gt; @高立业&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/05-Qwen2.5-7B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Qwen2.5-7B-Instruct Lora 微调&lt;/a&gt; @左春生&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/06-Qwen2.5-7B-Instruct%20o1-like%20%E6%8E%A8%E7%90%86%E9%93%BE%E5%AE%9E%E7%8E%B0.md&quot;&gt;Qwen2.5-7B-Instruct o1-like 推理链实现&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/07-Qwen2.5-7B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83%20SwanLab%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95%E7%89%88.md&quot;&gt;Qwen2.5-7B-Instruct Lora 微调 SwanLab 可视化记录版&lt;/a&gt; @林泽毅&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://machinelearning.apple.com/research/openelm&quot;&gt;Apple OpenELM&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/OpenELM/01-OpenELM-3B-Instruct%20FastApi%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;OpenELM-3B-Instruct FastApi 部署调用&lt;/a&gt; @王泽宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/OpenELM/02-OpenELM-3B-Instruct%20Lora%E5%BE%AE%E8%B0%83.md&quot;&gt;OpenELM-3B-Instruct Lora 微调&lt;/a&gt; @王泽宇&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct&quot;&gt;Llama3_1-8B-Instruct&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama3_1/01-Llama3_1-8B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Llama3_1-8B-Instruct FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama3_1/02-Llama3_1-8B-Instruct%20langchain%E6%8E%A5%E5%85%A5.md&quot;&gt;Llama3_1-8B-Instruct langchain 接入&lt;/a&gt; @张晋&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama3_1/03-Llama3_1-8B-Instruct%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;Llama3_1-8B-Instruct WebDemo 部署&lt;/a&gt; @张晋&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama3_1/04-Llama3_1-8B--Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Llama3_1-8B-Instruct Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama3_1/%E5%8A%A8%E6%89%8B%E8%BD%AC%E6%8D%A2GGUF%E6%A8%A1%E5%9E%8B%E5%B9%B6%E4%BD%BF%E7%94%A8Ollama%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2.md&quot;&gt;动手转换GGUF模型并使用Ollama本地部署&lt;/a&gt; @Gaoboy&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://huggingface.co/google/gemma-2-9b-it&quot;&gt;Gemma-2-9b-it&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma2/01-Gemma-2-9b-it%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Gemma-2-9b-it FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma2/02-Gemma-2-9b-it%20langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;Gemma-2-9b-it langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma2/03-Gemma-2-9b-it%20WebDemo%20%E9%83%A8%E7%BD%B2.md&quot;&gt;Gemma-2-9b-it WebDemo 部署&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma2/04-Gemma-2-9b-it%20peft%20lora%E5%BE%AE%E8%B0%83.md&quot;&gt;Gemma-2-9b-it Peft Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/IEIT-Yuan/Yuan-2.0&quot;&gt;Yuan2.0&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0/01-Yuan2.0-2B%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Yuan2.0-2B FastApi 部署调用&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0/02-Yuan2.0-2B%20Langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;Yuan2.0-2B Langchain 接入&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0/03-Yuan2.0-2B%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;Yuan2.0-2B WebDemo部署&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0/04-Yuan2.0-2B%20vLLM%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Yuan2.0-2B vLLM部署调用&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0/05-Yuan2.0-2B%20Lora%E5%BE%AE%E8%B0%83.md&quot;&gt;Yuan2.0-2B Lora微调&lt;/a&gt; @张帆&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/IEIT-Yuan/Yuan2.0-M32&quot;&gt;Yuan2.0-M32&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0-M32/01-Yuan2.0-M32%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Yuan2.0-M32 FastApi 部署调用&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0-M32/02-Yuan2.0-M32%20Langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;Yuan2.0-M32 Langchain 接入&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0-M32/03-Yuan2.0-M32%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;Yuan2.0-M32 WebDemo部署&lt;/a&gt; @张帆&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-Coder-V2&quot;&gt;DeepSeek-Coder-V2&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-Coder-V2/01-DeepSeek-Coder-V2-Lite-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;DeepSeek-Coder-V2-Lite-Instruct FastApi 部署调用&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-Coder-V2/02-DeepSeek-Coder-V2-Lite-Instruct%20%E6%8E%A5%E5%85%A5%20LangChain.md&quot;&gt;DeepSeek-Coder-V2-Lite-Instruct langchain 接入&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-Coder-V2/03-DeepSeek-Coder-V2-Lite-Instruct%20WebDemo%20%E9%83%A8%E7%BD%B2.md&quot;&gt;DeepSeek-Coder-V2-Lite-Instruct WebDemo 部署&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-Coder-V2/04-DeepSeek-Coder-V2-Lite-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;DeepSeek-Coder-V2-Lite-Instruct Lora 微调&lt;/a&gt; @余洋&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/bilibili/Index-1.9B&quot;&gt;哔哩哔哩 Index-1.9B&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/bilibili_Index-1.9B/01-Index-1.9B-chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Index-1.9B-Chat FastApi 部署调用&lt;/a&gt; @邓恺俊&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/bilibili_Index-1.9B/02-Index-1.9B-Chat%20%E6%8E%A5%E5%85%A5%20LangChain.md&quot;&gt;Index-1.9B-Chat langchain 接入&lt;/a&gt; @张友东&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/bilibili_Index-1.9B/03-Index-1.9B-chat%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;Index-1.9B-Chat WebDemo 部署&lt;/a&gt; @程宏&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/bilibili_Index-1.9B/04-Index-1.9B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Index-1.9B-Chat Lora 微调&lt;/a&gt; @姜舒凡&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/QwenLM/Qwen2&quot;&gt;Qwen2&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2/01-Qwen2-7B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen2-7B-Instruct FastApi 部署调用&lt;/a&gt; @康婧淇&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2/02-Qwen2-7B-Instruct%20Langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;Qwen2-7B-Instruct langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2/03-Qwen2-7B-Instruct%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;Qwen2-7B-Instruct WebDemo 部署&lt;/a&gt; @三水&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2/04-Qwen2-7B-Instruct%20vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen2-7B-Instruct vLLM 部署调用&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2/05-Qwen2-7B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Qwen2-7B-Instruct Lora 微调&lt;/a&gt; @散步&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/THUDM/GLM-4.git&quot;&gt;GLM-4&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/01-GLM-4-9B-chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;GLM-4-9B-chat FastApi 部署调用&lt;/a&gt; @张友东&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/02-GLM-4-9B-chat%20langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;GLM-4-9B-chat langchain 接入&lt;/a&gt; @谭逸珂&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/03-GLM-4-9B-Chat%20WebDemo.md&quot;&gt;GLM-4-9B-chat WebDemo 部署&lt;/a&gt; @何至轩&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/04-GLM-4-9B-Chat%20vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;GLM-4-9B-chat vLLM 部署&lt;/a&gt; @王熠明&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/05-GLM-4-9B-chat%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;GLM-4-9B-chat Lora 微调&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/05-GLM-4-9B-chat-hf%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;GLM-4-9B-chat-hf Lora 微调&lt;/a&gt; @付志远&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/QwenLM/Qwen1.5.git&quot;&gt;Qwen 1.5&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/01-Qwen1.5-7B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen1.5-7B-chat FastApi 部署调用&lt;/a&gt; @颜鑫&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/02-Qwen1.5-7B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&quot;&gt;Qwen1.5-7B-chat langchain 接入&lt;/a&gt; @颜鑫&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/03-Qwen1.5-7B-Chat%20WebDemo.md&quot;&gt;Qwen1.5-7B-chat WebDemo 部署&lt;/a&gt; @颜鑫&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/04-Qwen1.5-7B-chat%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Qwen1.5-7B-chat Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/05-Qwen1.5-7B-Chat-GPTQ-Int4%20%20WebDemo.md&quot;&gt;Qwen1.5-72B-chat-GPTQ-Int4 部署环境&lt;/a&gt; @byx020119&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/06-Qwen1.5-MoE-A2.7B.md&quot;&gt;Qwen1.5-MoE-chat Transformers 部署调用&lt;/a&gt; @丁悦&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/07-Qwen1.5-7B-Chat%20vLLM%20%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen1.5-7B-chat vLLM推理部署&lt;/a&gt; @高立业&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/08-Qwen1.5-7B-chat%20LoRA%E5%BE%AE%E8%B0%83%E6%8E%A5%E5%85%A5%E5%AE%9E%E9%AA%8C%E7%AE%A1%E7%90%86.md&quot;&gt;Qwen1.5-7B-chat Lora 微调 接入SwanLab实验管理平台&lt;/a&gt; @黄柏特&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://huggingface.co/google/gemma-7b-it&quot;&gt;谷歌-Gemma&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma/01-Gemma-2B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;gemma-2b-it FastApi 部署调用 &lt;/a&gt; @东东&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma/02-Gemma-2B-Instruct%20langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;gemma-2b-it langchain 接入 &lt;/a&gt; @东东&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma/03-Gemma-2B-Instruct%20WebDemo%20%E9%83%A8%E7%BD%B2.md&quot;&gt;gemma-2b-it WebDemo 部署 &lt;/a&gt; @东东&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma/04-Gemma-2B-Instruct%20Lora%E5%BE%AE%E8%B0%83.md&quot;&gt;gemma-2b-it Peft Lora 微调 &lt;/a&gt; @东东&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://huggingface.co/microsoft/Phi-3-mini-4k-instruct&quot;&gt;phi-3&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi-3/01-Phi-3-mini-4k-instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Phi-3-mini-4k-instruct FastApi 部署调用&lt;/a&gt; @郑皓桦&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi-3/02-Phi-3-mini-4k-instruct%20langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;Phi-3-mini-4k-instruct langchain 接入&lt;/a&gt; @郑皓桦&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi-3/03-Phi-3-mini-4k-instruct%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;Phi-3-mini-4k-instruct WebDemo 部署&lt;/a&gt; @丁悦&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi-3/04-Phi-3-mini-4k-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Phi-3-mini-4k-instruct Lora 微调&lt;/a&gt; @丁悦&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/thu-coai/CharacterGLM-6B&quot;&gt;CharacterGLM-6B&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/CharacterGLM/01-CharacterGLM-6B%20Transformer%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;CharacterGLM-6B Transformers 部署调用&lt;/a&gt; @孙健壮&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/CharacterGLM/02-CharacterGLM-6B%20FastApi%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;CharacterGLM-6B FastApi 部署调用&lt;/a&gt; @孙健壮&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/CharacterGLM/03-CharacterGLM-6B-chat.md&quot;&gt;CharacterGLM-6B webdemo 部署&lt;/a&gt; @孙健壮&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/CharacterGLM/04-CharacterGLM-6B%20Lora%E5%BE%AE%E8%B0%83.md&quot;&gt;CharacterGLM-6B Lora 微调&lt;/a&gt; @孙健壮&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/meta-llama/llama3.git&quot;&gt;LLaMA3-8B-Instruct&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/LLaMA3/01-LLaMA3-8B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;LLaMA3-8B-Instruct FastApi 部署调用&lt;/a&gt; @高立业&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/LLaMA3/02-LLaMA3-8B-Instruct%20langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;LLaMA3-8B-Instruct langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/LLaMA3/03-LLaMA3-8B-Instruct%20WebDemo%20%E9%83%A8%E7%BD%B2.md&quot;&gt;LLaMA3-8B-Instruct WebDemo 部署&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/LLaMA3/04-LLaMA3-8B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;LLaMA3-8B-Instruct Lora 微调&lt;/a&gt; @高立业&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://modelscope.cn/models/xverse/XVERSE-7B-Chat/summary&quot;&gt;XVERSE-7B-Chat&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/XVERSE/01-XVERSE-7B-chat%20Transformers%E6%8E%A8%E7%90%86.md&quot;&gt;XVERSE-7B-Chat transformers 部署调用&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/XVERSE/02-XVERSE-7B-chat%20FastAPI%E9%83%A8%E7%BD%B2.md&quot;&gt;XVERSE-7B-Chat FastApi 部署调用&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/XVERSE/03-XVERSE-7B-chat%20langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;XVERSE-7B-Chat langchain 接入&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/XVERSE/04-XVERSE-7B-chat%20WebDemo%20%E9%83%A8%E7%BD%B2.md&quot;&gt;XVERSE-7B-Chat WebDemo 部署&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/XVERSE/05-XVERSE-7B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;XVERSE-7B-Chat Lora 微调&lt;/a&gt; @郭志航&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/OpenNLPLab/TransnormerLLM.git&quot;&gt;TransNormerLLM&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/TransNormer/01-TransNormer-7B%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;TransNormerLLM-7B-Chat FastApi 部署调用&lt;/a&gt; @王茂霖&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/TransNormer/02-TransNormer-7B%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&quot;&gt;TransNormerLLM-7B-Chat langchain 接入&lt;/a&gt; @王茂霖&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/TransNormer/03-TransNormer-7B%20WebDemo.md&quot;&gt;TransNormerLLM-7B-Chat WebDemo 部署&lt;/a&gt; @王茂霖&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/TransNormer/04-TrasnNormer-7B%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;TransNormerLLM-7B-Chat Lora 微调&lt;/a&gt; @王茂霖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/vivo-ai-lab/BlueLM.git&quot;&gt;BlueLM Vivo 蓝心大模型&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BlueLM/01-BlueLM-7B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2.md&quot;&gt;BlueLM-7B-Chat FatApi 部署调用&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BlueLM/02-BlueLM-7B-Chat%20langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;BlueLM-7B-Chat langchain 接入&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BlueLM/03-BlueLM-7B-Chat%20WebDemo%20%E9%83%A8%E7%BD%B2.md&quot;&gt;BlueLM-7B-Chat WebDemo 部署&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BlueLM/04-BlueLM-7B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;BlueLM-7B-Chat Lora 微调&lt;/a&gt; @郭志航&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/InternLM/InternLM&quot;&gt;InternLM2&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM2/01-InternLM2-7B-chat%20FastAPI%E9%83%A8%E7%BD%B2.md&quot;&gt;InternLM2-7B-chat FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM2/02-InternLM2-7B-chat%20langchain%20%E6%8E%A5%E5%85%A5.md&quot;&gt;InternLM2-7B-chat langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM2/03-InternLM2-7B-chat%20WebDemo%20%E9%83%A8%E7%BD%B2.md&quot;&gt;InternLM2-7B-chat WebDemo 部署&lt;/a&gt; @郑皓桦&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM2/04-InternLM2-7B-chat%20Xtuner%20Qlora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;InternLM2-7B-chat Xtuner Qlora 微调&lt;/a&gt; @郑皓桦&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-LLM&quot;&gt;DeepSeek 深度求索&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/01-DeepSeek-7B-chat%20FastApi.md&quot;&gt;DeepSeek-7B-chat FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/02-DeepSeek-7B-chat%20langchain.md&quot;&gt;DeepSeek-7B-chat langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/03-DeepSeek-7B-chat%20WebDemo.md&quot;&gt;DeepSeek-7B-chat WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/04-DeepSeek-7B-chat%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;DeepSeek-7B-chat Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/05-DeepSeek-7B-chat%204bits%E9%87%8F%E5%8C%96%20Qlora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;DeepSeek-7B-chat 4bits量化 Qlora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/06-DeepSeek-MoE-16b-chat%20Transformer%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;DeepSeek-MoE-16b-chat Transformers 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/06-DeepSeek-MoE-16b-chat%20FastApi.md&quot;&gt;DeepSeek-MoE-16b-chat FastApi 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/07-deepseek_fine_tune.ipynb&quot;&gt;DeepSeek-coder-6.7b finetune colab&lt;/a&gt; @Swiftie&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/08-deepseek_web_demo.ipynb&quot;&gt;Deepseek-coder-6.7b webdemo colab&lt;/a&gt; @Swiftie&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/OpenBMB/MiniCPM.git&quot;&gt;MiniCPM&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM/MiniCPM-2B-chat%20transformers%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;MiniCPM-2B-chat transformers 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM/MiniCPM-2B-chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;MiniCPM-2B-chat FastApi 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM/MiniCPM-2B-chat%20langchain%E6%8E%A5%E5%85%A5.md&quot;&gt;MiniCPM-2B-chat langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM/MiniCPM-2B-chat%20WebDemo%E9%83%A8%E7%BD%B2.md&quot;&gt;MiniCPM-2B-chat webdemo 部署&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM/MiniCPM-2B-chat%20Lora%20&amp;amp;&amp;amp;%20Full%20%E5%BE%AE%E8%B0%83.md&quot;&gt;MiniCPM-2B-chat Lora &amp;amp;&amp;amp; Full 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; 官方友情链接：&lt;a href=&quot;https://modelbest.feishu.cn/wiki/D2tFw8Pcsi5CIzkaHNacLK64npg&quot;&gt;面壁小钢炮MiniCPM教程&lt;/a&gt; @OpenBMB&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; 官方友情链接：&lt;a href=&quot;https://github.com/OpenBMB/MiniCPM-CookBook&quot;&gt;MiniCPM-Cookbook&lt;/a&gt; @OpenBMB&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/QwenLM/Qwen-Audio.git&quot;&gt;Qwen-Audio&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen-Audio/01-Qwen-Audio-chat%20FastApi.md&quot;&gt;Qwen-Audio FastApi 部署调用&lt;/a&gt; @陈思州&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen-Audio/02-Qwen-Audio-chat%20WebDemo.md&quot;&gt;Qwen-Audio WebDemo&lt;/a&gt; @陈思州&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/QwenLM/Qwen.git&quot;&gt;Qwen&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/01-Qwen-7B-Chat%20Transformers%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen-7B-chat Transformers 部署调用&lt;/a&gt; @李娇娇&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/02-Qwen-7B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Qwen-7B-chat FastApi 部署调用&lt;/a&gt; @李娇娇&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/03-Qwen-7B-Chat%20WebDemo.md&quot;&gt;Qwen-7B-chat WebDemo&lt;/a&gt; @李娇娇&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/04-Qwen-7B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Qwen-7B-chat Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/05-Qwen-7B-Chat%20Ptuning%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Qwen-7B-chat ptuning 微调&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/06-Qwen-7B-chat%20%E5%85%A8%E9%87%8F%E5%BE%AE%E8%B0%83.md&quot;&gt;Qwen-7B-chat 全量微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/07-Qwen-7B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&quot;&gt;Qwen-7B-Chat 接入langchain搭建知识库助手&lt;/a&gt; @李娇娇&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/08-Qwen-7B-Chat%20Lora%20%E4%BD%8E%E7%B2%BE%E5%BA%A6%E5%BE%AE%E8%B0%83.md&quot;&gt;Qwen-7B-chat 低精度训练&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/09-Qwen-1_8B-chat%20CPU%20%E9%83%A8%E7%BD%B2%20.md&quot;&gt;Qwen-1_8B-chat CPU 部署&lt;/a&gt; @散步&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/01-ai/Yi.git&quot;&gt;Yi 零一万物&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yi/01-Yi-6B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Yi-6B-chat FastApi 部署调用&lt;/a&gt; @李柯辰&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yi/02-Yi-6B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&quot;&gt;Yi-6B-chat langchain接入&lt;/a&gt; @李柯辰&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yi/03-Yi-6B-chat%20WebDemo.md&quot;&gt;Yi-6B-chat WebDemo&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yi/04-Yi-6B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Yi-6B-chat Lora 微调&lt;/a&gt; @李娇娇&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.baichuan-ai.com/home&quot;&gt;Baichuan 百川智能&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/BaiChuan/01-Baichuan2-7B-chat%2BFastApi%2B%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;Baichuan2-7B-chat FastApi 部署调用&lt;/a&gt; @惠佳豪&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BaiChuan/02-Baichuan-7B-chat%2BWebDemo.md&quot;&gt;Baichuan2-7B-chat WebDemo&lt;/a&gt; @惠佳豪&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BaiChuan/03-Baichuan2-7B-chat%E6%8E%A5%E5%85%A5LangChain%E6%A1%86%E6%9E%B6.md&quot;&gt;Baichuan2-7B-chat 接入 LangChain 框架&lt;/a&gt; @惠佳豪&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BaiChuan/04-Baichuan2-7B-chat%2Blora%2B%E5%BE%AE%E8%B0%83.md&quot;&gt;Baichuan2-7B-chat Lora 微调&lt;/a&gt; @惠佳豪&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/InternLM/InternLM.git&quot;&gt;InternLM&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/01-InternLM-Chat-7B%20Transformers%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;InternLM-Chat-7B Transformers 部署调用&lt;/a&gt; @小罗&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/02-internLM-Chat-7B%20FastApi.md&quot;&gt;InternLM-Chat-7B FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/03-InternLM-Chat-7B.md&quot;&gt;InternLM-Chat-7B WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/04-Lagent+InternLM-Chat-7B-V1.1.md&quot;&gt;Lagent+InternLM-Chat-7B-V1.1 WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/05-%E6%B5%A6%E8%AF%AD%E7%81%B5%E7%AC%94%E5%9B%BE%E6%96%87%E7%90%86%E8%A7%A3&amp;amp;%E5%88%9B%E4%BD%9C.md&quot;&gt;浦语灵笔图文理解&amp;amp;创作 WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/06-InternLM%E6%8E%A5%E5%85%A5LangChain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&quot;&gt;InternLM-Chat-7B 接入 LangChain 框架&lt;/a&gt; @Logan Zou&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://hf-mirror.com/FlagAlpha/Atom-7B-Chat&quot;&gt;Atom (llama2)&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Atom/01-Atom-7B-chat-WebDemo.md&quot;&gt;Atom-7B-chat WebDemo&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Atom/02-Atom-7B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md&quot;&gt;Atom-7B-chat Lora 微调&lt;/a&gt; @Logan Zou&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Atom/03-Atom-7B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&quot;&gt;Atom-7B-Chat 接入langchain搭建知识库助手&lt;/a&gt; @陈思州&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Atom/04-Atom-7B-chat%20%E5%85%A8%E9%87%8F%E5%BE%AE%E8%B0%83.md&quot;&gt;Atom-7B-chat 全量微调&lt;/a&gt; @Logan Zou&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/THUDM/ChatGLM3.git&quot;&gt;ChatGLM3&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/01-ChatGLM3-6B%20Transformer%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;ChatGLM3-6B Transformers 部署调用&lt;/a&gt; @丁悦&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/02-ChatGLM3-6B%20FastApi%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md&quot;&gt;ChatGLM3-6B FastApi 部署调用&lt;/a&gt; @丁悦&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/03-ChatGLM3-6B-chat.md&quot;&gt;ChatGLM3-6B chat WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/04-ChatGLM3-6B-Code-Interpreter.md&quot;&gt;ChatGLM3-6B Code Interpreter WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/05-ChatGLM3-6B%E6%8E%A5%E5%85%A5LangChain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md&quot;&gt;ChatGLM3-6B 接入 LangChain 框架&lt;/a&gt; @Logan Zou&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/06-ChatGLM3-6B-Lora%E5%BE%AE%E8%B0%83.md&quot;&gt;ChatGLM3-6B Lora 微调&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;通用环境配置&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/01-pip%E3%80%81conda%E6%8D%A2%E6%BA%90.md&quot;&gt;pip、conda 换源&lt;/a&gt; @不要葱姜蒜&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/02-AutoDL%E5%BC%80%E6%94%BE%E7%AB%AF%E5%8F%A3.md&quot;&gt;AutoDL 开放端口&lt;/a&gt; @不要葱姜蒜&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型下载&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md&quot;&gt;hugging face&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md&quot;&gt;hugging face&lt;/a&gt; 镜像下载 @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md&quot;&gt;modelscope&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md&quot;&gt;git-lfs&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md&quot;&gt;Openxlab&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Issue &amp;amp;&amp;amp; PR&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/04-Issue&amp;amp;PR&amp;amp;update.md&quot;&gt;Issue 提交&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/04-Issue&amp;amp;PR&amp;amp;update.md&quot;&gt;PR 提交&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; &lt;a href=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/04-Issue&amp;amp;PR&amp;amp;update.md&quot;&gt;fork更新&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;致谢&lt;/h2&gt; 
&lt;h3&gt;核心贡献者&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/KMnO4-zx&quot;&gt;宋志学(不要葱姜蒜)-项目负责人&lt;/a&gt; （Datawhale成员-中国矿业大学(北京)）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/logan-zou&quot;&gt;邹雨衡-项目负责人&lt;/a&gt; （Datawhale成员-对外经济贸易大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Hongru0306&quot;&gt;肖鸿儒&lt;/a&gt; （Datawhale成员-同济大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/acwwt&quot;&gt;郭志航&lt;/a&gt;（内容创作者）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Zeyi-Lin&quot;&gt;林泽毅&lt;/a&gt;（内容创作者-SwanLab产品负责人）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/zhangfanTJU&quot;&gt;张帆&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Tsumugii24&quot;&gt;姜舒凡&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Aphasia0515&quot;&gt;李娇娇&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/dingyue772&quot;&gt;丁悦&lt;/a&gt; （Datawhale-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/moyitech&quot;&gt;王泽宇&lt;/a&gt;（内容创作者-太原理工大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/L4HeyXiao&quot;&gt;惠佳豪&lt;/a&gt; （Datawhale-宣传大使）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mlw67&quot;&gt;王茂霖&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Caleb-Sun-jz&quot;&gt;孙健壮&lt;/a&gt;（内容创作者-对外经济贸易大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/LucaChen&quot;&gt;东东&lt;/a&gt;（内容创作者-谷歌开发者机器学习技术专家）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/0-yy-0&quot;&gt;高立业&lt;/a&gt;（内容创作者-DataWhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Kailigithub&quot;&gt;Kailigithub&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/BaiYu96&quot;&gt;郑皓桦&lt;/a&gt; （内容创作者）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Joe-2002&quot;&gt;李柯辰&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/chg0901&quot;&gt;程宏&lt;/a&gt;（内容创作者-Datawhale意向成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jjyaoao&quot;&gt;陈思州&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/sanbuphy&quot;&gt;散步&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/thomas-yanxin&quot;&gt;颜鑫&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/yeyeyeyeeeee&quot;&gt;荞麦&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/anine09&quot;&gt;骆秀韬&lt;/a&gt;（内容创作者-Datawhale成员-似然实验室）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/cswangxiaowei&quot;&gt;Swiftie&lt;/a&gt; （小米NLP算法工程师）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/KashiwaByte&quot;&gt;黄柏特&lt;/a&gt;（内容创作者-西安电子科技大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/AXYZdong&quot;&gt;张友东&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/YangYu-NUAA&quot;&gt;余洋&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Jin-Zhang-Yaoguang&quot;&gt;张晋&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/lta155&quot;&gt;娄天奥&lt;/a&gt;（内容创作者-中国科学院大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/LinChentang&quot;&gt;左春生&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/little1d&quot;&gt;杨卓&lt;/a&gt;（内容创作者-西安电子科技大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/lyj11111111&quot;&gt;小罗&lt;/a&gt; （内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Kedreamix&quot;&gt;邓恺俊&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/XiLinky&quot;&gt;赵文恺&lt;/a&gt;（内容创作者-太原理工大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/comfzy&quot;&gt;付志远&lt;/a&gt;（内容创作者-海南大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/study520ai520&quot;&gt;杜森&lt;/a&gt;（内容创作者-Datawhale成员-南阳理工学院）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/isaacahahah&quot;&gt;郑远婧&lt;/a&gt;（内容创作者-鲸英助教-福州大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/LikeGiver&quot;&gt;谭逸珂&lt;/a&gt;（内容创作者-对外经济贸易大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Bald0Wang&quot;&gt;王熠明&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/pod2c&quot;&gt;何至轩&lt;/a&gt;（内容创作者-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jodie-kang&quot;&gt;康婧淇&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/sssanssss&quot;&gt;三水&lt;/a&gt;（内容创作者-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/langlibai66&quot;&gt;杨晨旭&lt;/a&gt;（内容创作者-太原理工大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/2710932616&quot;&gt;赵伟&lt;/a&gt;（内容创作者-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/gzhuuser&quot;&gt;苏向标&lt;/a&gt;（内容创作者-广州大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/riannyway&quot;&gt;陈睿&lt;/a&gt;（内容创作者-西交利物浦大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/LINHYYY&quot;&gt;林恒宇&lt;/a&gt;（内容创作者-广东东软学院-鲸英助教）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：排名根据贡献程度排序&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;其他&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;特别感谢&lt;a href=&quot;https://github.com/Sm1les&quot;&gt;@Sm1les&lt;/a&gt;对本项目的帮助与支持&lt;/li&gt; 
 &lt;li&gt;部分lora代码和讲解参考仓库：&lt;a href=&quot;https://github.com/zyds/transformers-code.git&quot;&gt;https://github.com/zyds/transformers-code.git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;如果有任何想法可以联系我们 DataWhale 也欢迎大家多多提出 issue&lt;/li&gt; 
 &lt;li&gt;特别感谢以下为教程做出贡献的同学！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align=&quot;center&quot; style=&quot;margin-top: 30px;&quot;&gt; 
 &lt;a href=&quot;https://github.com/datawhalechina/self-llm/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=datawhalechina/self-llm&quot;&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Star History&lt;/h3&gt; 
&lt;div align=&quot;center&quot; style=&quot;margin-top: 30px;&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/datawhalechina/self-llm/master/images/star-history-2024129.png&quot;&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>AI4Finance-Foundation/FinGPT</title>
      <link>https://github.com/AI4Finance-Foundation/FinGPT</link>
      <description>&lt;p&gt;FinGPT: Open-Source Financial Large Language Models! Revolutionize 🔥 We release the trained model on HuggingFace.&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;img align=&quot;center&quot; width=&quot;30%&quot; alt=&quot;image&quot; src=&quot;https://github.com/AI4Finance-Foundation/FinGPT/assets/31713746/e0371951-1ce1-488e-aa25-0992dafcc139&quot;&gt; 
&lt;/div&gt; 
&lt;h1&gt;FinGPT: Open-Source Financial Large Language Models&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://pepy.tech/project/fingpt&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/fingpt&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pepy.tech/project/fingpt&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/fingpt/week&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.python.org/downloads/release/python-360/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/python-3.6-blue.svg?sanitize=true&quot; alt=&quot;Python 3.8&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/fingpt/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/fingpt.svg?sanitize=true&quot; alt=&quot;PyPI&quot;&gt;&lt;/a&gt; &lt;img src=&quot;https://img.shields.io/github/license/AI4Finance-Foundation/fingpt.svg?color=brightgreen&quot; alt=&quot;License&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/issues-raw/AI4Finance-Foundation/fingpt?label=Issues&quot; alt=&quot;&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/issues-closed-raw/AI4Finance-Foundation/fingpt?label=Closed+Issues&quot; alt=&quot;&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/issues-pr-raw/AI4Finance-Foundation/fingpt?label=Open+PRs&quot; alt=&quot;&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/issues-pr-closed-raw/AI4Finance-Foundation/fingpt?label=Closed+PRs&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/logo_transparent_background.png&quot; width=&quot;40%&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;Let us not expect Wall Street to open-source LLMs or open APIs, due to FinTech institutes&#39; internal regulations and policies.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2306.06031&quot;&gt;Blueprint of FinGPT&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://huggingface.co/FinGPT&quot;&gt;https://huggingface.co/FinGPT&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://discord.gg/trsr8SXpW5&quot;&gt;&lt;img src=&quot;https://dcbadge.vercel.app/api/server/trsr8SXpW5&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://api.visitorbadge.io/api/VisitorHit?user=AI4Finance-Foundation&amp;amp;repo=FinGPT&amp;amp;countColor=%23B17A&quot; alt=&quot;Visitors&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;What&#39;s New:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[Model Release] Nov, 2023: We release &lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Forecaster&quot;&gt;FinGPT-Forecaster&lt;/a&gt;! 🔥&lt;a href=&quot;https://huggingface.co/spaces/FinGPT/FinGPT-Forecaster&quot;&gt;Demo&lt;/a&gt;, &lt;a href=&quot;https://medium.datadriveninvestor.com/introducing-fingpt-forecaster-the-future-of-robo-advisory-services-50add34e3d3c&quot;&gt;Medium Blog&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-forecaster_dow30_llama2-7b_lora&quot;&gt;Model&lt;/a&gt; are available on Huggingface🤗!&lt;/li&gt; 
 &lt;li&gt;[Paper Acceptance] Oct, 2023: &lt;a href=&quot;https://arxiv.org/abs/2310.04793&quot;&gt;&quot;FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets&quot;&lt;/a&gt; is accepted🎉 by &lt;a href=&quot;https://an-instructive-workshop.github.io/&quot;&gt;Instruction Workshop&lt;/a&gt; @ NeurIPS 2023&lt;/li&gt; 
 &lt;li&gt;[Paper Acceptance] Oct, 2023: &lt;a href=&quot;https://arxiv.org/abs/2307.10485&quot;&gt;&quot;FinGPT: Democratizing Internet-scale Data for Financial Large Language Models&quot;&lt;/a&gt; is accepted🎉 by &lt;a href=&quot;https://an-instructive-workshop.github.io/&quot;&gt;Instruction Workshop&lt;/a&gt; @ NeurIPS 2023&lt;/li&gt; 
 &lt;li&gt;[Model Release] Oct, 2023: We release the &lt;a href=&quot;https://huggingface.co/FinGPT&quot;&gt;financial multi-task LLMs&lt;/a&gt; 🔥 produced when evaluating base-LLMs on &lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Benchmark&quot;&gt;FinGPT-Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[Paper Acceptance] Sep, 2023: &lt;a href=&quot;https://arxiv.org/abs/2310.04027&quot;&gt;&quot;Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models&quot;&lt;/a&gt; is accepted🎉 by &lt;a href=&quot;https://ai-finance.org/icaif-23-accepted-papers/&quot;&gt;ACM International Conference on AI in Finance (ICAIF-23)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[Model Release] Aug, 2023: We release the &lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora&quot;&gt;financial sentiment analysis model&lt;/a&gt; 🔥&lt;/li&gt; 
 &lt;li&gt;[Paper Acceptance] Jul, 2023: &lt;a href=&quot;https://arxiv.org/abs/2306.12659&quot;&gt;&quot;Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models&quot;&lt;/a&gt; is accepted🎉 by &lt;a href=&quot;https://finllm.github.io/workshop/#/fcb&quot;&gt;FinLLM 2023&lt;/a&gt;@IJCAI 2023&lt;/li&gt; 
 &lt;li&gt;[Paper Acceptance] Jul, 2023: &lt;a href=&quot;https://arxiv.org/abs/2306.06031&quot;&gt;&quot;FinGPT: Open-Source Financial Large Language Models&quot;&lt;/a&gt; is accepted🎉 by &lt;a href=&quot;https://finllm.github.io/workshop/#/fcb&quot;&gt;FinLLM 2023&lt;/a&gt;@IJCAI 2023&lt;/li&gt; 
 &lt;li&gt;[Medium Blog] Jun 2023: &lt;a href=&quot;https://medium.datadriveninvestor.com/fingpt-powering-the-future-of-finance-with-20-cutting-edge-applications-7c4d082ad3d8&quot;&gt;FinGPT: Powering the Future of Finance with 20 Cutting-Edge Applications&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why FinGPT?&lt;/h2&gt; 
&lt;p&gt;1). Finance is highly dynamic. &lt;a href=&quot;https://arxiv.org/abs/2303.17564&quot;&gt;BloombergGPT&lt;/a&gt; trained an LLM using a mixture of finance data and general-purpose data, which took about 53 days, at a cost of around &lt;strong&gt;$3M&lt;/strong&gt;). It is costly to retrain an LLM model like BloombergGPT every month or every week, thus lightweight adaptation is highly favorable. FinGPT can be fine-tuned swiftly to incorporate new data (the cost falls significantly, less than &lt;strong&gt;$300 per fine-tuning&lt;/strong&gt;).&lt;/p&gt; 
&lt;p&gt;2). Democratizing Internet-scale financial data is critical, say allowing timely updates of the model (monthly or weekly updates) using an automatic data curation pipeline. BloombergGPT has privileged data access and APIs, while FinGPT presents a more accessible alternative. It prioritizes lightweight adaptation, leveraging the best available open-source LLMs.&lt;/p&gt; 
&lt;p&gt;3). The key technology is &quot;RLHF (Reinforcement learning from human feedback)&quot;, which is missing in BloombergGPT. RLHF enables an LLM model to learn individual preferences (risk-aversion level, investing habits, personalized robo-advisor, etc.), which is the &quot;secret&quot; ingredient of ChatGPT and GPT4.&lt;/p&gt; 
&lt;h3&gt;Milestone of AI Robo-Advisor: FinGPT-Forecaster&lt;/h3&gt; 
&lt;p&gt;Try the latest released FinGPT-Forecaster demo at our &lt;a href=&quot;https://huggingface.co/spaces/FinGPT/FinGPT-Forecaster&quot;&gt;HuggingFace Space&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The dataset for FinGPT-Forecaster: &lt;a href=&quot;https://huggingface.co/datasets/FinGPT/fingpt-forecaster-dow30-202305-202405&quot;&gt;https://huggingface.co/datasets/FinGPT/fingpt-forecaster-dow30-202305-202405&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt/FinGPT_Forecaster/figs/interface.png&quot; alt=&quot;demo_interface&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Enter the following inputs:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;ticker symbol (e.g. AAPL, MSFT, NVDA)&lt;/li&gt; 
 &lt;li&gt;the day from which you want the prediction to happen (yyyy-mm-dd)&lt;/li&gt; 
 &lt;li&gt;the number of past weeks where market news are retrieved&lt;/li&gt; 
 &lt;li&gt;whether to add the latest basic financials as additional information&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Click Submit！ And you&#39;ll be responded with a well-rounded analysis of the company and a prediction for next week&#39;s stock price movement!&lt;/p&gt; 
&lt;p&gt;For detailed and more customized implementation, please refer to &lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Forecaster&quot;&gt;FinGPT-Forecaster&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;FinGPT Demos:&lt;/h2&gt; 
&lt;h3&gt;Current State-of-the-arts for Financial Sentiment Analysis&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt&quot;&gt;FinGPT V3 (Updated on 10/12/2023)&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;What&#39;s new: &lt;strong&gt;Best trainable and inferable FinGPT for sentiment analysis on a single RTX 3090, which is even better than GPT-4 and ChatGPT Finetuning.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora&quot;&gt;FinGPT v3&lt;/a&gt; series are LLMs finetuned with the LoRA method on the News and Tweets sentiment analysis dataset which achieve the best scores on most of the financial sentiment analysis datasets with low cost.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;FinGPT v3.3 use llama2-13b as base model; FinGPT v3.2 uses llama2-7b as base model; FinGPT v3.1 uses chatglm2-6B as base model.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Benchmark Results:&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; 
    &lt;table&gt; 
     &lt;thead&gt; 
      &lt;tr&gt; 
       &lt;th&gt;Weighted F1&lt;/th&gt; 
       &lt;th align=&quot;center&quot;&gt;FPB&lt;/th&gt; 
       &lt;th align=&quot;center&quot;&gt;FiQA-SA&lt;/th&gt; 
       &lt;th align=&quot;center&quot;&gt;TFNS&lt;/th&gt; 
       &lt;th align=&quot;center&quot;&gt;NWGI&lt;/th&gt; 
       &lt;th align=&quot;center&quot;&gt;Devices&lt;/th&gt; 
       &lt;th align=&quot;center&quot;&gt;Time&lt;/th&gt; 
       &lt;th align=&quot;center&quot;&gt;Cost&lt;/th&gt; 
      &lt;/tr&gt; 
     &lt;/thead&gt; 
     &lt;tbody&gt; 
      &lt;tr&gt; 
       &lt;td&gt;&lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora&quot;&gt;FinGPT v3.3&lt;/a&gt;&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;&lt;strong&gt;0.882&lt;/strong&gt;&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.874&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;&lt;strong&gt;0.903&lt;/strong&gt;&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;&lt;strong&gt;0.643&lt;/strong&gt;&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;1 × RTX 3090&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;17.25 hours&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;$17.25&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;FinGPT v3.2&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.850&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.860&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.894&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.636&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;1 × A100&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;5.5 hours&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;$ 22.55&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;FinGPT v3.1&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.855&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.850&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.875&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.642&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;1 × A100&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;5.5 hours&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;$ 22.55&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;FinGPT (8bit)&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.855&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.847&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.879&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.632&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;1 × RTX 3090&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;6.47 hours&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;$ 6.47&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;FinGPT (QLoRA)&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.777&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.752&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.828&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.583&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;1 × RTX 3090&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;4.15 hours&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;$ 4.15&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;OpenAI Fine-tune&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.878&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;&lt;strong&gt;0.887&lt;/strong&gt;&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.883&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;GPT-4&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.833&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.630&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.808&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;FinBERT&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.880&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.596&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.733&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.538&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;4 × NVIDIA K80 GPU&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;Llama2-7B&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.390&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.800&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.296&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.503&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;2048 × A100&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;21 days&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;$ 4.23 million&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;BloombergGPT&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.511&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;0.751&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;512 × A100&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;53 days&lt;/td&gt; 
       &lt;td align=&quot;center&quot;&gt;$ 2.67 million&lt;/td&gt; 
      &lt;/tr&gt; 
     &lt;/tbody&gt; 
    &lt;/table&gt; &lt;p&gt;&lt;strong&gt;Cost per GPU hour.&lt;/strong&gt; For &lt;strong&gt;A100 GPUs&lt;/strong&gt;, the AWS p4d.24xlarge instance, equipped with 8 A100 GPUs is used as a benchmark to estimate the costs. Note that BloombergGPT also used p4d.24xlarge As of July 11, 2023, the hourly rate for this instance stands at $32.773. Consequently, the estimated cost per GPU hour comes to $32.77 divided by 8, resulting in approximately &lt;strong&gt;$4.10&lt;/strong&gt;. With this value as the reference unit price (1 GPU hour). &lt;strong&gt;BloombergGPT estimated cost= 512 x 53 x 24 = 651,264 GPU hours x $4.10 = $2,670,182.40&lt;/strong&gt;. For &lt;strong&gt;RTX 3090&lt;/strong&gt;, we assume its cost per hour is approximately &lt;strong&gt;$1.0&lt;/strong&gt;, which is actually much higher than available GPUs from platforms like vast.ai.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Reproduce the results by running &lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt/FinGPT_Sentiment_Analysis_v3/benchmark/benchmarks.ipynb&quot;&gt;benchmarks&lt;/a&gt;, and the detailed tutorial is on the way.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Finetune your own FinGPT v3 model with the LoRA method on only an RTX 3090 with this &lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt/FinGPT_Sentiment_Analysis_v3/training_8bit/train_Llama2_13B.ipynb&quot;&gt;notebook&lt;/a&gt; in 8bit or this &lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt/FinGPT_Sentiment_Analysis_v3/training_int4/train.ipynb&quot;&gt;notebook&lt;/a&gt; in int4 (QLoRA)&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt&quot;&gt;FinGPT V1&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;FinGPT by finetuning ChatGLM2 / Llama2 with LoRA with the market-labeled data for the Chinese Market&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Instruction Tuning Datasets and Models&lt;/h2&gt; 
&lt;p&gt;The datasets we used, and the &lt;strong&gt;multi-task financial LLM&lt;/strong&gt; models are available at &lt;a href=&quot;https://huggingface.co/FinGPT&quot;&gt;https://huggingface.co/FinGPT&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Benchmark&quot;&gt;Our Code&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Datasets&lt;/th&gt; 
   &lt;th&gt;Train Rows&lt;/th&gt; 
   &lt;th&gt;Test Rows&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/datasets/FinGPT/fingpt-sentiment-train&quot;&gt;fingpt-sentiment-train&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;76.8K&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;Sentiment Analysis Training Instructions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/datasets/FinGPT/fingpt-finred&quot;&gt;fingpt-finred&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;27.6k&lt;/td&gt; 
   &lt;td&gt;5.11k&lt;/td&gt; 
   &lt;td&gt;Financial Relation Extraction Instructions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/datasets/FinGPT/fingpt-headline&quot;&gt;fingpt-headline&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;82.2k&lt;/td&gt; 
   &lt;td&gt;20.5k&lt;/td&gt; 
   &lt;td&gt;Financial Headline Analysis Instructions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/datasets/FinGPT/fingpt-ner&quot;&gt;fingpt-ner&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;511&lt;/td&gt; 
   &lt;td&gt;98&lt;/td&gt; 
   &lt;td&gt;Financial Named-Entity Recognition Instructions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/datasets/FinGPT/fingpt-fiqa_qa&quot;&gt;fingpt-fiqa_qa&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;17.1k&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;Financial Q&amp;amp;A Instructions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/datasets/FinGPT/fingpt-fineval&quot;&gt;fingpt-fineval&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.06k&lt;/td&gt; 
   &lt;td&gt;265&lt;/td&gt; 
   &lt;td&gt;Chinese Multiple-Choice Questions Instructions&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Multi-task financial LLMs Models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;  demo_tasks = [
      &#39;Financial Sentiment Analysis&#39;,
      &#39;Financial Relation Extraction&#39;,
      &#39;Financial Headline Classification&#39;,
      &#39;Financial Named Entity Recognition&#39;,]
  demo_inputs = [
      &quot;Glaxo&#39;s ViiV Healthcare Signs China Manufacturing Deal With Desano&quot;,
      &quot;Apple Inc. Chief Executive Steve Jobs sought to soothe investor concerns about his health on Monday, saying his weight loss was caused by a hormone imbalance that is relatively simple to treat.&quot;,
      &#39;gold trades in red in early trade; eyes near-term range at rs 28,300-28,600&#39;,
      &#39;This LOAN AND SECURITY AGREEMENT dated January 27 , 1999 , between SILICON VALLEY BANK (&quot; Bank &quot;), a California - chartered bank with its principal place of business at 3003 Tasman Drive , Santa Clara , California 95054 with a loan production office located at 40 William St ., Ste .&#39;,]
  demo_instructions = [
      &#39;What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.&#39;,
      &#39;Given phrases that describe the relationship between two words/phrases as options, extract the word/phrase pair and the corresponding lexical relationship between them from the input text. The output format should be &quot;relation1: word1, word2; relation2: word3, word4&quot;. Options: product/material produced, manufacturer, distributed by, industry, position held, original broadcaster, owned by, founded by, distribution format, headquarters location, stock exchange, currency, parent organization, chief executive officer, director/manager, owner of, operator, member of, employer, chairperson, platform, subsidiary, legal form, publisher, developer, brand, business division, location of formation, creator.&#39;,
      &#39;Does the news headline talk about price going up? Please choose an answer from {Yes/No}.&#39;,
      &#39;Please extract entities and their types from the input sentence, entity types should be chosen from {person/organization/location}.&#39;,]
&lt;/code&gt;&lt;/pre&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Models&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Function&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-mt_llama2-7b_lora&quot;&gt;fingpt-mt_llama2-7b_lora&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fine-tuned Llama2-7b model with LoRA&lt;/td&gt; 
   &lt;td&gt;Multi-Task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-mt_falcon-7b_lora&quot;&gt;fingpt-mt_falcon-7b_lora&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fine-tuned falcon-7b model with LoRA&lt;/td&gt; 
   &lt;td&gt;Multi-Task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-mt_bloom-7b1_lora&quot;&gt;fingpt-mt_bloom-7b1_lora&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fine-tuned bloom-7b1 model with LoRA&lt;/td&gt; 
   &lt;td&gt;Multi-Task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-mt_mpt-7b_lora&quot;&gt;fingpt-mt_mpt-7b_lora&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fine-tuned mpt-7b model with LoRA&lt;/td&gt; 
   &lt;td&gt;Multi-Task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-mt_chatglm2-6b_lora&quot;&gt;fingpt-mt_chatglm2-6b_lora&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fine-tuned chatglm-6b model with LoRA&lt;/td&gt; 
   &lt;td&gt;Multi-Task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-mt_qwen-7b_lora&quot;&gt;fingpt-mt_qwen-7b_lora&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fine-tuned qwen-7b model with LoRA&lt;/td&gt; 
   &lt;td&gt;Multi-Task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-sentiment_llama2-13b_lora&quot;&gt;fingpt-sentiment_llama2-13b_lora&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fine-tuned llama2-13b model with LoRA&lt;/td&gt; 
   &lt;td&gt;Single-Task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/FinGPT/fingpt-forecaster_dow30_llama2-7b_lora&quot;&gt;fingpt-forecaster_dow30_llama2-7b_lora&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fine-tuned llama2-7b model with LoRA&lt;/td&gt; 
   &lt;td&gt;Single-Task&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Tutorials&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://byfintech.medium.com/beginners-guide-to-fingpt-training-with-lora-chatglm2-6b-9eb5ace7fe99&quot;&gt;[Training] Beginner’s Guide to FinGPT: Training with LoRA and ChatGLM2–6B One Notebook, $10 GPU&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Understanding FinGPT: An Educational Blog Series&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.datadriveninvestor.com/fingpt-powering-the-future-of-finance-with-20-cutting-edge-applications-7c4d082ad3d8&quot;&gt;FinGPT: Powering the Future of Finance with 20 Cutting-Edge Applications &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.datadriveninvestor.com/fingpt-i-why-we-built-the-first-open-source-large-language-model-for-finance-c01b5517ca&quot;&gt;FinGPT I: Why We Built the First Open-Source Large Language Model for Finance &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.datadriveninvestor.com/fingpt-ii-cracking-the-financial-sentiment-analysis-task-using-instruction-tuning-of-3333bce428c4&quot;&gt;FinGPT II: Cracking the Financial Sentiment Analysis Task Using Instruction Tuning of General-Purpose Large Language Models &lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FinGPT Ecosystem&lt;/h2&gt; 
&lt;h3&gt;FinGPT embraces a full-stack framework for FinLLMs with five layers:&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Data source layer&lt;/strong&gt;: This layer assures comprehensive market coverage, addressing the temporal sensitivity of financial data through real-time information capture.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data engineering layer&lt;/strong&gt;: Primed for real-time NLP data processing, this layer tackles the inherent challenges of high temporal sensitivity and low signal-to-noise ratio in financial data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLMs layer&lt;/strong&gt;: Focusing on a range of fine-tuning methodologies such as LoRA, this layer mitigates the highly dynamic nature of financial data, ensuring the model’s relevance and accuracy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task layer&lt;/strong&gt;: This layer is responsible for executing fundamental tasks. These tasks serve as the benchmarks for performance evaluations and cross-comparisons in the realm of FinLLMs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Application layer&lt;/strong&gt;: Showcasing practical applications and demos, this layer highlights the potential capability of FinGPT in the financial sector.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;FinGPT Framework: Open-Source Financial Large Language Models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/FinGPT_framework_20240301.png&quot;&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_RAG&quot;&gt;FinGPT-RAG&lt;/a&gt;: We present a retrieval-augmented large language model framework specifically designed for financial sentiment analysis, optimizing information depth and context through external knowledge retrieval, thereby ensuring nuanced predictions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/FinGPT_RAG_framework.png&quot;&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinNLP&quot;&gt;FinGPT-FinNLP&lt;/a&gt;: FinNLP provides a playground for all people interested in LLMs and NLP in Finance. Here we provide full pipelines for LLM training and finetuning in the field of finance. The full architecture is shown in the following picture. Detail codes and introductions can be found &lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinNLP&quot;&gt;here&lt;/a&gt;. Or you may refer to the &lt;a href=&quot;https://ai4finance-foundation.github.io/FinNLP/&quot;&gt;wiki&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/FinGPT_FinNLP_data_source.png&quot;&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinGPT/tree/master/fingpt/FinGPT_Benchmark&quot;&gt;FinGPT-Benchmark&lt;/a&gt;: We introduce a novel Instruction Tuning paradigm optimized for open-source Large Language Models (LLMs) in finance, enhancing their adaptability to diverse financial datasets while also facilitating cost-effective, systematic benchmarking from task-specific, multi-task, and zero-shot instruction tuning tasks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/FinGPT_Benchmark_20231110.png&quot;&gt; 
&lt;/div&gt; 
&lt;h2&gt;Open-Source Base Model used in the LLMs layer of FinGPT&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Feel free to contribute more open-source base models tailored for various language-specific financial markets.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Base Model&lt;/th&gt; 
   &lt;th&gt;Pretraining Tokens&lt;/th&gt; 
   &lt;th&gt;Context Length&lt;/th&gt; 
   &lt;th&gt;Model Advantages&lt;/th&gt; 
   &lt;th&gt;Model Size&lt;/th&gt; 
   &lt;th&gt;Experiment Results&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/facebookresearch/llama&quot;&gt;Llama-2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2 Trillion&lt;/td&gt; 
   &lt;td&gt;4096&lt;/td&gt; 
   &lt;td&gt;Llama-2 excels on English-based market data&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/meta-llama/Llama-2-7b-hf&quot;&gt;llama-2-7b&lt;/a&gt; and &lt;a href=&quot;https://huggingface.co/meta-llama/Llama-2-13b-hf&quot;&gt;Llama-2-13b&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;llama-2 consistently shows superior fine-tuning results&lt;/td&gt; 
   &lt;td&gt;Financial Sentiment Analysis, Robo-Advisor&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/falconry/falcon&quot;&gt;Falcon&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1,500B&lt;/td&gt; 
   &lt;td&gt;2048&lt;/td&gt; 
   &lt;td&gt;Maintains high-quality results while being more resource-efficient&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/tiiuae/falcon-7b&quot;&gt;falcon-7b&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Good for English market data&lt;/td&gt; 
   &lt;td&gt;Financial Sentiment Analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mosaicml/llm-foundry&quot;&gt;MPT&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1T&lt;/td&gt; 
   &lt;td&gt;2048&lt;/td&gt; 
   &lt;td&gt;MPT models can be trained with high throughput efficiency and stable convergence&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/mosaicml/mpt-7b&quot;&gt;mpt-7b&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Good for English market data&lt;/td&gt; 
   &lt;td&gt;Financial Sentiment Analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/bigscience-workshop/bigscience/tree/master/train/tr11-176B-ml#readme&quot;&gt;Bloom&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;366B&lt;/td&gt; 
   &lt;td&gt;2048&lt;/td&gt; 
   &lt;td&gt;World’s largest open multilingual language model&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/bigscience/bloom-7b1&quot;&gt;bloom-7b1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Good for English market data&lt;/td&gt; 
   &lt;td&gt;Financial Sentiment Analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/THUDM/ChatGLM2-6B&quot;&gt;ChatGLM2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.4T&lt;/td&gt; 
   &lt;td&gt;32K&lt;/td&gt; 
   &lt;td&gt;Exceptional capability for Chinese language expression&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/THUDM/chatglm2-6b&quot;&gt;chatglm2-6b&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Shows prowess for Chinese market data&lt;/td&gt; 
   &lt;td&gt;Financial Sentiment Analysis, Financial Report Summary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/QwenLM/Qwen-7B&quot;&gt;Qwen&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.2T&lt;/td&gt; 
   &lt;td&gt;8k&lt;/td&gt; 
   &lt;td&gt;Fast response and high accuracy&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/tangger/Qwen-7B-Chat&quot;&gt;qwen-7b&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Effective for Chinese market data&lt;/td&gt; 
   &lt;td&gt;Financial Sentiment Analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/InternLM/InternLM&quot;&gt;InternLM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.8T&lt;/td&gt; 
   &lt;td&gt;8k&lt;/td&gt; 
   &lt;td&gt;Can flexibly and independently construct workflows&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://huggingface.co/internlm/internlm-7b&quot;&gt;internlm-7b&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Effective for Chinese market data&lt;/td&gt; 
   &lt;td&gt;Financial Sentiment Analysis&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;Benchmark Results for the above open-source Base Models in the financial sentiment analysis task using the same instruction template for SFT (LoRA): 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;Weighted F1/Acc&lt;/th&gt; 
     &lt;th&gt;Llama2&lt;/th&gt; 
     &lt;th&gt;Falcon&lt;/th&gt; 
     &lt;th&gt;MPT&lt;/th&gt; 
     &lt;th&gt;Bloom&lt;/th&gt; 
     &lt;th&gt;ChatGLM2&lt;/th&gt; 
     &lt;th&gt;Qwen&lt;/th&gt; 
     &lt;th&gt;InternLM&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;a href=&quot;https://huggingface.co/datasets/financial_phrasebank&quot;&gt;FPB&lt;/a&gt;&lt;/td&gt; 
     &lt;td&gt;0.863/0.863&lt;/td&gt; 
     &lt;td&gt;0.846/0.849&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;0.872&lt;/strong&gt;/&lt;strong&gt;0.872&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;0.810/0.810&lt;/td&gt; 
     &lt;td&gt;0.850/0.849&lt;/td&gt; 
     &lt;td&gt;0.854/0.854&lt;/td&gt; 
     &lt;td&gt;0.709/0.714&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;a href=&quot;https://huggingface.co/datasets/pauri32/fiqa-2018&quot;&gt;FiQA-SA&lt;/a&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;0.871&lt;/strong&gt;/0.855&lt;/td&gt; 
     &lt;td&gt;0.840/0.811&lt;/td&gt; 
     &lt;td&gt;0.863/0.844&lt;/td&gt; 
     &lt;td&gt;0.771/0.753&lt;/td&gt; 
     &lt;td&gt;0.864/&lt;strong&gt;0.862&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;0.867/0.851&lt;/td&gt; 
     &lt;td&gt;0.679/0.687&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;a href=&quot;https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment&quot;&gt;TFNS&lt;/a&gt;&lt;/td&gt; 
     &lt;td&gt;0.896/0.895&lt;/td&gt; 
     &lt;td&gt;0.893/0.893&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;0.907&lt;/strong&gt;/&lt;strong&gt;0.907&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;0.840/0.840&lt;/td&gt; 
     &lt;td&gt;0.859/0.858&lt;/td&gt; 
     &lt;td&gt;0.883/0.882&lt;/td&gt; 
     &lt;td&gt;0.729/0.731&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;a href=&quot;https://huggingface.co/datasets/oliverwang15/news_with_gpt_instructions&quot;&gt;NWGI&lt;/a&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;strong&gt;0.649/0.651&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;0.636/0.638&lt;/td&gt; 
     &lt;td&gt;0.640/0.641&lt;/td&gt; 
     &lt;td&gt;0.573/0.574&lt;/td&gt; 
     &lt;td&gt;0.619/0.629&lt;/td&gt; 
     &lt;td&gt;0.638/0.643&lt;/td&gt; 
     &lt;td&gt;0.498/0.503&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;All Thanks To Our Contributors :&lt;/h3&gt; 
&lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinGPT/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=AI4Finance-Foundation/FinGPT&quot;&gt; &lt;/a&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://datascience.columbia.edu/news/2023/columbia-perspectives-on-chatgpt/?utm_source=sendinblue&amp;amp;utm_campaign=DSI%20Newsletter%20April%202023&amp;amp;utm_medium=email&quot;&gt;Columbia Perspectives on ChatGPT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[MIT Technology Review] &lt;a href=&quot;https://www.technologyreview.com/2023/03/25/1070275/chatgpt-revolutionize-economy-decide-what-looks-like/&quot;&gt;ChatGPT is about to revolutionize the economy. We need to decide what that looks like&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[BloombergGPT] &lt;a href=&quot;https://arxiv.org/abs/2303.17564&quot;&gt;BloombergGPT: A Large Language Model for Finance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[Finextra] &lt;a href=&quot;https://www.finextra.com/newsarticle/41973/chatgpt-and-bing-ai-to-sit-as-panellists-at-fintech-conference&quot;&gt;ChatGPT and Bing AI to sit as panellists at fintech conference&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ChatGPT at AI4Finance&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[YouTube video] &lt;a href=&quot;https://www.youtube.com/watch?v=fhBw3j_O9LE&quot;&gt;I Built a Trading Bot with ChatGPT&lt;/a&gt;, combining ChatGPT and FinRL.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@ai4finance/hey-chatgpt-explain-finrl-code-to-me-6a91d612296f&quot;&gt;Hey, ChatGPT! Explain FinRL code to me!&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introductory&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2303.12712&quot;&gt;Sparks of artificial general intelligence: Early experiments with GPT-4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[GPT-4] &lt;a href=&quot;https://arxiv.org/abs/2303.08774&quot;&gt;GPT-4 Technical Report&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[InstructGPT] &lt;a href=&quot;https://openreview.net/forum?id=TG8KACxEON&quot;&gt;Training language models to follow instructions with human feedback&lt;/a&gt; NeurIPS 2022.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://medium.com/walmartglobaltech/the-journey-of-open-ai-gpt-models-32d95b7b7fb2&quot;&gt;The Journey of Open AI GPT models&lt;/a&gt;. GPT models explained. Open AI&#39;s GPT-1, GPT-2, GPT-3.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[GPT-3] &lt;a href=&quot;https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html&quot;&gt;Language models are few-shot learners&lt;/a&gt; NeurIPS 2020.&lt;/li&gt; 
 &lt;li&gt;[GPT-2] &lt;a href=&quot;https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf&quot;&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[GPT-1] &lt;a href=&quot;https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf&quot;&gt;Improving Language Understanding by Generative Pre-Training&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[Transformer] &lt;a href=&quot;https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html&quot;&gt;Attention is All you Need&lt;/a&gt; NeurIPS 2017.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;(Financial) Big Data&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;[BloombergGPT] &lt;a href=&quot;https://arxiv.org/abs/2303.17564&quot;&gt;BloombergGPT: A Large Language Model for Finance&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://lifearchitect.ai/whats-in-my-ai/&quot;&gt;WHAT’S IN MY AI?&lt;/a&gt; A Comprehensive Analysis of Datasets Used to Train GPT-1, GPT-2, GPT-3, GPT-NeoX-20B, Megatron-11B, MT-NLG, and Gopher&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinRL-Meta&quot;&gt;FinRL-Meta Repo&lt;/a&gt; and paper &lt;a href=&quot;https://proceedings.neurips.cc/paper_files/paper/2022/hash/0bf54b80686d2c4dc0808c2e98d430f7-Abstract-Datasets_and_Benchmarks.html&quot;&gt;FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement Learning&lt;/a&gt;. Advances in Neural Information Processing Systems, 2022.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[AI4Finance] &lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinNLP&quot;&gt;FinNLP&lt;/a&gt; Democratizing Internet-scale financial data.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Interesting Demos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gwern.net/gpt-3#prompts-as-programming&quot;&gt;GPT-3 Creative Fiction&lt;/a&gt; Creative writing by OpenAI’s GPT-3 model, demonstrating poetry, dialogue, puns, literary parodies, and storytelling. Plus advice on effective GPT-3 prompt programming &amp;amp; avoiding common errors.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ChatGPT for FinTech&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ChatGPT Trading Bot&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[YouTube video] &lt;a href=&quot;https://www.youtube.com/watch?v=unsa_gXPAJ4&quot;&gt;ChatGPT Trading strategy 20097% returns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[YouTube video] &lt;a href=&quot;https://www.youtube.com/watch?v=4SG2884RcDY&quot;&gt;ChatGPT Coding - Make A Profitable Trading Strategy In Five Minutes!&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[YouTube video] &lt;a href=&quot;https://www.youtube.com/watch?v=dIEZVPVOZPQ&quot;&gt;Easy Automated Live Trading using ChatGPT (+9660.3% hands free)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[YouTube video] &lt;a href=&quot;https://www.youtube.com/watch?v=YxjvjK5AD2M&quot;&gt;ChatGPT Trading Strategy 893% Returns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[YouTube video] &lt;a href=&quot;https://www.youtube.com/watch?v=9VPfd08uU4Q&quot;&gt;ChatGPT 10 Million Trading Strategy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[YouTube video] &lt;a href=&quot;https://www.youtube.com/watch?v=LpzeshX6s2w&quot;&gt;ChatGPT: Your Crypto Assistant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[YouTube video] &lt;a href=&quot;https://www.youtube.com/watch?v=ekz6ugJE1h0&amp;amp;t=3s&quot;&gt;Generate Insane Trading Returns with ChatGPT and TradingView&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- 
**(Fast and accurate) Sentiment Analysis**

   GPT-3 can help study customer surveys, social media tweets from customers/users.

   Tweets
+ [Tweet Classifier](https://platform.openai.com/playground/p/default-tweet-classifier?model=text-davinci-003)
+ [Advanced Tweet Classifier](https://platform.openai.com/playground/p/default-adv-tweet-classifier?model=text-davinci-003)

  Financial News
+ [Algorithmic Trading using Sentiment Analysis on News Articles](https://towardsdatascience.com/https-towardsdatascience-com-algorithmic-trading-using-sentiment-analysis-on-news-articles-83db77966704)
+ [Accessing Historical Financial News Headlines with Python](https://python.plainenglish.io/access-historical-financial-news-headlines-with-python-be1b8faaea9f)

**PromptNet** Analogy to ImageNet and WordNet, it is critical to build a PromptNet.

+ [Awesome_Prompting_Papers_in_Computer_Vision](https://github.com/ttengwang/Awesome_Prompting_Papers_in_Computer_Vision)
+ [OpenPrompt](https://github.com/thunlp/OpenPrompt)
+ [promptsource](https://github.com/bigscience-workshop/promptsource)

**Robo-advisor**

**Coding-tutor**

+ [Hey, ChatGPT! Explain FinRL code to me!](https://medium.com/@ai4finance/hey-chatgpt-explain-finrl-code-to-me-6a91d612296f)

**Blogs about ChatGPT for FinTech**

## ChatGPT APIs

Prompting as a new programming paradigm!
+ [Towards Data Science] [GPT-3: Creative Potential of NLP](https://towardsdatascience.com/gpt-3-creative-potential-of-nlp-d5ccae16c1ab)
+ [YouTube video] [OpenAI GPT-3 - Prompt Engineering For Financial NLP](https://www.youtube.com/watch?v=Nl2Cdbao5Ws)

+ [OpenAI API for GPT-3](https://platform.openai.com/docs/models/gpt-3)
+ [ChatGPT-wrapper: python and shell](https://github.com/mmabrouk/chatgpt-wrapper)
+ [OpenAI Examples Library](https://platform.openai.com/examples)
+ [GPT-3 Sandbox (Github)](https://github.com/shreyashankar/gpt3-sandbox) Enable users to create cool web demos using OpenAI GPT-3 API.
+ [Exploring the Capabilities of the ChatGPT API: A Beginner’s Guide](https://levelup.gitconnected.com/exploring-the-capabilities-of-the-chatgpt-api-a-beginners-guide-e9089d49961f)
+ [Reverse engineered ChatGPT API](https://github.com/acheong08/ChatGPT)

**Prompting programming**

## ChatGPT relatives: 

[A Release Timeline](https://github.com/osanseviero/ml_timeline) of many LLMs.

[PaLM](https://arxiv.org/abs/2204.02311)

[Chincella](https://arxiv.org/abs/2203.15556)

Interesting evaluations:
+ [RLHF for pretraining](https://arxiv.org/abs/2302.08582)

+ [Compare ChatGPT with GPT3.5](https://arxiv.org/pdf/2302.06476.pdf)

+ [Is ChatGPT A Good Translator? A Preliminary Study](https://arxiv.org/pdf/2301.08745.pdf)

+ [A Multitask, Multilingual, Multimodal Evaluation of ChatGPT
on Reasoning, Hallucination, and Interactivity](https://arxiv.org/pdf/2302.04023.pdf)

[YouTube video] [Physics Solution: ChatGPT vs. Google](https://www.youtube.com/watch?v=x4dIx9VYQoM)
---&gt; 
&lt;h2&gt;Citing FinGPT&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@article{yang2023fingpt,
  title={FinGPT: Open-Source Financial Large Language Models},
  author={Yang, Hongyang and Liu, Xiao-Yang and Wang, Christina Dan},
  journal={FinLLM Symposium at IJCAI 2023},
  year={2023}
}
@article{zhang2023instructfingpt,
      title={Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models}, 
      author={Boyu Zhang and Hongyang Yang and Xiao-Yang Liu},
      journal={FinLLM Symposium at IJCAI 2023},
      year={2023}
}
@article{zhang2023fingptrag,
  title={Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models},
  author={Zhang, Boyu and Yang, Hongyang and Zhou, tianyu and Babar, Ali and Liu, Xiao-Yang},
 journal = {ACM International Conference on AI in Finance (ICAIF)},
  year={2023}
}

@article{wang2023fingptbenchmark,
  title={FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets},
  author={Wang, Neng and Yang, Hongyang and Wang, Christina Dan},
  journal={NeurIPS Workshop on Instruction Tuning and Instruction Following},
  year={2023}
}
@article{2023finnlp,
  title={Data-centric FinGPT: Democratizing Internet-scale Data for Financial Large Language Models},
  author={Liu, Xiao-Yang and Wang, Guoxuan and Yang, Hongyang and Zha, Daochen},
  journal={NeurIPS Workshop on Instruction Tuning and Instruction Following},
  year={2023}
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://finllm.github.io/workshop/#/fcb&quot; target=&quot;_blank&quot;&gt; &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/fingpt_best_presentation.png&quot; width=&quot;65%&quot;&gt; &lt;/a&gt;
&lt;/div&gt;
&lt;a href=&quot;https://finllm.github.io/workshop/#/fcb&quot; target=&quot;_blank&quot;&gt; &lt;h2&gt;LICENSE&lt;/h2&gt; &lt;p&gt;MIT License&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Disclaimer: We are sharing codes for academic purposes under the MIT education license. Nothing herein is financial advice, and NOT a recommendation to trade real money. Please use common sense and always first consult a professional before trading or investing.&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>microsoft/generative-ai-for-beginners</title>
      <link>https://github.com/microsoft/generative-ai-for-beginners</link>
      <description>&lt;p&gt;21 Lessons, Get Started Building with Generative AI 🔗 https://microsoft.github.io/generative-ai-for-beginners/&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/images/repo-thumbnailv4-fixed.png?WT.mc_id=academic-105485-koreyst&quot; alt=&quot;Generative AI For Beginners&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;21 Lessons teaching everything you need to know to start building Generative AI applications&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/Generative-AI-For-Beginners/raw/master/LICENSE?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/microsoft/Generative-AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub license&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/graphs/contributors/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/microsoft/Generative-AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub contributors&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/issues/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/microsoft/Generative-AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub issues&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/pulls/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr/microsoft/Generative-AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub pull-requests&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://makeapullrequest.com?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/watchers/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/watchers/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Watch&quot; alt=&quot;GitHub watchers&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/network/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Fork&quot; alt=&quot;GitHub forks&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/stargazers/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Star&quot; alt=&quot;GitHub stars&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://dcbadge.limes.pink/api/server/ByRwuEEgH4&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Generative AI for Beginners (Version 3) - A Course&lt;/h1&gt; 
&lt;p&gt;Learn the fundamentals of building Generative AI applications with our 21-lesson comprehensive course by Microsoft Cloud Advocates.&lt;/p&gt; 
&lt;h2&gt;🌱 Getting Started&lt;/h2&gt; 
&lt;p&gt;This course has 21 lessons. Each lesson covers its own topic so start wherever you like!&lt;/p&gt; 
&lt;p&gt;Lessons are labeled either &quot;Learn&quot; lessons explaining a Generative AI concept or &quot;Build&quot; lessons that explain a concept and code examples in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt; when possible.&lt;/p&gt; 
&lt;p&gt;For .NET Developers checkout &lt;a href=&quot;https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst&quot;&gt;Generative AI for Beginners (.NET Edition)&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Each lesson also includes a &quot;Keep Learning&quot; section with additional learning tools.&lt;/p&gt; 
&lt;h2&gt;What You Need&lt;/h2&gt; 
&lt;h3&gt;To run the code of this course, you can use either:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://azure.microsoft.com/products/ai-services/openai-service?WT.mc_id=academic-105485-koreyst&quot;&gt;Azure OpenAI Service&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; &quot;aoai-assignment&quot;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst&quot;&gt;GitHub Marketplace Model Catalog&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; &quot;githubmodels&quot;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://platform.openai.com/docs/quickstart?context=python?WT.mc_id=academic-105485-koreyst&quot;&gt;OpenAI API&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; &quot;oai-assignment&quot;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Basic knowledge of Python or TypeScript is helpful - *For absolute beginners check out these &lt;a href=&quot;https://learn.microsoft.com/training/paths/python-language/?WT.mc_id=academic-105485-koreyst&quot;&gt;Python&lt;/a&gt; and &lt;a href=&quot;https://learn.microsoft.com/training/paths/build-javascript-applications-typescript/?WT.mc_id=academic-105485-koreyst&quot;&gt;TypeScript&lt;/a&gt; courses&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;A GitHub account to &lt;a href=&quot;https://github.com/microsoft/generative-ai-for-beginners/fork?WT.mc_id=academic-105485-koreyst&quot;&gt;fork this entire repo&lt;/a&gt; to your own GitHub account&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We have created a &lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/00-course-setup/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Course Setup&lt;/a&gt;&lt;/strong&gt; lesson to help you with setting up your development environment.&lt;/p&gt; 
&lt;p&gt;Don&#39;t forget to &lt;a href=&quot;https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst&quot;&gt;star (🌟) this repo&lt;/a&gt; to find it easier later.&lt;/p&gt; 
&lt;h2&gt;🧠 Ready to Deploy?&lt;/h2&gt; 
&lt;p&gt;If you are looking for more advanced code samples, check out our &lt;a href=&quot;https://aka.ms/genai-beg-code?WT.mc_id=academic-105485-koreyst&quot;&gt;collection of Generative AI Code Samples&lt;/a&gt; in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;🗣️ Meet Other Learners, Get Support&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href=&quot;https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst&quot;&gt;official AI Discord server&lt;/a&gt; to meet and network with other learners taking this course and get support.&lt;/p&gt; 
&lt;h2&gt;🚀 Building a Startup?&lt;/h2&gt; 
&lt;p&gt;Sign up for &lt;a href=&quot;https://aka.ms/genai-foundershub?WT.mc_id=academic-105485-koreyst&quot;&gt;Microsoft for Startups Founders Hub&lt;/a&gt; to receive &lt;strong&gt;free OpenAI credits&lt;/strong&gt; and up to &lt;strong&gt;$150k towards Azure credits to access OpenAI models through Azure OpenAI Services&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;🙏 Want to help?&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? &lt;a href=&quot;https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst&quot;&gt;Raise an issue&lt;/a&gt; or &lt;a href=&quot;https://github.com/microsoft/generative-ai-for-beginners/pulls?WT.mc_id=academic-105485-koreyst&quot;&gt;Create a pull request&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📂 Each lesson includes:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A short video introduction to the topic&lt;/li&gt; 
 &lt;li&gt;A written lesson located in the README&lt;/li&gt; 
 &lt;li&gt;Python and TypeScript code samples supporting Azure OpenAI and OpenAI API&lt;/li&gt; 
 &lt;li&gt;Links to extra resources to continue your learning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🗃️ Lessons&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Lesson Link&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Extra Learning&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;00&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/00-course-setup/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Course Setup&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to Setup Your Development Environment&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/01-introduction-to-genai/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Introduction to Generative AI and LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; Understanding what Generative AI is and how Large Language Models (LLMs) work.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson-1-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Exploring and comparing different LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to select the right model for your use case&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Using Generative AI Responsibly&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to build Generative AI Applications responsibly&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Understanding Prompt Engineering Fundamentals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; Hands-on Prompt Engineering Best Practices&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Creating Advanced Prompts&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to apply prompt engineering techniques that improve the outcome of your prompts.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson5-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building Text Generation Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A text generation app using Azure OpenAI / OpenAI API&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson6-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/07-building-chat-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building Chat Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; Techniques for efficiently building and integrating chat applications.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lessons7-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building Search Apps Vector Databases&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A search application that uses Embeddings to search for data.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson8-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/09-building-image-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building Image Generation Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An image generation application&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson9-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/10-building-low-code-ai-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building Low Code AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A Generative AI application using Low Code tools&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson10-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/11-integrating-with-function-calling/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Integrating External Applications with Function Calling&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; What is function calling and its use cases for applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson11-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Designing UX for AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to apply UX design principles when developing Generative AI Applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson12-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/13-securing-ai-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Securing Your Generative AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The threats and risks to AI systems and methods to secure these systems.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson13-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;The Generative AI Application Lifecycle&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The tools and metrics to manage the LLM Lifecycle and LLMOps&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson14-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/15-rag-and-vector-databases/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Retrieval Augmented Generation (RAG) and Vector Databases&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using a RAG Framework to retrieve embeddings from a Vector Databases&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/16-open-source-models/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Open Source Models and Hugging Face&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using open source models available on Hugging Face&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/17-ai-agents/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;AI Agents&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using an AI Agent Framework&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson17-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Fine-Tuning LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The what, why and how of fine-tuning LLMs&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/19-slm/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building with SLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The benefits of building with Small Language Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/20-mistral/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building with Mistral Models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The features and differences of the Mistral Family Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/21-meta/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building with Meta Models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The features and differences of the Meta Family Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;🌟 Special thanks&lt;/h3&gt; 
&lt;p&gt;Special thanks to &lt;a href=&quot;https://www.linkedin.com/in/john0isaac/&quot;&gt;&lt;strong&gt;John Aziz&lt;/strong&gt;&lt;/a&gt; for creating all of the GitHub Actions and workflows&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/in/bernhard-merkle-738b73/&quot;&gt;&lt;strong&gt;Bernhard Merkle&lt;/strong&gt;&lt;/a&gt; for making key contributions to each lesson to improve the learner and code experience.&lt;/p&gt; 
&lt;h2&gt;🎒 Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;strong&gt;NEW&lt;/strong&gt; AI Agents for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;strong&gt;NEW&lt;/strong&gt; Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/genai-js-course?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;strong&gt;NEW&lt;/strong&gt; Generative AI for Beginners using JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung&quot;&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst&quot;&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst&quot;&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst&quot;&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>mongodb-developer/GenAI-Showcase</title>
      <link>https://github.com/mongodb-developer/GenAI-Showcase</link>
      <description>&lt;p&gt;GenAI Cookbook&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;MongoDB&#39;s GenAI Showcase&lt;/h2&gt; 
&lt;p&gt;Welcome to MongoDB&#39;s Generative AI Showcase Repository!&lt;/p&gt; 
&lt;p&gt;Whether you are just starting out on your Generative AI journey, or looking to build advanced GenAI applications, we&#39;ve got you covered. This repository has an exhaustive list of examples and sample applications that cover Retrieval-Augmented Generation (RAG), AI Agents, and industry-specific use cases.&lt;/p&gt; 
&lt;p&gt;Discover how MongoDB integrates into RAG pipelines and AI Agents, serving as a vector database, operational database, and memory provider.&lt;/p&gt; 
&lt;h2&gt;Contents&lt;/h2&gt; 
&lt;p&gt;This repo mainly contains:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jupyter notebooks examples for RAG, agentic applications, evaluations etc. under &lt;code&gt;notebooks&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Javascipt and Python apps and demos under &lt;code&gt;apps&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Contributions from our AI partners under &lt;code&gt;partners&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;You will need to connect to a MongoDB cluster to run any of the apps or examples in this repo. Follow these steps to get set up:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Register for a &lt;a href=&quot;https://www.mongodb.com/cloud/atlas/register&quot;&gt;free MongoDB Atlas account&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.mongodb.com/docs/guides/atlas/cluster/&quot;&gt;Create a new database cluster&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.mongodb.com/docs/guides/atlas/connection-string/&quot;&gt;Obtain the connection string&lt;/a&gt; for your database cluster&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please read our &lt;a href=&quot;https://raw.githubusercontent.com/mongodb-developer/GenAI-Showcase/main/CONTRIBUTING.md&quot;&gt;Contribution Guidelines&lt;/a&gt; for more information on how to participate.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href=&quot;https://raw.githubusercontent.com/mongodb-developer/GenAI-Showcase/main/LICENSE&quot;&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Support&lt;/h2&gt; 
&lt;p&gt;As you work through these examples, if you encounter any problems, please &lt;a href=&quot;https://github.com/mongodb-developer/GenAI-Showcase/issues/new&quot;&gt;open a new issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Additional Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.mongodb.com/resources/use-cases/artificial-intelligence?utm_campaign=ai_learning_hub&amp;amp;utm_source=github&amp;amp;utm_medium=referral&quot;&gt;AI Learning Hub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.mongodb.com/community/forums/c/generative-ai/162&quot;&gt;GenAI Community Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mongodb/docs-notebooks&quot;&gt;Tutorials and code examples from our official docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>openai/CLIP</title>
      <link>https://github.com/openai/CLIP</link>
      <description>&lt;p&gt;CLIP (Contrastive Language-Image Pretraining), Predict the most relevant text snippet given an image&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CLIP&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://openai.com/blog/clip/&quot;&gt;[Blog]&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/2103.00020&quot;&gt;[Paper]&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/openai/CLIP/main/model-card.md&quot;&gt;[Model Card]&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb&quot;&gt;[Colab]&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;CLIP (Contrastive Language-Image Pre-Training) is a neural network trained on a variety of (image, text) pairs. It can be instructed in natural language to predict the most relevant text snippet, given an image, without directly optimizing for the task, similarly to the zero-shot capabilities of GPT-2 and 3. We found CLIP matches the performance of the original ResNet50 on ImageNet “zero-shot” without using any of the original 1.28M labeled examples, overcoming several major challenges in computer vision.&lt;/p&gt; 
&lt;h2&gt;Approach&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/openai/CLIP/main/CLIP.png&quot; alt=&quot;CLIP&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;First, &lt;a href=&quot;https://pytorch.org/get-started/locally/&quot;&gt;install PyTorch 1.7.1&lt;/a&gt; (or later) and torchvision, as well as small additional dependencies, and then install this repo as a Python package. On a CUDA GPU machine, the following will do the trick:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0
$ pip install ftfy regex tqdm
$ pip install git+https://github.com/openai/CLIP.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;cudatoolkit=11.0&lt;/code&gt; above with the appropriate CUDA version on your machine or &lt;code&gt;cpuonly&lt;/code&gt; when installing on a machine without a GPU.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import torch
import clip
from PIL import Image

device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
model, preprocess = clip.load(&quot;ViT-B/32&quot;, device=device)

image = preprocess(Image.open(&quot;CLIP.png&quot;)).unsqueeze(0).to(device)
text = clip.tokenize([&quot;a diagram&quot;, &quot;a dog&quot;, &quot;a cat&quot;]).to(device)

with torch.no_grad():
    image_features = model.encode_image(image)
    text_features = model.encode_text(text)
    
    logits_per_image, logits_per_text = model(image, text)
    probs = logits_per_image.softmax(dim=-1).cpu().numpy()

print(&quot;Label probs:&quot;, probs)  # prints: [[0.9927937  0.00421068 0.00299572]]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;p&gt;The CLIP module &lt;code&gt;clip&lt;/code&gt; provides the following methods:&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;clip.available_models()&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Returns the names of the available CLIP models.&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;clip.load(name, device=..., jit=False)&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Returns the model and the TorchVision transform needed by the model, specified by the model name returned by &lt;code&gt;clip.available_models()&lt;/code&gt;. It will download the model as necessary. The &lt;code&gt;name&lt;/code&gt; argument can also be a path to a local checkpoint.&lt;/p&gt; 
&lt;p&gt;The device to run the model can be optionally specified, and the default is to use the first CUDA device if there is any, otherwise the CPU. When &lt;code&gt;jit&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, a non-JIT version of the model will be loaded.&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;clip.tokenize(text: Union[str, List[str]], context_length=77)&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Returns a LongTensor containing tokenized sequences of given text input(s). This can be used as the input to the model&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;The model returned by &lt;code&gt;clip.load()&lt;/code&gt; supports the following methods:&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;model.encode_image(image: Tensor)&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Given a batch of images, returns the image features encoded by the vision portion of the CLIP model.&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;model.encode_text(text: Tensor)&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Given a batch of text tokens, returns the text features encoded by the language portion of the CLIP model.&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;model(image: Tensor, text: Tensor)&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Given a batch of images and a batch of text tokens, returns two Tensors, containing the logit scores corresponding to each image and text input. The values are cosine similarities between the corresponding image and text features, times 100.&lt;/p&gt; 
&lt;h2&gt;More Examples&lt;/h2&gt; 
&lt;h3&gt;Zero-Shot Prediction&lt;/h3&gt; 
&lt;p&gt;The code below performs zero-shot prediction using CLIP, as shown in Appendix B in the paper. This example takes an image from the &lt;a href=&quot;https://www.cs.toronto.edu/~kriz/cifar.html&quot;&gt;CIFAR-100 dataset&lt;/a&gt;, and predicts the most likely labels among the 100 textual labels from the dataset.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import os
import clip
import torch
from torchvision.datasets import CIFAR100

# Load the model
device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
model, preprocess = clip.load(&#39;ViT-B/32&#39;, device)

# Download the dataset
cifar100 = CIFAR100(root=os.path.expanduser(&quot;~/.cache&quot;), download=True, train=False)

# Prepare the inputs
image, class_id = cifar100[3637]
image_input = preprocess(image).unsqueeze(0).to(device)
text_inputs = torch.cat([clip.tokenize(f&quot;a photo of a {c}&quot;) for c in cifar100.classes]).to(device)

# Calculate features
with torch.no_grad():
    image_features = model.encode_image(image_input)
    text_features = model.encode_text(text_inputs)

# Pick the top 5 most similar labels for the image
image_features /= image_features.norm(dim=-1, keepdim=True)
text_features /= text_features.norm(dim=-1, keepdim=True)
similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)
values, indices = similarity[0].topk(5)

# Print the result
print(&quot;\nTop predictions:\n&quot;)
for value, index in zip(values, indices):
    print(f&quot;{cifar100.classes[index]:&amp;gt;16s}: {100 * value.item():.2f}%&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The output will look like the following (the exact numbers may be slightly different depending on the compute device):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Top predictions:

           snake: 65.31%
          turtle: 12.29%
    sweet_pepper: 3.83%
          lizard: 1.88%
       crocodile: 1.75%
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that this example uses the &lt;code&gt;encode_image()&lt;/code&gt; and &lt;code&gt;encode_text()&lt;/code&gt; methods that return the encoded features of given inputs.&lt;/p&gt; 
&lt;h3&gt;Linear-probe evaluation&lt;/h3&gt; 
&lt;p&gt;The example below uses &lt;a href=&quot;https://scikit-learn.org/&quot;&gt;scikit-learn&lt;/a&gt; to perform logistic regression on image features.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import os
import clip
import torch

import numpy as np
from sklearn.linear_model import LogisticRegression
from torch.utils.data import DataLoader
from torchvision.datasets import CIFAR100
from tqdm import tqdm

# Load the model
device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
model, preprocess = clip.load(&#39;ViT-B/32&#39;, device)

# Load the dataset
root = os.path.expanduser(&quot;~/.cache&quot;)
train = CIFAR100(root, download=True, train=True, transform=preprocess)
test = CIFAR100(root, download=True, train=False, transform=preprocess)


def get_features(dataset):
    all_features = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in tqdm(DataLoader(dataset, batch_size=100)):
            features = model.encode_image(images.to(device))

            all_features.append(features)
            all_labels.append(labels)

    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()

# Calculate the image features
train_features, train_labels = get_features(train)
test_features, test_labels = get_features(test)

# Perform logistic regression
classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)
classifier.fit(train_features, train_labels)

# Evaluate using the logistic regression classifier
predictions = classifier.predict(test_features)
accuracy = np.mean((test_labels == predictions).astype(float)) * 100.
print(f&quot;Accuracy = {accuracy:.3f}&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the &lt;code&gt;C&lt;/code&gt; value should be determined via a hyperparameter sweep using a validation split.&lt;/p&gt; 
&lt;h2&gt;See Also&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mlfoundations/open_clip&quot;&gt;OpenCLIP&lt;/a&gt;: includes larger and independently trained CLIP models up to ViT-G/14&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://huggingface.co/docs/transformers/model_doc/clip&quot;&gt;Hugging Face implementation of CLIP&lt;/a&gt;: for easier integration with the HF ecosystem&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>jackfrued/Python-100-Days</title>
      <link>https://github.com/jackfrued/Python-100-Days</link>
      <description>&lt;p&gt;Python - 100天从新手到大师&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Python - 100天从新手到大师&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;作者&lt;/strong&gt;：骆昊&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;：如果访问 GitHub 比较慢的话，可以关注我的知乎号（&lt;a href=&quot;https://www.zhihu.com/people/jackfrued&quot;&gt;&lt;strong&gt;Python-Jack&lt;/strong&gt;&lt;/a&gt;），上面的&lt;a href=&quot;https://zhuanlan.zhihu.com/c_1216656665569013760&quot;&gt;“&lt;strong&gt;从零开始学Python&lt;/strong&gt;”&lt;/a&gt;专栏（对应本项目前 20 天的内容）比较适合初学者，其他的专栏如“&lt;a href=&quot;https://www.zhihu.com/column/c_1620074540456964096&quot;&gt;&lt;strong&gt;数据思维和统计思维&lt;/strong&gt;&lt;/a&gt;”、“&lt;a href=&quot;https://www.zhihu.com/column/c_1217746527315496960&quot;&gt;&lt;strong&gt;基于Python的数据分析&lt;/strong&gt;&lt;/a&gt;”、“&lt;a href=&quot;https://www.zhihu.com/column/c_1628900668109946880&quot;&gt;&lt;strong&gt;说走就走的AI之旅&lt;/strong&gt;&lt;/a&gt;”等也在持续创作和更新中，欢迎大家关注、点赞和评论。如果希望结伴学习或者讨论问题，可以加入下面的 QQ 交流群（三个群加一个即可），请不要重复加群，也不要在群里发布广告和其他色情、低俗或敏感内容。如果遇到解决不了的问题，可以添加我的私人微信（微信号：&lt;strong&gt;jackfrued&lt;/strong&gt;），备注好自己的称呼和需求，我会为大家提供力所能及的帮助。&lt;/p&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/python_study_qq_group.png&quot; style=&quot;zoom:30%;&quot;&gt; 
 &lt;p&gt;本项目对应的部分视频在B站（账号：&lt;a href=&quot;https://space.bilibili.com/1177252794&quot;&gt;&lt;strong&gt;骆昊jackfrued&lt;/strong&gt;&lt;/a&gt;）可以找到，有兴趣的小伙伴可以关注一下，刚刚起号还希望大家多多支持！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Python应用领域和职业发展分析&lt;/h3&gt; 
&lt;p&gt;简单的说，Python是一个“优雅”、“明确”、“简单”的编程语言。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;学习曲线低，非专业人士也能上手&lt;/li&gt; 
 &lt;li&gt;开源系统，拥有强大的生态圈&lt;/li&gt; 
 &lt;li&gt;解释型语言，完美的平台可移植性&lt;/li&gt; 
 &lt;li&gt;动态类型语言，支持面向对象和函数式编程&lt;/li&gt; 
 &lt;li&gt;代码规范程度高，可读性强&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Python在以下领域都有用武之地。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;后端开发 - Python / Java / Go / PHP&lt;/li&gt; 
 &lt;li&gt;DevOps - Python / Shell / Ruby&lt;/li&gt; 
 &lt;li&gt;数据采集 - Python / C++ / Java&lt;/li&gt; 
 &lt;li&gt;量化交易 - Python / C++ / R&lt;/li&gt; 
 &lt;li&gt;数据科学 - Python / R / Julia / Matlab&lt;/li&gt; 
 &lt;li&gt;机器学习 - Python / R / C++ / Julia&lt;/li&gt; 
 &lt;li&gt;自动化测试 - Python / Shell&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;作为一名Python开发者，根据个人的喜好和职业规划，可以选择的就业领域也非常多。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python后端开发工程师（服务器、云平台、数据接口）&lt;/li&gt; 
 &lt;li&gt;Python运维工程师（自动化运维、SRE、DevOps）&lt;/li&gt; 
 &lt;li&gt;Python数据分析师（数据分析、商业智能、数字化运营）&lt;/li&gt; 
 &lt;li&gt;Python数据科学家（机器学习、深度学习、算法专家）&lt;/li&gt; 
 &lt;li&gt;Python爬虫工程师（不推荐此赛道！！！）&lt;/li&gt; 
 &lt;li&gt;Python测试工程师（自动化测试、测试开发）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;：目前，&lt;strong&gt;数据科学赛道是非常热门的方向&lt;/strong&gt;，因为不管是互联网行业还是传统行业都已经积累了大量的数据，各行各业都需要数据科学家从已有的数据中发现更多的商业价值，从而为企业的决策提供数据的支撑，这就是所谓的数据驱动决策。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;给初学者的几个建议：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Make English as your working language.&lt;/strong&gt; （让英语成为你的工作语言）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Practice makes perfect.&lt;/strong&gt; （熟能生巧）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;All experience comes from the mistakes you&#39;ve made.&lt;/strong&gt; （所有的经验都源于你犯过的错误）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Don&#39;t be a freeloader.&lt;/strong&gt; （不要当伸手党）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Either outstanding or out.&lt;/strong&gt; （要么出众，要么出局）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Day01~20 - Python语言基础&lt;/h3&gt; 
&lt;h4&gt;Day01 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/01.%E5%88%9D%E8%AF%86Python.md&quot;&gt;初识Python&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Python简介 
  &lt;ul&gt; 
   &lt;li&gt;Python编年史&lt;/li&gt; 
   &lt;li&gt;Python优缺点&lt;/li&gt; 
   &lt;li&gt;Python应用领域&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;安装Python环境 
  &lt;ul&gt; 
   &lt;li&gt;Windows环境&lt;/li&gt; 
   &lt;li&gt;macOS环境&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day02 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/02.%E7%AC%AC%E4%B8%80%E4%B8%AAPython%E7%A8%8B%E5%BA%8F.md&quot;&gt;第一个Python程序&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;编写代码的工具&lt;/li&gt; 
 &lt;li&gt;你好世界&lt;/li&gt; 
 &lt;li&gt;注释你的代码&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day03 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/03.Python%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%8F%98%E9%87%8F.md&quot;&gt;Python语言中的变量&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;一些常识&lt;/li&gt; 
 &lt;li&gt;变量和类型&lt;/li&gt; 
 &lt;li&gt;变量命名&lt;/li&gt; 
 &lt;li&gt;变量的使用&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day04 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/04.Python%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%AE%97%E7%AC%A6.md&quot;&gt;Python语言中的运算符&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;算术运算符&lt;/li&gt; 
 &lt;li&gt;赋值运算符&lt;/li&gt; 
 &lt;li&gt;比较运算符和逻辑运算符&lt;/li&gt; 
 &lt;li&gt;运算符和表达式应用 
  &lt;ul&gt; 
   &lt;li&gt;华氏和摄氏温度转换&lt;/li&gt; 
   &lt;li&gt;计算圆的周长和面积&lt;/li&gt; 
   &lt;li&gt;判断闰年&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day05 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/05.%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84.md&quot;&gt;分支结构&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;使用if和else构造分支结构&lt;/li&gt; 
 &lt;li&gt;使用match和case构造分支结构&lt;/li&gt; 
 &lt;li&gt;分支结构的应用 
  &lt;ul&gt; 
   &lt;li&gt;分段函数求值&lt;/li&gt; 
   &lt;li&gt;百分制成绩转换成等级&lt;/li&gt; 
   &lt;li&gt;计算三角形的周长和面积&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day06 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/06.%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84.md&quot;&gt;循环结构&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;for-in循环&lt;/li&gt; 
 &lt;li&gt;while循环&lt;/li&gt; 
 &lt;li&gt;break和continue&lt;/li&gt; 
 &lt;li&gt;嵌套的循环结构&lt;/li&gt; 
 &lt;li&gt;循环结构的应用 
  &lt;ul&gt; 
   &lt;li&gt;判断素数&lt;/li&gt; 
   &lt;li&gt;最大公约数&lt;/li&gt; 
   &lt;li&gt;猜数字游戏&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day07 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/07.%E5%88%86%E6%94%AF%E5%92%8C%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84%E5%AE%9E%E6%88%98.md&quot;&gt;分支和循环结构实战&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;例子1：100以内的素数&lt;/li&gt; 
 &lt;li&gt;例子2：斐波那契数列&lt;/li&gt; 
 &lt;li&gt;例子3：寻找水仙花数&lt;/li&gt; 
 &lt;li&gt;例子4：百钱百鸡问题&lt;/li&gt; 
 &lt;li&gt;例子5：CRAPS赌博游戏&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day08 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/08.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%88%97%E8%A1%A8-1.md&quot;&gt;常用数据结构之列表-1&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;创建列表&lt;/li&gt; 
 &lt;li&gt;列表的运算&lt;/li&gt; 
 &lt;li&gt;元素的遍历&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day09 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/09.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%88%97%E8%A1%A8-2.md&quot;&gt;常用数据结构之列表-2&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;列表的方法 
  &lt;ul&gt; 
   &lt;li&gt;添加和删除元素&lt;/li&gt; 
   &lt;li&gt;元素位置和频次&lt;/li&gt; 
   &lt;li&gt;元素排序和反转&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;列表生成式&lt;/li&gt; 
 &lt;li&gt;嵌套列表&lt;/li&gt; 
 &lt;li&gt;列表的应用&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day10 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/10.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%83%E7%BB%84.md&quot;&gt;常用数据结构之元组&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;元组的定义和运算&lt;/li&gt; 
 &lt;li&gt;打包和解包操作&lt;/li&gt; 
 &lt;li&gt;交换变量的值&lt;/li&gt; 
 &lt;li&gt;元组和列表的比较&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day11 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/11.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%AD%97%E7%AC%A6%E4%B8%B2.md&quot;&gt;常用数据结构之字符串&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;字符串的定义 
  &lt;ul&gt; 
   &lt;li&gt;转义字符&lt;/li&gt; 
   &lt;li&gt;原始字符串&lt;/li&gt; 
   &lt;li&gt;字符的特殊表示&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;字符串的运算 
  &lt;ul&gt; 
   &lt;li&gt;拼接和重复&lt;/li&gt; 
   &lt;li&gt;比较运算&lt;/li&gt; 
   &lt;li&gt;成员运算&lt;/li&gt; 
   &lt;li&gt;获取字符串长度&lt;/li&gt; 
   &lt;li&gt;索引和切片&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;字符的遍历&lt;/li&gt; 
 &lt;li&gt;字符串的方法 
  &lt;ul&gt; 
   &lt;li&gt;大小写相关操作&lt;/li&gt; 
   &lt;li&gt;查找操作&lt;/li&gt; 
   &lt;li&gt;性质判断&lt;/li&gt; 
   &lt;li&gt;格式化&lt;/li&gt; 
   &lt;li&gt;修剪操作&lt;/li&gt; 
   &lt;li&gt;替换操作&lt;/li&gt; 
   &lt;li&gt;拆分与合并&lt;/li&gt; 
   &lt;li&gt;编码与解码&lt;/li&gt; 
   &lt;li&gt;其他方法&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day12 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/12.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E9%9B%86%E5%90%88.md&quot;&gt;常用数据结构之集合&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;创建集合&lt;/li&gt; 
 &lt;li&gt;元素的变量&lt;/li&gt; 
 &lt;li&gt;集合的运算 
  &lt;ul&gt; 
   &lt;li&gt;成员运算&lt;/li&gt; 
   &lt;li&gt;二元运算&lt;/li&gt; 
   &lt;li&gt;比较运算&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;集合的方法&lt;/li&gt; 
 &lt;li&gt;不可变集合&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day13 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/13.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%AD%97%E5%85%B8.md&quot;&gt;常用数据结构之字典&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;创建和使用字典&lt;/li&gt; 
 &lt;li&gt;字典的运算&lt;/li&gt; 
 &lt;li&gt;字典的方法&lt;/li&gt; 
 &lt;li&gt;字典的应用&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day14 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/14.%E5%87%BD%E6%95%B0%E5%92%8C%E6%A8%A1%E5%9D%97.md&quot;&gt;函数和模块&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;定义函数&lt;/li&gt; 
 &lt;li&gt;函数的参数 
  &lt;ul&gt; 
   &lt;li&gt;位置参数和关键字参数&lt;/li&gt; 
   &lt;li&gt;参数的默认值&lt;/li&gt; 
   &lt;li&gt;可变参数&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;用模块管理函数&lt;/li&gt; 
 &lt;li&gt;标准库中的模块和函数&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day15 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/15.%E5%87%BD%E6%95%B0%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98.md&quot;&gt;函数应用实战&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;例子1：随机验证码&lt;/li&gt; 
 &lt;li&gt;例子2：判断素数&lt;/li&gt; 
 &lt;li&gt;例子3：最大公约数和最小公倍数&lt;/li&gt; 
 &lt;li&gt;例子4：数据统计&lt;/li&gt; 
 &lt;li&gt;例子5：双色球随机选号&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day16 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/16.%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6.md&quot;&gt;函数使用进阶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;高阶函数&lt;/li&gt; 
 &lt;li&gt;Lambda函数&lt;/li&gt; 
 &lt;li&gt;偏函数&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day17 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/17.%E5%87%BD%E6%95%B0%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8.md&quot;&gt;函数高级应用&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;装饰器&lt;/li&gt; 
 &lt;li&gt;递归调用&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day18 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/18.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8.md&quot;&gt;面向对象编程入门&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;类和对象&lt;/li&gt; 
 &lt;li&gt;定义类&lt;/li&gt; 
 &lt;li&gt;创建和使用对象&lt;/li&gt; 
 &lt;li&gt;初始化方法&lt;/li&gt; 
 &lt;li&gt;面向对象的支柱&lt;/li&gt; 
 &lt;li&gt;面向对象案例 
  &lt;ul&gt; 
   &lt;li&gt;例子1：数字时钟&lt;/li&gt; 
   &lt;li&gt;例子2：平面上的点&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day19 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/19.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E8%BF%9B%E9%98%B6.md&quot;&gt;面向对象编程进阶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;可见性和属性装饰器&lt;/li&gt; 
 &lt;li&gt;动态属性&lt;/li&gt; 
 &lt;li&gt;静态方法和类方法&lt;/li&gt; 
 &lt;li&gt;继承和多态&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day20 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/20.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E5%BA%94%E7%94%A8.md&quot;&gt;面向对象编程应用&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;扑克游戏&lt;/li&gt; 
 &lt;li&gt;工资结算系统&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day21~30 - Python语言应用&lt;/h3&gt; 
&lt;h4&gt;Day21 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/21.%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.md&quot;&gt;文件读写和异常处理&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;打开和关闭文件&lt;/li&gt; 
 &lt;li&gt;读写文本文件&lt;/li&gt; 
 &lt;li&gt;异常处理机制&lt;/li&gt; 
 &lt;li&gt;上下文管理器语法&lt;/li&gt; 
 &lt;li&gt;读写二进制文件&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day22 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/22.%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96.md&quot;&gt;对象的序列化和反序列化&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;JSON概述&lt;/li&gt; 
 &lt;li&gt;读写JSON格式的数据&lt;/li&gt; 
 &lt;li&gt;包管理工具pip&lt;/li&gt; 
 &lt;li&gt;使用网络API获取数据&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day23 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/23.Python%E8%AF%BB%E5%86%99CSV%E6%96%87%E4%BB%B6.md&quot;&gt;Python读写CSV文件&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;CSV文件介绍&lt;/li&gt; 
 &lt;li&gt;将数据写入CSV文件&lt;/li&gt; 
 &lt;li&gt;从CSV文件读取数据&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day24 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/24.%E7%94%A8Python%E8%AF%BB%E5%86%99Excel%E6%96%87%E4%BB%B6-1.md&quot;&gt;Python读写Excel文件-1&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Excel简介&lt;/li&gt; 
 &lt;li&gt;读Excel文件&lt;/li&gt; 
 &lt;li&gt;写Excel文件&lt;/li&gt; 
 &lt;li&gt;调整样式&lt;/li&gt; 
 &lt;li&gt;公式计算&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day25 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/25.Python%E8%AF%BB%E5%86%99Excel%E6%96%87%E4%BB%B6-2.md&quot;&gt;Python读写Excel文件-2&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Excel简介&lt;/li&gt; 
 &lt;li&gt;读Excel文件&lt;/li&gt; 
 &lt;li&gt;写Excel文件&lt;/li&gt; 
 &lt;li&gt;调整样式&lt;/li&gt; 
 &lt;li&gt;生成统计图表&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day26 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/26.Python%E6%93%8D%E4%BD%9CWord%E5%92%8CPowerPoint%E6%96%87%E4%BB%B6.md&quot;&gt;Python操作Word和PowerPoint文件&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;操作Word文档&lt;/li&gt; 
 &lt;li&gt;生成PowerPoint&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day27 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/27.Python%E6%93%8D%E4%BD%9CPDF%E6%96%87%E4%BB%B6.md&quot;&gt;Python操作PDF文件&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;从PDF中提取文本&lt;/li&gt; 
 &lt;li&gt;旋转和叠加页面&lt;/li&gt; 
 &lt;li&gt;加密PDF文件&lt;/li&gt; 
 &lt;li&gt;批量添加水印&lt;/li&gt; 
 &lt;li&gt;创建PDF文件&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day28 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/28.Python%E5%A4%84%E7%90%86%E5%9B%BE%E5%83%8F.md&quot;&gt;Python处理图像&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;入门知识&lt;/li&gt; 
 &lt;li&gt;用Pillow处理图像&lt;/li&gt; 
 &lt;li&gt;使用Pillow绘图&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day29 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/29.Python%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E5%92%8C%E7%9F%AD%E4%BF%A1.md&quot;&gt;Python发送邮件和短信&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;发送电子邮件&lt;/li&gt; 
 &lt;li&gt;发送短信&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day30 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/30.%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%BA%94%E7%94%A8.md&quot;&gt;正则表达式的应用&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;正则表达式相关知识&lt;/li&gt; 
 &lt;li&gt;Python对正则表达式的支持 
  &lt;ul&gt; 
   &lt;li&gt;例子1：输入验证&lt;/li&gt; 
   &lt;li&gt;例子2：内容提取&lt;/li&gt; 
   &lt;li&gt;例子3：内容替换&lt;/li&gt; 
   &lt;li&gt;例子4：长句拆分&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day31~35 - 其他相关内容&lt;/h3&gt; 
&lt;h4&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day31-35/31.Python%E8%AF%AD%E8%A8%80%E8%BF%9B%E9%98%B6.md&quot;&gt;Python语言进阶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;重要知识点&lt;/li&gt; 
 &lt;li&gt;数据结构和算法&lt;/li&gt; 
 &lt;li&gt;函数的使用方式&lt;/li&gt; 
 &lt;li&gt;面向对象相关知识&lt;/li&gt; 
 &lt;li&gt;迭代器和生成器&lt;/li&gt; 
 &lt;li&gt;并发编程&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day31-35/32-33.Web%E5%89%8D%E7%AB%AF%E5%85%A5%E9%97%A8.md&quot;&gt;Web前端入门&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;用HTML标签承载页面内容&lt;/li&gt; 
 &lt;li&gt;用CSS渲染页面&lt;/li&gt; 
 &lt;li&gt;用JavaScript处理交互式行为&lt;/li&gt; 
 &lt;li&gt;Vue.js入门&lt;/li&gt; 
 &lt;li&gt;Element的使用&lt;/li&gt; 
 &lt;li&gt;Bootstrap的使用&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day31-35/34-35.%E7%8E%A9%E8%BD%ACLinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.md&quot;&gt;玩转Linux操作系统&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;操作系统发展史和Linux概述&lt;/li&gt; 
 &lt;li&gt;Linux基础命令&lt;/li&gt; 
 &lt;li&gt;Linux中的实用程序&lt;/li&gt; 
 &lt;li&gt;Linux的文件系统&lt;/li&gt; 
 &lt;li&gt;Vim编辑器的应用&lt;/li&gt; 
 &lt;li&gt;环境变量和Shell编程&lt;/li&gt; 
 &lt;li&gt;软件的安装和服务的配置&lt;/li&gt; 
 &lt;li&gt;网络访问和管理&lt;/li&gt; 
 &lt;li&gt;其他相关内容&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day36~45 - 数据库基础和进阶&lt;/h3&gt; 
&lt;h4&gt;Day36 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/36.%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CMySQL%E6%A6%82%E8%BF%B0.md&quot;&gt;关系型数据库和MySQL概述&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;关系型数据库概述&lt;/li&gt; 
 &lt;li&gt;MySQL简介&lt;/li&gt; 
 &lt;li&gt;安装MySQL&lt;/li&gt; 
 &lt;li&gt;MySQL基本命令&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day37 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/37.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDDL.md&quot;&gt;SQL详解之DDL&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;建库建表&lt;/li&gt; 
 &lt;li&gt;删除表和修改表&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day38 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/38.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDML.md&quot;&gt;SQL详解之DML&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;insert操作&lt;/li&gt; 
 &lt;li&gt;delete操作&lt;/li&gt; 
 &lt;li&gt;update操作&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day39 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/39.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDQL.md&quot;&gt;SQL详解之DQL&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;投影和别名&lt;/li&gt; 
 &lt;li&gt;筛选数据&lt;/li&gt; 
 &lt;li&gt;空值处理&lt;/li&gt; 
 &lt;li&gt;去重&lt;/li&gt; 
 &lt;li&gt;排序&lt;/li&gt; 
 &lt;li&gt;聚合函数&lt;/li&gt; 
 &lt;li&gt;嵌套查询&lt;/li&gt; 
 &lt;li&gt;分组操作&lt;/li&gt; 
 &lt;li&gt;表连接 
  &lt;ul&gt; 
   &lt;li&gt;笛卡尔积&lt;/li&gt; 
   &lt;li&gt;内连接&lt;/li&gt; 
   &lt;li&gt;自然连接&lt;/li&gt; 
   &lt;li&gt;外连接&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;窗口函数 
  &lt;ul&gt; 
   &lt;li&gt;定义窗口&lt;/li&gt; 
   &lt;li&gt;排名函数&lt;/li&gt; 
   &lt;li&gt;取数函数&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day40 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/40.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDCL.md&quot;&gt;SQL详解之DCL&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;创建用户&lt;/li&gt; 
 &lt;li&gt;授予权限&lt;/li&gt; 
 &lt;li&gt;召回权限&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day41 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/41.MySQL%E6%96%B0%E7%89%B9%E6%80%A7.md&quot;&gt;MySQL新特性&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;JSON类型&lt;/li&gt; 
 &lt;li&gt;窗口函数&lt;/li&gt; 
 &lt;li&gt;公共表表达式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Day42 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/42.%E8%A7%86%E5%9B%BE%E3%80%81%E5%87%BD%E6%95%B0%E5%92%8C%E8%BF%87%E7%A8%8B.md&quot;&gt;视图、函数和过程&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;视图 
  &lt;ul&gt; 
   &lt;li&gt;使用场景&lt;/li&gt; 
   &lt;li&gt;创建视图&lt;/li&gt; 
   &lt;li&gt;使用限制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;函数 
  &lt;ul&gt; 
   &lt;li&gt;内置函数&lt;/li&gt; 
   &lt;li&gt;用户自定义函数（UDF）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;过程 
  &lt;ul&gt; 
   &lt;li&gt;创建过程&lt;/li&gt; 
   &lt;li&gt;调用过程&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day43 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/43.%E7%B4%A2%E5%BC%95.md&quot;&gt;索引&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;执行计划&lt;/li&gt; 
 &lt;li&gt;索引的原理&lt;/li&gt; 
 &lt;li&gt;创建索引 
  &lt;ul&gt; 
   &lt;li&gt;普通索引&lt;/li&gt; 
   &lt;li&gt;唯一索引&lt;/li&gt; 
   &lt;li&gt;前缀索引&lt;/li&gt; 
   &lt;li&gt;复合索引&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;注意事项&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day44 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/44.Python%E6%8E%A5%E5%85%A5MySQL%E6%95%B0%E6%8D%AE%E5%BA%93.md&quot;&gt;Python接入MySQL数据库&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;安装三方库&lt;/li&gt; 
 &lt;li&gt;创建连接&lt;/li&gt; 
 &lt;li&gt;获取游标&lt;/li&gt; 
 &lt;li&gt;执行SQL语句&lt;/li&gt; 
 &lt;li&gt;通过游标抓取数据&lt;/li&gt; 
 &lt;li&gt;事务提交和回滚&lt;/li&gt; 
 &lt;li&gt;释放连接&lt;/li&gt; 
 &lt;li&gt;编写ETL脚本&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day45 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/45.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%92%8CHiveSQL.md&quot;&gt;大数据平台和HiveSQL&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Hadoop生态圈&lt;/li&gt; 
 &lt;li&gt;Hive概述&lt;/li&gt; 
 &lt;li&gt;准备工作&lt;/li&gt; 
 &lt;li&gt;数据类型&lt;/li&gt; 
 &lt;li&gt;DDL操作&lt;/li&gt; 
 &lt;li&gt;DML操作&lt;/li&gt; 
 &lt;li&gt;数据查询&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day46~60 - 实战Django&lt;/h3&gt; 
&lt;h4&gt;Day46 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/46.Django%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.md&quot;&gt;Django快速上手&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Web应用工作机制&lt;/li&gt; 
 &lt;li&gt;HTTP请求和响应&lt;/li&gt; 
 &lt;li&gt;Django框架概述&lt;/li&gt; 
 &lt;li&gt;5分钟快速上手&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day47 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/47.%E6%B7%B1%E5%85%A5%E6%A8%A1%E5%9E%8B.md&quot;&gt;深入模型&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;关系型数据库配置&lt;/li&gt; 
 &lt;li&gt;使用ORM完成对模型的CRUD操作&lt;/li&gt; 
 &lt;li&gt;管理后台的使用&lt;/li&gt; 
 &lt;li&gt;Django模型最佳实践&lt;/li&gt; 
 &lt;li&gt;模型定义参考&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day48 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/48.%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E5%92%8CAjax%E8%AF%B7%E6%B1%82.md&quot;&gt;静态资源和Ajax请求&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;加载静态资源&lt;/li&gt; 
 &lt;li&gt;Ajax概述&lt;/li&gt; 
 &lt;li&gt;用Ajax实现投票功能&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day49 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/49.Cookie%E5%92%8CSession.md&quot;&gt;Cookie和Session&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;实现用户跟踪&lt;/li&gt; 
 &lt;li&gt;cookie和session的关系&lt;/li&gt; 
 &lt;li&gt;Django框架对session的支持&lt;/li&gt; 
 &lt;li&gt;视图函数中的cookie读写操作&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day50 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/50.%E5%88%B6%E4%BD%9C%E6%8A%A5%E8%A1%A8.md&quot;&gt;报表和日志&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;通过&lt;code&gt;HttpResponse&lt;/code&gt;修改响应头&lt;/li&gt; 
 &lt;li&gt;使用&lt;code&gt;StreamingHttpResponse&lt;/code&gt;处理大文件&lt;/li&gt; 
 &lt;li&gt;使用&lt;code&gt;xlwt&lt;/code&gt;生成Excel报表&lt;/li&gt; 
 &lt;li&gt;使用&lt;code&gt;reportlab&lt;/code&gt;生成PDF报表&lt;/li&gt; 
 &lt;li&gt;使用ECharts生成前端图表&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day51 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/51.%E6%97%A5%E5%BF%97%E5%92%8C%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7%E6%A0%8F.md&quot;&gt;日志和调试工具栏&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;配置日志&lt;/li&gt; 
 &lt;li&gt;配置Django-Debug-Toolbar&lt;/li&gt; 
 &lt;li&gt;优化ORM代码&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day52 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/52.%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%BA%94%E7%94%A8.md&quot;&gt;中间件的应用&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;什么是中间件&lt;/li&gt; 
 &lt;li&gt;Django框架内置的中间件&lt;/li&gt; 
 &lt;li&gt;自定义中间件及其应用场景&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day53 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/53.%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8.md&quot;&gt;前后端分离开发入门&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;返回JSON格式的数据&lt;/li&gt; 
 &lt;li&gt;用Vue.js渲染页面&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day54 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/54.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E5%85%A5%E9%97%A8.md&quot;&gt;RESTful架构和DRF入门&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;REST概述&lt;/li&gt; 
 &lt;li&gt;DRF库使用入门&lt;/li&gt; 
 &lt;li&gt;前后端分离开发&lt;/li&gt; 
 &lt;li&gt;JWT的应用&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day55 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/55.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E8%BF%9B%E9%98%B6.md&quot;&gt;RESTful架构和DRF进阶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;使用CBV&lt;/li&gt; 
 &lt;li&gt;数据分页&lt;/li&gt; 
 &lt;li&gt;数据筛选&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day56 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/56.%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98.md&quot;&gt;使用缓存&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;网站优化第一定律&lt;/li&gt; 
 &lt;li&gt;在Django项目中使用Redis提供缓存服务&lt;/li&gt; 
 &lt;li&gt;在视图函数中读写缓存&lt;/li&gt; 
 &lt;li&gt;使用装饰器实现页面缓存&lt;/li&gt; 
 &lt;li&gt;为数据接口提供缓存服务&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day57 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/57.%E6%8E%A5%E5%85%A5%E4%B8%89%E6%96%B9%E5%B9%B3%E5%8F%B0.md&quot;&gt;接入三方平台&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;文件上传表单控件和图片文件预览&lt;/li&gt; 
 &lt;li&gt;服务器端如何处理上传的文件&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day58 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/58.%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1%E5%92%8C%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.md&quot;&gt;异步任务和定时任务&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;网站优化第二定律&lt;/li&gt; 
 &lt;li&gt;配置消息队列服务&lt;/li&gt; 
 &lt;li&gt;在项目中使用Celery实现任务异步化&lt;/li&gt; 
 &lt;li&gt;在项目中使用Celery实现定时任务&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day59 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/59.%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.md&quot;&gt;单元测试&lt;/a&gt;&lt;/h4&gt; 
&lt;h4&gt;Day60 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/60.%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF.md&quot;&gt;项目上线&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Python中的单元测试&lt;/li&gt; 
 &lt;li&gt;Django框架对单元测试的支持&lt;/li&gt; 
 &lt;li&gt;使用版本控制系统&lt;/li&gt; 
 &lt;li&gt;配置和使用uWSGI&lt;/li&gt; 
 &lt;li&gt;动静分离和Nginx配置&lt;/li&gt; 
 &lt;li&gt;配置HTTPS&lt;/li&gt; 
 &lt;li&gt;配置域名解析&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day61~65 - 网络数据采集&lt;/h3&gt; 
&lt;h4&gt;Day61 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/61.%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%A6%82%E8%BF%B0.md&quot;&gt;网络数据采集概述&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;网络爬虫的概念及其应用领域&lt;/li&gt; 
 &lt;li&gt;网络爬虫的合法性探讨&lt;/li&gt; 
 &lt;li&gt;开发网络爬虫的相关工具&lt;/li&gt; 
 &lt;li&gt;一个爬虫程序的构成&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day62 - 数据抓取和解析&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/62.%E7%94%A8Python%E8%8E%B7%E5%8F%96%E7%BD%91%E7%BB%9C%E8%B5%84%E6%BA%90-1.md&quot;&gt;使用&lt;code&gt;requests&lt;/code&gt;三方库实现数据抓取&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/62.%E7%94%A8Python%E8%A7%A3%E6%9E%90HTML%E9%A1%B5%E9%9D%A2-2.md&quot;&gt;页面解析的三种方式&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;正则表达式解析&lt;/li&gt; 
   &lt;li&gt;XPath解析&lt;/li&gt; 
   &lt;li&gt;CSS选择器解析&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day63 - Python中的并发编程&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/63.Python%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-1.md&quot;&gt;多线程&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/63.Python%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2.md&quot;&gt;多进程&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/63.Python%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-3.md&quot;&gt;异步I/O&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day64 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/64.%E4%BD%BF%E7%94%A8Selenium%E6%8A%93%E5%8F%96%E7%BD%91%E9%A1%B5%E5%8A%A8%E6%80%81%E5%86%85%E5%AE%B9.md&quot;&gt;使用Selenium抓取网页动态内容&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;安装Selenium&lt;/li&gt; 
 &lt;li&gt;加载页面&lt;/li&gt; 
 &lt;li&gt;查找元素和模拟用户行为&lt;/li&gt; 
 &lt;li&gt;隐式等待和显示等待&lt;/li&gt; 
 &lt;li&gt;执行JavaScript代码&lt;/li&gt; 
 &lt;li&gt;Selenium反爬破解&lt;/li&gt; 
 &lt;li&gt;设置无头浏览器&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day65 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/65.%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy%E7%AE%80%E4%BB%8B.md&quot;&gt;爬虫框架Scrapy简介&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Scrapy核心组件&lt;/li&gt; 
 &lt;li&gt;Scrapy工作流程&lt;/li&gt; 
 &lt;li&gt;安装Scrapy和创建项目&lt;/li&gt; 
 &lt;li&gt;编写蜘蛛程序&lt;/li&gt; 
 &lt;li&gt;编写中间件和管道程序&lt;/li&gt; 
 &lt;li&gt;Scrapy配置文件&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day66~80 - Python数据分析&lt;/h3&gt; 
&lt;h4&gt;Day66 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/66.%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A6%82%E8%BF%B0.md&quot;&gt;数据分析概述&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;数据分析师的职责&lt;/li&gt; 
 &lt;li&gt;数据分析师的技能栈&lt;/li&gt; 
 &lt;li&gt;数据分析相关库&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day67 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/67.%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87.md&quot;&gt;环境准备&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;安装和使用anaconda 
  &lt;ul&gt; 
   &lt;li&gt;conda相关命令&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;安装和使用jupyter-lab 
  &lt;ul&gt; 
   &lt;li&gt;安装和启动&lt;/li&gt; 
   &lt;li&gt;使用小技巧&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day68 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/68.NumPy%E7%9A%84%E5%BA%94%E7%94%A8-1.md&quot;&gt;NumPy的应用-1&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;创建数组对象&lt;/li&gt; 
 &lt;li&gt;数组对象的属性&lt;/li&gt; 
 &lt;li&gt;数组对象的索引运算 
  &lt;ul&gt; 
   &lt;li&gt;普通索引&lt;/li&gt; 
   &lt;li&gt;花式索引&lt;/li&gt; 
   &lt;li&gt;布尔索引&lt;/li&gt; 
   &lt;li&gt;切片索引&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;案例：使用数组处理图像&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day69 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/69.NumPy%E7%9A%84%E5%BA%94%E7%94%A8-2.md&quot;&gt;NumPy的应用-2&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;数组对象的相关方法 
  &lt;ul&gt; 
   &lt;li&gt;获取描述性统计信息&lt;/li&gt; 
   &lt;li&gt;其他相关方法&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day70 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/70.NumPy%E7%9A%84%E5%BA%94%E7%94%A8-3.md&quot;&gt;NumPy的应用-3&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;数组的运算 
  &lt;ul&gt; 
   &lt;li&gt;数组跟标量的运算&lt;/li&gt; 
   &lt;li&gt;数组跟数组的运算&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;通用一元函数&lt;/li&gt; 
 &lt;li&gt;通用二元函数&lt;/li&gt; 
 &lt;li&gt;广播机制&lt;/li&gt; 
 &lt;li&gt;Numpy常用函数&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day71 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/71.NumPy%E7%9A%84%E5%BA%94%E7%94%A8-4.md&quot;&gt;NumPy的应用-4&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;向量&lt;/li&gt; 
 &lt;li&gt;行列式&lt;/li&gt; 
 &lt;li&gt;矩阵&lt;/li&gt; 
 &lt;li&gt;多项式&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day72 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/72.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-1.md&quot;&gt;深入浅出pandas-1&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;创建Series对象&lt;/li&gt; 
 &lt;li&gt;Series对象的运算&lt;/li&gt; 
 &lt;li&gt;Series对象的属性和方法&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day73 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/73.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-2.md&quot;&gt;深入浅出pandas-2&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;创建DataFrame对象&lt;/li&gt; 
 &lt;li&gt;DataFrame对象的属性和方法&lt;/li&gt; 
 &lt;li&gt;读写DataFrame中的数据&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day74 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/74.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-3.md&quot;&gt;深入浅出pandas-3&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;数据重塑 
  &lt;ul&gt; 
   &lt;li&gt;数据拼接&lt;/li&gt; 
   &lt;li&gt;数据合并&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;数据清洗 
  &lt;ul&gt; 
   &lt;li&gt;缺失值&lt;/li&gt; 
   &lt;li&gt;重复值&lt;/li&gt; 
   &lt;li&gt;异常值&lt;/li&gt; 
   &lt;li&gt;预处理&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day75 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/75.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-4.md&quot;&gt;深入浅出pandas-4&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;数据透视 
  &lt;ul&gt; 
   &lt;li&gt;获取描述性统计信息&lt;/li&gt; 
   &lt;li&gt;排序和头部值&lt;/li&gt; 
   &lt;li&gt;分组聚合&lt;/li&gt; 
   &lt;li&gt;透视表和交叉表&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;数据呈现&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day76 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/76.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-5.md&quot;&gt;深入浅出pandas-5&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;计算同比环比&lt;/li&gt; 
 &lt;li&gt;窗口计算&lt;/li&gt; 
 &lt;li&gt;相关性判定&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day77 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/77.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-6.md&quot;&gt;深入浅出pandas-6&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;索引的使用 
  &lt;ul&gt; 
   &lt;li&gt;范围索引&lt;/li&gt; 
   &lt;li&gt;分类索引&lt;/li&gt; 
   &lt;li&gt;多级索引&lt;/li&gt; 
   &lt;li&gt;间隔索引&lt;/li&gt; 
   &lt;li&gt;日期时间索引&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day78 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/78.%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-1.md&quot;&gt;数据可视化-1&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;安装和导入matplotlib&lt;/li&gt; 
 &lt;li&gt;创建画布&lt;/li&gt; 
 &lt;li&gt;创建坐标系&lt;/li&gt; 
 &lt;li&gt;绘制图表 
  &lt;ul&gt; 
   &lt;li&gt;折线图&lt;/li&gt; 
   &lt;li&gt;散点图&lt;/li&gt; 
   &lt;li&gt;柱状图&lt;/li&gt; 
   &lt;li&gt;饼状图&lt;/li&gt; 
   &lt;li&gt;直方图&lt;/li&gt; 
   &lt;li&gt;箱线图&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;显示和保存图表&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day79 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/79.%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-2.md&quot;&gt;数据可视化-2&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;高阶图表 
  &lt;ul&gt; 
   &lt;li&gt;气泡图&lt;/li&gt; 
   &lt;li&gt;面积图&lt;/li&gt; 
   &lt;li&gt;雷达图&lt;/li&gt; 
   &lt;li&gt;玫瑰图&lt;/li&gt; 
   &lt;li&gt;3D图表&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day80 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/80.%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-3.md&quot;&gt;数据可视化-3&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Seaborn&lt;/li&gt; 
 &lt;li&gt;Pyecharts&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day81~90 - 机器学习&lt;/h3&gt; 
&lt;h4&gt;Day81 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/81.%E6%B5%85%E8%B0%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.md&quot;&gt;浅谈机器学习&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;人工智能发展史&lt;/li&gt; 
 &lt;li&gt;什么是机器学习&lt;/li&gt; 
 &lt;li&gt;机器学习应用领域&lt;/li&gt; 
 &lt;li&gt;机器学习的分类&lt;/li&gt; 
 &lt;li&gt;机器学习的步骤&lt;/li&gt; 
 &lt;li&gt;第一次机器学习&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day82 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/82.k%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95.md&quot;&gt;k最近邻算法&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;距离的度量&lt;/li&gt; 
 &lt;li&gt;数据集介绍&lt;/li&gt; 
 &lt;li&gt;kNN分类的实现&lt;/li&gt; 
 &lt;li&gt;模型评估&lt;/li&gt; 
 &lt;li&gt;参数调优&lt;/li&gt; 
 &lt;li&gt;kNN回归的实现&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day83 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/83.%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97.md&quot;&gt;决策树和随机森林&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;决策树的构建 
  &lt;ul&gt; 
   &lt;li&gt;特征选择&lt;/li&gt; 
   &lt;li&gt;数据分裂&lt;/li&gt; 
   &lt;li&gt;树的剪枝&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;实现决策树模型&lt;/li&gt; 
 &lt;li&gt;随机森林概述&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day84 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/84.%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95.md&quot;&gt;朴素贝叶斯算法&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;贝叶斯定理&lt;/li&gt; 
 &lt;li&gt;朴素贝叶斯&lt;/li&gt; 
 &lt;li&gt;算法原理 
  &lt;ul&gt; 
   &lt;li&gt;训练阶段&lt;/li&gt; 
   &lt;li&gt;预测阶段&lt;/li&gt; 
   &lt;li&gt;代码实现&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;算法优缺点&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day85 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/85.%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B.md&quot;&gt;回归模型&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;回归模型的分类&lt;/li&gt; 
 &lt;li&gt;回归系数的计算&lt;/li&gt; 
 &lt;li&gt;新数据集介绍&lt;/li&gt; 
 &lt;li&gt;线性回归代码实现&lt;/li&gt; 
 &lt;li&gt;回归模型的评估&lt;/li&gt; 
 &lt;li&gt;引入正则化项&lt;/li&gt; 
 &lt;li&gt;线性回归另一种实现&lt;/li&gt; 
 &lt;li&gt;多项式回归&lt;/li&gt; 
 &lt;li&gt;逻辑回归&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day86 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/86.K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.md&quot;&gt;K-Means聚类算法&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;算法原理&lt;/li&gt; 
 &lt;li&gt;数学描述&lt;/li&gt; 
 &lt;li&gt;代码实现&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day87 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/87.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95.md&quot;&gt;集成学习算法&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;算法分类&lt;/li&gt; 
 &lt;li&gt;AdaBoost&lt;/li&gt; 
 &lt;li&gt;GBDT&lt;/li&gt; 
 &lt;li&gt;XGBoost&lt;/li&gt; 
 &lt;li&gt;LightGBM&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day88 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/88.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.md&quot;&gt;神经网络模型&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;基本构成&lt;/li&gt; 
 &lt;li&gt;工作原理&lt;/li&gt; 
 &lt;li&gt;代码实现&lt;/li&gt; 
 &lt;li&gt;模型优缺点&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day89 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/89.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8.md&quot;&gt;自然语言处理入门&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;词袋模型&lt;/li&gt; 
 &lt;li&gt;词向量&lt;/li&gt; 
 &lt;li&gt;NPLM和RNN&lt;/li&gt; 
 &lt;li&gt;Seq2Seq&lt;/li&gt; 
 &lt;li&gt;Transformer&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day90 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/90.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.md&quot;&gt;机器学习实战&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;数据探索&lt;/li&gt; 
 &lt;li&gt;特征工程&lt;/li&gt; 
 &lt;li&gt;模型训练&lt;/li&gt; 
 &lt;li&gt;模型评估&lt;/li&gt; 
 &lt;li&gt;模型部署&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day91~99 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100&quot;&gt;团队项目开发&lt;/a&gt;&lt;/h3&gt; 
&lt;h4&gt;第91天：&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/91.%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md&quot;&gt;团队项目开发的问题和解决方案&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;软件过程模型&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;经典过程模型（瀑布模型）&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;可行性分析（研究做还是不做），输出《可行性分析报告》。&lt;/li&gt; 
     &lt;li&gt;需求分析（研究做什么），输出《需求规格说明书》和产品界面原型图。&lt;/li&gt; 
     &lt;li&gt;概要设计和详细设计，输出概念模型图（ER图）、物理模型图、类图、时序图等。&lt;/li&gt; 
     &lt;li&gt;编码 / 测试。&lt;/li&gt; 
     &lt;li&gt;上线 / 维护。&lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt;瀑布模型最大的缺点是无法拥抱需求变化，整套流程结束后才能看到产品，团队士气低落。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;敏捷开发（Scrum）- 产品所有者、Scrum Master、研发人员 - Sprint&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;产品的Backlog（用户故事、产品原型）。&lt;/li&gt; 
     &lt;li&gt;计划会议（评估和预算）。&lt;/li&gt; 
     &lt;li&gt;日常开发（站立会议、番茄工作法、结对编程、测试先行、代码重构……）。&lt;/li&gt; 
     &lt;li&gt;修复bug（问题描述、重现步骤、测试人员、被指派人）。&lt;/li&gt; 
     &lt;li&gt;发布版本。&lt;/li&gt; 
     &lt;li&gt;评审会议（Showcase，用户需要参与）。&lt;/li&gt; 
     &lt;li&gt;回顾会议（对当前迭代周期做一个总结）。&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;blockquote&gt; 
     &lt;p&gt;补充：敏捷软件开发宣言&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;strong&gt;个体和互动&lt;/strong&gt; 高于 流程和工具&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;工作的软件&lt;/strong&gt; 高于 详尽的文档&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;客户合作&lt;/strong&gt; 高于 合同谈判&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;响应变化&lt;/strong&gt; 高于 遵循计划&lt;/li&gt; 
     &lt;/ul&gt; 
    &lt;/blockquote&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/agile-scrum-sprint-cycle.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
    &lt;blockquote&gt; 
     &lt;p&gt;角色：产品所有者（决定做什么，能对需求拍板的人）、团队负责人（解决各种问题，专注如何更好的工作，屏蔽外部对开发团队的影响）、开发团队（项目执行人员，具体指开发人员和测试人员）。&lt;/p&gt; 
    &lt;/blockquote&gt; 
    &lt;blockquote&gt; 
     &lt;p&gt;准备工作：商业案例和资金、合同、憧憬、初始产品需求、初始发布计划、入股、组建团队。&lt;/p&gt; 
    &lt;/blockquote&gt; 
    &lt;blockquote&gt; 
     &lt;p&gt;敏捷团队通常人数为8-10人。&lt;/p&gt; 
    &lt;/blockquote&gt; 
    &lt;blockquote&gt; 
     &lt;p&gt;工作量估算：将开发任务量化，包括原型、Logo设计、UI设计、前端开发等，尽量把每个工作分解到最小任务量，最小任务量标准为工作时间不能超过两天，然后估算总体项目时间。把每个任务都贴在看板上面，看板上分三部分：to do（待完成）、in progress（进行中）和done（已完成）。&lt;/p&gt; 
    &lt;/blockquote&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;项目团队组建&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;团队的构成和角色&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/company_architecture.png&quot; alt=&quot;company_architecture&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;编程规范和代码审查（&lt;code&gt;flake8&lt;/code&gt;、&lt;code&gt;pylint&lt;/code&gt;）&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/pylint.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Python中的一些“惯例”（请参考&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/%E7%95%AA%E5%A4%96%E7%AF%87/Python%E7%BC%96%E7%A8%8B%E6%83%AF%E4%BE%8B.md&quot;&gt;《Python惯例-如何编写Pythonic的代码》&lt;/a&gt;）&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;影响代码可读性的原因：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;代码注释太少或者没有注释&lt;/li&gt; 
     &lt;li&gt;代码破坏了语言的最佳实践&lt;/li&gt; 
     &lt;li&gt;反模式编程（意大利面代码、复制-黏贴编程、自负编程、……）&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;团队开发工具介绍&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;版本控制：Git、Mercury&lt;/li&gt; 
   &lt;li&gt;缺陷管理：&lt;a href=&quot;https://about.gitlab.com/&quot;&gt;Gitlab&lt;/a&gt;、&lt;a href=&quot;http://www.redmine.org.cn/&quot;&gt;Redmine&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;敏捷闭环工具：&lt;a href=&quot;https://www.zentao.net/&quot;&gt;禅道&lt;/a&gt;、&lt;a href=&quot;https://www.atlassian.com/software/jira/features&quot;&gt;JIRA&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;持续集成：&lt;a href=&quot;https://jenkins.io/&quot;&gt;Jenkins&lt;/a&gt;、&lt;a href=&quot;https://travis-ci.org/&quot;&gt;Travis-CI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;请参考&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/91.%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md&quot;&gt;《团队项目开发的问题和解决方案》&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;项目选题和理解业务&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;选题范围设定&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;CMS（用户端）：新闻聚合网站、问答/分享社区、影评/书评网站等。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;MIS（用户端+管理端）：KMS、KPI考核系统、HRS、CRM系统、供应链系统、仓储管理系统等。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;App后台（管理端+数据接口）：二手交易类、报刊杂志类、小众电商类、新闻资讯类、旅游类、社交类、阅读类等。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;其他类型：自身行业背景和工作经验、业务容易理解和把控。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;需求理解、模块划分和任务分配&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;需求理解：头脑风暴和竞品分析。&lt;/li&gt; 
   &lt;li&gt;模块划分：画思维导图（XMind），每个模块是一个枝节点，每个具体的功能是一个叶节点（用动词表述），需要确保每个叶节点无法再生出新节点，确定每个叶子节点的重要性、优先级和工作量。&lt;/li&gt; 
   &lt;li&gt;任务分配：由项目负责人根据上面的指标为每个团队成员分配任务。&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/requirements_by_xmind.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;制定项目进度表（每日更新）&lt;/p&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;模块&lt;/th&gt; 
     &lt;th&gt;功能&lt;/th&gt; 
     &lt;th&gt;人员&lt;/th&gt; 
     &lt;th&gt;状态&lt;/th&gt; 
     &lt;th&gt;完成&lt;/th&gt; 
     &lt;th&gt;工时&lt;/th&gt; 
     &lt;th&gt;计划开始&lt;/th&gt; 
     &lt;th&gt;实际开始&lt;/th&gt; 
     &lt;th&gt;计划结束&lt;/th&gt; 
     &lt;th&gt;实际结束&lt;/th&gt; 
     &lt;th&gt;备注&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;评论&lt;/td&gt; 
     &lt;td&gt;添加评论&lt;/td&gt; 
     &lt;td&gt;王大锤&lt;/td&gt; 
     &lt;td&gt;正在进行&lt;/td&gt; 
     &lt;td&gt;50%&lt;/td&gt; 
     &lt;td&gt;4&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;删除评论&lt;/td&gt; 
     &lt;td&gt;王大锤&lt;/td&gt; 
     &lt;td&gt;等待&lt;/td&gt; 
     &lt;td&gt;0%&lt;/td&gt; 
     &lt;td&gt;2&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;查看评论&lt;/td&gt; 
     &lt;td&gt;白元芳&lt;/td&gt; 
     &lt;td&gt;正在进行&lt;/td&gt; 
     &lt;td&gt;20%&lt;/td&gt; 
     &lt;td&gt;4&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;需要进行代码审查&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;评论投票&lt;/td&gt; 
     &lt;td&gt;白元芳&lt;/td&gt; 
     &lt;td&gt;等待&lt;/td&gt; 
     &lt;td&gt;0%&lt;/td&gt; 
     &lt;td&gt;4&lt;/td&gt; 
     &lt;td&gt;2018/8/8&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;2018/8/8&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;OOAD和数据库设计&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;UML（统一建模语言）的类图&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/uml-class-diagram.png&quot; alt=&quot;uml&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通过模型创建表（正向工程），例如在Django项目中可以通过下面的命令创建二维表。&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;python manage.py makemigrations app
python manage.py migrate
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用PowerDesigner绘制物理模型图。&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/power-designer-pdm.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通过数据表创建模型（反向工程），例如在Django项目中可以通过下面的命令生成模型。&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;python manage.py inspectdb &amp;gt; app/models.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;第92天：&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/92.Docker%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3.md&quot;&gt;Docker容器技术详解&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Docker简介&lt;/li&gt; 
 &lt;li&gt;安装Docker&lt;/li&gt; 
 &lt;li&gt;使用Docker创建容器（Nginx、MySQL、Redis、Gitlab、Jenkins）&lt;/li&gt; 
 &lt;li&gt;构建Docker镜像（Dockerfile的编写和相关指令）&lt;/li&gt; 
 &lt;li&gt;容器编排（Docker-compose）&lt;/li&gt; 
 &lt;li&gt;集群管理（Kubernetes）&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;第93天：&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/93.MySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.md&quot;&gt;MySQL性能优化&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;基本原则&lt;/li&gt; 
 &lt;li&gt;InnoDB引擎&lt;/li&gt; 
 &lt;li&gt;索引的使用和注意事项&lt;/li&gt; 
 &lt;li&gt;数据分区&lt;/li&gt; 
 &lt;li&gt;SQL优化&lt;/li&gt; 
 &lt;li&gt;配置优化&lt;/li&gt; 
 &lt;li&gt;架构优化&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;第94天：&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/94.%E7%BD%91%E7%BB%9CAPI%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1.md&quot;&gt;网络API接口设计&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;设计原则 
  &lt;ul&gt; 
   &lt;li&gt;关键问题&lt;/li&gt; 
   &lt;li&gt;其他问题&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;文档撰写&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;第95天：[使用Django开发商业项目](./Day91-100/95.使用Django开发商业项 目.md)&lt;/h4&gt; 
&lt;h5&gt;项目开发中的公共问题&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;数据库的配置（多数据库、主从复制、数据库路由）&lt;/li&gt; 
 &lt;li&gt;缓存的配置（分区缓存、键设置、超时设置、主从复制、故障恢复（哨兵））&lt;/li&gt; 
 &lt;li&gt;日志的配置&lt;/li&gt; 
 &lt;li&gt;分析和调试（Django-Debug-ToolBar）&lt;/li&gt; 
 &lt;li&gt;好用的Python模块（日期计算、图像处理、数据加密、三方API）&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;REST API设计&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;RESTful架构 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2011/09/restful.html&quot;&gt;理解RESTful架构&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2014/05/restful_api.html&quot;&gt;RESTful API设计指南&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html&quot;&gt;RESTful API最佳实践&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;API接口文档的撰写 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;http://rap2.taobao.org/&quot;&gt;RAP2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;http://yapi.demo.qunar.com/&quot;&gt;YAPI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.django-rest-framework.org/&quot;&gt;django-REST-framework&lt;/a&gt;的应用&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;项目中的重点难点剖析&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;使用缓存缓解数据库压力 - Redis&lt;/li&gt; 
 &lt;li&gt;使用消息队列做解耦合和削峰 - Celery + RabbitMQ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;第96天：&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/96.%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E5%92%8C%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95.md&quot;&gt;软件测试和自动化测试&lt;/a&gt;&lt;/h4&gt; 
&lt;h5&gt;单元测试&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;测试的种类&lt;/li&gt; 
 &lt;li&gt;编写单元测试（&lt;code&gt;unittest&lt;/code&gt;、&lt;code&gt;pytest&lt;/code&gt;、&lt;code&gt;nose2&lt;/code&gt;、&lt;code&gt;tox&lt;/code&gt;、&lt;code&gt;ddt&lt;/code&gt;、……）&lt;/li&gt; 
 &lt;li&gt;测试覆盖率（&lt;code&gt;coverage&lt;/code&gt;）&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;Django项目部署&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;部署前的准备工作 
  &lt;ul&gt; 
   &lt;li&gt;关键设置（SECRET_KEY / DEBUG / ALLOWED_HOSTS / 缓存 / 数据库）&lt;/li&gt; 
   &lt;li&gt;HTTPS / CSRF_COOKIE_SECUR / SESSION_COOKIE_SECURE&lt;/li&gt; 
   &lt;li&gt;日志相关配置&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Linux常用命令回顾&lt;/li&gt; 
 &lt;li&gt;Linux常用服务的安装和配置&lt;/li&gt; 
 &lt;li&gt;uWSGI/Gunicorn和Nginx的使用 
  &lt;ul&gt; 
   &lt;li&gt;Gunicorn和uWSGI的比较 
    &lt;ul&gt; 
     &lt;li&gt;对于不需要大量定制化的简单应用程序，Gunicorn是一个不错的选择，uWSGI的学习曲线比Gunicorn要陡峭得多，Gunicorn的默认参数就已经能够适应大多数应用程序。&lt;/li&gt; 
     &lt;li&gt;uWSGI支持异构部署。&lt;/li&gt; 
     &lt;li&gt;由于Nginx本身支持uWSGI，在线上一般都将Nginx和uWSGI捆绑在一起部署，而且uWSGI属于功能齐全且高度定制的WSGI中间件。&lt;/li&gt; 
     &lt;li&gt;在性能上，Gunicorn和uWSGI其实表现相当。&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;使用虚拟化技术（Docker）部署测试环境和生产环境&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;性能测试&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;AB的使用&lt;/li&gt; 
 &lt;li&gt;SQLslap的使用&lt;/li&gt; 
 &lt;li&gt;sysbench的使用&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;自动化测试&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;使用Shell和Python进行自动化测试&lt;/li&gt; 
 &lt;li&gt;使用Selenium实现自动化测试 
  &lt;ul&gt; 
   &lt;li&gt;Selenium IDE&lt;/li&gt; 
   &lt;li&gt;Selenium WebDriver&lt;/li&gt; 
   &lt;li&gt;Selenium Remote Control&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;测试工具Robot Framework介绍&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;第97天：&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/97.%E7%94%B5%E5%95%86%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9%E5%89%96%E6%9E%90.md&quot;&gt;电商网站技术要点剖析&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;商业模式和需求要点&lt;/li&gt; 
 &lt;li&gt;物理模型设计&lt;/li&gt; 
 &lt;li&gt;第三方登录&lt;/li&gt; 
 &lt;li&gt;缓存预热和查询缓存&lt;/li&gt; 
 &lt;li&gt;购物车的实现&lt;/li&gt; 
 &lt;li&gt;支付功能集成&lt;/li&gt; 
 &lt;li&gt;秒杀和超卖问题&lt;/li&gt; 
 &lt;li&gt;静态资源管理&lt;/li&gt; 
 &lt;li&gt;全文检索方案&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;第98天：&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/98.%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%E5%92%8C%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98.md&quot;&gt;项目部署上线和性能调优&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;MySQL数据库调优&lt;/li&gt; 
 &lt;li&gt;Web服务器性能优化 
  &lt;ul&gt; 
   &lt;li&gt;Nginx负载均衡配置&lt;/li&gt; 
   &lt;li&gt;Keepalived实现高可用&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;代码性能调优 
  &lt;ul&gt; 
   &lt;li&gt;多线程&lt;/li&gt; 
   &lt;li&gt;异步化&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;静态资源访问优化 
  &lt;ul&gt; 
   &lt;li&gt;云存储&lt;/li&gt; 
   &lt;li&gt;CDN&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;第99天：&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/99.%E9%9D%A2%E8%AF%95%E4%B8%AD%E7%9A%84%E5%85%AC%E5%85%B1%E9%97%AE%E9%A2%98.md&quot;&gt;面试中的公共问题&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;计算机基础&lt;/li&gt; 
 &lt;li&gt;Python基础&lt;/li&gt; 
 &lt;li&gt;Web框架相关&lt;/li&gt; 
 &lt;li&gt;爬虫相关问题&lt;/li&gt; 
 &lt;li&gt;数据分析&lt;/li&gt; 
 &lt;li&gt;项目相关&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;第100天 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/100.%E8%A1%A5%E5%85%85%E5%86%85%E5%AE%B9.md&quot;&gt;补充内容&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;面试宝典&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Python 面试宝典&lt;/li&gt; 
   &lt;li&gt;SQL 面试宝典（数据分析师）&lt;/li&gt; 
   &lt;li&gt;商业分析面试宝典&lt;/li&gt; 
   &lt;li&gt;机器学习面试宝典&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;机器学习数学基础&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;深度学习&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;计算机视觉&lt;/li&gt; 
   &lt;li&gt;大语言模型&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>panaversity/learn-agentic-ai</title>
      <link>https://github.com/panaversity/learn-agentic-ai</link>
      <description>&lt;p&gt;Learn Agentic AI using OpenAI Agents SDK, Autogen, CrewAI, LangGraph, and Knowledge Graphs.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Learn Agentic AI&lt;/h1&gt; 
&lt;p&gt;This repo is part of the &lt;a href=&quot;https://docs.google.com/document/d/15usu1hkrrRLRjcq_3nCTT-0ljEcgiC44iSdvdqrCprk/edit?usp=sharing&quot;&gt;Panaversity Certified Agentic &amp;amp; Robotic AI Engineer&lt;/a&gt; program. It covers AI-201 and AI-202 courses.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/panaversity/learn-agentic-ai/main/toptrend.webp&quot; alt=&quot;Agentic AI Top Trend&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Watch The NVIDIA CEO Jensen Huang Keynote at CES 2025&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=k82RwXqZHY8&quot; title=&quot;NVIDIA CEO Jensen Huang Keynote at CES 2025&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/panaversity/learn-agentic-ai/main/hr.jpeg&quot; alt=&quot;HR for Agents&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Reference:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/alexwang2911_aiagents-robotics-technology-activity-7282829390445453314-QLeS&quot;&gt;https://www.linkedin.com/posts/alexwang2911_aiagents-robotics-technology-activity-7282829390445453314-QLeS&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Our Teaching Approach&lt;/h3&gt; 
&lt;p&gt;We will be following this approach to teach Agentic AI Engineering:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.google.com/document/d/1vgdGpda2YknjPRKnRi9qHgDbGX_kWSjct_V6Up3ed80/edit?usp=sharing&quot;&gt;https://docs.google.com/document/d/1vgdGpda2YknjPRKnRi9qHgDbGX_kWSjct_V6Up3ed80/edit?usp=sharing&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;AI-201: Fundamentals of Agentic AI - From Foundations to Autonomous Agents&lt;/h3&gt; 
&lt;p&gt;AI 201 Fundamentals of Agentic AI we cover chapters: 00-06&lt;/p&gt; 
&lt;p&gt;Kickstart your journey into Agentic AI! This course provides a rapid yet comprehensive introduction to Conversational, Generative, and Agentic AI. You&#39;ll master the foundational concepts using &lt;strong&gt;OpenAI Agents SDK&lt;/strong&gt;, then immediately build practical Conversational AI applications to understand human-AI interaction firsthand. The focus quickly shifts to Agentic Design Patterns, which you&#39;ll implement using OpenAI Agents SDK to create truly autonomous AI agents. You&#39;ll become proficient with OpenAI Agents SDK, developing agents ready for real-world tasks. Furthermore, you&#39;ll gain the unique skills to construct Model Context Protocol (MCP) servers and agents, enabling you to build next-generation augmented LLMs. Finally, we&#39;ll explore the groundbreaking potential of Agentic Payments, envisioning the future of AI in finance.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PL0vKVrkG4hWovpr0FX6Gs-06hfsPDEUe6&quot;&gt;AI-201 Video Playlist&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Note: These videos are for additional learning, and do not cover all the material taught in the onsite classes.&lt;/p&gt; 
&lt;h3&gt;AI-202: Advanced Agentic AI Engineering - Master Enterprise-Scale AI Agent Development&lt;/h3&gt; 
&lt;p&gt;AI 202 Advanced Agentic AI we cover chapters: 06, 7a, 8, 8a, 9, 9a, 10, 10a, 11, and 12&lt;/p&gt; 
&lt;p&gt;Ready to engineer truly sophisticated AI agent systems? AI-202 builds upon your AI-201 foundation to propel you into advanced Agentic AI engineering. You&#39;ll master powerful frameworks like Microsoft AutoGen to construct complex agents for intricate tasks and advanced decision-making. Focusing on Agent-to-Agent communication and orchestration, you&#39;ll develop enterprise-ready multi-agent solutions. You&#39;ll build robust Model Context Protocol (MCP) servers, and then craft dynamic, user-centric agentic frontends with Next.js and TypeScript. The course culminates in a professional project where you&#39;ll design and deploy a complete enterprise-grade agentic solution, showcasing your mastery of cutting-edge AI technologies and your readiness for the forefront of the field.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NirDiamant/GenAI_Agents</title>
      <link>https://github.com/NirDiamant/GenAI_Agents</link>
      <description>&lt;p&gt;This repository provides tutorials and implementations for various Generative AI Agent techniques, from basic to advanced. It serves as a comprehensive guide for building intelligent, interactive AI systems.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;http://makeapullrequest.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.linkedin.com/in/nir-diamant-759323134/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/LinkedIn-Connect-blue&quot; alt=&quot;LinkedIn&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/NirDiamantAI&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/NirDiamantAI?label=Follow%20@NirDiamantAI&amp;amp;style=social&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/cA6Aa4uyDX&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20our%20community-7289da?style=flat-square&amp;amp;logo=discord&amp;amp;logoColor=white&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🌟 &lt;strong&gt;Support This Project:&lt;/strong&gt; Your sponsorship fuels innovation in GenAI agent development. &lt;strong&gt;&lt;a href=&quot;https://github.com/sponsors/NirDiamant&quot;&gt;Become a sponsor&lt;/a&gt;&lt;/strong&gt; to help maintain and expand this valuable resource!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;GenAI Agents: Comprehensive Repository for Development and Implementation 🚀&lt;/h1&gt; 
&lt;p&gt;Welcome to one of the most extensive and dynamic collections of Generative AI (GenAI) agent tutorials and implementations available today. This repository serves as a comprehensive resource for learning, building, and sharing GenAI agents, ranging from simple conversational bots to complex, multi-agent systems.&lt;/p&gt; 
&lt;h2&gt;📫 Stay Updated!&lt;/h2&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align=&quot;center&quot;&gt;🚀&lt;br&gt;&lt;b&gt;Cutting-edge&lt;br&gt;Updates&lt;/b&gt;&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;💡&lt;br&gt;&lt;b&gt;Expert&lt;br&gt;Insights&lt;/b&gt;&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;🎯&lt;br&gt;&lt;b&gt;Top 0.1%&lt;br&gt;Content&lt;/b&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;p&gt;&lt;a href=&quot;https://diamantai.substack.com/?r=336pe4&amp;amp;utm_campaign=pub-share-checklist&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/images/subscribe-button.svg?sanitize=true&quot; alt=&quot;Subscribe to DiamantAI Newsletter&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Join over 15,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!&lt;/em&gt; &lt;em&gt;&lt;strong&gt;Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href=&quot;https://diamantai.substack.com/?r=336pe4&amp;amp;utm_campaign=pub-share-checklist&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/images/substack_image.png&quot; alt=&quot;DiamantAI&#39;s newsletter&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Generative AI agents are at the forefront of artificial intelligence, revolutionizing the way we interact with and leverage AI technologies. This repository is designed to guide you through the development journey, from basic agent implementations to advanced, cutting-edge systems.&lt;/p&gt; 
&lt;p&gt;Our goal is to provide a valuable resource for everyone - from beginners taking their first steps in AI to seasoned practitioners pushing the boundaries of what&#39;s possible. By offering a range of examples from foundational to complex, we aim to facilitate learning, experimentation, and innovation in the rapidly evolving field of GenAI agents.&lt;/p&gt; 
&lt;p&gt;Furthermore, this repository serves as a platform for showcasing innovative agent creations. Whether you&#39;ve developed a novel agent architecture or found an innovative application for existing techniques, we encourage you to share your work with the community.&lt;/p&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;p&gt;📚 Dive into my &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_Techniques&quot;&gt;comprehensive guide on RAG techniques&lt;/a&gt;&lt;/strong&gt; to learn about integrating external knowledge into AI systems, enhancing their capabilities with up-to-date and relevant information retrieval.&lt;/p&gt; 
&lt;p&gt;🖋️ Explore my &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/Prompt_Engineering&quot;&gt;Prompt Engineering Techniques guide&lt;/a&gt;&lt;/strong&gt; for an extensive collection of prompting strategies, from fundamental concepts to advanced methods, improving your ability to communicate effectively with AI language models.&lt;/p&gt; 
&lt;h2&gt;A Community-Driven Knowledge Hub&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;This repository grows stronger with your contributions!&lt;/strong&gt; Join our vibrant Discord community — the central hub for shaping and advancing this project together 🤝&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://discord.gg/cA6Aa4uyDX&quot;&gt;GenAI Agents Discord Community&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Whether you&#39;re a novice eager to learn or an expert ready to share your knowledge, your insights can shape the future of GenAI agents. Join us to propose ideas, get feedback, and collaborate on innovative implementations. For contribution guidelines, please refer to our &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/strong&gt; file. Let&#39;s advance GenAI agent technology together!&lt;/p&gt; 
&lt;p&gt;🔗 For discussions on GenAI, agents, or to explore knowledge-sharing opportunities, feel free to &lt;strong&gt;&lt;a href=&quot;https://www.linkedin.com/in/nir-diamant-759323134/&quot;&gt;connect on LinkedIn&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🎓 Learn to build GenAI agents from beginner to advanced levels&lt;/li&gt; 
 &lt;li&gt;🧠 Explore a wide range of agent architectures and applications&lt;/li&gt; 
 &lt;li&gt;📚 Step-by-step tutorials and comprehensive documentation&lt;/li&gt; 
 &lt;li&gt;🛠️ Practical, ready-to-use agent implementations&lt;/li&gt; 
 &lt;li&gt;🌟 Regular updates with the latest advancements in GenAI&lt;/li&gt; 
 &lt;li&gt;🤝 Share your own agent creations with the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;GenAI Agent Implementations&lt;/h2&gt; 
&lt;p&gt;Explore our extensive list of GenAI agent implementations, sorted by categories:&lt;/p&gt; 
&lt;h3&gt;🌱 Beginner-Friendly Agents&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simple Conversational Agent&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_conversational_agent.ipynb&quot;&gt;LangChain&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_conversational_agent-pydanticai.ipynb&quot;&gt;PydanticAI&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A context-aware conversational AI maintains information across interactions, enabling more natural dialogues.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Integrates a language model, prompt template, and history manager to generate contextual responses and track conversation sessions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_question_answering_agent.ipynb&quot;&gt;Simple Question Answering Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Answering (QA) agent using LangChain and OpenAI&#39;s language model understands user queries and provides relevant, concise answers.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Combines OpenAI&#39;s GPT model, a prompt template, and an LLMChain to process user questions and generate AI-driven responses in a streamlined manner.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simple Data Analysis Agent&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_data_analysis_agent_notebook.ipynb&quot;&gt;LangChain&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_data_analysis_agent_notebook-pydanticai.ipynb&quot;&gt;PydanticAI&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An AI-powered data analysis agent interprets and answers questions about datasets using natural language, combining language models with data manipulation tools for intuitive data exploration.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Integrates a language model, data manipulation framework, and agent framework to process natural language queries and perform data analysis on a synthetic dataset, enabling accessible insights for non-technical users.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🔧 Framework Tutorial: LangGraph&lt;/h3&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/langgraph-tutorial.ipynb&quot;&gt;Introduction to LangGraph: Building Modular AI Workflows&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;This tutorial introduces LangGraph, a powerful framework for creating modular, graph-based AI workflows. Learn how to leverage LangGraph to build more complex and flexible AI agents that can handle multi-step processes efficiently.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Step-by-step guide on using LangGraph to create a StateGraph workflow. The tutorial covers key concepts such as state management, node creation, and graph compilation. It demonstrates these principles by constructing a simple text analysis pipeline, serving as a foundation for more advanced agent architectures.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/your-first-ai-agent-simpler-than?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🎓 Educational and Research Agents&lt;/h3&gt; 
&lt;ol start=&quot;5&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/Academic_Task_Learning_Agent_LangGraph.ipynb&quot;&gt;ATLAS: Academic Task and Learning Agent System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;ATLAS demonstrates how to build an intelligent multi-agent system that transforms academic support through AI-powered assistance. The system leverages LangGraph&#39;s workflow framework to coordinate multiple specialized agents that provide personalized academic planning, note-taking, and advisory support.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Implements a state-managed multi-agent architecture using four specialized agents (Coordinator, Planner, Notewriter, and Advisor) working in concert through LangGraph&#39;s workflow framework. The system features sophisticated workflows for profile analysis and academic support, with continuous adaptation based on student performance and feedback.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=yxowMLL2dDI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/atlas-when-artificial-intelligence?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/scientific_paper_agent_langgraph.ipynb&quot;&gt;Scientific Paper Agent - Literature Review&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An intelligent research assistant that helps users navigate, understand, and analyze scientific literature through an orchestrated workflow. The system combines academic APIs with sophisticated paper processing techniques to automate literature review tasks, enabling researchers to efficiently extract insights from academic papers while maintaining research rigor and quality control.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Leverages LangGraph to create a five-node workflow system including decision making, planning, tool execution, and quality validation nodes. The system integrates the CORE API for paper access, PDFplumber for document processing, and advanced language models for analysis. Key features include a retry mechanism for robust paper downloads, structured data handling through Pydantic models, and quality-focused improvement cycles with human-in-the-loop validation options.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://youtu.be/Bc4YtpHY6Ws&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/nexus-ai-the-revolutionary-research?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/chiron_learning_agent_langgraph.ipynb&quot;&gt;Chiron - A Feynman-Enhanced Learning Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An adaptive learning agent that guides users through educational content using a structured checkpoint system and Feynman-style teaching. The system processes learning materials (either user-provided or web-retrieved), verifies understanding through interactive checkpoints, and provides simplified explanations when needed, creating a personalized learning experience that mimics one-on-one tutoring.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Uses LangGraph to orchestrate a learning workflow that includes checkpoint definition, context building, understanding verification, and Feynman teaching nodes. The system integrates web search for dynamic content retrieval, employs semantic chunking for context processing, and manages embeddings for relevant information retrieval. Key features include a 70% understanding threshold for progression, interactive human-in-the-loop validation, and structured output through Pydantic models for consistent data handling.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qsdiTGkB8mk&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;💼 Business and Professional Agents&lt;/h3&gt; 
&lt;ol start=&quot;8&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/customer_support_agent_langgraph.ipynb&quot;&gt;Customer Support Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An intelligent customer support agent using LangGraph categorizes queries, analyzes sentiment, and provides appropriate responses or escalates issues.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to create a workflow combining state management, query categorization, sentiment analysis, and response generation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/essay_grading_system_langgraph.ipynb&quot;&gt;Essay Grading Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An automated essay grading system using LangGraph and an LLM model evaluates essays based on relevance, grammar, structure, and depth of analysis.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes a state graph to define the grading workflow, incorporating separate grading functions for each criterion.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_travel_planner_langgraph.ipynb&quot;&gt;Travel Planning Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A Travel Planner using LangGraph demonstrates how to build a stateful, multi-step conversational AI application that collects user input and generates personalized travel itineraries.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes StateGraph to define the application flow, incorporates custom PlannerState for process management.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/agent_hackathon_genAI_career_assistant.ipynb&quot;&gt;GenAI Career Assistant Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;The GenAI Career Assistant demonstrates how to create a multi-agent system that provides personalized guidance for careers in Generative AI. Using LangGraph and Gemini LLM, the system delivers customized learning paths, resume assistance, interview preparation, and job search support.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Leverages a multi-agent architecture using LangGraph to coordinate specialized agents (Learning, Resume, Interview, Job Search) through TypedDict-based state management. The system employs sophisticated query categorization and routing while integrating with external tools like DuckDuckGo for job searches and dynamic content generation.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=IcKh0ltXO_8&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/project_manager_assistant_agent.ipynb&quot;&gt;Project Manager Assistant Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An AI agent designed to assist in project management tasks by automating the process of creating actionable tasks from project descriptions, identifying dependencies, scheduling work, and assigning tasks to team members based on expertise. The system includes risk assessment and self-reflection capabilities to optimize project plans through multiple iterations, aiming to minimize overall project risk.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Leverages LangGraph to orchestrate a workflow of specialized nodes including task generation, dependency mapping, scheduling, allocation, and risk assessment. Each node uses GPT-4o-mini for structured outputs following Pydantic models. The system implements a feedback loop for self-improvement, where risk scores trigger reflection cycles that generate insights to optimize the project plan. Visualization tools display Gantt charts of the generated schedules across iterations.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=R7YWjzg3LpI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ClauseAI.ipynb&quot;&gt;Contract Analysis Assistant (ClauseAI)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;ClauseAI demonstrates how to build an AI-powered contract analysis system using a multi-agent approach. The system employs specialized AI agents for different aspects of contract review, from clause analysis to compliance checking, and leverages LangGraph for workflow orchestration and Pinecone for efficient clause retrieval and comparison.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Implements a sophisticated state-based workflow using LangGraph to coordinate multiple AI agents through contract analysis stages. The system features Pydantic models for data validation, vector storage with Pinecone for clause comparison, and LLM-based analysis for generating comprehensive contract reports. The implementation includes parallel processing capabilities and customizable report generation based on user requirements.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=rP8uv_tXuSI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/e2e_testing_agent.ipynb&quot;&gt;E2E Testing Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;The E2E Testing Agent demonstrates how to build an AI-powered system that converts natural language test instructions into executable end-to-end web tests. Using LangGraph for workflow orchestration and Playwright for browser automation, the system enables users to specify test cases in plain English while handling the complexity of test generation and execution.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Implements a structured workflow using LangGraph to coordinate test generation, validation, and execution. The system features TypedDict state management, integration with Playwright for browser automation, and LLM-based code generation for converting natural language instructions into executable test scripts. The implementation includes DOM state analysis, error handling, and comprehensive test reporting.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=jPXtpzcCtyA&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🎨 Creative and Content Generation Agents&lt;/h3&gt; 
&lt;ol start=&quot;15&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/gif_animation_generator_langgraph.ipynb&quot;&gt;GIF Animation Generator Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A GIF animation generator that integrates LangGraph for workflow management, GPT-4 for text generation, and DALL-E for image creation, producing custom animations from user prompts.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a workflow that generates character descriptions, plots, and image prompts using GPT-4, creates images with DALL-E 3, and assembles them into GIFs using PIL. Employs asynchronous programming for efficient parallel processing.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/tts_poem_generator_agent_langgraph.ipynb&quot;&gt;TTS Poem Generator Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An advanced text-to-speech (TTS) agent using LangGraph and OpenAI&#39;s APIs classifies input text, processes it based on content type, and generates corresponding speech output.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a workflow that classifies input text using GPT models, applies content-specific processing, and converts the processed text to speech using OpenAI&#39;s TTS API. The system adapts its output based on the identified content type (general, poem, news, or joke).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/music_compositor_agent_langgraph.ipynb&quot;&gt;Music Compositor Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An AI Music Compositor using LangGraph and OpenAI&#39;s language models generates custom musical compositions based on user input. The system processes the input through specialized components, each contributing to the final musical piece, which is then converted to a playable MIDI file.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;LangGraph orchestrates a workflow that transforms user input into a musical composition, using ChatOpenAI (GPT-4) to generate melody, harmony, and rhythm, which are then style-adapted. The final AI-generated composition is converted to a MIDI file using music21 and can be played back using pygame.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ContentIntelligence.ipynb&quot;&gt;Content Intelligence: Multi-Platform Content Generation Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;Content Intelligence demonstrates how to build an advanced content generation system that transforms input text into platform-optimized content across multiple social media channels. The system employs LangGraph for workflow orchestration to analyze content, conduct research, and generate tailored content while maintaining brand consistency across different platforms.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Implements a sophisticated workflow using LangGraph to coordinate multiple specialized nodes (Summary, Research, Platform-Specific) through the content generation process. The system features TypedDict and Pydantic models for state management, integration with Tavily Search for research enhancement, and platform-specific content generation using GPT-4. The implementation includes parallel processing for multiple platforms and customizable content templates.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=DPMtPbKmWnU&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/business_meme_generator.ipynb&quot;&gt;Business Meme Generator Using LangGraph and Memegen.link&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;The Business Meme Generator demonstrates how to create an AI-powered system that generates contextually relevant memes based on company website analysis. Using LangGraph for workflow orchestration, the system combines Groq&#39;s Llama model for text analysis and the Memegen.link API to automatically produce brand-aligned memes for digital marketing.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Implements a state-managed workflow using LangGraph to coordinate website content analysis, meme concept generation, and image creation. The system features Pydantic models for data validation, asynchronous processing with aiohttp, and integration with external APIs (Groq, Memegen.link) to create a complete meme generation pipeline with customizable templates.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://youtu.be/lsdDaGmkSCw?si=oF3CGfhbRqz1_Vm8&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/murder_mystery_agent_langgraph.ipynb&quot;&gt;Murder Mystery Game with LLM Agents&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A text-based detective game that utilizes autonomous LLM agents as interactive characters in a procedurally generated murder mystery. Drawing inspiration from the UNBOUNDED paper, the system creates unique scenarios each time, with players taking on the role of Sherlock Holmes to solve the case through character interviews and deductive reasoning.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Leverages two LangGraph workflows - a main game loop for story/character generation and game progression, and a conversation sub-graph for character interactions. The system uses a combination of LLM-powered narrative generation, character AI, and structured game mechanics to create an immersive investigative experience with replayable storylines.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=_3cJYlk2EmA&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;📊 Analysis and Information Processing Agents&lt;/h3&gt; 
&lt;ol start=&quot;21&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/memory_enhanced_conversational_agent.ipynb&quot;&gt;Memory-Enhanced Conversational Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A memory-enhanced conversational AI agent incorporates short-term and long-term memory systems to maintain context within conversations and across multiple sessions, improving interaction quality and personalization.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Integrates a language model with separate short-term and long-term memory stores, utilizes a prompt template incorporating both memory types, and employs a memory manager for storage and retrieval. The system includes an interaction loop that updates and utilizes memories for each response.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/multi_agent_collaboration_system.ipynb&quot;&gt;Multi-Agent Collaboration System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A multi-agent collaboration system combining historical research with data analysis, leveraging large language models to simulate specialized agents working together to answer complex historical questions.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes a base Agent class to create specialized HistoryResearchAgent and DataAnalysisAgent, orchestrated by a HistoryDataCollaborationSystem. The system follows a five-step process: historical context provision, data needs identification, historical data provision, data analysis, and final synthesis.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/self_improving_agent.ipynb&quot;&gt;Self-Improving Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A Self-Improving Agent using LangChain engages in conversations, learns from interactions, and continuously improves its performance over time through reflection and adaptation.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Integrates a language model with chat history management, response generation, and a reflection mechanism. The system employs a learning system that incorporates insights from reflection to enhance future performance, creating a continuous improvement loop.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/task_oriented_agent.ipynb&quot;&gt;Task-Oriented Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A language model application using LangChain that summarizes text and translates the summary to Spanish, combining custom functions, structured tools, and an agent for efficient text processing.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes custom functions for summarization and translation, wrapped as structured tools. Employs a prompt template to guide the agent, which orchestrates the use of tools. An agent executor manages the process, taking input text and producing both an English summary and its Spanish translation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/search_the_internet_and_summarize.ipynb&quot;&gt;Internet Search and Summarize Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An intelligent web research assistant that combines web search capabilities with AI-powered summarization, automating the process of gathering information from the internet and distilling it into concise, relevant summaries.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Integrates a web search module using DuckDuckGo&#39;s API, a result parser, and a text summarization engine leveraging OpenAI&#39;s language models. The system performs site-specific or general searches, extracts relevant content, generates concise summaries, and compiles attributed results for efficient information retrieval and synthesis.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/research_team_autogen.ipynb&quot;&gt;Multi agent research team - Autogen&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;This technique explores a multi-agent system for collaborative research using the AutoGen library. It employs agents to solve tasks collaboratively, focusing on efficient execution and quality assurance. The system enhances research by distributing tasks among specialized agents.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Agents are configured with specific roles using the GPT-4 model, including admin, developer, planner, executor, and quality assurance. Interaction management ensures orderly communication with defined transitions. Task execution involves collaborative planning, coding, execution, and quality checking, demonstrating a scalable framework for various domains.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/yanivvak/dream-team&quot;&gt;comprehensive solution with UI&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/build-your-dream-team-with-autogen/ba-p/4157961&quot;&gt;Blogpost&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/sales_call_analyzer_agent.ipynb&quot;&gt;Sales Call Analyzer&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An intelligent system that automates the analysis of sales call recordings by combining audio transcription with advanced natural language processing. The analyzer transcribes audio using OpenAI&#39;s Whisper, processes the text using NLP techniques, and generates comprehensive reports including sentiment analysis, key phrases, pain points, and actionable recommendations to improve sales performance.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes multiple components in a structured workflow: OpenAI Whisper for audio transcription, CrewAI for task automation and agent management, and LangChain for orchestrating the analysis pipeline. The system processes audio through a series of steps from transcription to detailed analysis, leveraging custom agents and tasks to generate structured JSON reports containing insights about customer sentiment, sales opportunities, and recommended improvements.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=SKAt_PvznDw&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/Weather_Disaster_Management_AI_AGENT.ipynb&quot;&gt;Weather Emergency &amp;amp; Response System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A comprehensive system demonstrating two agent graph implementations for weather emergency response: a real-time graph processing live weather data, and a hybrid graph combining real and simulated data for testing high-severity scenarios. The system handles complete workflow from data gathering through emergency plan generation, with automated notifications and human verification steps.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph for orchestrating complex workflows with state management, integrating OpenWeatherMap API for real-time data, and Gemini for analysis and response generation. The system incorporates email notifications, social media monitoring simulation, and severity-based routing with configurable human verification for low/medium severity events.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=AgiOAJl_apw&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/self_healing_code.ipynb&quot;&gt;Self-Healing Codebase System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An intelligent system that automatically detects, diagnoses, and fixes runtime code errors using LangGraph workflow orchestration and ChromaDB vector storage. The system maintains a memory of encountered bugs and their fixes through vector embeddings, enabling pattern recognition for similar errors across the codebase.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes a state-based graph workflow that processes function definitions and runtime arguments through specialized nodes for error detection, code analysis, and fix generation. Incorporates ChromaDB for vector-based storage of bug patterns and fixes, with automated search and retrieval capabilities for similar error patterns, while maintaining code execution safety through structured validation steps.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ga7ShvIXOvE&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/database_discovery_fleet.ipynb&quot;&gt;DataScribe: AI-Powered Schema Explorer&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An intelligent agent system that enables intuitive exploration and querying of relational databases through natural language interactions. The system utilizes a fleet of specialized agents, coordinated by a stateful Supervisor, to handle schema discovery, query planning, and data analysis tasks while maintaining contextual understanding through vector-based relationship graphs.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Leverages LangGraph for orchestrating a multi-agent workflow including discovery, inference, and planning agents, with NetworkX for relationship graph visualization and management. The system incorporates dynamic state management through TypedDict classes, maintains database context between sessions using a db_graph attribute, and includes safety measures to prevent unauthorized database modifications.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;📰 News and Information Agents&lt;/h3&gt; 
&lt;ol start=&quot;31&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/news_tldr_langgraph.ipynb&quot;&gt;News TL;DR using LangGraph&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A news summarization system that generates concise TL;DR summaries of current events based on user queries. The system leverages large language models for decision making and summarization while integrating with news APIs to access up-to-date content, allowing users to quickly catch up on topics of interest through generated bullet-point summaries.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a workflow combining multiple components: GPT-4o-mini for generating search terms and article summaries, NewsAPI for retrieving article metadata, BeautifulSoup for web scraping article content, and Asyncio for concurrent processing. The system follows a structured pipeline from query processing through article selection and summarization, managing the flow between components to produce relevant TL;DRs of current news articles.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=0fRxW6miybI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/stop-reading-start-understanding?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ainsight_langgraph.ipynb&quot;&gt;AInsight: AI/ML Weekly News Reporter&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;AInsight demonstrates how to build an intelligent news aggregation and summarization system using a multi-agent architecture. The system employs three specialized agents (NewsSearcher, Summarizer, Publisher) to automatically collect, process and summarize AI/ML news for general audiences through LangGraph-based workflow orchestration.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Implements a state-managed multi-agent system using LangGraph to coordinate the news collection (Tavily API), technical content summarization (GPT-4), and report generation processes. The system features modular architecture with TypedDict-based state management, external API integration, and markdown report generation with customizable templates.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kH5S1is2D_0&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/journalism_focused_ai_assistant_langgraph.ipynb&quot;&gt;Journalism-Focused AI Assistant&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A specialized AI assistant that helps journalists tackle modern journalistic challenges like misinformation, bias, and information overload. The system integrates fact-checking, tone analysis, summarization, and grammar review tools to enhance the accuracy and efficiency of journalistic work while maintaining ethical reporting standards.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Leverages LangGraph to orchestrate a workflow of specialized components including language models for analysis and generation, web search integration via DuckDuckGo&#39;s API, document parsing tools like PyMuPDFLoader and WebBaseLoader, text splitting with RecursiveCharacterTextSplitter, and structured JSON outputs. Each component works together through a unified workflow to analyze content, verify facts, detect bias, extract quotes, and generate comprehensive reports.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/blog_writer_swarm.ipynb&quot;&gt;Blog Writer (Open AI Swarm)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A multi-agent system for collaborative blog post creation using OpenAI&#39;s Swarm package. It leverages specialized agents to perform research, planning, writing, and editing tasks efficiently.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes OpenAI&#39;s Swarm Package to manage agent interactions. Includes an admin, researcher, planner, writer, and editor, each with specific roles. The system follows a structured workflow: topic setting, outlining, research, drafting, and editing. This approach enhances content creation through task distribution, specialization, and collaborative problem-solving.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/openai/swarm&quot;&gt;Swarm Repo&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/generate_podcast_agent_langgraph.ipynb&quot;&gt;Podcast Internet Search and Generate Agent 🎙️&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A two step agent that first searches the internet for a given topic and then generates a podcast on the topic found. The search step uses a search agent and search function to find the most relevant information. The second step uses a podcast generation agent and generation function to create a podcast on the topic found.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a two-step workflow. The first step involves a search agent and function to gather information from the internet. The second step uses a podcast generation agent and function to create a podcast based on the gathered information.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🛍️ Shopping and Product Analysis Agents&lt;/h3&gt; 
&lt;ol start=&quot;36&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ShopGenie.ipynb&quot;&gt;ShopGenie - Redefining Online Shopping Customer Experience&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An AI-powered shopping assistant that helps customers make informed purchasing decisions even without domain expertise. The system analyzes product information from multiple sources, compares specifications and reviews, identifies the best option based on user needs, and delivers recommendations through email with supporting video reviews, creating a comprehensive shopping experience.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Uses LangGraph to orchestrate a workflow combining Tavily for web search, Llama-3.1-70B for structured data analysis and product comparison, and YouTube API for review video retrieval. The system processes search results through multiple nodes including schema mapping, product comparison, review identification, and email generation. Key features include structured Pydantic models for consistent data handling, retry mechanisms for robust API interactions, and email delivery through SMTP for sharing recommendations.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Js0sK0u53dQ&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/car_buyer_agent_langgraph.ipynb&quot;&gt;Car Buyer AI Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;The Smart Product Buyer AI Agent demonstrates how to build an intelligent system that assists users in making informed purchasing decisions. Using LangGraph and LLM-based intelligence, the system processes user requirements, scrapes product listings from websites like AutoTrader, and provides detailed analysis and recommendations for car purchases.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Implements a state-based workflow using LangGraph to coordinate user interaction, web scraping, and decision support. The system features TypedDict state management, async web scraping with Playwright, and integrates with external APIs for comprehensive product analysis. The implementation includes a Gradio interface for real-time chat interaction and modular scraper architecture for easy extension to additional product categories.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=I61I1fp0qys&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🎯 Task Management and Productivity Agents&lt;/h3&gt; 
&lt;ol start=&quot;38&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/taskifier.ipynb&quot;&gt;Taskifier - Intelligent Task Allocation &amp;amp; Management&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An intelligent task management system that analyzes user work styles and creates personalized task breakdown strategies, born from the observation that procrastination often stems from task ambiguity among students and early-career professionals. The system evaluates historical work patterns, gathers relevant task information through web search, and generates customized step-by-step approaches to optimize productivity and reduce workflow paralysis.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Leverages LangGraph for orchestrating a multi-step workflow including work style analysis, information gathering via Tavily API, and customized plan generation. The system maintains state through the process, integrating historical work pattern data with fresh task research to output detailed, personalized task execution plans aligned with the user&#39;s natural working style.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=1W_p_RVi9KE&amp;amp;t=25s&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/grocery_management_agents_system.ipynb&quot;&gt;Grocery Management Agents System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A multi-agent system built with CrewAI that automates grocery management tasks including receipt interpretation, expiration date tracking, inventory management, and recipe recommendations. The system uses specialized agents to extract data from receipts, estimate product shelf life, track consumption, and suggest recipes to minimize food waste.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Implements four specialized agents using CrewAI - a Receipt Interpreter that extracts item details from receipts, an Expiration Date Estimator that determines shelf life using online sources, a Grocery Tracker that maintains inventory based on consumption, and a Recipe Recommender that suggests meals using available ingredients. Each agent has specific tools and tasks orchestrated through a crew workflow.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=FlMu5pKSaHI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🔍 Quality Assurance and Testing Agents&lt;/h3&gt; 
&lt;ol start=&quot;40&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/graph_inspector_system_langgraph.ipynb&quot;&gt;LangGraph-Based Systems Inspector&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A comprehensive testing and validation tool for LangGraph-based applications that automatically analyzes system architecture, generates test cases, and identifies potential vulnerabilities through multi-agent inspection. The inspector employs specialized AI testers to evaluate different aspects of the system, from basic functionality to security concerns and edge cases.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Integrates LangGraph for workflow orchestration, multiple LLM-powered testing agents, and a structured evaluation pipeline that includes static analysis, test case generation, and results verification. The system uses Pydantic for data validation, NetworkX for graph representation, and implements a modular architecture that allows for parallel test execution and comprehensive result analysis.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=fQd6lXc-Y9A&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/langgraph-systems-inspector-an-ai?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/EU_Green_Compliance_FAQ_Bot.ipynb&quot;&gt;EU Green Deal FAQ Bot&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;The EU Green Deal FAQ Bot demonstrates how to build a RAG-based AI agent that helps businesses understand EU green deal policies. The system processes complex regulatory documents into manageable chunks and provides instant, accurate answers to common questions about environmental compliance, emissions reporting, and waste management requirements.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Implements a sophisticated RAG pipeline using FAISS vectorstore for document storage, semantic chunking for preprocessing, and multiple specialized agents (Retriever, Summarizer, Evaluator) for query processing. The system features query rephrasing for improved accuracy, cross-reference with gold Q&amp;amp;A datasets for answer validation, and comprehensive evaluation metrics to ensure response quality and relevance.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Av0kBQjwU-Y&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/systematic_review_of_scientific_articles.ipynb&quot;&gt;Systematic Review Automation System + Paper Draft Creation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;A comprehensive system for automating academic systematic reviews using a directed graph architecture and LangChain components. The system generates complete, publication-ready systematic review papers, automatically processing everything from literature search through final draft generation with multiple revision cycles.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;Utilizes a state-based graph workflow that handles paper search and selection (up to 3 papers), PDF processing, and generates a complete academic paper with all standard sections (abstract, introduction, methods, results, conclusions, references). The system incorporates multiple revision cycles with automated critique and improvement phases, all orchestrated through LangGraph state management.&lt;/p&gt; &lt;h4&gt;Additional Resources 📚&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qi35mGGkCtg&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🌟 Special Advanced Technique 🌟&lt;/h3&gt; 
&lt;ol start=&quot;43&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/Controllable-RAG-Agent&quot;&gt;Sophisticated Controllable Agent for Complex RAG Tasks 🤖&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview 🔎&lt;/h4&gt; &lt;p&gt;An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the &quot;brain&quot; 🧠 of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.&lt;/p&gt; &lt;h4&gt;Implementation 🛠️&lt;/h4&gt; &lt;p&gt;• Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To begin exploring and building GenAI agents:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repository: &lt;pre&gt;&lt;code&gt;git clone https://github.com/NirDiamant/GenAI_Agents.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to the technique you&#39;re interested in: &lt;pre&gt;&lt;code&gt;cd all_agents_tutorials/technique-name
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Follow the detailed implementation guide in each technique&#39;s notebook.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! If you have a new technique or improvement to suggest:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create your feature branch: &lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Commit your changes: &lt;code&gt;git commit -m &#39;Add some AmazingFeature&#39;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Push to the branch: &lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Open a pull request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/graphs/contributors&quot;&gt;&lt;img src=&quot;https://contrib.rocks/image?repo=NirDiamant/GenAI_Agents&quot; alt=&quot;Contributors&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under a custom non-commercial license - see the &lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;⭐️ If you find this repository helpful, please consider giving it a star!&lt;/p&gt; 
&lt;p&gt;Keywords: GenAI, Generative AI, Agents, NLP, AI, Machine Learning, Natural Language Processing, LLM, Conversational AI, Task-Oriented AI&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/ai-agents-for-beginners</title>
      <link>https://github.com/microsoft/ai-agents-for-beginners</link>
      <description>&lt;p&gt;10 Lessons to Get Started Building AI Agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Agents for Beginners - A Course&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/images/repo-thumbnail.png&quot; alt=&quot;Generative AI For Beginners&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;10 Lessons teaching everything you need to know to start building AI Agents&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners/raw/master/LICENSE?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/microsoft/ai-agents-for-beginners.svg?sanitize=true&quot; alt=&quot;GitHub license&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/graphs/contributors/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/microsoft/ai-agents-for-beginners.svg?sanitize=true&quot; alt=&quot;GitHub contributors&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/issues/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/microsoft/ai-agents-for-beginners.svg?sanitize=true&quot; alt=&quot;GitHub issues&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/pulls/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr/microsoft/ai-agents-for-beginners.svg?sanitize=true&quot; alt=&quot;GitHub pull-requests&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://makeapullrequest.com?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/watchers/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/watchers/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Watch&quot; alt=&quot;GitHub watchers&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/network/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Fork&quot; alt=&quot;GitHub forks&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/stargazers/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Star&quot; alt=&quot;GitHub stars&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://discord.gg/kzRShWzttr&quot;&gt;&lt;img src=&quot;https://dcbadge.limes.pink/api/server/kzRShWzttr&quot; alt=&quot;Azure AI Discord&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🌱 Getting Started&lt;/h2&gt; 
&lt;p&gt;This course has 10 lessons covering the fundamentals of building AI Agents. Each lesson covers its own topic so start wherever you like!&lt;/p&gt; 
&lt;p&gt;There is multi-language support for this course. Go to our &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/#-multi-language-support&quot;&gt;available languages here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If this is your first time building with Generative AI models, check out our &lt;a href=&quot;https://aka.ms/genai-beginners&quot;&gt;Generative AI For Beginners&lt;/a&gt; course, which includes 21 lessons on building with GenAI.&lt;/p&gt; 
&lt;p&gt;Don&#39;t forget to &lt;a href=&quot;https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst&quot;&gt;star (🌟) this repo&lt;/a&gt; and &lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners/fork&quot;&gt;fork this repo&lt;/a&gt; to run the code.&lt;/p&gt; 
&lt;h3&gt;What You Need&lt;/h3&gt; 
&lt;p&gt;Each lesson in this course includes code examples, which can be found in the code_samples folder. You can &lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners/fork&quot;&gt;fork this repo&lt;/a&gt; to create your own copy.&lt;/p&gt; 
&lt;p&gt;The code example in these exercises, utilize Azure AI Foundry and GitHub Model Catalogs for interacting with Language Models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/github-models&quot;&gt;Github Models&lt;/a&gt; - Free / Limited&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/ai-foundry&quot;&gt;Azure AI Foundry&lt;/a&gt; - Azure Account Required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This course also uses the following AI Agent frameworks and services from Microsoft:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/ai-agent-service&quot;&gt;Azure AI Agent Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/semantic-kernel&quot;&gt;Semantic Kernel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-agents/autogen&quot;&gt;AutoGen&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information on running the code for this course, go to the &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/00-course-setup/README.md&quot;&gt;Course Setup&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🙏 Want to help?&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? &lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners/issues?WT.mc_id=academic-105485-koreyst&quot;&gt;Raise an issue&lt;/a&gt; or &lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners/pulls?WT.mc_id=academic-105485-koreyst&quot;&gt;Create a pull request&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you get stuck or have any questions about building AI Agents, join our &lt;a href=&quot;https://discord.gg/kzRShWzttr&quot;&gt;Azure AI Community Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;📂 Each lesson includes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A written lesson located in the README (Videos Coming March 2025)&lt;/li&gt; 
 &lt;li&gt;Python code samples supporting Azure AI Foundry and Github Models (Free)&lt;/li&gt; 
 &lt;li&gt;Links to extra resources to continue your learning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🗃️ Lessons&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Lesson&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Link&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Intro to AI Agents and Use Cases&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/01-intro-to-ai-agents/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Exploring Agentic Frameworks&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/02-explore-agentic-frameworks/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Understanding Agentic Design Patterns&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/03-agentic-design-patterns/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tool Use Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/04-tool-use/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agentic RAG&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/05-agentic-rag/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Building Trustworthy AI Agents&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/06-building-trustworthy-agents/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Planning Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/07-planning-design/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multi-Agent Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/08-multi-agent/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Metacognition Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/09-metacognition/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AI Agents in Production&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/10-ai-agents-production/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🌐 Multi-Language Support&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Code&lt;/th&gt; 
   &lt;th&gt;Link to Translated README&lt;/th&gt; 
   &lt;th&gt;Last Updated&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chinese (Simplified)&lt;/td&gt; 
   &lt;td&gt;zh&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/zh/README.md&quot;&gt;Chinese Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2025-02-13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chinese (Traditional)&lt;/td&gt; 
   &lt;td&gt;tw&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/tw/README.md&quot;&gt;Chinese Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2025-02-13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chinese (Hong Kong)&lt;/td&gt; 
   &lt;td&gt;hk&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hk/README.md&quot;&gt;Chinese (Hong Kong) Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2025-02-13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;French&lt;/td&gt; 
   &lt;td&gt;fr&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/fr/README.md&quot;&gt;French Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2025-02-13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Japanese&lt;/td&gt; 
   &lt;td&gt;ja&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ja/README.md&quot;&gt;Japanese Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2025-02-13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Korean&lt;/td&gt; 
   &lt;td&gt;ko&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ko/README.md&quot;&gt;Korean Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2025-02-13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portuguese&lt;/td&gt; 
   &lt;td&gt;pt&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/pt/README.md&quot;&gt;Portuguese Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2025-02-13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Spanish&lt;/td&gt; 
   &lt;td&gt;es&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/es/README.md&quot;&gt;Spanish Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2025-02-13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;German&lt;/td&gt; 
   &lt;td&gt;de&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/de/README.md&quot;&gt;German Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2025-02-13&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🎒 Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;strong&gt;NEW&lt;/strong&gt; Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung&quot;&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst&quot;&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst&quot;&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst&quot;&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🌟 Community Thanks&lt;/h2&gt; 
&lt;p&gt;Thanks to &lt;a href=&quot;https://www.linkedin.com/in/shivam2003/&quot;&gt;Shivam Goyal&lt;/a&gt; for contributing important code samples demonstrating Agentic RAG.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&quot;https://cla.opensource.microsoft.com&quot;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href=&quot;https://opensource.microsoft.com/codeofconduct/&quot;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&quot;https://opensource.microsoft.com/codeofconduct/faq/&quot;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&quot;mailto:opencode@microsoft.com&quot;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&quot;https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general&quot;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos is subject to those third-parties&#39; policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>CompVis/latent-diffusion</title>
      <link>https://github.com/CompVis/latent-diffusion</link>
      <description>&lt;p&gt;High-Resolution Image Synthesis with Latent Diffusion Models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Latent Diffusion Models&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2112.10752&quot;&gt;arXiv&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/#bibtex&quot;&gt;BibTeX&lt;/a&gt;&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/assets/results.gif&quot;&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2112.10752&quot;&gt;&lt;strong&gt;High-Resolution Image Synthesis with Latent Diffusion Models&lt;/strong&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&quot;https://github.com/rromb&quot;&gt;Robin Rombach&lt;/a&gt;*, &lt;a href=&quot;https://github.com/ablattmann&quot;&gt;Andreas Blattmann&lt;/a&gt;*, &lt;a href=&quot;https://github.com/qp-qp&quot;&gt;Dominik Lorenz&lt;/a&gt;, &lt;a href=&quot;https://github.com/pesser&quot;&gt;Patrick Esser&lt;/a&gt;, &lt;a href=&quot;https://hci.iwr.uni-heidelberg.de/Staff/bommer&quot;&gt;Björn Ommer&lt;/a&gt;&lt;br&gt; * equal contribution&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/assets/modelfigure.png&quot;&gt; &lt;/p&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;h3&gt;July 2022&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Inference code and model weights to run our &lt;a href=&quot;https://arxiv.org/abs/2204.11824&quot;&gt;retrieval-augmented diffusion models&lt;/a&gt; are now available. See &lt;a href=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/#retrieval-augmented-diffusion-models&quot;&gt;this section&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;April 2022&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Thanks to &lt;a href=&quot;https://github.com/crowsonkb&quot;&gt;Katherine Crowson&lt;/a&gt;, classifier-free guidance received a ~2x speedup and the &lt;a href=&quot;https://arxiv.org/abs/2202.09778&quot;&gt;PLMS sampler&lt;/a&gt; is available. See also &lt;a href=&quot;https://github.com/CompVis/latent-diffusion/pull/51&quot;&gt;this PR&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Our 1.45B &lt;a href=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/#text-to-image&quot;&gt;latent diffusion LAION model&lt;/a&gt; was integrated into &lt;a href=&quot;https://huggingface.co/spaces&quot;&gt;Huggingface Spaces 🤗&lt;/a&gt; using &lt;a href=&quot;https://github.com/gradio-app/gradio&quot;&gt;Gradio&lt;/a&gt;. Try out the Web Demo: &lt;a href=&quot;https://huggingface.co/spaces/multimodalart/latentdiffusion&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&quot; alt=&quot;Hugging Face Spaces&quot;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;More pre-trained LDMs are available:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;A 1.45B &lt;a href=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/#text-to-image&quot;&gt;model&lt;/a&gt; trained on the &lt;a href=&quot;https://arxiv.org/abs/2111.02114&quot;&gt;LAION-400M&lt;/a&gt; database.&lt;/li&gt; 
   &lt;li&gt;A class-conditional model on ImageNet, achieving a FID of 3.6 when using &lt;a href=&quot;https://openreview.net/pdf?id=qw8AKxfYbI&quot;&gt;classifier-free guidance&lt;/a&gt; Available via a &lt;a href=&quot;https://colab.research.google.com/github/CompVis/latent-diffusion/blob/main/scripts/latent_imagenet_diffusion.ipynb&quot;&gt;colab notebook&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/CompVis/latent-diffusion/blob/main/scripts/latent_imagenet_diffusion.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;&quot;&gt;&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;A suitable &lt;a href=&quot;https://conda.io/&quot;&gt;conda&lt;/a&gt; environment named &lt;code&gt;ldm&lt;/code&gt; can be created and activated with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;conda env create -f environment.yaml
conda activate ldm
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Pretrained Models&lt;/h1&gt; 
&lt;p&gt;A general list of all available checkpoints is available in via our &lt;a href=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/#model-zoo&quot;&gt;model zoo&lt;/a&gt;. If you use any of these models in your work, we are always happy to receive a &lt;a href=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/#bibtex&quot;&gt;citation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Retrieval Augmented Diffusion Models&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/assets/rdm-preview.jpg&quot; alt=&quot;rdm-figure&quot;&gt; We include inference code to run our retrieval-augmented diffusion models (RDMs) as described in &lt;a href=&quot;https://arxiv.org/abs/2204.11824&quot;&gt;https://arxiv.org/abs/2204.11824&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get started, install the additionally required python packages into your &lt;code&gt;ldm&lt;/code&gt; environment&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install transformers==4.19.2 scann kornia==0.6.4 torchmetrics==0.6.0
pip install git+https://github.com/arogozhnikov/einops.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and download the trained weights (preliminary ceckpoints):&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;mkdir -p models/rdm/rdm768x768/
wget -O models/rdm/rdm768x768/model.ckpt https://ommer-lab.com/files/rdm/model.ckpt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As these models are conditioned on a set of CLIP image embeddings, our RDMs support different inference modes, which are described in the following.&lt;/p&gt; 
&lt;h4&gt;RDM with text-prompt only (no explicit retrieval needed)&lt;/h4&gt; 
&lt;p&gt;Since CLIP offers a shared image/text feature space, and RDMs learn to cover a neighborhood of a given example during training, we can directly take a CLIP text embedding of a given prompt and condition on it. Run this mode via&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python scripts/knn2img.py  --prompt &quot;a happy bear reading a newspaper, oil on canvas&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;RDM with text-to-image retrieval&lt;/h4&gt; 
&lt;p&gt;To be able to run a RDM conditioned on a text-prompt and additionally images retrieved from this prompt, you will also need to download the corresponding retrieval database. We provide two distinct databases extracted from the &lt;a href=&quot;https://storage.googleapis.com/openimages/web/index.html&quot;&gt;Openimages-&lt;/a&gt; and &lt;a href=&quot;https://github.com/liaopeiyuan/artbench&quot;&gt;ArtBench-&lt;/a&gt; datasets. Interchanging the databases results in different capabilities of the model as visualized below, although the learned weights are the same in both cases.&lt;/p&gt; 
&lt;p&gt;Download the retrieval-databases which contain the retrieval-datasets (&lt;a href=&quot;https://storage.googleapis.com/openimages/web/index.html&quot;&gt;Openimages&lt;/a&gt; (~11GB) and &lt;a href=&quot;https://github.com/liaopeiyuan/artbench&quot;&gt;ArtBench&lt;/a&gt; (~82MB)) compressed into CLIP image embeddings:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;mkdir -p data/rdm/retrieval_databases
wget -O data/rdm/retrieval_databases/artbench.zip https://ommer-lab.com/files/rdm/artbench_databases.zip
wget -O data/rdm/retrieval_databases/openimages.zip https://ommer-lab.com/files/rdm/openimages_database.zip
unzip data/rdm/retrieval_databases/artbench.zip -d data/rdm/retrieval_databases/
unzip data/rdm/retrieval_databases/openimages.zip -d data/rdm/retrieval_databases/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We also provide trained &lt;a href=&quot;https://github.com/google-research/google-research/tree/master/scann&quot;&gt;ScaNN&lt;/a&gt; search indices for ArtBench. Download and extract via&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;mkdir -p data/rdm/searchers
wget -O data/rdm/searchers/artbench.zip https://ommer-lab.com/files/rdm/artbench_searchers.zip
unzip data/rdm/searchers/artbench.zip -d data/rdm/searchers
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since the index for OpenImages is large (~21 GB), we provide a script to create and save it for usage during sampling. Note however, that sampling with the OpenImages database will not be possible without this index. Run the script via&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python scripts/train_searcher.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Retrieval based text-guided sampling with visual nearest neighbors can be started via&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python scripts/knn2img.py  --prompt &quot;a happy pineapple&quot; --use_neighbors --knn &amp;lt;number_of_neighbors&amp;gt; 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the maximum supported number of neighbors is 20. The database can be changed via the cmd parameter &lt;code&gt;--database&lt;/code&gt; which can be &lt;code&gt;[openimages, artbench-art_nouveau, artbench-baroque, artbench-expressionism, artbench-impressionism, artbench-post_impressionism, artbench-realism, artbench-renaissance, artbench-romanticism, artbench-surrealism, artbench-ukiyo_e]&lt;/code&gt;. For using &lt;code&gt;--database openimages&lt;/code&gt;, the above script (&lt;code&gt;scripts/train_searcher.py&lt;/code&gt;) must be executed before. Due to their relatively small size, the artbench datasetbases are best suited for creating more abstract concepts and do not work well for detailed text control.&lt;/p&gt; 
&lt;h4&gt;Coming Soon&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;better models&lt;/li&gt; 
 &lt;li&gt;more resolutions&lt;/li&gt; 
 &lt;li&gt;image-to-image retrieval&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Text-to-Image&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/assets/txt2img-preview.png&quot; alt=&quot;text2img-figure&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Download the pre-trained weights (5.7GB)&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mkdir -p models/ldm/text2img-large/
wget -O models/ldm/text2img-large/model.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and sample with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python scripts/txt2img.py --prompt &quot;a virus monster is playing guitar, oil on canvas&quot; --ddim_eta 0.0 --n_samples 4 --n_iter 4 --scale 5.0  --ddim_steps 50
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will save each sample individually as well as a grid of size &lt;code&gt;n_iter&lt;/code&gt; x &lt;code&gt;n_samples&lt;/code&gt; at the specified output location (default: &lt;code&gt;outputs/txt2img-samples&lt;/code&gt;). Quality, sampling speed and diversity are best controlled via the &lt;code&gt;scale&lt;/code&gt;, &lt;code&gt;ddim_steps&lt;/code&gt; and &lt;code&gt;ddim_eta&lt;/code&gt; arguments. As a rule of thumb, higher values of &lt;code&gt;scale&lt;/code&gt; produce better samples at the cost of a reduced output diversity.&lt;br&gt; Furthermore, increasing &lt;code&gt;ddim_steps&lt;/code&gt; generally also gives higher quality samples, but returns are diminishing for values &amp;gt; 250. Fast sampling (i.e. low values of &lt;code&gt;ddim_steps&lt;/code&gt;) while retaining good quality can be achieved by using &lt;code&gt;--ddim_eta 0.0&lt;/code&gt;.&lt;br&gt; Faster sampling (i.e. even lower values of &lt;code&gt;ddim_steps&lt;/code&gt;) while retaining good quality can be achieved by using &lt;code&gt;--ddim_eta 0.0&lt;/code&gt; and &lt;code&gt;--plms&lt;/code&gt; (see &lt;a href=&quot;https://arxiv.org/abs/2202.09778&quot;&gt;Pseudo Numerical Methods for Diffusion Models on Manifolds&lt;/a&gt;).&lt;/p&gt; 
&lt;h4&gt;Beyond 256²&lt;/h4&gt; 
&lt;p&gt;For certain inputs, simply running the model in a convolutional fashion on larger features than it was trained on can sometimes result in interesting results. To try it out, tune the &lt;code&gt;H&lt;/code&gt; and &lt;code&gt;W&lt;/code&gt; arguments (which will be integer-divided by 8 in order to calculate the corresponding latent size), e.g. run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python scripts/txt2img.py --prompt &quot;a sunset behind a mountain range, vector image&quot; --ddim_eta 1.0 --n_samples 1 --n_iter 1 --H 384 --W 1024 --scale 5.0  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;to create a sample of size 384x1024. Note, however, that controllability is reduced compared to the 256x256 setting.&lt;/p&gt; 
&lt;p&gt;The example below was generated using the above command. &lt;img src=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/assets/txt2img-convsample.png&quot; alt=&quot;text2img-figure-conv&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Inpainting&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/assets/inpainting.png&quot; alt=&quot;inpainting&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Download the pre-trained weights&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;wget -O models/ldm/inpainting_big/last.ckpt https://heibox.uni-heidelberg.de/f/4d9ac7ea40c64582b7c9/?dl=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and sample with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python scripts/inpaint.py --indir data/inpainting_examples/ --outdir outputs/inpainting_results
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;indir&lt;/code&gt; should contain images &lt;code&gt;*.png&lt;/code&gt; and masks &lt;code&gt;&amp;lt;image_fname&amp;gt;_mask.png&lt;/code&gt; like the examples provided in &lt;code&gt;data/inpainting_examples&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Class-Conditional ImageNet&lt;/h2&gt; 
&lt;p&gt;Available via a &lt;a href=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/scripts/latent_imagenet_diffusion.ipynb&quot;&gt;notebook&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/CompVis/latent-diffusion/blob/main/scripts/latent_imagenet_diffusion.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;&quot;&gt;&lt;/a&gt;. &lt;img src=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/assets/birdhouse.png&quot; alt=&quot;class-conditional&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Unconditional Models&lt;/h2&gt; 
&lt;p&gt;We also provide a script for sampling from unconditional LDMs (e.g. LSUN, FFHQ, ...). Start it via&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;CUDA_VISIBLE_DEVICES=&amp;lt;GPU_ID&amp;gt; python scripts/sample_diffusion.py -r models/ldm/&amp;lt;model_spec&amp;gt;/model.ckpt -l &amp;lt;logdir&amp;gt; -n &amp;lt;\#samples&amp;gt; --batch_size &amp;lt;batch_size&amp;gt; -c &amp;lt;\#ddim steps&amp;gt; -e &amp;lt;\#eta&amp;gt; 
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Train your own LDMs&lt;/h1&gt; 
&lt;h2&gt;Data preparation&lt;/h2&gt; 
&lt;h3&gt;Faces&lt;/h3&gt; 
&lt;p&gt;For downloading the CelebA-HQ and FFHQ datasets, proceed as described in the &lt;a href=&quot;https://github.com/CompVis/taming-transformers#celeba-hq&quot;&gt;taming-transformers&lt;/a&gt; repository.&lt;/p&gt; 
&lt;h3&gt;LSUN&lt;/h3&gt; 
&lt;p&gt;The LSUN datasets can be conveniently downloaded via the script available &lt;a href=&quot;https://github.com/fyu/lsun&quot;&gt;here&lt;/a&gt;. We performed a custom split into training and validation images, and provide the corresponding filenames at &lt;a href=&quot;https://ommer-lab.com/files/lsun.zip&quot;&gt;https://ommer-lab.com/files/lsun.zip&lt;/a&gt;. After downloading, extract them to &lt;code&gt;./data/lsun&lt;/code&gt;. The beds/cats/churches subsets should also be placed/symlinked at &lt;code&gt;./data/lsun/bedrooms&lt;/code&gt;/&lt;code&gt;./data/lsun/cats&lt;/code&gt;/&lt;code&gt;./data/lsun/churches&lt;/code&gt;, respectively.&lt;/p&gt; 
&lt;h3&gt;ImageNet&lt;/h3&gt; 
&lt;p&gt;The code will try to download (through &lt;a href=&quot;http://academictorrents.com/&quot;&gt;Academic Torrents&lt;/a&gt;) and prepare ImageNet the first time it is used. However, since ImageNet is quite large, this requires a lot of disk space and time. If you already have ImageNet on your disk, you can speed things up by putting the data into &lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/&lt;/code&gt; (which defaults to &lt;code&gt;~/.cache/autoencoders/data/ILSVRC2012_{split}/data/&lt;/code&gt;), where &lt;code&gt;{split}&lt;/code&gt; is one of &lt;code&gt;train&lt;/code&gt;/&lt;code&gt;validation&lt;/code&gt;. It should have the following structure:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/
├── n01440764
│   ├── n01440764_10026.JPEG
│   ├── n01440764_10027.JPEG
│   ├── ...
├── n01443537
│   ├── n01443537_10007.JPEG
│   ├── n01443537_10014.JPEG
│   ├── ...
├── ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you haven&#39;t extracted the data, you can also place &lt;code&gt;ILSVRC2012_img_train.tar&lt;/code&gt;/&lt;code&gt;ILSVRC2012_img_val.tar&lt;/code&gt; (or symlinks to them) into &lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_train/&lt;/code&gt; / &lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_validation/&lt;/code&gt;, which will then be extracted into above structure without downloading it again. Note that this will only happen if neither a folder &lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/data/&lt;/code&gt; nor a file &lt;code&gt;${XDG_CACHE}/autoencoders/data/ILSVRC2012_{split}/.ready&lt;/code&gt; exist. Remove them if you want to force running the dataset preparation again.&lt;/p&gt; 
&lt;h2&gt;Model Training&lt;/h2&gt; 
&lt;p&gt;Logs and checkpoints for trained models are saved to &lt;code&gt;logs/&amp;lt;START_DATE_AND_TIME&amp;gt;_&amp;lt;config_spec&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Training autoencoder models&lt;/h3&gt; 
&lt;p&gt;Configs for training a KL-regularized autoencoder on ImageNet are provided at &lt;code&gt;configs/autoencoder&lt;/code&gt;. Training can be started by running&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=&amp;lt;GPU_ID&amp;gt; python main.py --base configs/autoencoder/&amp;lt;config_spec&amp;gt;.yaml -t --gpus 0,    
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where &lt;code&gt;config_spec&lt;/code&gt; is one of {&lt;code&gt;autoencoder_kl_8x8x64&lt;/code&gt;(f=32, d=64), &lt;code&gt;autoencoder_kl_16x16x16&lt;/code&gt;(f=16, d=16), &lt;code&gt;autoencoder_kl_32x32x4&lt;/code&gt;(f=8, d=4), &lt;code&gt;autoencoder_kl_64x64x3&lt;/code&gt;(f=4, d=3)}.&lt;/p&gt; 
&lt;p&gt;For training VQ-regularized models, see the &lt;a href=&quot;https://github.com/CompVis/taming-transformers&quot;&gt;taming-transformers&lt;/a&gt; repository.&lt;/p&gt; 
&lt;h3&gt;Training LDMs&lt;/h3&gt; 
&lt;p&gt;In &lt;code&gt;configs/latent-diffusion/&lt;/code&gt; we provide configs for training LDMs on the LSUN-, CelebA-HQ, FFHQ and ImageNet datasets. Training can be started by running&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;CUDA_VISIBLE_DEVICES=&amp;lt;GPU_ID&amp;gt; python main.py --base configs/latent-diffusion/&amp;lt;config_spec&amp;gt;.yaml -t --gpus 0,
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where &lt;code&gt;&amp;lt;config_spec&amp;gt;&lt;/code&gt; is one of {&lt;code&gt;celebahq-ldm-vq-4&lt;/code&gt;(f=4, VQ-reg. autoencoder, spatial size 64x64x3),&lt;code&gt;ffhq-ldm-vq-4&lt;/code&gt;(f=4, VQ-reg. autoencoder, spatial size 64x64x3), &lt;code&gt;lsun_bedrooms-ldm-vq-4&lt;/code&gt;(f=4, VQ-reg. autoencoder, spatial size 64x64x3), &lt;code&gt;lsun_churches-ldm-vq-4&lt;/code&gt;(f=8, KL-reg. autoencoder, spatial size 32x32x4),&lt;code&gt;cin-ldm-vq-8&lt;/code&gt;(f=8, VQ-reg. autoencoder, spatial size 32x32x4)}.&lt;/p&gt; 
&lt;h1&gt;Model Zoo&lt;/h1&gt; 
&lt;h2&gt;Pretrained Autoencoding Models&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/assets/reconstruction2.png&quot; alt=&quot;rec2&quot;&gt;&lt;/p&gt; 
&lt;p&gt;All models were trained until convergence (no further substantial improvement in rFID).&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;rFID vs val&lt;/th&gt; 
   &lt;th&gt;train steps&lt;/th&gt; 
   &lt;th&gt;PSNR&lt;/th&gt; 
   &lt;th&gt;PSIM&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
   &lt;th&gt;Comments&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;f=4, VQ (Z=8192, d=3)&lt;/td&gt; 
   &lt;td&gt;0.58&lt;/td&gt; 
   &lt;td&gt;533066&lt;/td&gt; 
   &lt;td&gt;27.43 +/- 4.26&lt;/td&gt; 
   &lt;td&gt;0.53 +/- 0.21&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/vq-f4.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/vq-f4.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;f=4, VQ (Z=8192, d=3)&lt;/td&gt; 
   &lt;td&gt;1.06&lt;/td&gt; 
   &lt;td&gt;658131&lt;/td&gt; 
   &lt;td&gt;25.21 +/- 4.17&lt;/td&gt; 
   &lt;td&gt;0.72 +/- 0.26&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://heibox.uni-heidelberg.de/f/9c6681f64bb94338a069/?dl=1&quot;&gt;https://heibox.uni-heidelberg.de/f/9c6681f64bb94338a069/?dl=1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;no attention&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;f=8, VQ (Z=16384, d=4)&lt;/td&gt; 
   &lt;td&gt;1.14&lt;/td&gt; 
   &lt;td&gt;971043&lt;/td&gt; 
   &lt;td&gt;23.07 +/- 3.99&lt;/td&gt; 
   &lt;td&gt;1.17 +/- 0.36&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/vq-f8.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/vq-f8.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;f=8, VQ (Z=256, d=4)&lt;/td&gt; 
   &lt;td&gt;1.49&lt;/td&gt; 
   &lt;td&gt;1608649&lt;/td&gt; 
   &lt;td&gt;22.35 +/- 3.81&lt;/td&gt; 
   &lt;td&gt;1.26 +/- 0.37&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/vq-f8-n256.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/vq-f8-n256.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;f=16, VQ (Z=16384, d=8)&lt;/td&gt; 
   &lt;td&gt;5.15&lt;/td&gt; 
   &lt;td&gt;1101166&lt;/td&gt; 
   &lt;td&gt;20.83 +/- 3.61&lt;/td&gt; 
   &lt;td&gt;1.73 +/- 0.43&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://heibox.uni-heidelberg.de/f/0e42b04e2e904890a9b6/?dl=1&quot;&gt;https://heibox.uni-heidelberg.de/f/0e42b04e2e904890a9b6/?dl=1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;f=4, KL&lt;/td&gt; 
   &lt;td&gt;0.27&lt;/td&gt; 
   &lt;td&gt;176991&lt;/td&gt; 
   &lt;td&gt;27.53 +/- 4.54&lt;/td&gt; 
   &lt;td&gt;0.55 +/- 0.24&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/kl-f4.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/kl-f4.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;f=8, KL&lt;/td&gt; 
   &lt;td&gt;0.90&lt;/td&gt; 
   &lt;td&gt;246803&lt;/td&gt; 
   &lt;td&gt;24.19 +/- 4.19&lt;/td&gt; 
   &lt;td&gt;1.02 +/- 0.35&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/kl-f8.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/kl-f8.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;f=16, KL (d=16)&lt;/td&gt; 
   &lt;td&gt;0.87&lt;/td&gt; 
   &lt;td&gt;442998&lt;/td&gt; 
   &lt;td&gt;24.08 +/- 4.22&lt;/td&gt; 
   &lt;td&gt;1.07 +/- 0.36&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/kl-f16.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/kl-f16.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;f=32, KL (d=64)&lt;/td&gt; 
   &lt;td&gt;2.04&lt;/td&gt; 
   &lt;td&gt;406763&lt;/td&gt; 
   &lt;td&gt;22.27 +/- 3.93&lt;/td&gt; 
   &lt;td&gt;1.41 +/- 0.40&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/kl-f32.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/kl-f32.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Get the models&lt;/h3&gt; 
&lt;p&gt;Running the following script downloads und extracts all available pretrained autoencoding models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;bash scripts/download_first_stages.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The first stage models can then be found in &lt;code&gt;models/first_stage_models/&amp;lt;model_spec&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Pretrained LDMs&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Datset&lt;/th&gt; 
   &lt;th&gt;Task&lt;/th&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;FID&lt;/th&gt; 
   &lt;th&gt;IS&lt;/th&gt; 
   &lt;th&gt;Prec&lt;/th&gt; 
   &lt;th&gt;Recall&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
   &lt;th&gt;Comments&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CelebA-HQ&lt;/td&gt; 
   &lt;td&gt;Unconditional Image Synthesis&lt;/td&gt; 
   &lt;td&gt;LDM-VQ-4 (200 DDIM steps, eta=0)&lt;/td&gt; 
   &lt;td&gt;5.11 (5.11)&lt;/td&gt; 
   &lt;td&gt;3.29&lt;/td&gt; 
   &lt;td&gt;0.72&lt;/td&gt; 
   &lt;td&gt;0.49&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/celeba.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/celeba.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FFHQ&lt;/td&gt; 
   &lt;td&gt;Unconditional Image Synthesis&lt;/td&gt; 
   &lt;td&gt;LDM-VQ-4 (200 DDIM steps, eta=1)&lt;/td&gt; 
   &lt;td&gt;4.98 (4.98)&lt;/td&gt; 
   &lt;td&gt;4.50 (4.50)&lt;/td&gt; 
   &lt;td&gt;0.73&lt;/td&gt; 
   &lt;td&gt;0.50&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/ffhq.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/ffhq.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LSUN-Churches&lt;/td&gt; 
   &lt;td&gt;Unconditional Image Synthesis&lt;/td&gt; 
   &lt;td&gt;LDM-KL-8 (400 DDIM steps, eta=0)&lt;/td&gt; 
   &lt;td&gt;4.02 (4.02)&lt;/td&gt; 
   &lt;td&gt;2.72&lt;/td&gt; 
   &lt;td&gt;0.64&lt;/td&gt; 
   &lt;td&gt;0.52&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/lsun_churches.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/lsun_churches.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LSUN-Bedrooms&lt;/td&gt; 
   &lt;td&gt;Unconditional Image Synthesis&lt;/td&gt; 
   &lt;td&gt;LDM-VQ-4 (200 DDIM steps, eta=1)&lt;/td&gt; 
   &lt;td&gt;2.95 (3.0)&lt;/td&gt; 
   &lt;td&gt;2.22 (2.23)&lt;/td&gt; 
   &lt;td&gt;0.66&lt;/td&gt; 
   &lt;td&gt;0.48&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/lsun_bedrooms.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/lsun_bedrooms.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ImageNet&lt;/td&gt; 
   &lt;td&gt;Class-conditional Image Synthesis&lt;/td&gt; 
   &lt;td&gt;LDM-VQ-8 (200 DDIM steps, eta=1)&lt;/td&gt; 
   &lt;td&gt;7.77(7.76)* /15.82**&lt;/td&gt; 
   &lt;td&gt;201.56(209.52)* /78.82**&lt;/td&gt; 
   &lt;td&gt;0.84* / 0.65**&lt;/td&gt; 
   &lt;td&gt;0.35* / 0.63**&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/cin.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/cin.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;*: w/ guiding, classifier_scale 10 **: w/o guiding, scores in bracket calculated with script provided by &lt;a href=&quot;https://github.com/openai/guided-diffusion&quot;&gt;ADM&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conceptual Captions&lt;/td&gt; 
   &lt;td&gt;Text-conditional Image Synthesis&lt;/td&gt; 
   &lt;td&gt;LDM-VQ-f4 (100 DDIM steps, eta=0)&lt;/td&gt; 
   &lt;td&gt;16.79&lt;/td&gt; 
   &lt;td&gt;13.89&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/text2img.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/text2img.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;finetuned from LAION&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenImages&lt;/td&gt; 
   &lt;td&gt;Super-resolution&lt;/td&gt; 
   &lt;td&gt;LDM-VQ-4&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/sr_bsr.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/sr_bsr.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;BSR image degradation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenImages&lt;/td&gt; 
   &lt;td&gt;Layout-to-Image Synthesis&lt;/td&gt; 
   &lt;td&gt;LDM-VQ-4 (200 DDIM steps, eta=0)&lt;/td&gt; 
   &lt;td&gt;32.02&lt;/td&gt; 
   &lt;td&gt;15.92&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/layout2img_model.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/layout2img_model.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Landscapes&lt;/td&gt; 
   &lt;td&gt;Semantic Image Synthesis&lt;/td&gt; 
   &lt;td&gt;LDM-VQ-4&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/semantic_synthesis256.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/semantic_synthesis256.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Landscapes&lt;/td&gt; 
   &lt;td&gt;Semantic Image Synthesis&lt;/td&gt; 
   &lt;td&gt;LDM-VQ-4&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://ommer-lab.com/files/latent-diffusion/semantic_synthesis.zip&quot;&gt;https://ommer-lab.com/files/latent-diffusion/semantic_synthesis.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;finetuned on resolution 512x512&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Get the models&lt;/h3&gt; 
&lt;p&gt;The LDMs listed above can jointly be downloaded and extracted via&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;bash scripts/download_models.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The models can then be found in &lt;code&gt;models/ldm/&amp;lt;model_spec&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Coming Soon...&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More inference scripts for conditional LDMs.&lt;/li&gt; 
 &lt;li&gt;In the meantime, you can play with our colab notebook &lt;a href=&quot;https://colab.research.google.com/drive/1xqzUi2iXQXDqXBHQGP9Mqt2YrYW6cx-J?usp=sharing&quot;&gt;https://colab.research.google.com/drive/1xqzUi2iXQXDqXBHQGP9Mqt2YrYW6cx-J?usp=sharing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Comments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Our codebase for the diffusion models builds heavily on &lt;a href=&quot;https://github.com/openai/guided-diffusion&quot;&gt;OpenAI&#39;s ADM codebase&lt;/a&gt; and &lt;a href=&quot;https://github.com/lucidrains/denoising-diffusion-pytorch&quot;&gt;https://github.com/lucidrains/denoising-diffusion-pytorch&lt;/a&gt;. Thanks for open-sourcing!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The implementation of the transformer encoder is from &lt;a href=&quot;https://github.com/lucidrains/x-transformers&quot;&gt;x-transformers&lt;/a&gt; by &lt;a href=&quot;https://github.com/lucidrains?tab=repositories&quot;&gt;lucidrains&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;BibTeX&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@misc{rombach2021highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{https://doi.org/10.48550/arxiv.2204.11824,
  doi = {10.48550/ARXIV.2204.11824},
  url = {https://arxiv.org/abs/2204.11824},
  author = {Blattmann, Andreas and Rombach, Robin and Oktay, Kaan and Ommer, Björn},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Retrieval-Augmented Diffusion Models},
  publisher = {arXiv},
  year = {2022},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>datawhalechina/llm-cookbook</title>
      <link>https://github.com/datawhalechina/llm-cookbook</link>
      <description>&lt;p&gt;面向开发者的 LLM 入门教程，吴恩达大模型系列课程中文版&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/datawhalechina/llm-cookbook/main/figures/readme.jpg&quot; alt=&quot;figures/readme.jpg&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;面向开发者的大模型手册 - LLM Cookbook&lt;/h1&gt; 
&lt;h2&gt;项目简介&lt;/h2&gt; 
&lt;p&gt;本项目是一个面向开发者的大模型手册，针对国内开发者的实际需求，主打 LLM 全方位入门实践。本项目基于吴恩达老师大模型系列课程内容，对原课程内容进行筛选、翻译、复现和调优，覆盖从 Prompt Engineering 到 RAG 开发、模型微调的全部流程，用最适合国内学习者的方式，指导国内开发者如何学习、入门 LLM 相关项目。&lt;/p&gt; 
&lt;p&gt;针对不同内容的特点，我们对共计 11 门吴恩达老师的大模型课程进行了翻译复现，并结合国内学习者的实际情况，对不同课程进行了分级和排序，初学者可以先系统学习我们的必修类课程，掌握入门 LLM 所有方向都需要掌握的基础技能和概念，再选择性地学习我们的选修类课程，在自己感兴趣的方向上不断探索和学习。&lt;/p&gt; 
&lt;p&gt;如果有你非常喜欢但我们还没有进行复现的吴恩达老师大模型课程，我们欢迎每一位开发者参考我们已有课程的格式和写法来对课程进行复现并提交 PR，在 PR 审核通过后，我们会根据课程内容将课程进行分级合并。欢迎每一位开发者的贡献！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;在线阅读地址：&lt;a href=&quot;https://datawhalechina.github.io/llm-cookbook/&quot;&gt;面向开发者的 LLM 入门课程-在线阅读&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PDF下载地址：&lt;a href=&quot;https://github.com/datawhalechina/llm-cookbook/releases/tag/v1%2C0%2C0&quot;&gt;面向开发者的 LLM 入门教程-PDF&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;英文原版地址：&lt;a href=&quot;https://learn.deeplearning.ai&quot;&gt;吴恩达关于大模型的系列课程&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;项目意义&lt;/h2&gt; 
&lt;p&gt;LLM 正在逐步改变人们的生活，而对于开发者，如何基于 LLM 提供的 API 快速、便捷地开发一些具备更强能力、集成LLM 的应用，来便捷地实现一些更新颖、更实用的能力，是一个急需学习的重要能力。&lt;/p&gt; 
&lt;p&gt;由吴恩达老师与 OpenAI 合作推出的大模型系列教程，从大模型时代开发者的基础技能出发，深入浅出地介绍了如何基于大模型 API、LangChain 架构快速开发结合大模型强大能力的应用。其中，《Prompt Engineering for Developers》教程面向入门 LLM 的开发者，深入浅出地介绍了对于开发者，如何构造 Prompt 并基于 OpenAI 提供的 API 实现包括总结、推断、转换等多种常用功能，是入门 LLM 开发的经典教程；《Building Systems with the ChatGPT API》教程面向想要基于 LLM 开发应用程序的开发者，简洁有效而又系统全面地介绍了如何基于 ChatGPT API 打造完整的对话系统；《LangChain for LLM Application Development》教程结合经典大模型开源框架 LangChain，介绍了如何基于 LangChain 框架开发具备实用功能、能力全面的应用程序，《LangChain Chat With Your Data》教程则在此基础上进一步介绍了如何使用 LangChain 架构结合个人私有数据开发个性化大模型应用；《Building Generative AI Applications with Gradio》、《Evaluating and Debugging Generative AI》教程分别介绍了两个实用工具 Gradio 与 W&amp;amp;B，指导开发者如何结合这两个工具来打造、评估生成式 AI 应用。&lt;/p&gt; 
&lt;p&gt;上述教程非常适用于开发者学习以开启基于 LLM 实际搭建应用程序之路。因此，我们将该系列课程翻译为中文，并复现其范例代码，也为其中一个视频增加了中文字幕，支持国内中文学习者直接使用，以帮助中文学习者更好地学习 LLM 开发；我们也同时实现了效果大致相当的中文 Prompt，支持学习者感受中文语境下 LLM 的学习使用，对比掌握多语言语境下的 Prompt 设计与 LLM 开发。未来，我们也将加入更多 Prompt 高级技巧，以丰富本课程内容，帮助开发者掌握更多、更巧妙的 Prompt 技能。&lt;/p&gt; 
&lt;h2&gt;项目受众&lt;/h2&gt; 
&lt;p&gt;所有具备基础 Python 能力，想要入门 LLM 的开发者。&lt;/p&gt; 
&lt;h2&gt;项目亮点&lt;/h2&gt; 
&lt;p&gt;《ChatGPT Prompt Engineering for Developers》、《Building Systems with the ChatGPT API》等教程作为由吴恩达老师与 OpenAI 联合推出的官方教程，在可预见的未来会成为 LLM 的重要入门教程，但是目前还只支持英文版且国内访问受限，打造中文版且国内流畅访问的教程具有重要意义；同时，GPT 对中文、英文具有不同的理解能力，本教程在多次对比、实验之后确定了效果大致相当的中文 Prompt，支持学习者研究如何提升 ChatGPT 在中文语境下的理解与生成能力。&lt;/p&gt; 
&lt;h2&gt;学习指南&lt;/h2&gt; 
&lt;p&gt;本教程适用于所有具备基础 Python 能力，想要入门 LLM 的开发者。&lt;/p&gt; 
&lt;p&gt;如果你想要开始学习本教程，你需要提前具备：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;至少一个 LLM API（最好是 OpenAI，如果是其他 API，你可能需要参考&lt;a href=&quot;https://github.com/datawhalechina/llm-universe&quot;&gt;其他教程&lt;/a&gt;对 API 调用代码进行修改）&lt;/li&gt; 
 &lt;li&gt;能够使用 Python Jupyter Notebook&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;本教程共包括 11 门课程，分为必修类、选修类两个类别。必修类课程是我们认为最适合初学者学习以入门 LLM 的课程，包括了入门 LLM 所有方向都需要掌握的基础技能和概念，我们也针对必修类课程制作了适合阅读的在线阅读和 PDF 版本，在学习必修类课程时，我们建议学习者按照我们列出的顺序进行学习；选修类课程是在必修类课程上的拓展延伸，包括了 RAG 开发、模型微调、模型评估等多个方面，适合学习者在掌握了必修类课程之后选择自己感兴趣的方向和课程进行学习。&lt;/p&gt; 
&lt;p&gt;必修类课程包括：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;面向开发者的 Prompt Engineering。基于吴恩达老师《ChatGPT Prompt Engineering for Developers》课程打造，面向入门 LLM 的开发者，深入浅出地介绍了对于开发者，如何构造 Prompt 并基于 OpenAI 提供的 API 实现包括总结、推断、转换等多种常用功能，是入门 LLM 开发的第一步。&lt;/li&gt; 
 &lt;li&gt;搭建基于 ChatGPT 的问答系统。基于吴恩达老师《Building Systems with the ChatGPT API》课程打造，指导开发者如何基于 ChatGPT 提供的 API 开发一个完整的、全面的智能问答系统。通过代码实践，实现了基于 ChatGPT 开发问答系统的全流程，介绍了基于大模型开发的新范式，是大模型开发的实践基础。&lt;/li&gt; 
 &lt;li&gt;使用 LangChain 开发应用程序。基于吴恩达老师《LangChain for LLM Application Development》课程打造，对 LangChain 展开深入介绍，帮助学习者了解如何使用 LangChain，并基于 LangChain 开发完整的、具备强大能力的应用程序。&lt;/li&gt; 
 &lt;li&gt;使用 LangChain 访问个人数据。基于吴恩达老师《LangChain Chat with Your Data》课程打造，深入拓展 LangChain 提供的个人数据访问能力，指导开发者如何使用 LangChain 开发能够访问用户个人数据、提供个性化服务的大模型应用。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;选修类课程包括：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;使用 Gradio 搭建生成式 AI 应用。基于吴恩达老师《Building Generative AI Applications with Gradio》课程打造，指导开发者如何使用 Gradio 通过 Python 接口程序快速、高效地为生成式 AI 构建用户界面。&lt;/li&gt; 
 &lt;li&gt;评估改进生成式 AI。基于吴恩达老师《Evaluating and Debugging Generative AI》课程打造，结合 wandb，提供一套系统化的方法和工具，帮助开发者有效地跟踪和调试生成式 AI 模型。&lt;/li&gt; 
 &lt;li&gt;微调大语言模型。基于吴恩达老师《Finetuning Large Language Model》课程打造，结合 lamini 框架，讲述如何便捷高效地在本地基于个人数据微调开源大语言模型。&lt;/li&gt; 
 &lt;li&gt;大模型与语义检索。基于吴恩达老师《Large Language Models with Semantic Search》课程打造，针对检索增强生成，讲述了多种高级检索技巧以实现更准确、高效的检索增强 LLM 生成效果。&lt;/li&gt; 
 &lt;li&gt;基于 Chroma 的高级检索。基于吴恩达老师《Advanced Retrieval for AI with Chroma》课程打造，旨在介绍基于 Chroma 的高级检索技术，提升检索结果的准确性。&lt;/li&gt; 
 &lt;li&gt;搭建和评估高级 RAG 应用。基于吴恩达老师《Building and Evaluating Advanced RAG Applications》课程打造，介绍构建和实现高质量RAG系统所需的关键技术和评估框架。&lt;/li&gt; 
 &lt;li&gt;LangChain 的 Functions、Tools 和 Agents。基于吴恩达老师《Functions, Tools and Agents with LangChain》课程打造，介绍如何基于 LangChain 的新语法构建 Agent。&lt;/li&gt; 
 &lt;li&gt;Prompt 高级技巧。包括 CoT、自我一致性等多种 Prompt 高级技巧的基础理论与代码实现。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;其他资料包括：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;双语字幕视频地址：&lt;a href=&quot;https://www.bilibili.com/video/BV1Bo4y1A7FU/?share_source=copy_web&quot;&gt;吴恩达 x OpenAI的Prompt Engineering课程专业翻译版&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;中英双语字幕下载：&lt;a href=&quot;https://github.com/GitHubDaily/ChatGPT-Prompt-Engineering-for-Developers-in-Chinese&quot;&gt;《ChatGPT提示工程》非官方版中英双语字幕&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;视频讲解：&lt;a href=&quot;https://www.bilibili.com/video/BV1PN4y1k7y2/?spm_id_from=333.999.0.0&quot;&gt;面向开发者的 Prompt Engineering 讲解（数字游民大会）&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;目录结构说明：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;content：基于原课程复现的双语版代码，可运行的 Notebook，更新频率最高，更新速度最快。

docs：必修类课程文字教程版在线阅读源码，适合阅读的 md。

figures：图片文件。
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;致谢&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;核心贡献者&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/logan-zou&quot;&gt;邹雨衡-项目负责人&lt;/a&gt;（Datawhale成员-对外经济贸易大学研究生）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/LinChentang&quot;&gt;左春生-项目负责人&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://yam.gift/&quot;&gt;长琴-项目发起人&lt;/a&gt;（内容创作者-Datawhale成员-AI算法工程师）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Sophia-Huang&quot;&gt;玉琳-项目发起人&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/xuhu0115&quot;&gt;徐虎-教程编撰者&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Weihong-Liu&quot;&gt;刘伟鸿-教程编撰者&lt;/a&gt;（内容创作者-江南大学非全研究生）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://Joyenjoye.com&quot;&gt;Joye-教程编撰者&lt;/a&gt;（内容创作者-数据科学家）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/0-yy-0&quot;&gt;高立业&lt;/a&gt;（内容创作者-DataWhale成员-算法工程师）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/GKDGKD&quot;&gt;邓宇文&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/wisdom-pan&quot;&gt;魂兮&lt;/a&gt;（内容创作者-前端工程师）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/KMnO4-zx&quot;&gt;宋志学&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/YikunHan42&quot;&gt;韩颐堃&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/6forwater29&quot;&gt;陈逸涵&lt;/a&gt; (内容创作者-Datawhale意向成员-AI爱好者)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ztgg0228&quot;&gt;仲泰&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/leason-wan&quot;&gt;万礼行&lt;/a&gt;（内容创作者-视频翻译者）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Bald0Wang&quot;&gt;王熠明&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://yetingyun.blog.csdn.net&quot;&gt;曾浩龙&lt;/a&gt;（内容创作者-Datawhale 意向成员-JLU AI 研究生）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/xinqi-fan&quot;&gt;小饭同学&lt;/a&gt;（内容创作者）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/sunhanyu714%5D&quot;&gt;孙韩玉&lt;/a&gt;（内容创作者-算法量化部署工程师）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/YinHan-Zhang&quot;&gt;张银晗&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Jin-Zhang-Yaoguang&quot;&gt;张晋&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Aphasia0515&quot;&gt;李娇娇&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Kedreamix&quot;&gt;邓恺俊&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Zhiyuan-Fan&quot;&gt;范致远&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Beyondzjl&quot;&gt;周景林&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/very-very-very&quot;&gt;诸世纪&lt;/a&gt;（内容创作者-算法工程师）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/YixinZ-NUS&quot;&gt;Zhang Yixin&lt;/a&gt;（内容创作者-IT爱好者）&lt;/li&gt; 
 &lt;li&gt;Sarai（内容创作者-AI应用爱好者）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;其他&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;特别感谢 &lt;a href=&quot;https://github.com/Sm1les&quot;&gt;@Sm1les&lt;/a&gt;、&lt;a href=&quot;https://github.com/LSGOMYP&quot;&gt;@LSGOMYP&lt;/a&gt; 对本项目的帮助与支持；&lt;/li&gt; 
 &lt;li&gt;感谢 &lt;a href=&quot;https://github.com/GitHubDaily&quot;&gt;GithubDaily&lt;/a&gt; 提供的双语字幕；&lt;/li&gt; 
 &lt;li&gt;如果有任何想法可以联系我们 DataWhale 也欢迎大家多多提出 issue；&lt;/li&gt; 
 &lt;li&gt;特别感谢以下为教程做出贡献的同学！&lt;/li&gt; 
&lt;/ol&gt; 
&lt;a href=&quot;https://datawhalechina.github.io/llm-cookbook/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=datawhalechina/llm-cookbook&quot;&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href=&quot;https://contrib.rocks&quot;&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://star-history.com/#datawhalechina/llm-cookbook&amp;amp;Date&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=datawhalechina/llm-cookbook&amp;amp;type=Date&quot; alt=&quot;Star History Chart&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;关注我们&lt;/h2&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;扫描下方二维码关注公众号：Datawhale&lt;/p&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/datawhalechina/llm-cookbook/main/figures/qrcode.jpeg&quot; width=&quot;180&quot; height=&quot;180&quot;&gt; 
&lt;/div&gt; Datawhale 是一个专注于数据科学与 AI 领域的开源组织，汇集了众多领域院校和知名企业的优秀学习者，聚合了一群有开源精神和探索精神的团队成员。微信搜索公众号Datawhale可以加入我们。 
&lt;h2&gt;LICENSE&lt;/h2&gt; 
&lt;p&gt;&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-sa/4.0/&quot;&gt;&lt;img alt=&quot;知识共享许可协议&quot; style=&quot;border-width:0&quot; src=&quot;https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey&quot;&gt;&lt;/a&gt;&lt;br&gt;本作品采用&lt;a rel=&quot;license&quot; href=&quot;http://creativecommons.org/licenses/by-nc-sa/4.0/&quot;&gt;知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议&lt;/a&gt;进行许可。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/OmniParser</title>
      <link>https://github.com/microsoft/OmniParser</link>
      <description>&lt;p&gt;A simple screen parsing tool towards pure vision based GUI agent&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/microsoft/OmniParser/master/imgs/logo.png&quot; alt=&quot;Logo&quot;&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2408.00203&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Paper-green&quot; alt=&quot;arXiv&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;📢 [&lt;a href=&quot;https://microsoft.github.io/OmniParser/&quot;&gt;Project Page&lt;/a&gt;] [&lt;a href=&quot;https://www.microsoft.com/en-us/research/articles/omniparser-v2-turning-any-llm-into-a-computer-use-agent/&quot;&gt;V2 Blog Post&lt;/a&gt;] [&lt;a href=&quot;https://huggingface.co/microsoft/OmniParser-v2.0&quot;&gt;Models V2&lt;/a&gt;] [&lt;a href=&quot;https://huggingface.co/microsoft/OmniParser&quot;&gt;Models V1.5&lt;/a&gt;] [&lt;a href=&quot;https://huggingface.co/spaces/microsoft/OmniParser-v2&quot;&gt;HuggingFace Space Demo&lt;/a&gt;]&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OmniParser&lt;/strong&gt; is a comprehensive method for parsing user interface screenshots into structured and easy-to-understand elements, which significantly enhances the ability of GPT-4V to generate actions that can be accurately grounded in the corresponding regions of the interface.&lt;/p&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/3] We are gradually adding multi agents orchstration and improving user interface in OmniTool for better experience.&lt;/li&gt; 
 &lt;li&gt;[2025/2] We release OmniParser V2 &lt;a href=&quot;https://huggingface.co/microsoft/OmniParser-v2.0&quot;&gt;checkpoints&lt;/a&gt;. &lt;a href=&quot;https://1drv.ms/v/c/650b027c18d5a573/EWXbVESKWo9Buu6OYCwg06wBeoM97C6EOTG6RjvWLEN1Qg?e=alnHGC&quot;&gt;Watch Video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/2] We introduce OmniTool: Control a Windows 11 VM with OmniParser + your vision model of choice. OmniTool supports out of the box the following large language models - OpenAI (4o/o1/o3-mini), DeepSeek (R1), Qwen (2.5VL) or Anthropic Computer Use. &lt;a href=&quot;https://1drv.ms/v/c/650b027c18d5a573/EehZ7RzY69ZHn-MeQHrnnR4BCj3by-cLLpUVlxMjF4O65Q?e=8LxMgX&quot;&gt;Watch Video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/1] V2 is coming. We achieve new state of the art results 39.5% on the new grounding benchmark &lt;a href=&quot;https://github.com/likaixin2000/ScreenSpot-Pro-GUI-Grounding/tree/main&quot;&gt;Screen Spot Pro&lt;/a&gt; with OmniParser v2 (will be released soon)! Read more details &lt;a href=&quot;https://github.com/microsoft/OmniParser/tree/master/docs/Evaluation.md&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2024/11] We release an updated version, OmniParser V1.5 which features 1) more fine grained/small icon detection, 2) prediction of whether each screen element is interactable or not. Examples in the demo.ipynb.&lt;/li&gt; 
 &lt;li&gt;[2024/10] OmniParser was the #1 trending model on huggingface model hub (starting 10/29/2024).&lt;/li&gt; 
 &lt;li&gt;[2024/10] Feel free to checkout our demo on &lt;a href=&quot;https://huggingface.co/spaces/microsoft/OmniParser&quot;&gt;huggingface space&lt;/a&gt;! (stay tuned for OmniParser + Claude Computer Use)&lt;/li&gt; 
 &lt;li&gt;[2024/10] Both Interactive Region Detection Model and Icon functional description model are released! &lt;a href=&quot;https://huggingface.co/microsoft/OmniParser&quot;&gt;Hugginface models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2024/09] OmniParser achieves the best performance on &lt;a href=&quot;https://microsoft.github.io/WindowsAgentArena/&quot;&gt;Windows Agent Arena&lt;/a&gt;!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;First clone the repo, and then install environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;cd OmniParser
conda create -n &quot;omni&quot; python==3.12
conda activate omni
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure you have the V2 weights downloaded in weights folder (ensure caption weights folder is called icon_caption_florence). If not download them with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;   # download the model checkpoints to local directory OmniParser/weights/
   for f in icon_detect/{train_args.yaml,model.pt,model.yaml} icon_caption/{config.json,generation_config.json,model.safetensors}; do huggingface-cli download microsoft/OmniParser-v2.0 &quot;$f&quot; --local-dir weights; done
   mv weights/icon_caption weights/icon_caption_florence
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- ## [deprecated]
Then download the model ckpts files in: https://huggingface.co/microsoft/OmniParser, and put them under weights/, default folder structure is: weights/icon_detect, weights/icon_caption_florence, weights/icon_caption_blip2. 

For v1: 
convert the safetensor to .pt file. 
```python
python weights/convert_safetensor_to_pt.py

For v1.5: 
download &#39;model_v1_5.pt&#39; from https://huggingface.co/microsoft/OmniParser/tree/main/icon_detect_v1_5, make a new dir: weights/icon_detect_v1_5, and put it inside the folder. No weight conversion is needed. 
``` --&gt; 
&lt;h2&gt;Examples:&lt;/h2&gt; 
&lt;p&gt;We put together a few simple examples in the demo.ipynb.&lt;/p&gt; 
&lt;h2&gt;Gradio Demo&lt;/h2&gt; 
&lt;p&gt;To run gradio demo, simply run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;python gradio_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Weights License&lt;/h2&gt; 
&lt;p&gt;For the model checkpoints on huggingface model hub, please note that icon_detect model is under AGPL license since it is a license inherited from the original yolo model. And icon_caption_blip2 &amp;amp; icon_caption_florence is under MIT license. Please refer to the LICENSE file in the folder of each model: &lt;a href=&quot;https://huggingface.co/microsoft/OmniParser&quot;&gt;https://huggingface.co/microsoft/OmniParser&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;📚 Citation&lt;/h2&gt; 
&lt;p&gt;Our technical report can be found &lt;a href=&quot;https://arxiv.org/abs/2408.00203&quot;&gt;here&lt;/a&gt;. If you find our work useful, please consider citing our work:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{lu2024omniparserpurevisionbased,
      title={OmniParser for Pure Vision Based GUI Agent}, 
      author={Yadong Lu and Jianwei Yang and Yelong Shen and Ahmed Awadallah},
      year={2024},
      eprint={2408.00203},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.00203}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/langchain</title>
      <link>https://github.com/langchain-ai/langchain</link>
      <description>&lt;p&gt;🦜🔗 Build context-aware reasoning applications&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/static/img/logo-dark.svg&quot;&gt; 
 &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/static/img/logo-light.svg&quot;&gt; 
 &lt;img alt=&quot;LangChain Logo&quot; src=&quot;https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/logo-dark.svg?sanitize=true&quot; width=&quot;80%&quot;&gt; 
&lt;/picture&gt; 
&lt;div&gt; 
 &lt;br&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/langchain-ai/langchain/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/langchain-ai/langchain?style=flat-square&quot; alt=&quot;Release Notes&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/langchain-ai/langchain/actions/workflows/check_diffs.yml&quot;&gt;&lt;img src=&quot;https://github.com/langchain-ai/langchain/actions/workflows/check_diffs.yml/badge.svg?sanitize=true&quot; alt=&quot;CI&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/l/langchain-core?style=flat-square&quot; alt=&quot;PyPI - License&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypistats.org/packages/langchain-core&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/dm/langchain-core?style=flat-square&quot; alt=&quot;PyPI - Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://star-history.com/#langchain-ai/langchain&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/langchain-ai/langchain?style=flat-square&quot; alt=&quot;GitHub star chart&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/langchain-ai/langchain/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-raw/langchain-ai/langchain?style=flat-square&quot; alt=&quot;Open Issues&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/langchain-ai/langchain&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode&amp;amp;style=flat-square&quot; alt=&quot;Open in Dev Containers&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://codespaces.new/langchain-ai/langchain&quot;&gt;&lt;img src=&quot;https://github.com/codespaces/badge.svg?sanitize=true&quot; alt=&quot;Open in GitHub Codespaces&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/langchainai&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/url/https/twitter.com/langchainai.svg?style=social&amp;amp;label=Follow%20%40LangChainAI&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Looking for the JS/TS library? Check out &lt;a href=&quot;https://github.com/langchain-ai/langchainjs&quot;&gt;LangChain.js&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;LangChain is a framework for building LLM-powered applications. It helps you chain together interoperable components and third-party integrations to simplify AI application development — all while future-proofing decisions as the underlying technology evolves.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -U langchain
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To learn more about LangChain, check out &lt;a href=&quot;https://python.langchain.com/docs/introduction/&quot;&gt;the docs&lt;/a&gt;. If you’re looking for more advanced customization or agent orchestration, check out &lt;a href=&quot;https://langchain-ai.github.io/langgraph/&quot;&gt;LangGraph&lt;/a&gt;, our framework for building controllable agent workflows.&lt;/p&gt; 
&lt;h2&gt;Why use LangChain?&lt;/h2&gt; 
&lt;p&gt;LangChain helps developers build applications powered by LLMs through a standard interface for models, embeddings, vector stores, and more.&lt;/p&gt; 
&lt;p&gt;Use LangChain for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time data augmentation&lt;/strong&gt;. Easily connect LLMs to diverse data sources and external / internal systems, drawing from LangChain’s vast library of integrations with model providers, tools, vector stores, retrievers, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model interoperability&lt;/strong&gt;. Swap models in and out as your engineering team experiments to find the best choice for your application’s needs. As the industry frontier evolves, adapt quickly — LangChain’s abstractions keep you moving without losing momentum.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;LangChain’s ecosystem&lt;/h2&gt; 
&lt;p&gt;While the LangChain framework can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools when building LLM applications.&lt;/p&gt; 
&lt;p&gt;To improve your LLM application development, pair LangChain with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.langchain.com/langsmith&quot;&gt;LangSmith&lt;/a&gt; - Helpful for agent evals and observability. Debug poor-performing LLM app runs, evaluate agent trajectories, gain visibility in production, and improve performance over time.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://langchain-ai.github.io/langgraph/&quot;&gt;LangGraph&lt;/a&gt; - Build agents that can reliably handle complex tasks with LangGraph, our low-level agent orchestration framework. LangGraph offers customizable architecture, long-term memory, and human-in-the-loop workflows — and is trusted in production by companies like LinkedIn, Uber, Klarna, and GitLab.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://langchain-ai.github.io/langgraph/concepts/#langgraph-platform&quot;&gt;LangGraph Platform&lt;/a&gt; - Deploy and scale agents effortlessly with a purpose-built deployment platform for long running, stateful workflows. Discover, reuse, configure, and share agents across teams — and iterate quickly with visual prototyping in &lt;a href=&quot;https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/&quot;&gt;LangGraph Studio&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Additional resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://python.langchain.com/docs/tutorials/&quot;&gt;Tutorials&lt;/a&gt;: Simple walkthroughs with guided examples on getting started with LangChain.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://python.langchain.com/docs/how_to/&quot;&gt;How-to Guides&lt;/a&gt;: Quick, actionable code snippets for topics such as tool calling, RAG use cases, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://python.langchain.com/docs/concepts/&quot;&gt;Conceptual Guides&lt;/a&gt;: Explanations of key concepts behind the LangChain framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://python.langchain.com/api_reference/&quot;&gt;API Reference&lt;/a&gt;: Detailed reference on navigating base packages and integrations for LangChain.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>fivethirtyeight/data</title>
      <link>https://github.com/fivethirtyeight/data</link>
      <description>&lt;p&gt;Data and code behind the articles and graphics at FiveThirtyEight&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://img.shields.io/github/repo-size/fivethirtyeight/data&quot; alt=&quot;GitHub repo size&quot;&gt;&lt;/p&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://github.com/fivethirtyeight/data/raw/master/index.csv&quot;&gt;index&lt;/a&gt; for a list of the data and code we&#39;ve published and their accompanying stories.&lt;/p&gt; 
&lt;p&gt;As of June 13, 2023, sports predictions and forecasts are &lt;a href=&quot;https://awfulannouncing.com/disney/fivethirtyeight-no-more-sports-forecasts.html&quot;&gt;no longer being updated&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unless otherwise noted, our data sets are available under the &lt;a href=&quot;https://creativecommons.org/licenses/by/4.0/&quot;&gt;Creative Commons Attribution 4.0 International License&lt;/a&gt;, and the code is available under the &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;MIT License&lt;/a&gt;. If you find this information useful, please &lt;a href=&quot;mailto:contact@fivethirtyeight.com&quot;&gt;let us know&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AI4Finance-Foundation/FinRL</title>
      <link>https://github.com/AI4Finance-Foundation/FinRL</link>
      <description>&lt;p&gt;FinRL: Financial Reinforcement Learning. 🔥&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;img align=&quot;center&quot; width=&quot;30%&quot; alt=&quot;image&quot; src=&quot;https://github.com/AI4Finance-Foundation/FinGPT/assets/31713746/e0371951-1ce1-488e-aa25-0992dafcc139&quot;&gt; 
&lt;/div&gt; 
&lt;h1&gt;FinRL: Financial Reinforcement Learning &lt;a href=&quot;https://twitter.com/intent/tweet?text=FinRL-Financial-Deep-Reinforcement-Learning%20&amp;amp;url=https://github.com/AI4Finance-Foundation/FinRL&amp;amp;hashtags=DRL&amp;amp;hashtags=AI&quot;&gt;&lt;img src=&quot;http://www.tensorlet.org/wp-content/uploads/2021/01/button_twitter_22x22.png&quot; alt=&quot;twitter&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.facebook.com/sharer.php?u=http%3A%2F%2Fgithub.com%2FAI4Finance-Foundation%2FFinRL&quot;&gt;&lt;img src=&quot;http://www.tensorlet.org/wp-content/uploads/2021/01/facebook-button_22x22.png&quot; alt=&quot;facebook&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://plus.google.com/share?url=https://github.com/AI4Finance-Foundation/FinRL&quot;&gt;&lt;img src=&quot;http://www.tensorlet.org/wp-content/uploads/2021/01/button_google_22.xx_.png&quot; alt=&quot;google+&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2Fgithub.com%2FAI4Finance-Foundation%2FFinRL&quot;&gt;&lt;img src=&quot;http://www.tensorlet.org/wp-content/uploads/2021/01/button_linkedin_22x22.png&quot; alt=&quot;linkedin&quot;&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/figs/logo_transparent_background.png&quot; width=&quot;55%&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href=&quot;https://pepy.tech/project/finrl&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/finrl&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pepy.tech/project/finrl&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/finrl/week&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.python.org/downloads/release/python-360/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/python-3.6-blue.svg?sanitize=true&quot; alt=&quot;Python 3.6&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/finrl/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/finrl.svg?sanitize=true&quot; alt=&quot;PyPI&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://finrl.readthedocs.io/en/latest/?badge=latest&quot;&gt;&lt;img src=&quot;https://readthedocs.org/projects/finrl/badge/?version=latest&quot; alt=&quot;Documentation Status&quot;&gt;&lt;/a&gt; &lt;img src=&quot;https://img.shields.io/github/license/AI4Finance-Foundation/finrl.svg?color=brightgreen&quot; alt=&quot;License&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/issues-raw/AI4Finance-Foundation/finrl?label=Issues&quot; alt=&quot;&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/issues-closed-raw/AI4Finance-Foundation/finrl?label=Closed+Issues&quot; alt=&quot;&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/issues-pr-raw/AI4Finance-Foundation/finrl?label=Open+PRs&quot; alt=&quot;&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/issues-pr-closed-raw/AI4Finance-Foundation/finrl?label=Closed+PRs&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/AI4Finance-Foundation/ChatGPT-for-FinTech&quot;&gt;FinGPT&lt;/a&gt;: Open-source for open-finance! Revolutionize FinTech.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://discord.gg/trsr8SXpW5&quot;&gt;&lt;img src=&quot;https://dcbadge.vercel.app/api/server/trsr8SXpW5&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://api.visitorbadge.io/api/VisitorHit?user=AI4Finance-Foundation&amp;amp;repo=FinRL&amp;amp;countColor=%23B17A&quot; alt=&quot;Visitors&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Financial reinforcement learning (FinRL)&lt;/strong&gt; (&lt;a href=&quot;https://finrl.readthedocs.io/en/latest/index.html&quot;&gt;Document website&lt;/a&gt;) is &lt;strong&gt;the first open-source framework&lt;/strong&gt; for financial reinforcement learning. FinRL has evolved into an &lt;strong&gt;ecosystem&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dev Roadmap&lt;/th&gt; 
   &lt;th&gt;Stage&lt;/th&gt; 
   &lt;th&gt;Users&lt;/th&gt; 
   &lt;th&gt;Project&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.0 (Preparation)&lt;/td&gt; 
   &lt;td&gt;entrance&lt;/td&gt; 
   &lt;td&gt;practitioners&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinRL-Meta&quot;&gt;FinRL-Meta&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;gym-style market environments&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1.0 (Proof-of-Concept)&lt;/td&gt; 
   &lt;td&gt;full-stack&lt;/td&gt; 
   &lt;td&gt;developers&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinRL&quot;&gt;this repo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;automatic pipeline&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2.0 (Professional)&lt;/td&gt; 
   &lt;td&gt;profession&lt;/td&gt; 
   &lt;td&gt;experts&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/AI4Finance-Foundation/ElegantRL&quot;&gt;ElegantRL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;algorithms&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.0 (Production)&lt;/td&gt; 
   &lt;td&gt;service&lt;/td&gt; 
   &lt;td&gt;hedge funds&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinRL_Podracer&quot;&gt;Podracer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;cloud-native deployment&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Outline&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#overview&quot;&gt;Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#file-structure&quot;&gt;File Structure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#supported-data-sources&quot;&gt;Supported Data Sources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#status-update&quot;&gt;Status Update&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#tutorials&quot;&gt;Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#publications&quot;&gt;Publications&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#news&quot;&gt;News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#citing-finrl&quot;&gt;Citing FinRL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#join-and-contribute&quot;&gt;Join and Contribute&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#sponsorship&quot;&gt;Sponsorship&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/#license&quot;&gt;LICENSE&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;FinRL has three layers: market environments, agents, and applications. For a trading task (on the top), an agent (in the middle) interacts with a market environment (at the bottom), making sequential decisions.&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/figs/finrl_framework.png&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;A quick start: Stock_NeurIPS2018.ipynb. Videos &lt;a href=&quot;http://www.youtube.com/watch?v=ZSGJjtM-5jA&quot;&gt;FinRL&lt;/a&gt; at &lt;a href=&quot;https://www.youtube.com/channel/UCrVri6k3KPBa3NhapVV4K5g&quot;&gt;AI4Finance Youtube Channel&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;File Structure&lt;/h2&gt; 
&lt;p&gt;The main folder &lt;strong&gt;finrl&lt;/strong&gt; has three subfolders &lt;strong&gt;applications, agents, meta&lt;/strong&gt;. We employ a &lt;strong&gt;train-test-trade&lt;/strong&gt; pipeline with three files: train.py, test.py, and trade.py.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;FinRL
├── finrl (main folder)
│   ├── applications
│   	├── Stock_NeurIPS2018
│   	├── imitation_learning
│   	├── cryptocurrency_trading
│   	├── high_frequency_trading
│   	├── portfolio_allocation
│   	└── stock_trading
│   ├── agents
│   	├── elegantrl
│   	├── rllib
│   	└── stablebaseline3
│   ├── meta
│   	├── data_processors
│   	├── env_cryptocurrency_trading
│   	├── env_portfolio_allocation
│   	├── env_stock_trading
│   	├── preprocessor
│   	├── data_processor.py
│       ├── meta_config_tickers.py
│   	└── meta_config.py
│   ├── config.py
│   ├── config_tickers.py
│   ├── main.py
│   ├── plot.py
│   ├── train.py
│   ├── test.py
│   └── trade.py
│
├── examples
├── unit_tests (unit tests to verify codes on env &amp;amp; data)
│   ├── environments
│   	└── test_env_cashpenalty.py
│   └── downloaders
│   	├── test_yahoodownload.py
│   	└── test_alpaca_downloader.py
├── setup.py
├── requirements.txt
└── README.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported Data Sources&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Data Source&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Range and Frequency&lt;/th&gt; 
   &lt;th&gt;Request Limits&lt;/th&gt; 
   &lt;th&gt;Raw Data&lt;/th&gt; 
   &lt;th&gt;Preprocessed Data&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://alpaca.markets/docs/introduction/&quot;&gt;Akshare&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CN Securities&lt;/td&gt; 
   &lt;td&gt;2015-now, 1day&lt;/td&gt; 
   &lt;td&gt;Account-specific&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://alpaca.markets/docs/introduction/&quot;&gt;Alpaca&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;US Stocks, ETFs&lt;/td&gt; 
   &lt;td&gt;2015-now, 1min&lt;/td&gt; 
   &lt;td&gt;Account-specific&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;http://baostock.com/baostock/index.php/Python_API%E6%96%87%E6%A1%A3&quot;&gt;Baostock&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CN Securities&lt;/td&gt; 
   &lt;td&gt;1990-12-19-now, 5min&lt;/td&gt; 
   &lt;td&gt;Account-specific&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://binance-docs.github.io/apidocs/spot/en/#public-api-definitions&quot;&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Cryptocurrency&lt;/td&gt; 
   &lt;td&gt;API-specific, 1s, 1min&lt;/td&gt; 
   &lt;td&gt;API-specific&lt;/td&gt; 
   &lt;td&gt;Tick-level daily aggegrated trades, OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.ccxt.com/en/latest/manual.html&quot;&gt;CCXT&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Cryptocurrency&lt;/td&gt; 
   &lt;td&gt;API-specific, 1min&lt;/td&gt; 
   &lt;td&gt;API-specific&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://eodhistoricaldata.com/financial-apis/&quot;&gt;EODhistoricaldata&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;US Securities&lt;/td&gt; 
   &lt;td&gt;Frequency-specific, 1min&lt;/td&gt; 
   &lt;td&gt;API-specific&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://iexcloud.io/docs/api/&quot;&gt;IEXCloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;NMS US securities&lt;/td&gt; 
   &lt;td&gt;1970-now, 1 day&lt;/td&gt; 
   &lt;td&gt;100 per second per IP&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.joinquant.com/&quot;&gt;JoinQuant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CN Securities&lt;/td&gt; 
   &lt;td&gt;2005-now, 1min&lt;/td&gt; 
   &lt;td&gt;3 requests each time&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.quantconnect.com/docs/home/home&quot;&gt;QuantConnect&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;US Securities&lt;/td&gt; 
   &lt;td&gt;1998-now, 1s&lt;/td&gt; 
   &lt;td&gt;NA&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.ricequant.com/doc/rqdata/python/&quot;&gt;RiceQuant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CN Securities&lt;/td&gt; 
   &lt;td&gt;2005-now, 1ms&lt;/td&gt; 
   &lt;td&gt;Account-specific&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://sinotrade.github.io/zh_TW/tutor/prepare/terms/&quot;&gt;Sinopac&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Taiwan securities&lt;/td&gt; 
   &lt;td&gt;2023-04-13~now, 1min&lt;/td&gt; 
   &lt;td&gt;Account-specific&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://tushare.pro/document/1?doc_id=131&quot;&gt;Tushare&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CN Securities, A share&lt;/td&gt; 
   &lt;td&gt;-now, 1 min&lt;/td&gt; 
   &lt;td&gt;Account-specific&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://wrds-www.wharton.upenn.edu/pages/about/data-vendors/nyse-trade-and-quote-taq/&quot;&gt;WRDS&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;US Securities&lt;/td&gt; 
   &lt;td&gt;2003-now, 1ms&lt;/td&gt; 
   &lt;td&gt;5 requests each time&lt;/td&gt; 
   &lt;td&gt;Intraday Trades&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://pypi.org/project/yfinance/&quot;&gt;YahooFinance&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;US Securities&lt;/td&gt; 
   &lt;td&gt;Frequency-specific, 1min&lt;/td&gt; 
   &lt;td&gt;2,000/hour&lt;/td&gt; 
   &lt;td&gt;OHLCV&lt;/td&gt; 
   &lt;td&gt;Prices&amp;amp;Indicators&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;!-- |Data Source |Type |Max Frequency |Raw Data|Preprocessed Data|
|  ----  |  ----  |  ----  |  ----  |  ----  |
|    AkShare |  CN Securities | 1 day  |  OHLCV |  Prices, indicators |
|    Alpaca |  US Stocks, ETFs |  1 min |  OHLCV |  Prices, indicators |
|    Alpha Vantage | Stock, ETF, forex, crypto, technical indicators | 1 min |  OHLCV  &amp; Prices, indicators |
|    Baostock |  CN Securities |  5 min |  OHLCV |  Prices, indicators |
|    Binance |  Cryptocurrency |  1 s |  OHLCV |  Prices, indicators |
|    CCXT |  Cryptocurrency |  1 min  |  OHLCV |  Prices, indicators |
|    currencyapi |  Exchange rate | 1 day |  Exchange rate | Exchange rate, indicators |
|    currencylayer |  Exchange rate | 1 day  |  Exchange rate | Exchange rate, indicators |
|    EOD Historical Data | US stocks, and ETFs |  1 day  |  OHLCV  | Prices, indicators |
|    Exchangerates |  Exchange rate |  1 day  |  Exchange rate | Exchange rate, indicators |
|    findatapy |  CN Securities | 1 day  |  OHLCV |  Prices, indicators |
|    Financial Modeling prep | US stocks, currencies, crypto |  1 min |  OHLCV  | Prices, indicators |
|    finnhub | US Stocks, currencies, crypto |   1 day |  OHLCV  | Prices, indicators |
|    Fixer |  Exchange rate |  1 day  |  Exchange rate | Exchange rate, indicators |
|    IEXCloud |  NMS US securities | 1 day  | OHLCV |  Prices, indicators |
|    JoinQuant |  CN Securities |  1 min  |  OHLCV |  Prices, indicators |
|    Marketstack | 50+ countries |  1 day  |  OHLCV | Prices, indicators |
|    Open Exchange Rates |  Exchange rate |  1 day  |  Exchange rate | Exchange rate, indicators |
|    pandas\_datareader |  US Securities |  1 day |  OHLCV | Prices, indicators |
|    pandas-finance |  US Securities |  1 day  |  OHLCV  &amp; Prices, indicators |
|    Polygon |  US Securities |  1 day  |  OHLCV  | Prices, indicators |
|    Quandl | 250+ sources |  1 day  |  OHLCV  | Prices, indicators |
|    QuantConnect |  US Securities |  1 s |  OHLCV |  Prices, indicators |
|    RiceQuant |  CN Securities |  1 ms  |  OHLCV |  Prices, indicators |
|    Sinopac   | Taiwan securities | 1min | OHLCV |  Prices, indicators |
|    Tiingo | Stocks, crypto |  1 day  |  OHLCV  | Prices, indicators |
|    Tushare |  CN Securities | 1 min  |  OHLCV |  Prices, indicators |
|    WRDS |  US Securities |  1 ms  |  Intraday Trades | Prices, indicators |
|    XE |  Exchange rate |  1 day  |  Exchange rate | Exchange rate, indicators |
|    Xignite |  Exchange rate |  1 day  |  Exchange rate | Exchange rate, indicators |
|    YahooFinance |  US Securities | 1 min  |  OHLCV  |  Prices, indicators |
|    ystockquote |  US Securities |  1 day  |  OHLCV | Prices, indicators | --&gt; 
&lt;p&gt;OHLCV: open, high, low, and close prices; volume. adjusted_close: adjusted close price&lt;/p&gt; 
&lt;p&gt;Technical indicators: &#39;macd&#39;, &#39;boll_ub&#39;, &#39;boll_lb&#39;, &#39;rsi_30&#39;, &#39;dx_30&#39;, &#39;close_30_sma&#39;, &#39;close_60_sma&#39;. Users also can add new features.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/master/docs/source/start/installation.rst&quot;&gt;Install description for all operating systems (MAC OS, Ubuntu, Windows 10)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ai4finance.medium.com/finrl-for-quantitative-finance-install-and-setup-tutorial-for-beginners-1db80ad39159&quot;&gt;FinRL for Quantitative Finance: Install and Setup Tutorial for Beginners&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status Update&lt;/h2&gt; 
&lt;details&gt;
 &lt;summary&gt;&lt;b&gt;Version History&lt;/b&gt; &lt;i&gt;[click to expand]&lt;/i&gt;&lt;/summary&gt; 
 &lt;div&gt; 
  &lt;ul&gt; 
   &lt;li&gt;2022-06-25 0.3.5: Formal release of FinRL, neo_finrl is chenged to FinRL-Meta with related files in directory: &lt;em&gt;meta&lt;/em&gt;.&lt;/li&gt; 
   &lt;li&gt;2021-08-25 0.3.1: pytorch version with a three-layer architecture, apps (financial tasks), drl_agents (drl algorithms), neo_finrl (gym env)&lt;/li&gt; 
   &lt;li&gt;2020-12-14 Upgraded to &lt;strong&gt;Pytorch&lt;/strong&gt; with stable-baselines3; Remove tensorflow 1.0 at this moment, under development to support tensorflow 2.0&lt;/li&gt; 
   &lt;li&gt;2020-11-27 0.1: Beta version with tensorflow 1.5&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h2&gt;Tutorials&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[Towardsdatascience] &lt;a href=&quot;https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02&quot;&gt;Deep Reinforcement Learning for Automated Stock Trading&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Publications&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Title&lt;/th&gt; 
   &lt;th&gt;Conference/Journal&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
   &lt;th&gt;Citations&lt;/th&gt; 
   &lt;th&gt;Year&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dynamic Datasets and Market Environments for Financial Reinforcement Learning&lt;/td&gt; 
   &lt;td&gt;Machine Learning - Springer Nature&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/2304.13174&quot;&gt;paper&lt;/a&gt; &lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinRL-Meta&quot;&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;2024&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;FinRL-Meta&lt;/strong&gt;: FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement Learning&lt;/td&gt; 
   &lt;td&gt;NeurIPS 2022&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/2211.03107&quot;&gt;paper&lt;/a&gt; &lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinRL-Meta&quot;&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;37&lt;/td&gt; 
   &lt;td&gt;2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;FinRL&lt;/strong&gt;: Deep reinforcement learning framework to automate trading in quantitative finance&lt;/td&gt; 
   &lt;td&gt;ACM International Conference on AI in Finance (ICAIF)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3955949&quot;&gt;paper&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;49&lt;/td&gt; 
   &lt;td&gt;2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;FinRL&lt;/strong&gt;: A deep reinforcement learning library for automated stock trading in quantitative finance&lt;/td&gt; 
   &lt;td&gt;NeurIPS 2020 Deep RL Workshop&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/2011.09607&quot;&gt;paper&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;87&lt;/td&gt; 
   &lt;td&gt;2020&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deep reinforcement learning for automated stock trading: An ensemble strategy&lt;/td&gt; 
   &lt;td&gt;ACM International Conference on AI in Finance (ICAIF)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3690996&quot;&gt;paper&lt;/a&gt; &lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinRL-Meta/raw/master/tutorials/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb&quot;&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;154&lt;/td&gt; 
   &lt;td&gt;2020&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Practical deep reinforcement learning approach for stock trading&lt;/td&gt; 
   &lt;td&gt;NeurIPS 2018 Workshop on Challenges and Opportunities for AI in Financial Services&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1811.07522&quot;&gt;paper&lt;/a&gt; &lt;a href=&quot;https://github.com/AI4Finance-Foundation/DQN-DDPG_Stock_Trading%5D(https://github.com/AI4Finance-Foundation/FinRL/tree/master/examples)&quot;&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;164&lt;/td&gt; 
   &lt;td&gt;2018&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[央广网] &lt;a href=&quot;http://tech.cnr.cn/techph/20211123/t20211123_525669092.shtml&quot;&gt;2021 IDEA大会于福田圆满落幕：群英荟萃论道AI 多项目发布亮点纷呈&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[央广网] &lt;a href=&quot;https://baijiahao.baidu.com/s?id=1717101783873523790&amp;amp;wfr=spider&amp;amp;for=pc&quot;&gt;2021 IDEA大会开启AI思想盛宴 沈向洋理事长发布六大前沿产品&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[IDEA新闻] &lt;a href=&quot;https://idea.edu.cn/news/20211213143128.html&quot;&gt;2021 IDEA大会发布产品FinRL-Meta——基于数据驱动的强化学习金融风险模拟系统&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[知乎] &lt;a href=&quot;https://zhuanlan.zhihu.com/p/437804814&quot;&gt;FinRL-Meta基于数据驱动的强化学习金融元宇宙&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[量化投资与机器学习] &lt;a href=&quot;https://www.mdeditor.tw/pl/p5Gg&quot;&gt;基于深度强化学习的股票交易策略框架（代码+文档)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[运筹OR帷幄] &lt;a href=&quot;https://zhuanlan.zhihu.com/p/353557417&quot;&gt;领读计划NO.10 | 基于深度增强学习的量化交易机器人：从AlphaGo到FinRL的演变过程&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[深度强化实验室] &lt;a href=&quot;https://blog.csdn.net/deeprl/article/details/114828024&quot;&gt;【重磅推荐】哥大开源“FinRL”: 一个用于量化金融自动交易的深度强化学习库&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[商业新知] &lt;a href=&quot;https://www.shangyexinzhi.com/article/4170766.html&quot;&gt;金融科技讲座回顾|AI4Finance: 从AlphaGo到FinRL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[Kaggle] &lt;a href=&quot;https://www.kaggle.com/c/jane-street-market-prediction/discussion/199313&quot;&gt;Jane Street Market Prediction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[矩池云Matpool] &lt;a href=&quot;http://www.python88.com/topic/111918&quot;&gt;在矩池云上如何运行FinRL股票交易策略框架&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[财智无界] &lt;a href=&quot;https://www.sohu.com/a/486837028_120929319&quot;&gt;金融学会常务理事陈学彬: 深度强化学习在金融资产管理中的应用&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[Neurohive] &lt;a href=&quot;https://neurohive.io/ru/gotovye-prilozhenija/finrl-glubokoe-obuchenie-s-podkrepleniem-dlya-trejdinga/&quot;&gt;FinRL: глубокое обучение с подкреплением для трейдинга&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[ICHI.PRO] &lt;a href=&quot;https://ichi.pro/ko/yangjeog-geum-yung-eul-wihan-finrl-dan-il-jusig-geolaeleul-wihan-tyutolieol-61395882412716&quot;&gt;양적 금융을위한 FinRL: 단일 주식 거래를위한 튜토리얼&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[知乎] &lt;a href=&quot;https://zhuanlan.zhihu.com/p/563238735&quot;&gt;基于深度强化学习的金融交易策略（FinRL+Stable baselines3，以道琼斯30股票为例）&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[知乎] &lt;a href=&quot;https://zhuanlan.zhihu.com/p/616799055&quot;&gt;动态数据驱动的金融强化学习&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[知乎] &lt;a href=&quot;https://zhuanlan.zhihu.com/p/498115373&quot;&gt;FinRL的W&amp;amp;B化+超参数搜索和模型优化(基于Stable Baselines 3）&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[知乎] &lt;a href=&quot;https://zhuanlan.zhihu.com/p/544621882&quot;&gt;FinRL-Meta: 未来金融强化学习的元宇宙&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citing FinRL&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@article{dynamic_datasets,
    author = {Liu, Xiao-Yang and Xia, Ziyi and Yang, Hongyang and Gao, Jiechao and Zha, Daochen and Zhu, Ming and Wang, Christina Dan and Wang, Zhaoran and Guo, Jian},
    title = {Dynamic Datasets and Market Environments for Financial Reinforcement Learning},
    journal = {Machine Learning - Springer Nature},
    year = {2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;@article{liu2022finrl_meta,
  title={FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement Learning},
  author={Liu, Xiao-Yang and Xia, Ziyi and Rui, Jingyang and Gao, Jiechao and Yang, Hongyang and Zhu, Ming and Wang, Christina Dan and Wang, Zhaoran and Guo, Jian},
  journal={NeurIPS},
  year={2022}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;@article{liu2021finrl,
    author  = {Liu, Xiao-Yang and Yang, Hongyang and Gao, Jiechao and Wang, Christina Dan},
    title   = {{FinRL}: Deep reinforcement learning framework to automate trading in quantitative finance},
    journal = {ACM International Conference on AI in Finance (ICAIF)},
    year    = {2021}
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;@article{finrl2020,
    author  = {Liu, Xiao-Yang and Yang, Hongyang and Chen, Qian and Zhang, Runjia and Yang, Liuqing and Xiao, Bowen and Wang, Christina Dan},
    title   = {{FinRL}: A deep reinforcement learning library for automated stock trading in quantitative finance},
    journal = {Deep RL Workshop, NeurIPS 2020},
    year    = {2020}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;@article{liu2018practical,
  title={Practical deep reinforcement learning approach for stock trading},
  author={Liu, Xiao-Yang and Xiong, Zhuoran and Zhong, Shan and Yang, Hongyang and Walid, Anwar},
  journal={NeurIPS Workshop on Deep Reinforcement Learning},
  year={2018}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We published &lt;a href=&quot;http://tensorlet.org/projects/ai-in-finance/&quot;&gt;FinRL papers&lt;/a&gt; that are listed at &lt;a href=&quot;https://scholar.google.com/citations?view_op=list_works&amp;amp;hl=en&amp;amp;hl=en&amp;amp;user=XsdPXocAAAAJ&quot;&gt;Google Scholar&lt;/a&gt;. Previous papers are given in the &lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinRL/raw/master/tutorials/FinRL_papers.md&quot;&gt;list&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Join and Contribute&lt;/h2&gt; 
&lt;p&gt;Welcome to &lt;strong&gt;AI4Finance&lt;/strong&gt; community!&lt;/p&gt; 
&lt;p&gt;Please check &lt;a href=&quot;https://github.com/AI4Finance-Foundation/FinRL-Tutorials/raw/master/Contributing.md&quot;&gt;Contributing Guidances&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;p&gt;Thank you!&lt;/p&gt; 
&lt;a href=&quot;https://github.com/AI4Finance-LLC/FinRL-Library/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=AI4Finance-LLC/FinRL-Library&quot;&gt; &lt;/a&gt; 
&lt;h2&gt;LICENSE&lt;/h2&gt; 
&lt;p&gt;MIT License&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Disclaimer: We are sharing codes for academic purpose under the MIT education license. Nothing herein is financial advice, and NOT a recommendation to trade real money. Please use common sense and always first consult a professional before trading or investing.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/open_deep_research</title>
      <link>https://github.com/langchain-ai/open_deep_research</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open Deep Research&lt;/h1&gt; 
&lt;p&gt;Open Deep Research is an open source assistant that automates research and produces customizable reports on any topic. It allows you to customize the research and writing process with specific models, prompts, report structure, and search tools.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/6595d5cd-c981-43ec-8e8b-209e4fefc596&quot; alt=&quot;report-generation&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;🚀 Quickstart&lt;/h2&gt; 
&lt;p&gt;Ensure you have API keys set for your desired search tools and models.&lt;/p&gt; 
&lt;p&gt;Available search tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tavily.com/&quot;&gt;Tavily API&lt;/a&gt; - General web search&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api&quot;&gt;Perplexity API&lt;/a&gt; - General web search&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://exa.ai/&quot;&gt;Exa API&lt;/a&gt; - Powerful neural search for web content&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://arxiv.org/&quot;&gt;ArXiv&lt;/a&gt; - Academic papers in physics, mathematics, computer science, and more&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/&quot;&gt;PubMed&lt;/a&gt; - Biomedical literature from MEDLINE, life science journals, and online books&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.linkup.so/&quot;&gt;Linkup API&lt;/a&gt; - General web search&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://duckduckgo.com/&quot;&gt;DuckDuckGo API&lt;/a&gt; - General web search&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://google.com/&quot;&gt;Google Search API/Scrapper&lt;/a&gt; - Create custom search engine &lt;a href=&quot;https://programmablesearchengine.google.com/controlpanel/all&quot;&gt;here&lt;/a&gt; and get API key &lt;a href=&quot;https://developers.google.com/custom-search/v1/introduction&quot;&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Open Deep Research uses a planner LLM for report planning and a writer LLM for report writing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can select any model that is integrated &lt;a href=&quot;https://python.langchain.com/docs/how_to/chat_models_universal_init/&quot;&gt;with the &lt;code&gt;init_chat_model()&lt;/code&gt; API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See full list of supported integrations &lt;a href=&quot;https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html&quot;&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Using the package&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install open-deep-research
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As mentioned above, ensure API keys for LLMs and search tools are set:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export TAVILY_API_KEY=&amp;lt;your_tavily_api_key&amp;gt;
export ANTHROPIC_API_KEY=&amp;lt;your_anthropic_api_key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/langchain-ai/open_deep_research/main/src/open_deep_research/graph.ipynb&quot;&gt;src/open_deep_research/graph.ipynb&lt;/a&gt; for example usage in a Jupyter notebook:&lt;/p&gt; 
&lt;p&gt;Compile the graph:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from langgraph.checkpoint.memory import MemorySaver
from open_deep_research.graph import builder
memory = MemorySaver()
graph = builder.compile(checkpointer=memory)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the graph with a desired topic and configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import uuid 
thread = {&quot;configurable&quot;: {&quot;thread_id&quot;: str(uuid.uuid4()),
                           &quot;search_api&quot;: &quot;tavily&quot;,
                           &quot;planner_provider&quot;: &quot;anthropic&quot;,
                           &quot;planner_model&quot;: &quot;claude-3-7-sonnet-latest&quot;,
                           &quot;writer_provider&quot;: &quot;anthropic&quot;,
                           &quot;writer_model&quot;: &quot;claude-3-5-sonnet-latest&quot;,
                           &quot;max_search_depth&quot;: 1,
                           }}

topic = &quot;Overview of the AI inference market with focus on Fireworks, Together.ai, Groq&quot;
async for event in graph.astream({&quot;topic&quot;:topic,}, thread, stream_mode=&quot;updates&quot;):
    print(event)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The graph will stop when the report plan is generated, and you can pass feedback to update the report plan:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from langgraph.types import Command
async for event in graph.astream(Command(resume=&quot;Include a revenue estimate (ARR) in the sections&quot;), thread, stream_mode=&quot;updates&quot;):
    print(event)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When you are satisfied with the report plan, you can pass &lt;code&gt;True&lt;/code&gt; to proceed to report generation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;async for event in graph.astream(Command(resume=True), thread, stream_mode=&quot;updates&quot;):
    print(event)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running LangGraph Studio UI locally&lt;/h3&gt; 
&lt;p&gt;Clone the repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Edit the &lt;code&gt;.env&lt;/code&gt; file with your API keys (e.g., the API keys for default selections are shown below):&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set whatever APIs needed for your model and search tools.&lt;/p&gt; 
&lt;p&gt;Here are examples for several of the model and tool integrations available:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export TAVILY_API_KEY=&amp;lt;your_tavily_api_key&amp;gt;
export ANTHROPIC_API_KEY=&amp;lt;your_anthropic_api_key&amp;gt;
export OPENAI_API_KEY=&amp;lt;your_openai_api_key&amp;gt;
export PERPLEXITY_API_KEY=&amp;lt;your_perplexity_api_key&amp;gt;
export EXA_API_KEY=&amp;lt;your_exa_api_key&amp;gt;
export PUBMED_API_KEY=&amp;lt;your_pubmed_api_key&amp;gt;
export PUBMED_EMAIL=&amp;lt;your_email@example.com&amp;gt;
export LINKUP_API_KEY=&amp;lt;your_linkup_api_key&amp;gt;
export GOOGLE_API_KEY=&amp;lt;your_google_api_key&amp;gt;
export GOOGLE_CX=&amp;lt;your_google_custom_search_engine_id&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Launch the assistant with the LangGraph server locally, which will open in your browser:&lt;/p&gt; 
&lt;h4&gt;Mac&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Install uv package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies and start the LangGraph server
uvx --refresh --from &quot;langgraph-cli[inmem]&quot; --with-editable . --python 3.11 langgraph dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Windows / Linux&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-powershell&quot;&gt;# Install dependencies 
pip install -e .
pip install -U &quot;langgraph-cli[inmem]&quot; 

# Start the LangGraph server
langgraph dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use this to open the Studio UI:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;- 🚀 API: http://127.0.0.1:2024
- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- 📚 API Docs: http://127.0.0.1:2024/docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(1) Provide a &lt;code&gt;Topic&lt;/code&gt; and hit &lt;code&gt;Submit&lt;/code&gt;:&lt;/p&gt; 
&lt;img width=&quot;1326&quot; alt=&quot;input&quot; src=&quot;https://github.com/user-attachments/assets/de264b1b-8ea5-4090-8e72-e1ef1230262f&quot;&gt; 
&lt;p&gt;(2) This will generate a report plan and present it to the user for review.&lt;/p&gt; 
&lt;p&gt;(3) We can pass a string (&lt;code&gt;&quot;...&quot;&lt;/code&gt;) with feedback to regenerate the plan based on the feedback.&lt;/p&gt; 
&lt;img width=&quot;1326&quot; alt=&quot;feedback&quot; src=&quot;https://github.com/user-attachments/assets/c308e888-4642-4c74-bc78-76576a2da919&quot;&gt; 
&lt;p&gt;(4) Or, we can just pass &lt;code&gt;true&lt;/code&gt; to accept the plan.&lt;/p&gt; 
&lt;img width=&quot;1480&quot; alt=&quot;accept&quot; src=&quot;https://github.com/user-attachments/assets/ddeeb33b-fdce-494f-af8b-bd2acc1cef06&quot;&gt; 
&lt;p&gt;(5) Once accepted, the report sections will be generated.&lt;/p&gt; 
&lt;img width=&quot;1326&quot; alt=&quot;report_gen&quot; src=&quot;https://github.com/user-attachments/assets/74ff01cc-e7ed-47b8-bd0c-4ef615253c46&quot;&gt; 
&lt;p&gt;The report is produced as markdown.&lt;/p&gt; 
&lt;img width=&quot;1326&quot; alt=&quot;report&quot; src=&quot;https://github.com/user-attachments/assets/92d9f7b7-3aea-4025-be99-7fb0d4b47289&quot;&gt; 
&lt;h2&gt;📖 Customizing the report&lt;/h2&gt; 
&lt;p&gt;You can customize the research assistant&#39;s behavior through several parameters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;report_structure&lt;/code&gt;: Define a custom structure for your report (defaults to a standard research report format)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;number_of_queries&lt;/code&gt;: Number of search queries to generate per section (default: 2)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;max_search_depth&lt;/code&gt;: Maximum number of reflection and search iterations (default: 2)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;planner_provider&lt;/code&gt;: Model provider for planning phase (default: &quot;anthropic&quot;, but can be any provider from supported integrations with &lt;code&gt;init_chat_model&lt;/code&gt; as listed &lt;a href=&quot;https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html&quot;&gt;here&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;planner_model&lt;/code&gt;: Specific model for planning (default: &quot;claude-3-7-sonnet-latest&quot;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;writer_provider&lt;/code&gt;: Model provider for writing phase (default: &quot;anthropic&quot;, but can be any provider from supported integrations with &lt;code&gt;init_chat_model&lt;/code&gt; as listed &lt;a href=&quot;https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html&quot;&gt;here&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;writer_model&lt;/code&gt;: Model for writing the report (default: &quot;claude-3-5-sonnet-latest&quot;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;search_api&lt;/code&gt;: API to use for web searches (default: &quot;tavily&quot;, options include &quot;perplexity&quot;, &quot;exa&quot;, &quot;arxiv&quot;, &quot;pubmed&quot;, &quot;linkup&quot;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;These configurations allow you to fine-tune the research process based on your needs, from adjusting the depth of research to selecting specific AI models for different phases of report generation.&lt;/p&gt; 
&lt;h3&gt;Search API Configuration&lt;/h3&gt; 
&lt;p&gt;Not all search APIs support additional configuration parameters. Here are the ones that do:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Exa&lt;/strong&gt;: &lt;code&gt;max_characters&lt;/code&gt;, &lt;code&gt;num_results&lt;/code&gt;, &lt;code&gt;include_domains&lt;/code&gt;, &lt;code&gt;exclude_domains&lt;/code&gt;, &lt;code&gt;subpages&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Note: &lt;code&gt;include_domains&lt;/code&gt; and &lt;code&gt;exclude_domains&lt;/code&gt; cannot be used together&lt;/li&gt; 
   &lt;li&gt;Particularly useful when you need to narrow your research to specific trusted sources, ensure information accuracy, or when your research requires using specified domains (e.g., academic journals, government sites)&lt;/li&gt; 
   &lt;li&gt;Provides AI-generated summaries tailored to your specific query, making it easier to extract relevant information from search results&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ArXiv&lt;/strong&gt;: &lt;code&gt;load_max_docs&lt;/code&gt;, &lt;code&gt;get_full_documents&lt;/code&gt;, &lt;code&gt;load_all_available_meta&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PubMed&lt;/strong&gt;: &lt;code&gt;top_k_results&lt;/code&gt;, &lt;code&gt;email&lt;/code&gt;, &lt;code&gt;api_key&lt;/code&gt;, &lt;code&gt;doc_content_chars_max&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linkup&lt;/strong&gt;: &lt;code&gt;depth&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example with Exa configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;thread = {&quot;configurable&quot;: {&quot;thread_id&quot;: str(uuid.uuid4()),
                           &quot;search_api&quot;: &quot;exa&quot;,
                           &quot;search_api_config&quot;: {
                               &quot;num_results&quot;: 5,
                               &quot;include_domains&quot;: [&quot;nature.com&quot;, &quot;sciencedirect.com&quot;]
                           },
                           # Other configuration...
                           }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Model Considerations&lt;/h3&gt; 
&lt;p&gt;(1) You can pass any planner and writer models that are integrated &lt;a href=&quot;https://python.langchain.com/docs/how_to/chat_models_universal_init/&quot;&gt;with the &lt;code&gt;init_chat_model()&lt;/code&gt; API&lt;/a&gt;. See full list of supported integrations &lt;a href=&quot;https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;(2) &lt;strong&gt;The planner and writer models need to support structured outputs&lt;/strong&gt;: Check whether structured outputs are supported by the model you are using &lt;a href=&quot;https://python.langchain.com/docs/integrations/chat/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;(3) With Groq, there are token per minute (TPM) limits if you are on the &lt;code&gt;on_demand&lt;/code&gt; service tier:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;on_demand&lt;/code&gt; service tier has a limit of &lt;code&gt;6000 TPM&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;You will want a &lt;a href=&quot;https://github.com/cline/cline/issues/47#issuecomment-2640992272&quot;&gt;paid plan&lt;/a&gt; for section writing with Groq models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;(4) &lt;code&gt;deepseek-R1&lt;/code&gt; &lt;a href=&quot;https://api-docs.deepseek.com/guides/reasoning_model&quot;&gt;is not strong at function calling&lt;/a&gt;, which the assistant uses to generate structured outputs for report sections and report section grading. See example traces &lt;a href=&quot;https://smith.langchain.com/public/07d53997-4a6d-4ea8-9a1f-064a85cd6072/r&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Consider providers that are strong at function calling such as OpenAI, Anthropic, and certain OSS models like Groq&#39;s &lt;code&gt;llama-3.3-70b-versatile&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;If you see the following error, it is likely due to the model not being able to produce structured outputs (see &lt;a href=&quot;https://smith.langchain.com/public/8a6da065-3b8b-4a92-8df7-5468da336cbe/r&quot;&gt;trace&lt;/a&gt;):&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;groq.APIError: Failed to call a function. Please adjust your prompt. See &#39;failed_generation&#39; for more details.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How it works&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Plan and Execute&lt;/code&gt; - Open Deep Research follows a &lt;a href=&quot;https://github.com/assafelovic/gpt-researcher&quot;&gt;plan-and-execute workflow&lt;/a&gt; that separates planning from research, allowing for human-in-the-loop approval of a report plan before the more time-consuming research phase. It uses, by default, a &lt;a href=&quot;https://www.youtube.com/watch?v=f0RbwrBcFmc&quot;&gt;reasoning model&lt;/a&gt; to plan the report sections. During this phase, it uses web search to gather general information about the report topic to help in planning the report sections. But, it also accepts a report structure from the user to help guide the report sections as well as human feedback on the report plan.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Research and Write&lt;/code&gt; - Each section of the report is written in parallel. The research assistant uses web search via &lt;a href=&quot;https://tavily.com/&quot;&gt;Tavily API&lt;/a&gt;, &lt;a href=&quot;https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api&quot;&gt;Perplexity&lt;/a&gt;, &lt;a href=&quot;https://exa.ai/&quot;&gt;Exa&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/&quot;&gt;ArXiv&lt;/a&gt;, &lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/&quot;&gt;PubMed&lt;/a&gt; or &lt;a href=&quot;https://www.linkup.so/&quot;&gt;Linkup&lt;/a&gt; to gather information about each section topic. It will reflect on each report section and suggest follow-up questions for web search. This &quot;depth&quot; of research will proceed for any many iterations as the user wants. Any final sections, such as introductions and conclusions, are written after the main body of the report is written, which helps ensure that the report is cohesive and coherent. The planner determines main body versus final sections during the planning phase.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Managing different types&lt;/code&gt; - Open Deep Research is built on LangGraph, which has native support for configuration management &lt;a href=&quot;https://langchain-ai.github.io/langgraph/concepts/assistants/&quot;&gt;using assistants&lt;/a&gt;. The report &lt;code&gt;structure&lt;/code&gt; is a field in the graph configuration, which allows users to create different assistants for different types of reports.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;UX&lt;/h2&gt; 
&lt;h3&gt;Local deployment&lt;/h3&gt; 
&lt;p&gt;Follow the &lt;a href=&quot;https://raw.githubusercontent.com/langchain-ai/open_deep_research/main/#-quickstart&quot;&gt;quickstart&lt;/a&gt; to start LangGraph server locally.&lt;/p&gt; 
&lt;h3&gt;Hosted deployment&lt;/h3&gt; 
&lt;p&gt;You can easily deploy to &lt;a href=&quot;https://langchain-ai.github.io/langgraph/concepts/#deployment-options&quot;&gt;LangGraph Platform&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
